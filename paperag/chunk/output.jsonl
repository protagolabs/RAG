{"doc1": "The turbulence of recent months, meanwhile, has seen the rise of an exaggerated pessimism following the travails of self-driving taxi company Cruise, stripped of its license to operate in California, its leadership team and arguably its reputation following an ill-advised response to an accident in San Francisco.\n\nThe driverless car experiment has \u201cfailed miserably\u201d lamented one skeptic, while even Cruise\u2019s new boss Mo Elshenawy admitted the General Motors subsidiary was at an \u201call-time low\u201d as it faces massively reduced investment.\n\nViewed with a sense of perspective, however, the reality of the AV landscape lies somewhere in between these two extremes as we enter 2024. "}
{"doc2": "Level 3, as defined by the Society of Automotive Engineers, offers highly automated \u201chands-off, eyes off\u2019 driving, and other automakers are set to follow suit. BMW has already announced that Level 3 will be offered on the 7 Series in Germany, and the new Polestar 4 coupe-SUV has been developed to deliver this functionality, too.\n\nThe Rise of Chinese Automakers\nAnother key trend to keep an eye on will be the continued rise of Chinese automakers, both in China and on a global basis.\n\nXPeng\u2019s highly advanced Navigation Guided Pilot driver assistance tech \u2013 which works on both highways and cities \u2013 will be available China-wide by the end of 2024, and the company has made no secret of its plans to launch in more markets across the world."}
{"doc3": "Expect to hear more from ZEEKR, too, which has developed the SEA-M platform that facilitates Level 4 functionality \u2013 full self-driving capability in specific locations (although we\u2019re unlikely to see regulatory approval for this on passenger cars for quite some time).\n\nSEA-M\u2019s most interesting application may well be the purpose-built self-driving taxi that ZEEKR is co-developing with Waymo, which is scheduled to undergo a major testing program in 2024, prior to commercial launch. Its arrival is now even more eagerly anticipated, particularly given that production of Cruise\u2019s Origin self-driving cab has been suspended indefinitely.\n\nRelated:Automated Driving Spreads to More Chinese Cities"}
{"doc4": "Amid a self-driving taxi landscape where Cruise maneuvered from ambitious expansion plans to a self-inflicted implosion in a matter of months in 2023, predicting what might happen in 2024 with any degree of confidence is difficult. \n\nBut probable scenarios include a continued cautious rollout from Waymo in more metropolitan areas across the U.S. and a muted, low-key return for a significantly trimmed down Cruise in a location sympathetic towards AV testing \u2013 possibly Texas or Arizona \u2013 rather than its previous San Francisco hub.\n\nFurther afield, China\u2019s recent issuing of nationwide guidelines for robotaxi regulation is only likely to encourage big players such as Baidu and WeRide to extend their operations, and the latter\u2019s recent award of a testing license in Singapore \u2013 the fourth country it is now active in \u2013 underlines a desire to expand globally that will only gain momentum in 2024."}
{"doc5": "Autonomous Trucking\nIn the autonomous truck world, meanwhile, the key development may well be a significant ramp-up in driverless testing of heavy-duty long-haul vehicles. Already underway in China and Japan, America has lagged behind somewhat (despite a brief foray in 2021 by the now-departed TuSimple). Kodiak, for one, has plans in place to start driverless trials in 2024. Already under way in China and Japan, America has lagged behind somewhat (despite a brief foray in 2021 by the now-departed TuSimple). Kodiak, for one, has plans in place to start driverless trials in 2024.\n\nRelated:California Senate Passes Bill to Ban Driverless Trucks\n\nThere will also be a keen interest in whether these initial autonomous trucking operations and pilots move out of their heartland in the southern United States, now that Governor Gavin Newsom has vetoed California\u2019s proposed autonomous trucking ban. Industry insiders suggest there may be good news with regard to testing in the Golden State in 2024."}
{"doc6": "Section 2(2) \u2013 Statement of Safety Principles \u2013 the principles must now also be \u201cframed with a view to securing that authorised automated vehicles will achieve a level of safety equivalent to, or higher than, that of careful and competent human drivers\u201d.\nSection 2(4) \u2013 Statement of Safety Principles \u2013 requiring the Secretary of State, in preparing the statement, to consult organisations that appear to them to represent the interests of AV manufacturers, road users, and road safety.\nOther changes have been made since its introduction to the House of Lords in November 2023, but these mostly relate to less substantive points such as where the money from fines goes to, and dealing with how secondary legislation is passed (via affirmative and negative procedure).\n\nImportance of the Act\nThe Act has seven parts, each briefly summarised below:\n\nRegulatory Scheme: Establishes principles and a framework for licensing self-driving vehicles; introduces the concept of an authorised self-driving entity (ASDE), who is the person that will be legally responsible; provides for the implementation of \u2018no-user-in-charge\u2019 (NUiC) vehicles; and finally, enforcement and sanctions. You can read more about this in our previous article here.\nCriminal Liability: Defines \u2018user-in-charge\u2019 (UiC), and then outlines their liability and circumstances in which they will benefit from immunity; also adds AV-specific offences.\nPolicing and Investigation: Grants powers to stop and seize AVs; also introduces \u2018automated vehicle incident inspectors\u2019, whose chief function will be to identify factually the cause of incidents.\nMarketing Restrictions: Criminalises misuse of terminology that implies self-driving capabilities (both via a prescribed list and \u2018terms likely to confuse\u2019 road-users). You can read more about this in our previous article here.\nAutomated Passenger Services Permits: Empowers authorities to grant permits; also exempts AVs from otherwise applicable taxi legislation. You can read more about this in our previous article here.\nAdapting Existing Regimes: Enables the Secretary of State to amend \u2018type approval legislation\u2019; also extends vehicle examiners\u2019 powers to AVs, including allowing them to prohibit one from driving.\nGeneral Provisions: Defines terms, and confirms scope across England, Wales, and Scotland.\nFor a more detailed overview of the seven parts to the Act, see our initial commentary here."}
{"doc7": "Timeline for implementation\nWhilst regulation of the technology has been nascent for many years, with the Act and incoming secondary legislation to give effect to the Act\u2019s framework, regulation is now on the move in a positive direction which will be welcomed by those in the industry.\n\nThat being said, some of this legislation will take time to take effect. On the Act\u2019s return to the House of Lords on 8 May, Lord Davies noted that the secondary legislation would be launched in \u2018the coming months\u2019, building the new regulatory framework \u2018piece by piece\u2019. By way of time estimates, Lord Davies provided the following (in order of priority):\n\nRegulations on misleading marketing \u2013 consultation to commence later this year.\nDigitising traffic regulation orders \u2013 consultation to commence in the Autumn, with the aim of the legislation coming into force in Spring 2025.\nInitial work on the Statement of Safety Principles to begin this year \u2013 plan is to consult on this in 2025.\nDetailed regulations establishing authorisation, operator licensing and in-use regulation functions will follow later.\nComment\nIt will be of some assurance in an election year that the Act was passed with broad cross-party consensus and that there was alignment on the need to swiftly follow with work on secondary legislation, albeit there was a range of views expressed on approach (e.g. Bill Esterson MP (Shadow Roads Minister), in the Act\u2019s passage through the Commons, argued in favour of an advisory council to implement the secondary legislation)."}
{"doc8": "How Dubai is tackling the challenges of autonomous vehicle development\nAmid regulatory concerns and technological difficulties, the pace of autonomous vehicle (AV) development has slowed in recent years. Entrepreneurs need access to the right facilities and support to facilitate the future of driverless transport.\n\nForms of vehicle autonomy have existed since the mid-1990s with the introduction of adaptive cruise control (ACC), which could control the acceleration and deceleration of a car in response to the movement of a vehicle in front. In the 21st century, technology has developed well beyond this \u2018Level 1\u2019 autonomy, with 2023 seeing the first Level 3 vehicles from Mercedes-Benz hit the roads.\n\nEquipped with optical sensors and radar, this new generation of AVs can operate independently for a period, allowing the driver to take their eyes off the road until instructed to regain control. Looking to the future, Level 4 AVs, which can drive completely independently within a conditioned environment, and Level 5 AVs, able to operate anywhere without supervision, are no longer remote possibilities."}
{"doc9": "However, the timeline for the general adoption of these vehicles has expanded in the face of technological and regulatory issues. GlobalData research predicts that, due to the current experimental nature of most prototypes, global sales of Level 4 and Level 5 AVs in 2030 are now expected to number only 250,000 units. However, within another decade this is predicted to rise to 4 million. There also remain concerns over the dangers posed by driverless vehicles after several high-profile accidents. AV projects need to be tested in the right environments and scaled with care if they are to be implemented more widely in the next few decades.\n\nEnsuring the safety and compliance of AV technology\n\nThe greatest challenge currently facing AV development is a hostile regulatory environment and a lack of public trust, following fatal accidents caused partly by small failings in the autonomous systems involved."}
{"doc10": "According to Sammy Chan, manager, Automotive Sales Forecast at GlobalData: \u201cEven after accumulating millions of miles of AV driving experience technological progress advances relatively slowly, while setbacks are often severe and can derail a company\u2019s quest towards fully autonomous driving.\u201d\n\nRegulatory frameworks need to be in place to facilitate AV testing in a greater variety of driving conditions to prevent further accidents. The Level 3 Mercedes-Benz S-Class, launched last year, is only allowed to use its features on stretches of specific roads, for example a portion of motorway in Germany. Regulators across the globe, from the USA to the EU to Singapore, are currently adopting a cautious approach, although permission has been granted for vehicles without drivers in specific locations for testing purposes.\n\nDubai\u2019s plans to scale AV capabilities\nHowever, road systems and weather conditions can vary wildly from country to country, let alone from street to street. Deploying Level 4 and above AVs will be impossible without appropriate testing in diverse environments and the right regulatory frameworks. Dubai has become the first city in the Middle East to trial robotaxis, with the emirate deploying five fully autonomous electric taxis on a stretch of roads in the Jumeriah district in September 2023. The Dubai Roads and Transport Authority (RTA) plans to roll out 4,000 self-driving cars across the city by 2030 and anticipates that a quarter of all journeys within Dubai will be autonomous by that same year."}
{"doc11": "But testing AVs in safe, urban districts is one thing; planning for the implementation of AVs across the world in a variety of environments is another. \u201cMillions of autonomous driving miles have been amassed by the leaders in this space, but most of this has been in relatively safe operation environments, so it is not possible to extrapolate even successful tests to other more challenging locations,\u201d Chan points out.\n\nDubai is unique compared to other cities in the US and China that have tested AVs because of its desert climate. Understanding how AVs cope under the heat of an Arabian summer adds a further interesting dimension to the trial, alongside training AVs to operate in countries with different road systems and cultures. To improve the safety of all road users, it is key that the cars learn to recognise pedestrians that might be dressed differently from other countries, for example women in hijab.\n\nMeanwhile, Dubai Silicon Oasis (DSO), an economic zone affiliated with Dubai Integrated Economic Zones (DIEZ), is helping advance AV technology even further. September 2023 saw DSO host the Dubai World Congress for Self-Driving Transport, focused on developing autonomous buses. $2 million in prize money was shared between the promising startups King Long and BrightDrive, and a further $100,000 to students from Heriot-Watt University for their innovative ideas."}
{"doc12": "27 countries submitted proposals for self-driving buses to the competition, and hopefuls were granted access to their own unique testing space in DSO to improve their projects. Complete with state-of-the-art laboratories, a network of maturing startups, and access to a talented student pool from the Rochester Institute of Technology in Dubai, DSO is emerging as an ideal place to test and scale new AV technology.\n\nPreparing for the autonomous vehicles of the future\nAVs are currently powered by computer vision, sensors, and 3D imaging, but there is the potential for their capabilities to be enhanced even further through the incorporation of light detection and ranging (LiDAR) technology. LiDAR can offer higher-resolution images and process data more quickly across a wider range of environmental conditions. However, it is also extremely expensive and bulky, making its incorporation into AVs more difficult.\n\nFor the next generation of Level 4 AV capabilities to be unlocked, it is essential that the right ecosystems are in place to support innovation in the industry. Businesses based in DSO not only benefit from the DIEZ Venture Capital fund, Oraseya Capital, to finance their ideas, but a collaborative network of entrepreneurs and world-leading facilities for living and working too. With ample space for testing new projects in a safe environment, and the support of a forward-thinking government seeking to implement autonomous technology in a considerate way, DSO is tackling key challenges to enable a future driven by AVs."}
{"doc13": "Recent Breakthroughs\nIn the last couple of years, the different levels of automation have become apparent. Level 4 is the level at which a human is no longer needed, but that\u2019s clearly difficult to achieve. \n\nLevel 2, which uses Advanced Driving Assistance Systems, and Level 3, which has conditional automation, have increased in popularity. Mercedes-Benz introduced Level 3 conditionally in the US in January 2023, with Nevada the first state to authorise. \n\nWe\u2019ve also seen a number of driverless taxi fleets increase in number, but this has been issued a setback after a woman was trapped under a self-driving taxi in San Francisco. "}
{"doc14": "The impact of autonomous vehicles on urban planning\nSelf-driving vehicles (Connected Autonomous Vehicles or CAVs), along with electrification and sharing, will revolutionise how people travel by road in the future. In this paper, Associate Director Luke Kendall examines how the design of urban areas will need to respond to the introduction of CAVs, and with some urgency.\nThe current situation\n\nAutomation already exists in a limited form in public and private transport, from driver-assisted cars to automated systems such as the Dockland Light Rail system in London. CAVs, however, are a step change.\n\nIn recent years in the UK, we have started to see a shift away from private car ownership, although there are regional differences. This has in part seen an increased move to public transport but more significantly micro-mobility such as cycling and scootering, a trend that is set to continue as people prioritise their health and the environment. Click here to read more about the cycling boom."}
{"doc15": "We also know that electric vehicle (eVs) adoption in the UK is gradually accelerating. 66% more eVs were registered in 2020 than in 2019, and in September 2021 eVs made up 23.1% of new car registrations[i]. What is detracting from wider adoption is that cost in the UK of electric vehicles is around 1.3 x that of a conventional car while in other some European countries it is on a par. In the UK there are fewer charging points, and of these only 3% are ultra-fast change points, compared with 12% in Germany and 25% in China[ii]. You can find out more about street charging by reading our related article here.\n\nWhat are the benefits of Autonomous Vehicles?\n\nAn AV trip can be shared - Driverless cars could collect people from around the same locality or be shared between employees.\nReduced cost - The removal of the cost of a driver from driverless taxi/Uber-type services.\nReduced number of vehicles - Several studies suggest that the introduction of CAVs could lead to as much as a 90% reduction in vehicle need. There are likely to be fewer, but harder working, vehicles on the road, leading to decreased congestion and increased road space.\nIncreased access for individuals with disabilities, older people and children - A larger part of the population will be able to take part in daily mobility.\nPeople will be willing to take longer trips - People will be less reliant on living close to their places of work or education. They can use their journey time more effectively for work, reading, or even just family time.\nIncreased safety - CAVs will, in theory, be better driven leading to reduced road incidents. \u2018Mobility corridors\u2019 can be created to be shared with pedestrians and cyclists. A mobility corridor is where different modes of transport are brought closer together to share a common route without the need for separation in levels and design. Read our paper about rebalancing the streets for more on this, including an emerging Dutch model."}
{"doc16": "With AVs will come the desire to be dropped off at the door rather than finding a parking space and walking to the destination. Ad hoc drop-offs (like how a taxi operates now), can add to congestion if sensible locations are not provided. So, while some space may be reclaimed, some may still be required. We may see subterranean car parks retained as pickup and drop-off locations as well as being repurposed to accommodate the increase in other modes of micro-mobility.\n\nCAVs would need fewer parking facilities as they would not need to sit idle. They could carry out trips for others or tasks such as click and collect pickups.\n\nCurrent studies[iv] suggest that we could see as much as a 70% reduction in parking demand in towns and cities. This will require a significant rethinking of our development requirements and regulations and will shift land value."}
{"doc17": "What about commercial vehicles?\n\nMost studies focus on the impact on private cars and public transport. But there will also be consequences for commercial vehicles. If we can assume for a moment that delivery vehicles will not require an operative (a person) for loading and unloading, then cost will be reduced. Even if we assume someone is required for loading, the removal of the driver potentially increases safety. Deliveries could be better scheduled outside busy hours at more unsociable times and completed with more accuracy.\n\nThe logistics sector is already starting to introduce AVs for mail, parcel and even food deliveries. It is hoped the eVTOLs (electric devices with Virtual Take-off and Landing) for people and goods will further ease ground-level congestion, although ground-level deliveries are with us for the foreseeable future."}
{"doc18": "Platooning, or driving close together in a group, is something that has so far generally been considered for truck movements outside urban areas. It is possible that the principle could be applied to some areas of our urban network as individual vehicles start to aggregate together.\n\nHow Chapman Taylor is responding to the challenge\n\nAVs will be adopted, and CAVs, or at least voiceless with this ability, will be adopted in parallel. The recent acceleration of change suggests adoption is likely to be quicker than anticipated - more like a 10-year window. As designers, we are therefore going to be increasingly asked to consider the accommodation of CAVs."}
{"doc19": "In the short to medium term, we are considering the challenge of how to repurpose parking structures, particularly when they are integral to a property. We have already been considering this due to the reduction in private cars accessing town centres. We are exploring repurposing, rather than redeveloping, as this is a more sustainable way of retaining a high embodied carbon structure. Uses we have considered to date include workplace, residential, retail, play and recreational spaces, leisure and hydro or aeroponic farming.\n\nThe need for less parking space and the potential for more space-sharing, such as in \u2018mobility corridors\u2019, may reinvigorate the design of our public realm as we move away from the dominance of the private internal combustion car.\n\nAdoption of CAVs is likely to be contained or frustrated by the ability and flexibility of our streets to accommodate them during a period of transition. At Chapman Taylor we are planning for this now."}
{"doc20": "Autonomous Driving: The Steps to Self-Driving Vehicles\n\nAutonomous driving is no longer a distant vision of the future. But how close are we to this long-anticipated dream? And what exactly does the term mean? Experts divide the automation level of vehicles and their driving functions into six levels.\n\nThe vehicle moves as if guided by ghost hands and safely chauffeurs its passengers through confusing city traffic, on the country road, and at high speeds on the highway. Meanwhile, the occupants are working on the laptop, reading or closing their eyes. There is no human driver, nor a steering wheel or a pedal. In recent years, we have come close towards this vision of self-driving vehicles. In the meantime, vehicles are on the road, in some cases without human drivers as a back-up, in test situations, on defined routes or defined areas.\nFully autonomous vehicles operating in mixed traffic will become established in the foreseeable future. But according to experts it will take a few more years. Until then, vehicles with different levels of automation will be on the road. The six automation levels of vehicles and their driving functions are described in the SAE International J3016-Standard.\nLEVEL 0: NO DRIVING AUTOMATION\nIn principle, the automotive pioneers were already driving in this manner. Simplified: The driver steers, brakes and accelerates without the support of assistance systems. In fact, there are a few electronic helpers that, according to the SAE definition, can occur under Level 0, such as active safety systems like Electronic Stability Control (ESC) or Emergency Brake Assist (AEB), since they only support in certain situations. The \"non-automated\" vehicle is being phased out.\nDriver: Complete control."}
{"doc21": "LEVEL 1 - DRIVER ASSISTANCE\nThe driver is still fully responsible for the driving task and must always pay attention to traffic, encompass the steering wheel, and be ready for braking. However, advanced assistance systems are at driver\u00b4s disposal. When driving assisted, the assistance systems support either steering and braking or accelerating, either laterally or longitudinally, but not simultaneously. For example, Level 1 includes either a lane keeping assist (LKA) or an adaptive cruise control (ACC) with which the vehicle regulates the speed and its distance from the vehicle in front. The driver can override them at any time or even switch them off (if and on/off control is available). These advanced driver assistance systems (ADAS) are already available in almost all vehicle classes. ZF also offers a multitude of them.\nDriver: Is fully responsible for longitudinal and lateral guidance, is supported in specific cases.\n\nLEVEL 2 - PARTIAL DRIVING AUTOMATION\nThe most important difference to Level 1: The advanced driver assistance systems can now control the longitudinal and lateral dynamics at the same time. If, for example, lane keeping assist and ACC are combined in one system one speaks of level 2. ZF goes a little further and offers so-called Level 2 + systems for passenger cars. For Level 2+, various advanced driver assistance systems are intelligently interconnected and thus help to increase safety and comfort. However, the responsibility for everything the vehicle does remains solely with the driver. Drivers must monitor the system at all times, touch the steering wheel regularly, and be able to intervene immediately if necessary. Writing messages on the smartphone behind the steering wheel during driving remains taboo.\nDriver: Must constantly monitor the system.\n\nLEVEL 3 - CONDITIONAL DRIVING AUTOMATION\nIt's a big leap from level 2 to level 3. From this stage onwards, the vehicle temporarily takes over the driving task from the driver. The human driver does not have to monitor the system constantly, and may pursue other activities within certain limits. When the systems reach their limits, the driver must be able to intervene at any time - after a warning period. Germany has already created the legal requirements for highly automated systems in 2017. Meanwhile, Mercedes-Benz is the first manufacturer that got the approval for a level 3 system in passenger cars. Since 2022, the first vehicles with the system will roll over German highways, albeit initially only in the case of slower traffic or traffic jams. After all, the allowance is valid up to 60 kilometers per hour. In these situations, the driver may legally use the cell phone, watch movies, or participate in a video meeting. However, he must be able to intervene after a warning period. In the current case, this is 10 seconds. Sleeping behind the steering wheel, for example, stays taboo at level 3.\nDriver: May occasionally engage in non-driving activities."}
{"doc22": "LEVEL 4 - HIGH DRIVING AUTOMATION\nThe big difference to Level 3: The vehicle operates completely autonomously under certain conditions. The human being no longer has to be ready to intervene. He can work, watch movies and even sleep. And the vehicle may also drive alone, i.e. without occupants. It must be able to reach a safe state without the intervention of a human driver, i.e. to come to a standstill in a parking lot for example. However, the autonomy of the vehicle at Level 4 is still linked to certain conditions, such as a defined route, driving on the highway or in the parking garage. Numerous companies are already testing level 4 vehicles in road traffic. Since 1997, ZF shuttles have been operating fully automated in various projects worldwide on segregated lanes. Legally, Germany has created the framework for \"autonomous motor vehicles (up to level 4) in defined operating areas within public road traffic in regular operation\" as the first country worldwide.\nDriver: No longer has to be ready for intervention.\n\nLEVEL 5 - FULL DRIVING AUTOMATION\nFor Level 5, the autonomy of the vehicle is no longer subject to conditions. In contrast to Level 4, a Level 5 vehicle acts completely autonomously. The vehicle can drive anywhere in road traffic and under all conditions without human beings. Consequently, these vehicles do not require a steering wheel or a gas or brake pedal. A human driver no longer exists at this stage. They are turning into a passenger.\nDriver: Does not exist anymore. The human being becomes a passenger."}
{"doc23": "Riding Those Radio Waves: The Case for RADAR Sensors in Autonomous Technology\nLIDAR and RADAR operate off similar principles but RADAR technology uses radio waves to detect the presence and location of objects rather than light. The RADAR sensor emits a radio signal that bounces off objects in its path, and the sensor then receives the reflected signal. By analyzing this signal, the RADAR can determine the location, speed, and direction of detected objects and this information can in turn be used to predict their future movement and trajectory.\n\n \n\nRADAR can transmit and receive signals over longer distances than LIDAR, making it useful for detecting objects at greater ranges."}
{"doc24": " \n\nThere are several other advantages to using RADAR in autonomous vehicles. RADAR can operate in a wider range of weather conditions compared to LIDAR and cameras \u2013 an important feature given that vehicles have to operate in all types of unpredictable weather conditions. RADAR is also less expensive than LIDAR, making it a cost-effective option for many applications.\n\nOn the downside, RADAR sensors have lower resolution capabilities than LIDAR or cameras which can make it more difficult to identify small objects or distinguish between similar objects. Another limitation is that RADAR can be affected by interference from other RADAR systems, which can reduce its accuracy."}
{"doc25": "Overall, cameras are a critical component of autonomous and ADAS systems.\n\nThey are relatively inexpensive and have high-resolution capabilities, making them a popular choice for self-driving cars. However, cameras have limitations, particularly in low-light conditions, and they can struggle to accurately identify objects at long distances. \n\nWhat's Going to Work? Teamwork! Combining Sensors for Maximum Performance\nCameras, LIDAR, and RADAR each have their own strengths and weaknesses, and it is clear that no single sensor can be sufficient to provide all necessary data to an autonomous vehicle. Rather, by combining data from multiple sensors, the vehicle can build a comprehensive picture of its surroundings and navigate safely and efficiently. "}
{"doc26": "The daunting task of taking the driver out of the vehicle can lead to safer roads, increase profit margins for companies and create a better overall experience for riders. But the rollout has to be done cautiously and safely. Companies also need to demystify the experience by getting more people in the vehicles.\n\nDuring my trip in Phoenix, the steering wheel in the modified Chrysler Pacifica Hybrid minivan moved with every turn and lane change, as the vehicle used a suite of cameras, radar and sensors such as lidar to \u201csee\u201d its surroundings.\n\nThe vehicle also displayed what it was seeing \u2013 such as other cars, buildings and pedestrians \u2013 on screens in the back of the vehicle. The screens assist riders in knowing what the car is sensing, which could put them more at ease with what\u2019s happening."}
{"doc27": "I have been in a handful of highly automated and self-driving vehicles, but they\u2019ve all included backup safety drivers behind the wheel. That\u2019s not the case for Waymo\u2019s fleet of self-driving vehicles in the Phoenix suburbs of Chandler, Tempe, Mesa and Gilbert.\n\nWhile some Waymo vehicles have safety drivers during testing and inclement weather, the rest, such as the two I spent more than an hour riding in, did not have anyone other than myself in them.\n\nTrue potential\nFor me, the experience was liberating. It highlighted the true potential of autonomous vehicles, which some believe will be a multitrillion-dollar industry."}
{"doc28": "Shortly after hailing my first vehicle through the Waymo One app (like you would with Uber or Lyft), I was at ease with my ghost driver. In fact, I even preferred it after being on a plane for four hours and riding with two human drivers earlier in the day.\n\nBeing alone without a driver allowed me to have a little serenity. It enabled me to be productive without being interrupted or worrying about being an annoying or inconsiderate passenger. I FaceTimed, tweeted, made calls and changed destinations several times without feeling like a nuisance. I even wrote most of this article while in the second van.\n\nBeing able to do such things is what companies have been promising self-driving vehicles would deliver for years. That\u2019s in addition to increasing safety and saving massive amounts of capital by taking the driver \u2013 the most expensive cost for such companies \u2013 out of the vehicle."}
{"doc29": "But the reality is humans are unpredictable, and the amount of skill it takes to drive, whether it be to school or in a construction zone, was underappreciated. It\u2019s taken far longer than most expected to get to where we are today, which isn\u2019t too far. A lot of companies are doing private testing, but large fleets of autonomous vehicles that were promised by companies such as Uber\n, Lyft\n and General Motors\n are still not close to coming to fruition.\n\nWaymo, a division of Alphabet\n, became the first company to offer such a fleet to the public in late 2020. Its service area is limited to a roughly 50-square-mile area but it shows potential for these technologies. The company says it has given tens of thousands of rides since launching publicly in October 2020.\n\nWaymo isn\u2019t alone in this. There are others such as Amazon\n-backed Zoox, Cruise and Argo AI that are testing, and even operating, in limited areas across the country. However, they\u2019re not taking fares and operating for public use in as big and meaningful way as Waymo has been doing. Cruise, a majority-owned subsidiary of GM, is getting close to doing so at night in San Francisco."}
{"doc30": "Mostly smooth, but some issues\nOverall, the two Waymo vehicles I rode in operated as safely as many ride-hailing drivers I\u2019ve been with, including one I had to take to get to the service area for the self-driving vehicles. They handled neighborhood speed bumps, braking and acceleration with ease. After the novelty wore off, I was at ease with how the vehicles were handling most situations.\n\nBut the rides weren\u2019t flawless. Of course, neither are human drivers, but one of the promises of self-driving vehicles is the reduction, even elimination, of accidents. So, as safe as human drivers doesn\u2019t cut it.\n\nThe route selections also were odd. The vehicles seemed to sometimes prioritize going through neighborhood streets instead of taking left-hand turns or using median turnarounds (see the above picture). Waymo says the vehicles may choose a different route to avoid traffic."}
{"doc31": "There also were instances of hesitant, almost harsh, braking and steering movements. At one point, the first vehicle I was in also stopped in the middle of a crosswalk before deciding to reverse out of it. (My colleague Jennifer Elias experienced some similar snafus involving fire lanes.)\n\nHailing the vehicle also is different than a traditional taxi or ride-hailing service. You have to be precise in where the pickup location will be for the vehicle.\n\nIn a crowded Walmart parking lot, I found myself running after the vehicle, which was going in and out of lanes attempting to get to my side of the street. It was annoying but about the same level of frustration I had when attempting to find my Uber driver at the airport."}
{"doc32": "The Waymo vehicles were in line with costs of ride-hailing services. In total, I spent $49.20 on two trips that totaled 26.5 miles and took 1 hour and 17 minutes. The cost per mile averaged to $1.86 a mile.\n\nThat compares with my human-driven ride-hailing trips to get to and from the autonomous taxis that averaged $1.62 per mile, excluding tips, which brought the amount up to $1.88 per mile.\n\nMy Waymo trips included going from one Walmart to another, then stopping for lunch before hailing my second vehicle to take me to a post office and then a Target near the northern border of where the vehicles can drive."}
{"doc33": "Waymo One: The future of autonomous ride-hailing\n\nIn this article for Intelligent Transport, Waymo tells us more about the Waymo OneTM ride-hailing service, and explains why this autonomous transport offering is gaining momentum.\n\nWhat is Waymo One?\nWaymo One is our autonomous ride-hailing service, currently offering fully autonomous rides with no human driver in the East Valley of Phoenix, Arizona, and testing in San Francisco, California, through our Waymo One Trusted Tester programme. In fact, the beginning of October 2021 marked the one-year anniversary of Waymo opening up the Waymo One rider-only service to the public in Phoenix. To date, Waymo One has celebrated tens of thousands of trips, thousands of riders and hundreds of thousands of miles driven autonomously. As the first and only fully autonomous ride-hailing service, we\u2019re looking forward to bringing Waymo One to more people in the future."}
{"doc34": "Why did Waymo decide to launch this service?\nOur mission at Waymo is to make it safe and easy for people and things to get where they\u2019re going. Waymo One was built to provide a safe, reliable and altogether better way to get from point A to B. Freeing people from the stresses of driving, Waymo One offers a space for people to make the most of their commuting time, from catching up on a book in-between running errands, to getting some work done on the way to the office. \n\nHave trials of the Waymo One service been successful? What has the reaction been to the trials?\nWaymo One has completely changed transportation in Phoenix, being described by riders as their \u201cprimary mode of transportation.\u201d1 One rider, John, has taken over 400 rides in the past year. In San Francisco, the response to trials has been positive, too. In addition to the troves of positive reactions that we receive, our riders also provide useful feedback on more detailed aspects of their ride, from the in-car features that they want to see and whether or not the drive felt smooth, to how accurate the estimated time of arrival (ETA) for their trip was. All of that feedback is reviewed by our team and used to improve our service. Simply put, our riders are happy thus far, and we\u2019re happy to continue evolving to ensure that they get to their destinations efficiently and safely.\n\nHow does Waymo ensure passenger safety?\nSafety is at the forefront of Waymo\u2019s focus. Over a million people die on roadways annually, and 94 per cent of vehicle crashes in the United States involve human error or choice. The Waymo Driver, our autonomous driving technology, has the potential to help to reduce these tragedies by eliminating that human error. The Waymo Driver knows its exact location on the road; knows its surroundings; can see 360 degrees and up to three football fields away; makes predictions about what other vehicles will do; and decides on the best action to take next, all based on over 20 million miles of real-world driving experience and 20 billion miles of simulated driving experience."}
{"doc35": "What are the benefits of utilising autonomous vehicles in ride-hailing services?\nAutonomous ride-hailing services provide a level of overall convenience and safety that other services don\u2019t currently provide. Our Waymo riders feel safer on the roads, are happy with the convenience and delight of our service and feel comfortable in our vehicles. One frequent rider says that she prefers autonomous rides so that she doesn\u2019t have to worry about the emotions or driving experience of a human driver2. Also, because there is no human driver, Waymo cars are available to hail 24/7. This makes them a much more accessible option for those who need rides very late at night or early in the morning. Some riders have also expressed that they prefer using Waymo over other ride-hailing services, as there\u2019s no need to tip an autonomous driver.\n\nHow can autonomous technology benefit public transport on a wider scale?\n\nBeyond providing a new way to seamlessly get from point A to point B, autonomous technology can integrate with other forms of public transportation. For example, from September 2019 to March 2020, Waymo One partnered with Metro Valley \u2013 Phoenix Metro area\u2019s public transportation authority \u2013 on their RideChoice programme. RideChoice is a programme that provides public transportation for those with disabilities and those over the age of 65. In a survey that we conducted3 about our partnership with the programme, we found that autonomous vehicles provided easier and accessible public transportation for our participants. Not only did they feel safe and found Waymo One rides convenient, they also began using public transportation more. With the introduction of our Waymo One service, 59 per cent of participants began taking more trips than usual with the RideChoice programme. Overall, 93 per cent of all participants said that they would like to see autonomously driven rides become a permanent option of public transportation."}
{"doc36": "China\u2019s robotaxi push sparks concerns about job security for drivers\n\nKEY POINTS\nChina\u2019s yearslong effort to develop robotaxis is starting to gain traction with consumers \u2014but it\u2019s also rattling taxi drivers worried about losing their jobs as a result of increasing competition.\nBaidu\u2019s robotaxi unit Apollo Go became one of the top 10 trending hashtags on social media platform Weibo on Wednesday amid reports of rapid user adoption in Wuhan city, where the company began operating fully staffless vehicles in certain districts 24/7 in March.\nChina had more than 7 million registered ride-hailing drivers as of the end of May, roughly twice as many versus the 3.51 million drivers reported for July 2021, according to the Ministry of Transport.\n\nBEIJING \u2014 China\u2019s yearslong effort to develop robotaxis is starting to gain traction with consumers \u2014 but it\u2019s also rattling taxi drivers worried about losing their jobs as a result of increasing competition."}
{"doc37": "Also making the rounds on social media was an appeal in late June by a taxi company in Wuhan seeking reduced taxes and more restrictions on Apollo Go robotaxis as well as the number of ride-hailing cars.\n\nCNBC was unable to independently verify the document, which claimed the taxi company had to stop operating four of its 159-car fleet since April due to falling income.\n\nWage growth in China overall has slowed from around 10% annual increases prior to the pandemic, to 4% in recent years, according to Goldman Sachs analysis published last month. The pace improved to 5.6% year-on-year growth in the first quarter, the report said."}
{"doc38": "In comparison, the U.S. had nearly 400,000 taxi and ride-hailing drivers, shuttle drivers and chauffeurs in 2022, according to the latest available figures from the Bureau of Labor Statistics.\n\nThe number of ride-hailing companies in China has also climbed, from 241 in 2021 to 351 in May this year, according to the Ministry of Transport.\n\nChina pushes ahead with robotaxi support\nMultiple Chinese ministries in January released a plan to promote cloud-connected cars, including tests of at least 200 low-speed unmanned vehicles in each pilot region. Last week, the same authorities released a list of 20 initial pilot cities, including Beijing, Shanghai, Chongqing and Wuhan."}
{"doc39": "The public-facing rides are currently subsidized, and the number of vehicles on the road are still far lower than those of traditional taxis.\n\nThe Apollo Go app showed Thursday that a 45-minute robotaxi ride from Daxing airport to a southern suburb of Beijing would be fully subsidized \u2013 the entire 193.84 yuan ($26.66) cost was waived. The app also showed a 16-minute robotaxi ride within that Beijing suburb would cost 10.36 yuan, about half the 20 yuan fare listed by ride-hailing apps, which can call taxis.\n\nBaidu CEO Robin Li told investors in May that more than 70% of Apollo Go robotaxi rides in April were fully driverless, with no human staff inside. He predicted that share would reach 100% in the coming quarters \u2014 and allow Apollo Go to break even in Wuhan first."}
{"doc40": "Baidu robotaxis draw complaints from human drivers\n\nBEIJING - A fleet of more than 500 driverless taxis operated by Baidu's autonomous-driving unit in Wuhan, capital of central Hubei province, is quickly gaining customers despite vocal complaints from locals and taxi drivers, showing the complications of providing such services in an urban area.\n\nThe Apollo Go service, launched in August 2022, has become so popular in the city of 13.7 million that local taxi drivers are petitioning the municipal transport authority to limit its use.\nA letter sent in late June by Wuhan Jianshe Automotive Passenger Transportation, a local operator, said four of its 159 taxis had quit since April due to declining income, according to a report by the Southern Weekly newspaper. The company accused robotaxis of \"taking jobs from the grass roots\"."}
{"doc41": "Baidu did not immediately respond to a request for comment on Tuesday. The company said in May that it reported to the police several cases related to the spreading of misinformation about Apollo Go on social media, and more than 10 suspects were arrested.\n\nAfter burning cash for years, Baidu's autonomous-driving project is finally aiming to turn a profit, Wang Yunpeng, head of the company's Intelligent Driving Group, told staff in an internal letter in April.\n\nThe Beijing-based artificial intelligence (AI) giant expects Apollo Go to expand its Wuhan fleet to 1,000 vehicles and break even locally by the end of this year, Chen Zhuo, general manager of Baidu's self-driving unit, said recently."}
{"doc42": "Wuhan, a heavy investor in driverless technology, is a national pioneer in opening urban areas to robotaxi services, calling itself \"the world's largest autonomous-driving operation service region\".\n\nOther cities, such as Shenzhen and Shanghai, have also allowed robotaxis in designated roads or areas, although they are not as big as in Wuhan. Baidu aims to \"replicate the successful experience of Wuhan\" in other cities in the future, said Chen. The company has previously said it plans to make Apollo Go available in 100 cities by the end of this decade.\nWhile Baidu said passengers are generally happy with Apollo Go, which has achieved an average rating of 4.9 out of 5 in service quality, its fleet has also been the subject of over 300 complaints logged by Wuhan citizens on a government-run transport management website, alleging that the taxis reacted too slowly to traffic lights.\n\nAn accident earlier this week involving a Baidu robotaxi in Wuhan has also raised safety concerns. A minor collision with an electric scooter that ran a red light resulted in a scratch on an Apollo Go vehicle."}
{"doc43": "Self-driving car\n\nA self-driving car, also known as an autonomous car (AC), driverless car, robotaxi, robotic car or robo-car,[1][2][3] is a car that is capable of operating with reduced or no human input.[4][5] Self-driving cars are responsible for all driving activities, such as perceiving the environment, monitoring important systems, and controlling the vehicle, which includes navigating from origin to destination.[6]\n\nAs of early 2024, no system has achieved full autonomy (SAE Level 5). In December 2020, Waymo was the first to offer rides in self-driving taxis to the public in limited geographic areas (SAE Level 4),[7] and as of April 2024 offers services in Arizona (Phoenix) and California (San Francisco and Los Angeles). In June 2024, after a Waymo self-driving taxi crashed into a utility pole in Phoenix, Arizona, all 672 of its Jaguar I-Pace were recalled after they were found to have susceptibility to crashing into pole like items and had their software updated.[8][9][10] In July 2021, DeepRoute.ai started offering self-driving taxi rides in Shenzhen, China. Starting in February 2022, Cruise offered self-driving taxi service in San Francisco,[11] but suspended service in 2023. In 2021, Honda was the first manufacturer to sell an SAE Level 3 car,[12][13][14] followed by Mercedes-Benz in 2023.[15]"}
{"doc44": "History\nMain article: History of self-driving cars\nExperiments have been conducted on advanced driver assistance systems (ADAS) since at least the 1920s.[16] The first ADAS system was cruise control, which was invented in 1948 by Ralph Teetor.\n\nTrials began in the 1950s. The first semi-autonomous car was developed in 1977, by Japan's Tsukuba Mechanical Engineering Laboratory.[17] It required specially marked streets that were interpreted by two cameras on the vehicle and an analog computer. The vehicle reached speeds of 30 km/h (19 mph) with the support of an elevated rail.[18][19]\n\nCarnegie Mellon University's Navlab[20] and ALV[21][22] semi-autonomous projects launched in the 1980s, funded by the United States' Defense Advanced Research Projects Agency (DARPA) starting in 1984 and Mercedes-Benz and Bundeswehr University Munich's EUREKA Prometheus Project in 1987.[23] By 1985, ALV had reached 31 km/h (19 mph), on two-lane roads. Obstacle avoidance came in 1986, and day and night off-road driving by 1987.[24] In 1995 Navlab 5 completed the first autonomous US coast-to-coast journey. Traveling from Pittsburgh, Pennsylvania and San Diego, California, 98.2% of the trip was autonomous. It completed the trip at an average speed of 63.8 mph (102.7 km/h).[25][26][27][28] Until the second DARPA Grand Challenge in 2005, automated vehicle research in the United States was primarily funded by DARPA, the US Army, and the US Navy, yielding incremental advances in speeds, driving competence, controls, and sensor systems.[29]"}
{"doc45": "The US allocated US$650 million in 1991 for research on the National Automated Highway System,[30] which demonstrated automated driving, combining highway-embedded automation with vehicle technology, and cooperative networking between the vehicles and highway infrastructure. The programme concluded with a successful demonstration in 1997.[31] Partly funded by the National Automated Highway System and DARPA, Navlab drove 4,584 km (2,848 mi) across the US in 1995, 4,501 km (2,797 mi) or 98% autonomously.[32] In 2015, Delphi piloted a Delphi technology-based Audi, over 5,472 km (3,400 mi) through 15 states, 99% autonomously.[33] In 2015, Nevada, Florida, California, Virginia, Michigan, and Washington DC allowed autonomous car testing on public roads.[34]\n\nFrom 2016 to 2018, the European Commission funded development for connected and automated driving through Coordination Actions CARTRE and SCOUT programs.[35] The Strategic Transport Research and Innovation Agenda (STRIA) Roadmap for Connected and Automated Transport was published in 2019.[36]\n\nIn November 2017, Waymo announced testing of autonomous cars without a safety driver.[37] However, an employee was in the car to handle emergencies.[38]"}
{"doc46": "In December 2018, Waymo was the first to commercialize a robotaxi service, in Phoenix, Arizona.[39] In October 2020, Waymo launched a robotaxi service in a (geofenced) part of the area.[40][41] The cars were monitored in real-time, and remote engineers intervened to handle exceptional conditions.[42][41]\n\nIn March 2019, ahead of Roborace, Robocar set the Guinness World Record as the world's fastest autonomous car. Robocar reached 282.42 km/h (175.49 mph).[43]\n\nIn March 2021, Honda began leasing in Japan a limited edition of 100 Legend Hybrid EX sedans equipped with Level 3 \"Traffic Jam Pilot\" driving technology, which legally allowed drivers to take their eyes off the road when the car was travelling under 30 kilometres per hour (19 mph).[12][13][44][14]"}
{"doc47": "In December 2020, Waymo became the first service provider to offer driverless taxi rides to the general public, in a part of Phoenix, Arizona. Nuro began autonomous commercial delivery operations in California in 2021.[45] DeepRoute.ai launched robotaxi service in Shenzhen in July 2021.[46] In December 2021, Mercedes-Benz received approval for a Level 3 car.[15] In February 2022, Cruise became the second service provider to offer driverless taxi rides to the general public, in San Francisco.[11] In December 2022, several manufacturers scaled back plans for self-driving technology, including Ford and Volkswagen.[47] In 2023, Cruise suspended its robotaxi service.[48] Nuro was approved for Level 4 in Palo Alto in August, 2023.[49]\n\nAs of August 2023, vehicles operating at Level 3 and above were an insignificant market factor;[citation needed] as of early 2024, Honda leases a Level 3 car in Japan, and Mercedes sells two Level 3 cars in Germany, California and Nevada.[50][51]\n\nDefinitions\nOrganizations such as SAE have proposed terminology standards. However, most terms have no standard definition and are employed variously by vendors and others. Proposals to adopt aviation automation terminology for cars have not prevailed.[52]"}
{"doc48": "Names such as AutonoDrive, PilotAssist, Full-Self Driving or DrivePilot are used even though the products offer an assortment of features that may not match the names.[53] Despite offering a system ot called Full Self-Driving, Tesla stated that its system did not autonomously handle all driving tasks.[54] In the United Kingdom, a fully self-driving car is defined as a car so registered, rather than one that supports a specific feature set.[55] The Association of British Insurers claimed that the usage of the word autonomous in marketing was dangerous because car ads make motorists think \"autonomous\" and \"autopilot\" imply that the driver can rely on the car to control itself, even though they do not.\n\nAutomated driving system\nAn ADS is an SAE J3016 level 3 or higher system.\n\nAdvanced driver assistance system\nMain article: Advanced driver-assistance system\nAn ADAS is a system that automates specific driving features, such as keeping the car within its lane, cruise control, and emergency braking. An ADAS requires a human driver to handle tasks that the ADAS does not support."}
{"doc49": "\"automated vehicle\" means a vehicle that can move without continuous driver supervision, but that driver intervention is still expected or required in some ODDs;[58]\n\"fully automated vehicle\" means a vehicle that can move entirely without driver supervision;[58]\nCooperative system\nA remote driver is a driver that operates a vehicle at a distance, using a video and data connection.[59]\n\nAccording to SAE J3016,\nSome driving automation systems may indeed be autonomous if they perform all of their functions independently and self-sufficiently, but if they depend on communication and/or cooperation with outside entities, they should be considered cooperative rather than autonomous.\n\nOperational design domain"}
{"doc50": "Operational design domain (ODD) is a term for a particular operating context for an automated system, often used in the field of autonomous vehicles. The context is defined by a set of conditions, including environmental, geographical, time of day, and other conditions. For vehicles, traffic and roadway characteristics are included. Manufacturers use ODD to indicate where/how their product operates safely. A given system may operate differently according to the immediate ODD.[60]\n\nThe concept presumes that automated systems have limitations.[61] Relating system function to the ODDs it supports is important for developers and regulators to establish and communicate safe operating conditions. Systems should operate within those limitations. Some systems recognize the ODD and modify their behavior accordingly. For example, an autonomous car might recognize that traffic is heavy and disable its automated lane change feature. [61]\nVendors have taken a variety of approaches to the self-driving problem. Tesla's approach is to allow their \"full self-driving\" (FSD) system to be used in all ODDs as a Level 2 (hands/on, eyes/on) ADAS.[62] Waymo picked specific ODDs (city streets in Phoenix and San Francisco) for their Level 5 robotaxi service.[63] Mercedes Benz offers Level 3 service in Las Vegas in highway traffic jams at speeds up to 40 miles per hour (64 km/h).[64] Mobileye's SuperVision system offers hands-off/eyes-on driving on all road types at speeds up to 130 kilometres per hour (81 mph).[65] GM's hands-free Super Cruise operates on specific roads in specific conditions, stopping or returning control to the driver when ODD changes. In 2024 the company announced plans to expand road coverage from 400,000 miles to 750,000 miles.[66] Ford's BlueCruise hands-off system operates on 130,000 miles of US divided highways.[67]\n\nSelf-driving\nThe Union of Concerned Scientists defined self-driving as \"cars or trucks in which human drivers are never required to take control to safely operate the vehicle. Also known as autonomous or 'driverless' cars, they combine sensors and software to control, navigate, and drive the vehicle.\"[68]"}
{"doc51": "The British Automated and Electric Vehicles Act 2018 law defines a vehicle as \"driving itself\" if the vehicle is \"not being controlled, and does not need to be monitored, by an individual\".[69]\n\nAnother British government definition stated, \"Self-driving vehicles are vehicles that can safely and lawfully drive themselves\".[70]\n\nBritish definitions\nIn British English, the word automated alone has several meanings, such as in the sentence: \"Thatcham also found that the automated lane keeping systems could only meet two out of the twelve principles required to guarantee safety, going on to say they cannot, therefore, be classed as 'automated driving', preferring 'assisted driving'\".[71] The first occurrence of the \"automated\" word refers to an Unece automated system, while the second refers to the British legal definition of an automated vehicle. British law interprets the meaning of \"automated vehicle\" based on the interpretation section related to a vehicle \"driving itself\" and an insured vehicle.[72]"}
{"doc52": "In November 2023 the British Government introduced the Automated Vehicles Bill. It proposed definitions for related terms:[73]\n\nSelf-driving: \"A vehicle \u201csatisfies the self-driving test\u201d if it is designed or adapted with the intention that a feature of the vehicle will allow it to travel autonomously, and it is capable of doing so, by means of that feature, safely and legally.\"\nAutonomy: A vehicle travels \u201cautonomously\u201d if it is controlled by the vehicle, and neither the vehicle nor its surroundings are monitored by a person who can intervene.\nControl: control of vehicle motion.\nSafe: a vehicle that conforms to an acceptably safe standard.\nLegal: a vehicle that offers an acceptably low risk of committing a traffic infraction.\n\nSAE classification\nA six-level classification system \u2013 ranging from fully manual to fully automated \u2013 was published in 2014 by SAE International as J3016, Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems; the details are revised occasionally.[76] This classification is based on the role of the driver, rather than the vehicle's capabilities, although these are related. After SAE updated its classification in 2016, (J3016_201609),[77] the National Highway Traffic Safety Administration (NHTSA) adopted the SAE standard.[78][79] The classification is a topic of debate, with various revisions proposed.[80][81]"}
{"doc53": "Classifications\nA \"driving mode\", aka driving scenario, combines an ODD with matched driving requirements (e.g., expressway merging, traffic jam).[1][82] Cars may switch levels in accord with the driving mode.\n\nAbove Level 1, level differences are related to how responsibility for safe movement is divided/shared between ADAS and driver rather than specific driving features.\nSAE Automation Levels have been criticized for their technological focus. It has been argued that the structure of the levels suggests that automation increases linearly and that more automation is better, which may not be the case.[83] SAE Levels also do not account for changes that may be required to infrastructure[84] and road user behavior.[85][86]\n\nMobileye System"}
{"doc54": "Mobileye CEO Amnon Shashua and CTO Shai Shalev-Shwartz proposed an alternative taxonomy for autonomous driving systems, claiming that a more consumer-friendly approach was needed. Its categories reflect the amount of driver engagement that is required.[87][88] Some vehicle makers have informally adopted some of the terminology involved, while not formally committing to it.[89][90][91][92]\n\nEyes-on/hands-on\nThe first level, hands-on/eyes-on, implies that the driver is fully engaged in operating the vehicle, but is supervised by the system, which intervenes according to the features it supports (e.g., adaptive cruise control, automatic emergency braking). The driver is entirely responsible, with hands on the wheel, and eyes on the road.[88]\n\nEyes-on/hands-off\nEyes-on/hands-off allows the driver to let go of the wheel. The system drives, the driver monitors and remains prepared to resume control as needed.[88]"}
{"doc55": "Eyes-off/hands-off\nEyes-off/hands-off means that the driver can stop monitoring the system, leaving the system in full control. Eyes-off requires that no errors be reproducible (not triggered by exotic transitory conditions) or frequent, that speeds are contextually appropriate (e.g., 80 mph on limited-access roads), and that the system handle typical maneuvers (e.g., getting cut off by another vehicle). The automation level could vary according to the road (e.g., eyes-off on freeways, eyes-on on side streets).[88]\n\nNo driver\nThe highest level does not require a human driver in the car: monitoring is done either remotely (telepresence) or not at all.[88]\n\nSafety\nA critical requirement for the higher two levels is that the vehicle be able to conduct a Minimum Risk Maneuver and stop safely out of traffic without driver intervention.[88]"}
{"doc56": "Technology\nMain article: Vehicular automation\nArchitecture\nThe perception system processes visual and audio data from outside and inside the car to create a local model of the vehicle, the road, traffic, traffic controls and other observable objects, and their relative motion. The control system then takes actions to move the vehicle, considering the local model, road map, and driving regulations.[93][94][95][96]\n\n\nSeveral classifications have been proposed to describe ADAS technology. One proposal is to adopt these categories: navigation, path planning, perception, and car control.[97]\n\nNavigation\nMain article: Hybrid navigation\nNavigation involves the use of maps to define a path between origin and destination. Hybrid navigation is the use of multiple navigation systems. Some systems use basic maps, relying on perception to deal with anomalies. Such a map understands which roads lead to which others, whether a road is a freeway, a highway, are one-way, etc. Other systems require highly detailed maps, including lane maps, obstacles, traffic controls, etc."}
{"doc57": "Perception\nACs need to be able to perceive the world around them. Supporting technologies include combinations of cameras, LiDAR, radar, audio, and ultrasound,[98] GPS, and inertial measurement.[99][100][101] Deep neural networks are used to analyse inputs from these sensors to detect and identify objects and their trajectories.[102] Some systems use Bayesian simultaneous localization and mapping (SLAM) algorithms. Another technique is detection and tracking of other moving objects (DATMO), used to handle potential obstacles.[103][104] Other systems use roadside real-time locating system (RTLS) technologies to aid localization. Tesla's \"vision only\" system uses eight cameras, without LIDAR or radar, to create its bird's-eye view of the environment.[105]\n\nPath planning\nPath planning finds a sequence of segments that a vehicle can use to move from origin to destination. Techniques used for path planning include graph-based search and variational-based optimization techniques. Graph-based techniques can make harder decisions such as how to pass another vehicle/obstacle. Variational-based optimization techniques require more stringent restrictions on the vehicle's path to prevent collisions.[106] The large scale path of the vehicle can be determined by using a voronoi diagram, an occupancy grid mapping, or a driving corridor algorithm. The latter allows the vehicle to locate and drive within open space that is bounded by lanes or barriers.[107]\n\nMaps\nMaps are necessary for navigation. Map sophistication varies from simple graphs that show which roads connect to each other, with details such as one-way vs two-way, to those that are highly detailed, with information about lanes, traffic controls, roadworks, and more.[98] Researchers at the MITComputer Science and Artificial Intelligence Laboratory (CSAIL) developed a system called MapLite, which allows self-driving cars to drive with simple maps. The system combines the GPS position of the vehicle, a \"sparse topological map\" such as OpenStreetMap (which has only 2D road features), with sensors that observe road conditions.[108] One issue with highly-detailed maps is updating them as the world changes. Vehicles that can operate with less-detailed maps do not require frequent updates or geo-fencing."}
{"doc58": "Sensors\nSensors are necessary for the vehicle to properly respond to the driving environment. Sensor types include cameras, LiDAR, ultrasound, and radar. Control systems typically combine data from multiple sensors.[109] Multiple sensors can provide a more complete view of the surroundings and can be used to cross-check each other to correct errors.[110] For example, radar can image a scene in, e.g., a nighttime snowstorm, that defeats cameras and LiDAR, albeit at reduced precision. After experimenting with radar and ultrasound, Tesla adopted a vision-only approach, asserting that humans drive using only vision, and that cars should be able to do the same, while citing the lower cost of cameras versus other sensor types.[111] By contrast, Waymo makes use of the higher resolution of LiDAR sensors and cites the declining cost of that technology.[112]\n\nDrive by wire\nMain article: Drive by wire\nDrive by wire is the use of electrical or electro-mechanical systems for performing vehicle functions such as steering or speed control that are traditionally achieved by mechanical linkages.\n\nDriver monitoring\nMain article: Driver monitoring system\nDriver monitoring is used to assess the driver's attention and alertness. Techniques in use include eye monitoring, and requiring the driver to maintain torque on the steering wheel.[113] It attempts to understand driver status and identify dangerous driving behaviors.[114]"}
{"doc59": "Software update\nSee also: Over-the-air programming\nSoftware controls the vehicle, and can provide entertainment and other services. Over-the-air updates can deliver bug fixes and additional features over the internet. Software updates are one way to accomplish recalls that in the past required a visit to a service center. In March 2021, the UNECE regulation on software update and software update management systems was published.[120]\n\nSafety model\nA safety model is software that attempts to formalize rules that ensure that ACs operate safely.[121]\n\nIEEE is attempting to forge a standard for safety models as \"IEEE P2846: A Formal Model for Safety Considerations in Automated Vehicle Decision Making\".[122] In 2022, a research group at National Institute of Informatics (NII, Japan) enhanced Mobileye's Reliable Safety System as \"Goal-Aware RSS\" to enable RSS rules to deal with complex scenarios via program logic.[123]"}
{"doc60": "Notification\nThe US has standardized the use of turquoise lights to inform other drivers that a vehicle is driving autonomously. It will be used in the 2026 Mercedes-Benz EQS and S-Class sedans with Drive Pilot, an SAE Level 3 driving system.[citation needed]\n\nAs of 2023, the Turquoise light had not been standardized by the P.R.C or the UN-ECE.[124]\n\nArtificial Intelligence\nArtificial intelligence (AI) plays a pivotal role in the development and operation of autonomous vehicles (AVs), enabling them to perceive their surroundings, make decisions, and navigate safely without human intervention. AI algorithms empower AVs to interpret sensory data from various onboard sensors, such as cameras, LiDAR, radar, and GPS, to understand their environment and improve its technological ability and overall safety over time.[125]"}
{"doc61": "Challenges\n\nAutonomous delivery vehicles stuck in one place by attempting to avoid one another\nObstacles\nThe primary obstacle to ACs is the advanced software and mapping required to make them work safely across the wide variety of conditions that drivers experience.[126] In addition to handling day/night driving in good and bad weather[127] on roads of arbitrary quality, ACs must cope with other vehicles, road obstacles, poor/missing traffic controls, flawed maps, and handle endless edge cases, such as following the instructions of a police officer managing traffic at a crash site.\n\nOther obstacles include cost, liability,[128][129] consumer reluctance,[130] ethical dilemmas,[131][132] security,[133][134][135][136] privacy,[127] and legal/regulatory framework.[137] Further, AVs could automate the work of professional drivers, eliminating many jobs, which could slow acceptance.[138]"}
{"doc62": "Concerns\nDeceptive marketing\nTesla calls its Level 2 ADAS \"Full Self-Driving (FSD) Beta\".[139] US Senators Richard Blumenthal and Edward Markey called on the Federal Trade Commission (FTC) to investigate this marketing in 2021.[140] In December 2021 in Japan, Mercedes-Benz was punished by the Consumer Affairs Agency for misleading product descriptions.[141]\n\nMercedes-Benz was criticized for a misleading US commercial advertising E-Class models.[142] At that time, Mercedes-Benz rejected the claims and stopped its \"self-driving car\" ad campaign that had been running.[143][144] In August 2022, the California Department of Motor Vehicles (DMV) accused Tesla of deceptive marketing practices.[145]\n\nWith the Automated Vehicles Bill (AVB) self-driving car-makers could face prison for misleading adverts in the United-Kingdom.[146]"}
{"doc63": "Security\nIn the 2020s, concerns over ACs' vulnerability to cyberattacks and data theft emerged.[147]\n\nEspionage\nIn 2018 and 2019 former Apple engineers were charged with stealing information related to Apple's self-driving car project.[148][149][150] In 2021 the United States Department of Justice (DOJ) accused Chinese security officials of coordinating a hacking campaign to steal information from government entities, including research related to autonomous vehicles.[151][152] China has prepared \"the Provisions on Management of Automotive Data Security (Trial) to protect its own data\".[153][154]\n\nCellular Vehicle-to-Everything technologies are based on 5G wireless networks.[155] As of November 2022, the US Congress was considering the possibility that imported Chinese AC technology could facilitate espionage.[156]"}
{"doc64": "Testing of Chinese automated cars in the US has raised concern over which US data are collected by Chinese vehicles to be stored in Chinese country and concern with any link with the Chinese communist party.[157]\n\nDriver communications\nACs complicate the need for drivers to communicate with each other, e.g., to decide which car enters an intersection first. In an AC without a driver, traditional means such as hand signals do not work (no driver, no hands).[158]\n\nBehavior prediction\nACs must be able to predict the behavior of possibly moving vehicles, pedestrians, etc in real time in order to proceed safely.[95] The task becomes more challenging the further into the future the prediction extends, requiring rapid revisions to the estimate to cope with unpredicted behavior. One approach is to wholly recompute the position and trajectory of each object many times per second. Another is to cache the results of an earlier prediction for use in the next one to reduce computational complexity.[159][160]"}
{"doc65": "Handover\nThe ADAS has to be able to safely accept control from and return control to the driver.[161]\n\nTrust\nConsumers will avoid ACs unless they trust them as safe.[162][163] Robotaxis operating in San Francisco received pushback over perceived safety risks.[164] Automatic elevators were invented in 1900, but did not become common until operator strikes and trust was built with advertising and features such as an emergency stop button.[165][166]\n\nEconomics\nAutonomous also present various political and economic implications. The transportation sector holds significant sway in many the political and economic landscapes. For instance, many US states generates much annual revenue from transportation fees and taxes.[167] The advent of self-driving cars could profoundly affect the economy by potentially altering state tax revenue streams. Furthermore, the transition to autonomous vehicles might disrupt employment patterns and labor markets, particularly in industries heavily reliant on driving professions.[167] Data from the U.S. Bureau of Labor Statistics indicates that in 2019, the sector employed over two million individuals as tractor-trailer truck drivers.[168] Additionally, taxi and delivery drivers represented approximately 370,400 positions, and bus drivers constituted a workforce of over 680,000.[169][170][171] Collectively, this amounts to a conceivable displacement of nearly 2.9 million jobs, surpassing the job losses experienced in the 2008 Great Recession.[172]"}
{"doc66": "Equity and Inclusion\nThe prominence of certain demographic groups within the tech industry inevitably shapes the trajectory of autonomous vehicle (AV) development, potentially perpetuating existing inequalities.[173]\n\nEthical issues\nSee also: Machine ethics\nPedestrian Detection\nResearch from Georgia Tech revealed that autonomous vehicle detection systems were generally five percent less effective at recognizing darker-skinned individuals. This accuracy gap persisted despite adjustments for environmental variables like lighting and visual obstructions.[174]\n\nRationale for liability\nStandards for liability have yet to be adopted to address crashes and other incidents. Liability could rest with the vehicle occupant, its owner, the vehicle manufacturer, or even the ADAS technology supplier, possibly depending on the circumstances of the crash.[175] Additionally, the infusion of ArtificiaI Intelligence technology in autonomous vehicles adds layers of complexity to ownership and ethical dynamics. Given that AI systems are inherently self-learning, a question arises of whether accountability should rest with the vehicle owner, the manufacturer, or the AI developer?[176]"}
{"doc67": "Trolley problem\nThe trolley problem is a thought experiment in ethics. Adapted for ACs, it considers an AC carrying one passenger confronts a pedestrian who steps in its way. The ADAS notionally has to choose between killing the pedestrian or swerving into a wall, killing the passenger.[177] Possible frameworks include deontology (formal rules) and utilitarianism (harm reduction).[95][178][179]\n\nOne public opinion survey reported that harm reduction was preferred, except that passengers wanted the vehicle to prefer them, while pedestrians took the opposite view. Utilitarian regulations were unpopular.[180] Additionally, cultural viewpoints exert substantial influence on shaping responses to these ethical quandaries. Another study found that cultural biases impact preferences in prioritizing the rescue of certain individuals over others in car accident scenarios.[176]\n\nPrivacy\nSome ACs require an internet connection to function, opening the possibility that a hacker might gain access to private information such as destinations, routes, camera recordings, media preferences, and/or behavioral patterns, although this is true of an internet-connected device.[181][182][183]"}
{"doc68": "Road infrastructure\nACs make use of road infrastructure (e.g., traffic signs, turn lanes) and may require modifications to that infrastructure to fully achieve their safety and other goals.[184] In March 2023, the Japanese government unveiled a plan to set up a dedicated highway lane for ACs.[185] In April 2023, JR East announced their challenge to raise their self-driving level of Kesennuma Line bus rapid transit (BRT) in rural area from the current Level 2 to Level 4 at 60 km/h.[186]\n\nTesting\nApproaches\nACs can be tested via digital simulations,[187][188] in a controlled test environment,[189] and/or on public roads. Road testing typically requires some form of permit[190] or a commitment to adhere to acceptable operating principles.[191] For example, New York requires a test driver to be in the vehicle, prepared to override the ADAS as necessary.[192]\n\n2010s and disengagements"}
{"doc69": "A prototype of Waymo's self-driving car, navigating public streets in Mountain View, California in 2017\nIn California, self-driving car manufacturers are required to submit annual reports describing how often their vehicles autonomously disengaged from autonomous mode.[193] This is one measure of system robustness (ideally, the system should never disengage).[194]\n\nIn 2017, Waymo reported 63 disengagements over 352,545 mi (567,366 km) of testing, an average distance of 5,596 mi (9,006 km) between disengagements, the highest (best) among companies reporting such figures. Waymo also logged more autonomous miles than other companies. Their 2017 rate of 0.18 disengagements per 1,000 mi (1,600 km) was an improvement over the 0.2 disengagements per 1,000 mi (1,600 km) in 2016, and 0.8 in 2015. In March 2017, Uber reported an average of 0.67 mi (1.08 km) per disengagement. In the final three months of 2017, Cruise (owned by GM) averaged 5,224 mi (8,407 km) per disengagement over 62,689 mi (100,888 km).[195]\n\n2020s\nDisengagement definitions\nReporting companies use varying definitions of what qualifies as a disengagement, and such definitions can change over time.[197][194] Executives of self-driving car companies have criticized disengagements as a deceptive metric, because it does not consider varying road conditions.[198]"}
{"doc70": "Pedestrian reactions\nIn 2023 David R. Large, senior research fellow with the Human Factors Research Group at the University of Nottingham, disguised himself as a car seat in a study to test people's reactions to driverless cars. He said, \"We wanted to explore how pedestrians would interact with a driverless car and developed this unique methodology to explore their reactions.\" The study found that, in the absence of someone in the driving seat, pedestrians trust certain visual prompts more than others when deciding whether to cross the road.[213]\n\nIncidents\nTesla\nSee also: Tesla Autopilot \u00a7 Notable crashes\nAs of 2023, Tesla's ADAS Autopilot/Full Self Driving (beta) was classified as Level 2 ADAS.[214]\n\nOn 20 January 2016, the first of five known fatal crashes of a Tesla with Autopilot occurred, in China's Hubei province.[215] Initially, Tesla stated that the vehicle was so badly damaged from the impact that their recorder was not able to determine whether the car had been on Autopilot at the time. However, the car failed to take evasive action."}
{"doc71": "Another fatal Autopilot crash occurred in May in Florida in a Tesla Model S[216][217] that crashed into a tractor-trailer. In a civil suit between the father of the driver killed and Tesla, Tesla documented that the car had been on Autopilot.[218] According to Tesla, \"neither Autopilot nor the driver noticed the white side of the tractor-trailer against a brightly lit sky, so the brake was not applied.\" Tesla claimed that this was Tesla's first known Autopilot death in over 130 million miles (210 million kilometers) with Autopilot engaged. Tesla claimed that on average one fatality occurs every 94 million miles (151 million kilometers) across all vehicle types in the US.[219][220][221] However, this number also includes motorcycle/pedestrian fatalities.[222][223] The ultimate NTSB report concluded Tesla was not at fault; the investigation revealed that for Tesla cars, the crash rate dropped by 40 percent after Autopilot was installed.[224]\n\nGoogle Waymo\nSee also: Waymo \u00a7 Crashes\n\nGoogle's in-house automated car\nIn June 2015, Google confirmed that 12 vehicles had suffered collisions as of that date. Eight involved rear-end collisions at a stop sign or traffic light, in two of which the vehicle was side-swiped by another driver, one in which another driver rolled a stop sign, and one where a driver was controlling the car manually.[225] In July 2015, three employees suffered minor injuries when their vehicle was rear-ended by a car whose driver failed to brake. This was the first collision that resulted in injuries.[226]"}
{"doc72": "According to Google Waymo's accident reports as of early 2016, their test cars had been involved in 14 collisions, of which other drivers were at fault 13 times, although in 2016 the car's software caused a crash.[227] On 14 February 2016 a Google vehicle attempted to avoid sandbags blocking its path. During the maneuver it struck a bus. Google stated, \"In this case, we clearly bear some responsibility, because if our car hadn't moved, there wouldn't have been a collision.\"[228][229] Google characterized the crash as a misunderstanding and a learning experience. No injuries were reported.[227]\n\nUber's Advanced Technologies Group (ATG)\nIn March 2018, Elaine Herzberg died after she was hit by an AC tested by Uber's Advanced Technologies Group (ATG) in Arizona. A safety driver was in the car. Herzberg was crossing the road about 400 feet from an intersection.[230] Some experts said a human driver could have avoided the crash.[231] Arizona governor Doug Ducey suspended the company's ability to test its ACs citing an \"unquestionable failure\" of Uber to protect public safety.[232] Uber also stopped testing in California until receiving a new permit in 2020.[233][234]\n\nNTSB's final report determined that the immediate cause of the accident was that safety driver Rafaela Vasquez failed to monitor the road, because she was distracted by her phone, but that Uber's \"inadequate safety culture\" contributed. The report noted that the victim had \"a very high level\" of methamphetamine in her body.[235] The board called on federal regulators to carry out a review before allowing automated test vehicles to operate on public roads.[236][237]"}
{"doc73": "In September 2020, Vasquez pled guilty to negligent homicide.[238]\n\nNIO Navigate on Pilot\nOn 12 August 2021, a 31-year-old Chinese man was killed after his NIO ES8 collided with a construction vehicle.[citation needed] NIO's self-driving feature was in beta and could not deal with static obstacles.[239] The vehicle's manual clearly stated that the driver must take over near construction sites. Lawyers of the deceased's family questioned NIO's private access to the vehicle, which they argued did not guarantee the integrity of the data.[240]\n\nPony.ai\nIn November 2021, the California Department of Motor Vehicles (DMV) notified Pony.ai that it was suspending its testing permit following a reported collision in Fremont on 28 October.[241] In May 2022, DMV revoked Pony.ai's permit for failing to monitor the driving records of its safety drivers.[242]"}
{"doc74": "In a 2012 survey of about 1,000 German drivers, 22% had a positive attitude, 10% were undecided, 44% were skeptical and 24% were hostile.[247]\n\nA 2013 survey of 1,500 consumers across 10 countries found 57% \"stated they would be likely to ride in a car controlled entirely by technology that does not require a human driver\", with Brazil, India and China the most willing to trust automated technology.[248]\n\nIn a 2014 US telephone survey, over three-quarters of licensed drivers said they would consider buying a self-driving car, rising to 86% if car insurance were cheaper. 31.7% said they would not continue to drive once an automated car was available.[249]"}
{"doc75": "In 2015, a survey of 5,000 people from 109 countries reported that average respondents found manual driving the most enjoyable. 22% did not want to pay more money for autonomy. Respondents were found to be most concerned about hacking/misuse, and were also concerned about legal issues and safety. Finally, respondents from more developed countries were less comfortable with their vehicle sharing data.[250] The survey reported consumer interest in purchasing an AC, stating that 37% of surveyed current owners were either \"definitely\" or \"probably\" interested.[250]\n\nIn 2016, a survey of 1,603 people in Germany that controlled for age, gender, and education reported that men felt less anxiety and more enthusiasm, whereas women showed the opposite. The difference was pronounced between young men and women and decreased with age.[251]\n\nIn a 2016 US survey of 1,584 people, \"66 percent of respondents said they think autonomous cars are probably smarter than the average human driver\". People were worried about safety and hacking risk. Nevertheless, only 13% of the interviewees saw no advantages in this new kind of cars.[252]"}
{"doc76": "In a 2017 survey of 4,135 US adults found that many Americans anticipated significant impacts from various automation technologies including the widespread adoption of automated vehicles.[253]\n\nIn 2019, results from two opinion surveys of 54 and 187 US adults respectively were published. The questionnaire was termed the autonomous vehicle acceptance model (AVAM), including additional description to help respondents better understand the implications of various automation levels. Users were less accepting of high autonomy levels and displayed significantly lower intention to use autonomous vehicles. Additionally, partial autonomy (regardless of level) was perceived as requiring uniformly higher driver engagement (usage of hands, feet and eyes) than full autonomy.[254]\n\nIn the 2020s\nIn 2022, a survey reported that only a quarter (27%) of the world's population would feel safe in self-driving cars.[255]"}
{"doc77": "Level 2 \u2013 Partial Automation\nSee also: Lane centering \u00a7 Sample of level 2 automated cars, and List of self-driving system suppliers \u00a7 Date of first public road driverless operation\nSAE Level 2 features are available as part of the ADAS systems in many vehicles. In the US, 50% of new cars provide driver assistance for both steering and speed.[260]\n\nFord started offering BlueCruise service on certain vehicles in 2022; the system is named ActiveGlide in Lincoln vehicles. The system provided features such as lane centering, street sign recognition, and hands-free highway driving on more than 130,000 miles of divided highways. The 2022 1.2 version added features including hands-free lane changing, in-lane repositioning, and predictive speed assist.[261][262] In April 2023 BlueCruise was approved in the UK for use on certain motorways, starting with 2023 models of Ford's electric Mustang Mach-E SUV.[263]\n\nTesla's Autopilot and its Full Self-Driving (FSD) ADAS suites are available on all Tesla cars since 2016. FSD offers highway and street driving (without geofencing), navigation/turn management, steering, and dynamic cruise control, collision avoidance, lane-keeping/switching, emergency braking, obstacle avoidance, but still requires the driver to remain ready to control the vehicle at any moment. Its driver management system combines eye tracking with monitoring pressure on the steering wheel to ensure that drives are both eyes on and hands on.[264][265]"}
{"doc78": "Tesla's FSD rewrite V12 (released in March 2024) uses a single deep learning transformer model for all aspects of perception, monitoring, and control.[266][267] It relies on its eight cameras for its vision-only perception system, without use of LiDAR, radar, or ultrasound.[267] As of April 2024, FSD has been deployed on two million Tesla cars.[268] As of January 2024, Tesla has not initiated requests for Level 3 status for its systems and has not disclosed its reason for not doing so.[265]\n\nDevelopment\nGeneral Motors is developing the \"Ultra Cruise\" ADAS system, that will be a dramatic improvement over their current \"Super Cruise\" system. Ultra Cruise will cover \"95 percent\" of driving scenarios on 2 million miles of roads in the US, according to the company. The system hardware in and around the car includes multiple cameras, short- and long-range radar, and a LiDAR sensor, and will be powered by the Qualcomm Snapdragon Ride Platform. The luxury Cadillac Celestiq electric vehicle will be one of the first vehicles to feature Ultra Cruise.[269]\n\nEurope is developing a new \"Driver Control Assistance Systems\" (DCAS) level 2 regulation to no longer limit the use of lane changing systems to roads with 2 lanes and a physical separation from traffic in the opposite direction.[270][271]"}
{"doc79": "Level 3 \u2013 Conditional Automation\nAs of April 2024, two car manufacturers have sold or leased Level 3 cars: Honda in Japan, and Mercedes in Germany, Nevada and California.[51]\n\nMercedes Drive Pilot has been available on the EQS and S-class sedan in Germany since 2022, and in California and Nevada since 2023.[64] A subscription costs between \u20ac5,000 and \u20ac7,000 for three years in Germany and $2,500 for one year in the United States.[272] Drive Pilot can only be used when the vehicle is traveling under 40 miles per hour (64 km/h), there is a vehicle in front, readable line markings, during the day, clear weather, and on freeways mapped by Mercedes down to the centimeter (100,000 miles in California).[272][64] As of April 2024, one Mercedes vehicle with this capability has been sold in California.[272]\n\nDevelopment\nHonda continued to enhance its Level 3 technology.[273][274] As of 2023, 80 vehicles with Level 3 support had been sold.[275]"}
{"doc80": "Development\nIn July 2020, Toyota started public demonstration rides on Lexus LS (fifth generation) based TRI-P4 with Level 4 capability.[290] In August 2021, Toyota operated a potentially Level 4 service using e-Palette around the Tokyo 2020 Olympic Village.[291]\n\nIn September 2020, Mercedes-Benz introduced world's first commercial Level 4 Automated Valet Parking (AVP) system named Intelligent Park Pilot for its new S-Class.[292][293] In November 2022, Germany\u2019s Federal Motor Transport Authority (KBA) approved the system for use at Stuttgart Airport.[294]\n\nIn September 2021, Cruise, General Motors, and Honda started a joint testing programme, using Cruise AV.[295] In 2023, the Origin was put on indefinite hold following Cruise's loss of its operating permit.[296]"}
{"doc81": "## Abstract\n\nThe integration of embedded systems in autonomous vehicles represents a transformative paradigm shift in the automotive industry, offering unprecedented opportunities for enhanced safety, efficiency, and user experience. This comprehensive review explores the current landscape of embedded systems in autonomous vehicles, delving into emerging trends, persistent challenges, and future directions that shape the trajectory of this rapidly evolving field. The review begins by examining the foundational concepts of embedded systems in the context of autonomous vehicles, elucidating the intricate interplay between hardware and software components. It surveys the state-of-the-art technologies that empower these systems, including advanced sensors, actuators, and communication protocols, highlighting their pivotal roles in perception, decision-making, and control aspects of autonomous driving. One of the prominent trends discussed in this review is the increasing reliance on artificial intelligence (AI) and machine learning algorithms within embedded systems. The incorporation of these intelligent algorithms enables vehicles to adapt and learn from real-world scenarios, enhancing their ability to navigate diverse and dynamic environments. Additionally, the review sheds light on the growing emphasis on connectivity and edge computing, illustrating how embedded systems leverage these technologies to facilitate seamless communication between vehicles and their surrounding infrastructure. Despite the promising advancements, the review critically examines the persistent challenges that impede the widespread adoption of embedded systems in autonomous vehicles. Issues such as safety concerns, cybersecurity threats, and regulatory frameworks are analyzed, providing insights into the complex ecosystem in which these technologies operate. In addressing the future directions of embedded systems in autonomous vehicles, the review envisions a trajectory marked by continuous innovation and collaboration across industries. It anticipates the evolution of embedded systems towards more robust, adaptive, and fault-tolerant architectures, paving the way for increased autonomy and widespread deployment of autonomous vehicles. This comprehensive review provides a holistic understanding of embedded systems in autonomous vehicles, encapsulating current trends, challenges, and future directions. As the automotive landscape undergoes a paradigm shift, this review serves as a valuable resource for researchers, practitioners, and policymakers seeking to navigate the dynamic terrain of autonomous vehicle technology. \n\nKeyword: Autonomous Vehicle; Embedded Systems; Innovation; Automobile; Review "}
{"doc82": "## 1. Introduction\n\nThe convergence of embedded systems and autonomous vehicles represents a revolutionary nexus in the automotive landscape, ushering in a new era of mobility that promises enhanced safety, efficiency, and user experience (Allioui & Mourdi, 2023, DeNardis, 2020, Raihan, 2023). As the global automotive industry undergoes a transformative paradigm shift, the integration of advanced technologies within the intricate framework of embedded systems has become a linchpin in the development and deployment of autonomous vehicles.\n\nThis comprehensive review aims to provide a nuanced understanding of the current state of embedded systems in autonomous vehicles, offering insights into the prevailing trends, persistent challenges, and the future trajectories that shape this dynamic field. Embedded systems, comprising both hardware and software components seamlessly interwoven, play a pivotal role in the realization of autonomous driving capabilities, acting as the nerve center that facilitates perception, decision-making, and control in real-time. Against the backdrop of rapid technological advancements, the review will delve into the foundational concepts of embedded systems in the context of autonomous vehicles, elucidating the symbiotic relationship between hardware and software that underpins their functionality. From advanced sensors powering perception to the integration of artificial intelligence and machine learning algorithms, we will explore the state-of-the-art technologies that empower embedded systems and drive the evolution of autonomous vehicles (Bathla, et. al., 2022, Fayyad, et. a., 2020, Liu, et. al., \n2020)."}
{"doc83": "As the automotive industry progresses, this review will analyze emerging trends that define the trajectory of embedded systems in autonomous vehicles, including the increasing reliance on artificial intelligence, connectivity, and edge computing. While these trends promise unprecedented capabilities, the review will also critically examine the persistent challenges that act as roadblocks to the widespread adoption of embedded systems in autonomous vehicles, including safety concerns, cybersecurity threats, and the regulatory landscape.\n\nLooking ahead, the review will illuminate the potential future directions of embedded systems in autonomous vehicles, envisioning a path marked by continuous innovation, adaptive architectures, and increased fault tolerance. With a focus on collaboration and interdisciplinary approaches, this review aims to serve as a valuable resource for researchers, practitioners, and policymakers navigating the intricate landscape of embedded systems in the realm of autonomous vehicles.\n\n## 1.1. Foundational Concepts Of Embedded Systems In Autonomous Vehicles"}
{"doc84": "As autonomous vehicles continue to advance, the seamless integration of embedded systems stands as the bedrock of their functionality. Embedded systems, comprising both hardware and software elements intricately interwoven, play a pivotal role in shaping the landscape of autonomous driving (Allioui & Mourdi, 2023, Giannaros, et. al., 2023, Zhao, et. \n\nal., 2023). This exploration delves into the foundational concepts that define embedded systems in autonomous vehicles, examining their definition, components, the intricate interplay between hardware and software, and their crucial role in perception, decision-making, and control. Embedded systems are specialized computing systems designed to perform dedicated functions within a larger system or product (Barkalov, Titarenko & Mazurkiewicz, 2019, Marwedel, 2021). In the context of autonomous vehicles, these systems are the technological nerve center that enables the vehicle to perceive its surroundings, make informed decisions, and control its movements autonomously. The components of embedded systems in autonomous vehicles encompass both hardware and software elements.\n\nAutonomous vehicles are equipped with an array of sensors such as LiDAR, radar, cameras, and ultrasonic sensors. "}
{"doc85": "These sensors capture real-time data from the vehicle's surroundings, providing critical information for navigation and decision-making. These are the mechanisms responsible for translating decisions into actions. Examples include motors controlling steering, brakes, and accelerators. Actuators execute the commands generated by the embedded systems, allowing the vehicle to respond to its environment (Ayala & Mohd, 2021, Vargas, et. al., 2021, Yeong, et. al., 2021). This software interprets the data received from sensors, processes it, and generates control commands for the actuators. \n\nIt ensures the vehicle responds appropriately to its surroundings and follows a predefined trajectory. Embedded systems house sophisticated algorithms, often based on artificial intelligence and machine learning, to make complex decisions in real-time. These algorithms assess sensor data, predict potential scenarios, and determine the optimal course of action. The efficacy of embedded systems in autonomous vehicles lies in the seamless collaboration between their hardware and software components (Damaj, Yousafzai & Mouftah, 2022, Vermesan, et. al., 2021). The hardware captures and processes data from the vehicle's environment, while the software interprets this data, makes decisions, and translates them into actionable commands. This intricate interplay is crucial for the vehicle's ability to navigate diverse and dynamic scenarios. Embedded systems demand real-time processing capabilities to analyze sensor data and make splitsecond decisions (Munirathinam, 2020, Voudoukis, 2019). This requires a symbiotic relationship between highperformance hardware and efficient software to ensure responsiveness and accuracy. The communication between hardware and software components is characterized by a constant exchange of information. Sensors continuously feed data to the embedded software, which, in turn, generates commands for the actuators. This bidirectional communication ensures a continuous feedback loop for autonomous decision-making (Castelo-Branco, Cruz-Jesus & Oliveira, 2019, Zhou, et. al., 2020).\n\nEmbedded systems serve as the cognitive powerhouse of autonomous vehicles, orchestrating the three key elements of perception, decision-making, and control. Sensors embedded in the vehicle act as sensory organs, perceiving the external environment. LiDAR, radar, and cameras capture data on road conditions, obstacles, and other vehicles \n(Himeur, et. al., 2023, Ndlovu & Ayomoh, 2023, Raj & Surianarayanan, 2020). The embedded system processes this sensory input to create a comprehensive understanding of the surroundings. The processed data is then subjected to decision-making algorithms within the embedded system. These algorithms analyze the information, predict potential scenarios, and determine the best course of action. This may involve adjusting the vehicle's speed, changing lanes, or responding to unexpected obstacles. The final stage involves translating decisions into actions through control mechanisms. Actuators, under the command of the embedded system, adjust the vehicle's steering, acceleration, and braking to execute the chosen course of action. This seamless integration of perception, decision-making, and control ensures the vehicle's ability to navigate autonomously and respond to dynamic environments."}
{"doc86": "In conclusion, the foundational concepts of embedded systems in autonomous vehicles encompass a sophisticated interplay between hardware and software components. These systems serve as the intelligence hub, enabling vehicles to perceive their environment, make informed decisions, and execute precise control actions. As technology continues to advance, the refinement of these foundational concepts will play a pivotal role in shaping the future of autonomous driving, fostering safety, efficiency, and a transformative user experience.\n\n## 1.2. State-Of-The-Art Technologies Empowering Embedded Systems\n\nThe rapid evolution of autonomous vehicles relies on cutting-edge technologies that empower embedded systems to perceive, decide, and act in real-time (Bathla, et. al., 2022, Biswas & Wang, 2023, Vermesan, et. al., 2021). This exploration delves into the state-of-the-art technologies shaping the landscape of embedded systems in autonomous vehicles. The discussion spans advanced sensors for perception, actuators and control mechanisms, communication protocols enhancing vehicle connectivity, and the integration of artificial intelligence (AI) and machine learning (ML) \nalgorithms."}
{"doc87": "Perception is the cornerstone of autonomous driving, and advanced sensors play a pivotal role in enabling vehicles to interpret their surroundings accurately. These sensors provide a constant stream of real-time data, allowing the embedded systems to make informed decisions. Several key sensor technologies contribute to enhancing perception capabilities; LiDAR (Light Detection and Ranging sensors use laser beams to measure distances, creating detailed 3D \nmaps of the vehicle's surroundings (Gupta et. al., 2021, Sun, et. al., 2023, Zhao, et. al., 2023). These high-resolution maps provide crucial information about the environment, including the precise location of obstacles, pedestrians, and other vehicles. Radar sensors use radio waves to detect objects and assess their distance and speed. They excel in adverse weather conditions and low visibility scenarios, complementing the capabilities of other sensors. Radar technology contributes to the robustness of perception systems in various driving conditions. Vision-based systems, often comprising multiple cameras, capture visual information from the environment. Advanced computer vision algorithms analyze this visual data to identify and track objects, interpret road signs, and recognize lane markings. Cameras are essential for image recognition and scene understanding. Ultrasonic sensors use sound waves to detect objects in close proximity to the vehicle. They are particularly useful for parking assistance and obstacle detection at low speeds, enhancing the safety of autonomous vehicles during maneuvers \n(Obuhuma, Okoyo & McOyowo, 2019, Toa & Whitehead, 2020). Actuators and control mechanisms translate decisions made by embedded systems into physical actions, enabling the vehicle to navigate its environment autonomously. In autonomous vehicles, steer-by-wire systems eliminate the mechanical connection between the steering wheel and the wheels. Instead, electronic signals from the embedded system control the steering, allowing for precise adjustments and enhancing responsiveness. Brake-by-wire systems replace traditional hydraulic braking systems with electronic control. This technology allows for more precise control of braking forces, contributing to enhanced safety and responsiveness. Drive-by-wire systems electronically control the vehicle's acceleration and deceleration, eliminating the need for a physical connection between the accelerator pedal and the engine. This technology enhances the vehicle's overall controllability and responsiveness.\n\nConnectivity is a linchpin for the successful integration of autonomous vehicles into the broader transportation ecosystem. Communication protocols enable seamless data exchange between vehicles and infrastructure, fostering a connected and cooperative environment. Key communication technologies include; Vehicle-to-Vehicle (V2V) \nCommunication allows vehicles to share real-time information with each other, such as speed, position, and traffic conditions (Abbasi & Rahmani, 2023, Singh, 2023). This enables collaborative decision-making, improving overall traffic flow and enhancing safety by preventing collisions. Vehicle-to-Infrastructure (V2I) Communication establishes a connection between vehicles and infrastructure elements, such as traffic lights and road signs. This interaction provides vehicles with real-time information about traffic signals, construction zones, and other critical updates, optimizing route planning and decision-making. The deployment of 5G networks significantly enhances data transfer speeds and reduces latency, crucial for the real-time communication demands of autonomous vehicles. High-speed connectivity enables faster and more reliable information exchange, contributing to safer and more efficient autonomous driving.\n\nThe integration of AI and ML algorithms within embedded systems marks a paradigm shift in the capabilities of autonomous vehicles. These technologies enable vehicles to adapt, learn from experience, and make complex decisions in real-time. Key aspects of this integration include; AI algorithms fuse data from multiple sensors to create a comprehensive and accurate perception of the environment (Cunneen, Mullins & Murphy, 2019, Khayyam, et. al., 2020). "}
{"doc88": "This holistic approach enhances the reliability of the perception system, allowing the vehicle to make more informed decisions. Machine learning algorithms analyze vast datasets to predict potential scenarios and optimize path planning. \n\nThe embedded system uses this information to make decisions, adapting to dynamic environments and unforeseen obstacles. Deep learning techniques, such as convolutional neural networks (CNNs), excel in object recognition. These algorithms enable vehicles to identify and classify objects in their surroundings, distinguishing between pedestrians, vehicles, and other obstacles with high accuracy. Machine learning models can predict the behavior of other road users, anticipating their movements and intentions (Hansen, G\u00fcttel & Swart, 2019, Marwedel, 2021, Schranz, et. al., 2021). This predictive capability enhances the vehicle's ability to navigate complex traffic scenarios safely.\n\nIn conclusion, the state-of-the-art technologies empowering embedded systems in autonomous vehicles showcase a convergence of advanced sensors, actuators, communication protocols, and intelligent algorithms. As these technologies continue to evolve, they collectively contribute to the realization of safer, more efficient, and adaptive autonomous driving experiences. The ongoing integration of cutting-edge innovations positions embedded systems at the forefront of the autonomous vehicle revolution, driving the industry toward a future marked by unprecedented capabilities and transformative mobility solutions."}
{"doc89": "## 1.3. Emerging Trends In Embedded Systems For Autonomous Vehicles\n\nThe landscape of embedded systems in autonomous vehicles is continually evolving, marked by emerging trends that push the boundaries of innovation and redefine the capabilities of self-driving cars (Chai, Nie & Becker, 2021, Mallozzi, et. al., 2019, Zigure, 2023). This exploration delves into three prominent trends shaping the future of embedded systems in autonomous vehicles: the increasing reliance on artificial intelligence (AI) and machine learning, the integration of connectivity and edge computing, and the evolving adaptive and learning capabilities of embedded systems.\n\nThe integration of AI and machine learning stands as a pivotal trend in the evolution of embedded systems for autonomous vehicles. Traditional rule-based systems are giving way to more sophisticated and adaptive approaches, allowing vehicles to learn from data and experiences, thereby enhancing their decision-making capabilities. AI \nalgorithms enable sensor fusion, combining data from diverse sensors such as LiDAR, radar, and cameras. This holistic approach enhances the accuracy and reliability of perception systems, allowing the vehicle to form a comprehensive understanding of its surroundings (Gill, et. al., 2022, Grigorescu, et. al., 2020, Ma, et. al., 2020)."}
{"doc90": "Machine learning models are increasingly employed for path planning and decision-making. These algorithms analyze vast datasets to predict potential scenarios, optimize routes, and make decisions in real-time. The adaptability of machine learning enables vehicles to navigate complex and dynamic environments with improved efficiency. Deep learning techniques, including convolutional neural networks (CNNs), revolutionize object recognition. These algorithms enable the vehicle to distinguish and classify objects in its surroundings with unprecedented accuracy, including identifying pedestrians, other vehicles, and road signs. Machine learning models provide predictive analytics for anticipating the behavior of other road users. By learning from historical data and real-time observations, vehicles equipped with embedded systems can predict and respond to the movements and intentions of pedestrians, cyclists, and other vehicles on the road (Abou Elassad, et. al., 2020, Mozaffari, et. al., 2020, Yin, et. al., 2021).\n\nConnectivity and edge computing represent a transformative trend in embedded systems, enabling vehicles to communicate seamlessly with each other and with infrastructure elements. This trend is pivotal for achieving a connected and cooperative environment, fostering enhanced safety and efficiency. V2V communication facilitates the exchange of real-time information between vehicles on the road. This cooperative communication allows vehicles to share data on speed, position, and traffic conditions, contributing to collective decision-making and reducing the risk of collisions. V2I communication establishes a link between vehicles and infrastructure components such as traffic lights and road signs (Douch, et. al., 2022, Vermesan & Bacquet, 2022). This connectivity provides vehicles with up-to-date information on traffic signals, road conditions, and construction zones, optimizing route planning and decision-making. The deployment of 5G networks plays a crucial role in supporting the communication demands of autonomous vehicles. \n\nHigh-speed and low-latency connectivity enhance the reliability of real-time data exchange, ensuring vehicles receive timely information for decision-making. Edge computing involves processing data closer to the source, reducing latency and enhancing response times. In the context of autonomous vehicles, edge computing allows embedded systems to analyze and process data locally, enabling faster decision-making without relying solely on centralized cloud resources (Ahangar, et. al., 2021, Guevara & Auat Cheein, 2020, Hakak, et. al., 2023)."}
{"doc91": "The future of embedded systems in autonomous vehicles lies in their ability to adapt, learn, and evolve over time. This trend signifies a departure from static systems to dynamic architectures capable of continuous improvement. \n\nEmbedded systems are incorporating mechanisms for continuous learning, allowing vehicles to adapt to changing environments and scenarios. This adaptive learning ensures that the system becomes more proficient over time, refining its decision-making based on accumulated experience. Creating feedback loops within embedded systems enables them to learn from real-world outcomes. By analyzing the consequences of decisions and actions, the system can iteratively improve its algorithms, enhancing its ability to navigate diverse and challenging situations (Koci\u0107, Jovi\u010di\u0107 & Drndarevi\u0107, 2019, Liu, et. al., 2019). Adaptive embedded systems also extend to understanding and adapting to user preferences and behavior. These systems can tailor driving styles, comfort settings, and in-cabin experiences based on individual user habits, providing a personalized and user-centric driving experience. Building adaptive capabilities into embedded systems includes enhancing fault tolerance and self-healing mechanisms. This ensures that the system can identify and address issues in real-time, mitigating the impact of hardware or software failures without compromising safety.\n\nIn conclusion, the emerging trends in embedded systems for autonomous vehicles reflect a paradigm shift towards more intelligent, connected, and adaptive driving experiences. The increasing reliance on AI and machine learning, coupled with connectivity and edge computing, positions embedded systems at the forefront of the autonomous vehicle revolution. As these trends unfold, the adaptive and learning capabilities of embedded systems pave the way for a future where autonomous vehicles not only navigate roads but continually evolve to meet the dynamic challenges of the transportation landscape."}
{"doc92": "## 1.4. Persistent Challenges In Adoption\n\nThe advent of embedded systems in autonomous vehicles promises a transformative shift in the automotive industry, but this journey is not without its persistent challenges. As the technology evolves, three key hurdles continue to impede the widespread adoption of embedded systems in autonomous vehicles: safety concerns, cybersecurity threats to embedded systems, and regulatory frameworks with compliance issues. Safety is a paramount concern in the development and deployment of autonomous vehicles. The reliance on embedded systems for critical functions such as perception, decision-making, and control introduces challenges that demand rigorous evaluation and mitigation strategies (Lempp, & Siegfried, 2022, Paiva, et. al., 2021). Autonomous vehicles heavily depend on algorithms, including those powered by artificial intelligence and machine learning, for real-time decision-making. The complexity of real-world scenarios poses challenges in ensuring that these algorithms can accurately perceive and respond to various situations, raising concerns about the robustness of safetycritical functions (Andronie, et. al., 2021, Shi, et. al., 2020, Bachute & Subhedar, 2021).\n\nThe development of embedded systems involves addressing ethical considerations related to decision-making in unforeseen scenarios. Determining how vehicles should prioritize the safety of occupants, pedestrians, and other road users in critical situations is a challenging ethical dilemma that requires careful consideration and consensus within the industry. Embedded systems heavily rely on sensor technologies for perception. Ensuring the reliability of these sensors under diverse environmental conditions, such as adverse weather or challenging lighting, and implementing effective redundancy mechanisms are ongoing challenges in enhancing the safety of autonomous vehicles. The transition between autonomous and manual driving modes introduces challenges in designing effective human-machine interfaces. Ensuring that drivers can seamlessly take control of the vehicle and understand the system's capabilities and limitations is crucial for maintaining safety during transitions."}
{"doc93": "The increasing integration of connectivity and sophisticated software in embedded systems exposes autonomous vehicles to cybersecurity threats. Safeguarding these systems from malicious activities is a critical challenge that requires constant vigilance and proactive measures. Embedded systems are susceptible to cyber-attacks that exploit vulnerabilities in software and communication protocols. As vehicles become more connected, the potential for unauthorized access, data breaches, and manipulation of critical functions poses a significant threat to the safety and integrity of autonomous driving (Chattopadhyay, Lam & Tavva, 2020, Kim, et. al., 2021, Sun, Yu, & Zhang, 2021). The collection and transmission of large volumes of data by embedded systems raise concerns about data privacy. Protecting sensitive information, such as location data and personal preferences, from unauthorized access is a crucial aspect of building trust in autonomous vehicles. Secure Over-the-Air (OTA) Updates are essential for keeping embedded systems up-to-date with the latest software and security patches. However, ensuring the security of these updates to prevent tampering and unauthorized modifications is a persistent challenge, as compromised updates can potentially lead to system malfunctions or unauthorized control. The automotive industry faces the challenge of establishing collaborative security measures and standards to address cybersecurity threats effectively. Building a collective defense against cyber threats requires cooperation among manufacturers, technology providers, and regulatory bodies to establish robust security frameworks.\n\nThe deployment of autonomous vehicles is subject to a complex regulatory landscape that varies across regions. \n\nAchieving global regulatory alignment and ensuring compliance with existing and evolving standards pose challenges that impact the pace of adoption. The absence of unified global standards for autonomous vehicles and embedded systems creates challenges for manufacturers and developers. Divergent regulations across regions hinder the seamless deployment of autonomous vehicles, necessitating efforts to establish international standards that promote interoperability and safety. Developing comprehensive testing and certification protocols for embedded systems in autonomous vehicles is a formidable task. Establishing standardized procedures for evaluating the safety and performance of these systems is crucial for gaining regulatory approval and ensuring public confidence (Bezai, et. al., \n2021, Taeihagh & Lim, 2019, Tan & Taeihagh, 2021). The introduction of autonomous vehicles raises complex questions regarding legal liability in the event of accidents or failures. Establishing clear legal frameworks and insurance policies that address liability issues associated with autonomous driving is a persistent challenge requiring collaboration between legal experts, policymakers, and the automotive industry. Regulatory challenges also extend to public perception and acceptance. Building trust in autonomous vehicles necessitates transparent communication about safety measures, data privacy, and regulatory compliance. Regulatory bodies play a role in fostering an environment where users feel confident in the safety and reliability of embedded systems in autonomous vehicles. In conclusion, the persistent challenges in the adoption of embedded systems in autonomous vehicles revolve around safety concerns, cybersecurity threats, and regulatory frameworks. Addressing these challenges requires a multidisciplinary approach, involving collaboration between technology developers, regulatory bodies, policymakers, and the public. As the industry continues to navigate these challenges, the evolution of embedded systems in autonomous vehicles will be shaped by advancements in technology, proactive cybersecurity measures, and the establishment of robust regulatory frameworks that prioritize safety and public trust."}
{"doc94": "## 1.5. Addressing Challenges: Current Approaches And Solutions\n\nThe challenges surrounding the adoption of embedded systems in autonomous vehicles are met with ongoing efforts to innovate, enhance safety mechanisms, fortify cybersecurity measures, and establish comprehensive policy recommendations and regulatory frameworks. As the automotive industry continues to evolve, these current approaches serve as critical pillars for overcoming obstacles and advancing the deployment of autonomous vehicles \n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\n\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion techniques. By integrating diverse sensor technologies and ensuring multiple layers of sensing capabilities, vehicles can build a more comprehensive and accurate perception of their environment. This redundancy not only improves the reliability of embedded systems but also provides fail-safes in the event of sensor malfunctions. Innovations in ADAS play a pivotal role in bridging the transition between conventional and autonomous driving. Features such as adaptive cruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual integration of autonomous functionalities. These systems contribute to enhanced safety by assisting drivers and mitigating risks, paving the way for the broader acceptance of autonomous technologies. The development and testing of autonomous systems involve extensive simulations and controlled environments. "}
{"doc95": "Simulated scenarios allow engineers to expose embedded systems to a wide range of situations, including rare and dangerous events, to validate their responses. This approach aids in refining algorithms, improving safety mechanisms, and ensuring the robustness of autonomous vehicles before real-world deployment. Enhancements in HMI design focus on creating intuitive interfaces that facilitate effective communication between the vehicle and its occupants. Clear communication of the system's intentions, status, and the ability to hand over control to the driver when necessary, contribute to building trust and ensuring safety during autonomous driving (Fremont, et. al., 2020, Rosique, et. al., 2019, Stach, et. al., 2021).\n\nTo combat cybersecurity threats, embedded systems in autonomous vehicles employ robust encryption methods and secure communication protocols. Encryption ensures that data exchanged between vehicle components and external entities remains confidential and tamper-proof, reducing the risk of unauthorized access and manipulation. Embedded systems integrate intrusion detection systems that continuously monitor network activity and behavior. These systems can detect anomalies and potential cyber threats, triggering immediate responses to prevent unauthorized access or malicious activities. Real-time monitoring contributes to the early identification and mitigation of cybersecurity risks. Emphasizing secure software development practices is crucial in mitigating vulnerabilities in embedded systems. \n\nDevelopers follow industry best practices, conduct thorough code reviews, and implement secure coding standards to minimize the risk of software-related security flaws. Regular software updates and patches address identified vulnerabilities promptly. The automotive industry actively engages in collaborative initiatives to address cybersecurity challenges collectively. Organizations such as the Automotive Information Sharing and Analysis Center (Auto-ISAC) \nfacilitate information sharing among manufacturers, suppliers, and stakeholders. This collaborative approach enables the industry to stay ahead of emerging cybersecurity threats and collectively enhance the security posture of embedded systems. Addressing regulatory challenges involves international standardization efforts to create uniform guidelines for autonomous vehicles. Organizations such as the United Nations Economic Commission for Europe (UNECE) work towards establishing a global framework for the deployment of autonomous vehicles, encompassing safety, cybersecurity, and interoperability standards. Regulatory bodies recognize the need for a gradual evolution of regulations to accommodate the advancements in autonomous technologies. Rather than imposing rigid frameworks, regulators are adopting flexible approaches that allow for continuous adaptation to technological developments while prioritizing safety and public confidence. Policies are being developed to address ethical dilemmas in autonomous driving. Establishing clear ethical guidelines for decision-making algorithms and defining accountability frameworks helps navigate complex scenarios. These guidelines ensure transparency in how autonomous systems prioritize safety and handle unforeseen situations. Building public awareness and engagement is a key aspect of addressing regulatory challenges. Governments and regulatory bodies actively communicate with the public to explain the benefits, risks, and regulatory measures surrounding autonomous vehicles. Public input and feedback contribute to the development of regulations that align with societal expectations."}
{"doc96": "In conclusion, addressing the challenges associated with embedded systems in autonomous vehicles involves a multifaceted approach encompassing innovations in safety mechanisms, robust cybersecurity measures, and the development of effective policy recommendations and regulatory frameworks. As technology continues to advance, these current approaches serve as crucial foundations for fostering the safe and responsible deployment of autonomous vehicles. Collaborative efforts between industry stakeholders, regulators, and the public are essential to navigate the complexities and ensure the successful integration of autonomous technologies into our transportation systems.\n\n## 1.6. Future Directions Of Embedded Systems In Autonomous Vehicles\n\nThe trajectory of embedded systems in autonomous vehicles is poised for transformative advancements, driven by the pursuit of more robust, adaptive, and fault-tolerant architectures. As the automotive industry continues to push the boundaries of innovation, the future directions of embedded systems revolve around evolving architectures, implementing fault-tolerant designs with redundancy mechanisms, and anticipating advancements that propel autonomy towards widespread deployment (Divakarla, et. al., 2019, Miller, et. al., 2023, Telli, et. al., 2023)."}
{"doc97": "The future of embedded systems in autonomous vehicles is likely to witness a shift towards distributed and edge computing architectures. This evolution aims to distribute processing tasks across various components within the vehicle and leverage edge computing capabilities. By decentralizing computation, vehicles can enhance real-time decision-making, reduce latency, and improve overall system efficiency. Future embedded systems will likely adopt modular designs, allowing for easier integration and upgradability. Modular components enable manufacturers to adapt to evolving technologies by replacing or upgrading individual modules, enhancing the overall lifespan and capabilities of autonomous vehicles. This approach facilitates seamless integration of new sensors, processors, and algorithms as they become available. The integration of advanced communication technologies, including 5G and beyond, is anticipated to play a crucial role in future embedded systems. High-speed, low-latency communication is essential for real-time data exchange between vehicles and infrastructure, enabling faster decision-making and enhancing the overall connectivity and coordination of autonomous vehicles within smart transportation ecosystems. The future of embedded systems in autonomous vehicles involves the integration of adaptive learning architectures. These architectures go beyond traditional rule-based systems, allowing vehicles to continuously learn and adapt to their operating environments. Adaptive learning facilitates improved perception, decision-making, and the ability to navigate complex and dynamic scenarios with increased efficiency. To enhance safety and fault tolerance, future embedded systems will likely incorporate more redundant sensor systems. \n\nRedundancy in critical sensors, such as LiDAR, radar, and cameras, ensures that even if one sensor fails or provides inaccurate data, the vehicle can rely on alternative sensors for accurate perception and decision-making. Future embedded systems may prioritize decentralized decision-making to improve fault tolerance. Instead of relying on a central processing unit for all decision-making, vehicles could distribute decision-making tasks across multiple computing units. This approach reduces the impact of a single point of failure and enhances the overall robustness of the system. Predictive maintenance and failure prediction algorithms will become integral components of future embedded systems. These algorithms analyze data from various vehicle components to identify potential failures before they occur. Proactive maintenance based on predictive analytics ensures the timely replacement or repair of components, minimizing the risk of unexpected system failures.\n\nFuture embedded systems may feature advanced health monitoring capabilities to continuously assess the overall health and performance of the autonomous system. This monitoring includes self-diagnosis of embedded components, ensuring that any anomalies or deterioration in performance are detected early, allowing for preventive measures to be taken. The future of embedded systems in autonomous vehicles is expected to witness advancements towards achieving higher levels of autonomy (Abdulkarem, et. al., 2020, Anikwe, et. al., 2022, Marques, et. al., 2019). Level 4 and Level 5 autonomy, where vehicles can operate without human intervention in specific or all scenarios, respectively, are anticipated goals. Achieving these levels requires more sophisticated embedded systems capable of handling complex urban environments and diverse driving conditions. The widespread deployment of autonomous vehicles is likely to focus on urban mobility solutions. Shared autonomous fleets, ride-hailing services, and integration with public transportation systems are anticipated to play a significant role in addressing urban congestion and providing efficient, on-demand mobility solutions. The future deployment of autonomous vehicles will involve a more human-centric approach in system design. User experience, safety, and the integration of human preferences will be central considerations. Human-machine interfaces (HMIs) will evolve to ensure clear communication between the vehicle and its occupants, fostering trust and acceptance of autonomous technologies. Anticipated advancements in autonomy and widespread deployment will also rely on the development of comprehensive regulatory frameworks and industry standards. Collaboration between regulatory bodies, industry stakeholders, and policymakers will be essential to establish guidelines that ensure the safety, reliability, and ethical use of autonomous vehicles on a global scale."}
{"doc98": "In conclusion, the future directions of embedded systems in autonomous vehicles point towards the evolution of architectures for enhanced adaptability, fault-tolerant designs with redundancy mechanisms, and anticipated advancements in autonomy leading to widespread deployment. As the automotive industry continues to innovate, these directions pave the way for a future where autonomous vehicles seamlessly integrate into urban environments, prioritize user experience, and contribute to more sustainable and efficient transportation systems.\n\n## 2. Recommendation And Conclusion\n\nIn the exploration of embedded systems in autonomous vehicles, our comprehensive review has unveiled critical trends, persistent challenges, and promising future directions. The foundational concepts highlighted the intricate interplay between hardware and software, emphasizing their pivotal role in perception, decision-making, and control. State-ofthe-art technologies showcased the integration of advanced sensors, actuators, communication protocols, and AI \nalgorithms, propelling the capabilities of embedded systems in autonomous driving."}
{"doc99": "We delved into the challenges, addressing safety concerns, cybersecurity threats, and regulatory frameworks. Innovations in safety mechanisms, cybersecurity measures, and evolving policy recommendations emerged as crucial pillars in mitigating these challenges. Moreover, we examined emerging trends, such as the increasing reliance on AI, connectivity, and adaptive learning capabilities, foreseeing a future marked by more intelligent, connected, and adaptive autonomous vehicles. For researchers, this review underscores the need for continued exploration into the evolving architectures of embedded systems. The call is to deepen our understanding of adaptive learning mechanisms, faulttolerant designs, and the integration of emerging technologies. Investigating the human-machine interaction aspects and ethical considerations in decision-making algorithms will be vital for advancing the field.\n\nPractitioners are encouraged to adopt and contribute to the innovations discussed, prioritizing safety, security, and user-centric design. Emphasizing modular and upgradable components, as well as engaging in collaborative initiatives for cybersecurity, will be instrumental in the successful implementation of embedded systems in autonomous vehicles. \n\nPolicymakers play a central role in facilitating the widespread deployment of autonomous vehicles. The review highlights the importance of flexible regulatory frameworks that evolve with technological advancements. Encouraging international collaboration and standardization efforts can create a conducive environment for the industry to thrive while ensuring the safety and ethical considerations are at the forefront."}
{"doc100": "The journey towards fully autonomous vehicles requires a collective effort from researchers, practitioners, and policymakers. Collaboration is the cornerstone for addressing challenges, sharing insights, and fostering innovation. As we stand at the intersection of technology and mobility, the call to action is clear: Researchers from diverse fields, including computer science, engineering, ethics, and law, should collaborate to tackle the multifaceted challenges of embedded systems in autonomous vehicles. A holistic approach is essential for addressing technical, ethical, and regulatory dimensions. Practitioners should engage in active knowledge exchange platforms, sharing best practices, lessons learned, and emerging technologies. This collaborative ecosystem ensures a continuous flow of innovation and accelerates the development and deployment of safe and efficient autonomous vehicles. Policymakers must work collaboratively to establish global regulatory alignment. By fostering international standards and harmonizing regulations, they can create a conducive environment that encourages innovation while ensuring a consistent and safe deployment of autonomous vehicles worldwide.\n\nAll stakeholders should prioritize transparent communication and engage with the public. Building trust and understanding the benefits and challenges of autonomous vehicles are paramount. Public input should be incorporated into the regulatory frameworks, ensuring that policies align with societal expectations. In conclusion, the comprehensive review of embedded systems in autonomous vehicles paints a vivid picture of a transformative future. \n\nBy leveraging the insights, recommendations, and collaborative spirit outlined in this review, the collective efforts of researchers, practitioners, and policymakers can drive the automotive industry toward a safer, more connected, and autonomous future. The call to action is not just an invitation but a commitment to shaping a transportation landscape that is not only technologically advanced but also ethical, inclusive, and sustainable."}
{"doc101": "[21] Douch, S., Abid, M. R., Zine-Dine, K., Bouzidi, D., & Benhaddou, D. (2022). Edge computing technology enablers: A \nsystematic lecture study. IEEE Access, 10, 69264-69302.\n\n[22] Fayyad, J., Jaradat, M. A., Gruyer, D., & Najjaran, H. (2020). Deep learning sensor fusion for autonomous vehicle perception and localization: A review. Sensors, 20(15), 4220.\n\n[23] Fremont, D. J., Kim, E., Pant, Y. V., Seshia, S. A., Acharya, A., Bruso, X., ... & Mehta, S. (2020, September). Formal scenario-based testing of autonomous vehicles: From simulation to the real world. In 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC) (pp. 1-8). IEEE."}
{"doc102": "URBAN LANDSCAPE: A REVIEW: ANALYZING \nIMPLICATIONS FOR TRAFFIC, URBAN PLANNING, AND \nTHE ENVIRONMENT\nOmamode Henry Orieno1, Ndubuisi Leonard Ndubuisi2, Valentine Ikenna Ilojianya3, Preye Winston Biu4, & Beryl Odonkor5 1University of Bedfordshire, UK\n2Spacepointe Limited Rivers State, Nigeria 3Mechanical Engineering, the University of Alabama, USA\n4INEC Nigeria 5McKinsey and Company, Texas, USA\n___________________________________________________________________________\n*Corresponding Author: Omamode Henry Orieno Corresponding Author Email: orienohenry@gmail.com Article Received: 21-10-23 **Accepted:** 15-12-23 **Published:** 13-01-24 Licensing Details: Author retains the right of this article. The article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 License (http://www.creativecommons.org/licences/by-nc/4.0/) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the Journal open access page.\n\n___________________________________________________________________________\n\n## Abstract"}
{"doc103": "This study presents a comprehensive analysis of the impact of autonomous vehicles (AVs) on urban landscapes, focusing on traffic management, urban planning, and environmental sustainability in the United States. The main objectives were to explore the evolution of AV technology, assess its current state and innovations, and understand its implications for urban environments. Employing a systematic literature review and content analysis, the study analyzed data from peer-reviewed academic journals, industry reports, and government publications, focusing on literature published from 2007 to 2023. Key findings indicate that AVs have the potential to significantly alter urban traffic dynamics, reducing congestion and enhancing road safety. In urban planning, AVs necessitate a reevaluation of infrastructure, potentially leading to more efficient land use and reduced parking needs. Environmentally, AVs offer the promise of reduced emissions and improved air quality, especially when integrated with electric vehicle technology. However, these benefits are contingent upon overcoming technological challenges, ensuring public safety, and developing effective regulatory frameworks. The study envisions a future urban landscape where AVs contribute to more efficient, safer, and environmentally sustainable environments. It recommends comprehensive policy and industry strategies for the successful integration of AVs, emphasizing the need for standardized safety regulations, incentivizing AV adoption, and ensuring equitable access. Concluding insights suggest that while AVs hold significant potential for reshaping urban mobility, their successful integration requires addressing technological, policy, and societal challenges. Future research should focus on the long-term impacts of AVs on urban landscapes, exploring ethical and legal implications, and their role in broader sustainability goals.\n\nKeywords: Autonomous Vehicles, Urban Planning, Traffic Management, Environmental Sustainability. \n\n___________________________________________________________________________"}
{"doc104": "## Introduction The Advent Of Autonomous Vehicles: Transforming Urban Mobility.\n\nThe emergence of autonomous vehicles (AVs) marks a pivotal transformation in urban mobility, reshaping the vehicular landscape and promising significant changes in transportation dynamics. This technological revolution, characterized by the shift from human-operated to self-driving vehicles, holds the potential to address some of the most pressing challenges of urban mobility, including traffic congestion, environmental degradation, and accessibility (Kassens-Noor, Wilson, & Yigitcanlar, 2021). The historical trajectory of AVs reflects a transition from mere conceptualization to tangible reality, with current prototypes and proofs-of-concept driving substantial changes in long-term urban planning (Szab\u00f3, 2020). This evolution underscores the shift from traditional vehicular paradigms towards a more integrated, intelligent urban transport system. The promise of AVs extends beyond mere technological advancement; it encompasses a broader socio-technical transition, intertwining with various aspects of urban life and infrastructure (Szab\u00f3, 2020). The potential benefits of AVs in urban settings are manifold. Firstly, they offer a safer transportation alternative, potentially reducing the number of accidents and fatalities caused by human error. Secondly, AVs can significantly decrease traffic congestion through efficient route management and reduced need for parking spaces, thereby enhancing the overall efficiency of urban transportation systems (Kassens-Noor, Wilson, & Yigitcanlar, 2021). Furthermore, the environmental impact of AVs cannot be overstated; they hold the promise of reducing emissions through optimized driving patterns and the potential integration with electric vehicle technology. However, the integration of AVs into urban landscapes is not without challenges. The transition to autonomous mobility necessitates a reevaluation of urban infrastructure and planning. Cities must adapt to accommodate the unique requirements of AVs, such as the need for advanced communication systems and the reconfiguration of road networks (Szab\u00f3, 2020). Additionally, there are concerns regarding the equitable distribution of AV benefits, ensuring that all areas and demographics are adequately served. The socio-technical scenarios surrounding the implementation of AVs in urban environments are diverse. They range from a gradual, incremental integration that enhances existing public transport systems to a more radical transformation leading to a predominantly autonomous urban transport landscape (Szab\u00f3, 2020). These scenarios are not only shaped by technological advancements but also by policy decisions, public acceptance, and the readiness of urban infrastructure to adapt to this new mode of transportation. In conclusion, the advent of autonomous vehicles is set to revolutionize urban mobility, offering solutions to longstanding challenges while also presenting new ones. The successful integration of AVs into urban landscapes hinges on a delicate balance between technological innovation, policy-making, and urban planning. As cities evolve with these technological advancements, the role of AVs in shaping future urban mobility becomes increasingly significant, promising a safer, more efficient, and environmentally sustainable transportation landscape. Defining the Review Scope: Autonomous Vehicles and Their Urban Impact.\n\nThe integration of autonomous vehicles (AVs) into urban landscapes is a transformative development with far-reaching implications for urban planning, traffic management, and environmental sustainability. This review aims to explore the multifaceted impact of AVs on urban settings, focusing on their influence on residential locality choices, traffic network capacity, and highway capacity in mixed traffic environments. The advent of AVs is poised to redefine urban mobility, influencing where and how people choose to live. Hiramatsu (2022) highlights that the introduction of AVs can lead to a shift in residential patterns, with a tendency for people to relocate towards suburbs that are less wellserved by public transportation. This phenomenon is attributed to the reduced generalized transportation costs associated with AVs, which make commuting from distant areas more feasible and attractive. The study underscores the need for urban planners to consider these changing dynamics in residential choices, as they have significant implications for urban development and policy-making. The impact of AVs on urban traffic network capacity is another critical area of investigation. Lu, Tettamanti, H\u00f6rcer, and Varga (2019) conducted a detailed simulation study to assess how varying percentages of AVs affect the macroscopic fundamental diagram (MFD) of urban traffic networks. Their findings indicate a clear improvement in road capacity with the increasing penetration of AVs. This capacity enhancement is crucial for mitigating traffic congestion in urban areas, suggesting that AVs could be instrumental in creating more efficient and fluid urban traffic systems. Furthermore, the integration of AVs into mixed traffic environments presents unique challenges and opportunities for highway capacity. Abdulsattar, Siam, and Wang (2020) utilized an agentbased modeling approach to characterize the impacts of autonomous driving on highway capacity. Their research reveals that the inclusion of AVs in traffic streams has the potential to significantly increase highway capacity, especially at higher market penetration levels. This increase in capacity could lead to more efficient highway utilization, reducing congestion and enhancing overall traffic flow. The implications of these findings are profound for urban planners and policymakers. The potential shift in residential locality choices necessitates a reevaluation of urban development strategies, with a focus on ensuring equitable access to transportation and mitigating potential suburban sprawl. Additionally, the enhanced traffic network and highway capacities offered by AVs call for a reimagining of urban traffic management systems, embracing the opportunities presented by this new technology to create more sustainable and efficient urban environments. In summary, the integration of autonomous vehicles into urban landscapes is a complex process with significant implications for urban planning, traffic management, and environmental sustainability. This review aims to provide a comprehensive understanding of these implications, offering insights into how AVs can be harnessed to create more livable, efficient, and sustainable urban spaces. Historical Progression of Autonomous Vehicle Technologies The historical progression of autonomous vehicle (AV) technologies is a narrative of rapid evolution and innovation, marked by significant advancements in various domains crucial to the realization of fully autonomous driving. This journey, from the early conceptual stages to the current state of near-level 5 automation, reflects a complex interplay of technological, regulatory, and societal factors."}
{"doc105": "The early stages of AV development focused on foundational technologies such as environment detection, pedestrian detection, path planning, motion control, and vehicle cybersecurity. Parekh et al. (2022) provide a comprehensive review of these technologies, emphasizing the importance of accurate positioning and the need to address uncertainties like pedestrian behavior and diverse road conditions. The progression in these areas has been instrumental in advancing AVs from rudimentary automated functions to more sophisticated levels of autonomy. As AV technologies evolved, the focus shifted towards enhancing the electronic design of AVs, particularly in automated driving systems (ADS). Kim et al. (2021) discuss the evolution of ADS, which centralizes navigation systems, path decision-making, surrounding perception, and control systems. This evolution has seen AVs progress from vehicles requiring significant human interaction to those capable of conditional automation. However, achieving full automation (Level 5) remains a challenge, with ongoing research addressing various technological and regulatory hurdles. The integration of connected and autonomous vehicles (CAVs) into the broader transportation ecosystem marks a significant milestone in the evolution of AV technologies. Ahmed et al. (2022) highlight the advances in connected, autonomous, and connected autonomous vehicles, focusing on the role of advanced driving assistance systems (ADAS). These systems, which include sensors like Radar and LiDAR, vehicle-to-vehicle and vehicle-to-infrastructure communication systems, and adaptive cruise control technologies, are pivotal in enhancing the safety, efficiency, and overall functionality of AVs. The progression of AV technologies has also been influenced by regulatory and legislative developments. As Ahmed et al. (2022) note, the practical application of AV technologies necessitates a thorough understanding of state and federal guidance, legislation, and regulations. These regulatory frameworks play a critical role in shaping the deployment and integration of AVs into existing transportation networks. Moreover, the impact of AVs on traffic congestion, safety, fuel cost savings, and smart parking has been a key area of focus. The potential benefits of AVs in reducing traffic congestion and enhancing safety are significant, promising a future of stress-free, efficient, and environmentally friendly travel. However, realizing these benefits depends on the successful market penetration of AV technologies and their acceptance by end-users. In summary, the historical progression of autonomous vehicle technologies is a story of continuous innovation and adaptation. From the development of core technologies to the integration of AVs into the transportation ecosystem, this journey reflects the dynamic interplay of technological advancements, regulatory frameworks, and market forces. As AV technologies continue to evolve, they hold the promise of transforming the transportation landscape, offering safer, more efficient, and sustainable mobility solutions.\n\n## Aim And Objectives Of The Study.\n\nThe aim of this study is to comprehensively analyze and understand the impact of autonomous vehicles (AVs) on urban landscapes, particularly focusing on their implications for traffic management, urban planning, and environmental sustainability in the United States. The objectives of the study are; 1. To assess the current state and innovations in autonomous vehicle systems. 2. To understand the impact of AVs on urban traffic and planning."}
{"doc106": "The search strategy involved using a combination of keywords and phrases related to autonomous vehicles and their impact on urban environments. Search terms included \"autonomous vehicles,\" \"urban planning,\" \"traffic management,\" \"environmental impact,\" \"urban mobility,\" and \"smart cities.\" Boolean operators (AND, OR) were used to combine these terms effectively. The search was limited to documents published in English from 2007 to 2023, to ensure relevance and timeliness of the data. Inclusion and Exclusion Criteria for Relevant Literature The inclusion and exclusion criteria for selecting relevant literature were meticulously defined to ensure the comprehensiveness and relevance of the study. For inclusion, the study focused on peer-reviewed articles that specifically addressed autonomous vehicle technology, its impact on urban planning, traffic management, and environmental sustainability. The literature needed to provide empirical data, case studies, or theoretical frameworks that were directly relevant to the application of AVs in urban settings. To ensure the study's contemporary relevance, only publications from 2007 to 2023 were considered. On the exclusion front, the study omitted nonpeer-reviewed articles, opinion pieces, editorials, and any studies that solely focused on the technological aspects of AVs without a direct link to urban planning or environmental impacts. Additionally, publications in languages other than English were excluded to maintain consistency and coherence in data analysis. Selection Criteria The selection process involved an initial screening of titles and abstracts to identify potentially relevant articles. This was followed by a full-text review to ascertain the suitability of the articles based on the inclusion and exclusion criteria. Priority was given to studies that offered unique insights or significant findings related to the integration of AVs in urban environments. Data Analysis Data analysis in this study was conducted through a methodical content analysis approach. This involved a thorough examination of the selected literature to extract and synthesize key information, such as study objectives, methodologies, findings, and conclusions. The process was aimed at identifying recurring themes and patterns, particularly those related to the impact of autonomous vehicles on urban traffic, planning, and the environment. This synthesis of data provided a comprehensive overview of the current state of knowledge in the field, highlighting both the convergence and divergence in findings across different studies. The analysis culminated in drawing informed conclusions based on the synthesized data, which subsequently guided the formulation of recommendations and directions for future research. This approach ensured a structured and in-depth understanding of the multifaceted implications of autonomous vehicles in urban settings.\n\n## Literature Review Fundamental Concepts In Autonomous Vehicle Technology\n\nThe advent of autonomous vehicles (AVs) has introduced a paradigm shift in urban mobility, underpinned by a range of fundamental technological concepts. These concepts, which span from trajectory tracking to the broader social implications of AVs, are crucial in understanding the transformative impact of AVs in urban environments. One of the core technological aspects of AVs is their impact on the urban traffic model, particularly the Macroscopic Fundamental Diagram (MFD). Lu and Tettamanti (2018) explore how the integration of AVs into traditional traffic models influences the MFD, a critical tool for strategic traffic planning and real-time traffic control. Their research indicates that the inclusion of AVs, depending on their percentage in the traffic mix and their level of autonomy, significantly alters the urban MFD. This alteration has profound implications for urban traffic management, suggesting that AVs can enhance traffic flow and reduce congestion in urban areas. Another fundamental concept in AV technology is trajectory tracking, which is essential for the effective and stable control of AVs. Li, Li, and Zhang (2021) provide a comprehensive review of state-of-the-art trajectory tracking methods for AVs. They highlight the importance of advanced trajectory tracking controllers in ensuring that AVs can accurately follow predetermined paths, a critical requirement for safe and efficient autonomous driving. The development of these tracking methods is a testament to the technological advancements in the field of AVs, showcasing the progress towards achieving higher levels of vehicle autonomy. Beyond the technical aspects, the social implications of AVs, particularly in terms of time, are also a fundamental concept. McCarroll and Cugurullo (2022) delve into how the shift in urban transport dynamics brought about by AVs impacts the temporal experience of individuals. Their study theorizes that the time window created by AVs presents contrasting narratives regarding the experience of time within these vehicles. This perspective is crucial in understanding how AVs not only change the physical aspects of urban mobility but also influence the social dynamics of urban life, including the perception and utilization of time. In summary, the fundamental concepts in autonomous vehicle technology encompass a broad range of aspects, from the technical to the social. The impact of AVs on urban traffic models, the advancements in trajectory tracking methods, and the social implications of AVs in terms of time are all critical in understanding the transformative potential of AVs in urban environments. As AV technology continues to evolve, these concepts will play a pivotal role in shaping the future of urban mobility, offering insights into how cities can adapt to and benefit from this emerging technology. System Architecture of Autonomous Vehicles in Urban Environments. The system architecture of autonomous vehicles (AVs) in urban environments is a complex and multifaceted domain, encompassing various components essential for safe and efficient navigation. This architecture is designed to address the unique challenges posed by urban settings, such as dynamic traffic conditions, pedestrian interactions, and diverse road infrastructures."}
{"doc107": "Chen and Fraichard (2007) present a novel navigation architecture for AVs in urban environments, emphasizing the criticality of motion safety in these dynamic and partially known settings. Their architecture is built upon an efficient publish/subscribe-based middleware system, which facilitates modularity in design and the seamless integration of key functional components required for autonomous navigation. These components include perception, localization, mapping, real-time motion planning, and motion tracking. The architecture's ability to make safe motion decisions in real-time is particularly crucial, considering the unpredictable nature of urban environments with moving objects like other vehicles and pedestrians. In a related work, Chen and Fraichard (2008) delve deeper into the motion components of their proposed architecture. They focus on the real-time aspects of motion planning and tracking, which are vital for the autonomous navigation of car-like vehicles in urban settings. The architecture's design allows for the adaptation to various urban scenarios, ensuring that the AVs can navigate safely and efficiently, even in complex and unforeseen situations. Experimental results, carried out on both simulation platforms and actual vehicles, demonstrate the effectiveness of this architecture in managing the intricacies of urban driving. Lin, Hsu, Zhang, and Lin (2020) contribute to this field by exploring adaptive trajectory generation for AVs in urban environments. Their methodology is centered on adapting the vehicle's trajectory based on information detected by sensors, enabling the AV to safely navigate in mixed traffic conditions alongside human-driven vehicles. They construct rule-based conditions and a system architecture that takes into account vehicle dynamics and detected information. This approach is validated through simulation studies in various scenarios, including lane changes and unexpected events like roadside stops or cut-ins by other vehicles. \n\nThe results show that AVs can adaptively avoid collisions with obstacles by means of lanechanging or braking, based on the proposed system architecture.\n\nIn summary, the system architecture of AVs in urban environments is a critical area of research and development, addressing the unique challenges of urban mobility. The architectures proposed by Chen and Fraichard, and the adaptive trajectory generation methodology by Lin et al., represent significant advancements in this field. These architectures ensure that AVs can navigate safely and efficiently in urban settings, adapting to dynamic conditions and making real-time decisions in response to unforeseen events. As AV technology continues to evolve, these architectural frameworks will play a pivotal role in shaping the future of urban transportation, offering promising solutions for safe, efficient, and intelligent mobility in cities."}
{"doc108": "## Operational Modes And Interaction With Urban Infrastructure\n\nThe operational modes of autonomous vehicles (AVs) and their interaction with urban infrastructure are pivotal in shaping the future of urban mobility. These aspects determine how AVs integrate into existing urban landscapes, influencing traffic flow, urban planning, and the overall quality of urban life. Mudrak and Semwal (2021) address the critical issue of AV decision-making in relation to urban infrastructure optimization. As urban populations grow, traditional road networks, designed for lower traffic volumes, become increasingly congested. The introduction of AVs presents new opportunities for traffic management and urban infrastructure development. The authors propose an Agent Based Modelling environment to support the interaction of AVs with smarter urban infrastructure. This approach allows for a more collaborative experience between AVs and urban systems, where both can operate according to their own goals while enhancing selfmanagement capabilities. The integration of procedural content generation (PCG) and agentbased modelling concepts in this framework is crucial for establishing a dynamic and responsive urban traffic system. Consilvio et al. (2019) investigate the potentialities of AVs in urban spatial planning. They focus on the sustainability aspect, particularly in addressing urban congestion, emissions reduction, and road safety. The introduction of AVs is expected to significantly change the interaction between traffic flow and infrastructure. The paper models this interaction to explore the benefits of AV market penetration. A network design problem is presented to identify which road network links could be considered superfluous in an AV scenario and, therefore, repurposed for soft mobility, such as pedestrian and cyclist use. This approach is instrumental in reimagining urban spaces and promoting sustainable mobility solutions. In summary, the operational modes of AVs and their interaction with urban infrastructure are crucial in determining the future landscape of urban mobility. The research by these authors highlights the diverse aspects of this interaction, from traffic management and infrastructure optimization to the integration of AV-based mobility services and the reconfiguration of urban spaces. As AV technology continues to advance, these operational modes and interactions will play a significant role in shaping efficient, sustainable, and responsive urban environments. Evolutionary Milestones in Autonomous Vehicle Development The development of autonomous vehicles (AVs) has been marked by significant evolutionary milestones, shaping the trajectory of this transformative technology. From early conceptualizations to the latest advancements in perception, planning, and control systems, the journey of AVs reflects a confluence of technological innovation, interdisciplinary research, and visionary foresight. Chen et al. (2023) in their comprehensive work \"Milestones in Autonomous Driving and Intelligent Vehicles\u2014Part II: Perception and Planning\" provide a detailed overview of the advancements in AV perception and planning. This part of their series highlights the critical role of perception systems in AVs, which enable the vehicles to understand and interpret their surroundings. Advances in sensor technologies, such as LiDAR, radar, and cameras, have been pivotal in enhancing the perception capabilities of AVs. Furthermore, the development of sophisticated planning algorithms has enabled AVs to make safe and efficient navigation decisions in complex urban environments. This evolution in perception and planning underscores the shift from basic automated functions to more advanced levels of autonomy. Goel et al. (2022) offer a chronological analysis of the achievements in autonomous vehicle technology in their review paper on the development of e-Vehicles. They trace the journey of AVs from the early 20th century, when radio-controlled vehicles first appeared, to the present day, where semi-autonomous features like lane keeping, automatic braking, and adaptive cruise control have become commonplace. The paper highlights key technological milestones, such as the introduction of vision-guided autonomous vehicles in the 1980s, which laid the foundation for the current generation of AVs. The authors predict that the future of AVs will be characterized by an extensive network of vision-guided systems, leading to the widespread adoption of fully autonomous vehicles. In \"Milestones in Autonomous Driving and Intelligent Vehicles\u2014Part I: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors,\" Chen et al. (2023) \ndelve into the development of control systems, computing architecture, communication technologies, high-definition mapping, testing methodologies, and the understanding of human behaviors in relation to AVs. This part of their series emphasizes the importance of robust control systems and advanced computing architectures in ensuring the reliability and safety of AVs. The integration of communication technologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication, has been crucial in enhancing the situational awareness and operational efficiency of AVs. High-definition mapping has provided AVs with detailed environmental data, essential for precise navigation. Additionally, the authors discuss the challenges and advancements in testing AVs, as well as the need to understand and predict human behaviors for effective human-AV interaction. In summary, the evolutionary milestones in autonomous vehicle development encompass a wide range of technological advancements and interdisciplinary research efforts. From perception and planning to control systems and human factors, the journey of AVs reflects a continuous pursuit of innovation and improvement. As AV technology continues to evolve, these milestones will serve as the foundation for future advancements, paving the way for safer, more efficient, and intelligent transportation systems. Current State and Innovations in Autonomous Vehicle Systems. The current state and innovations in autonomous vehicle (AV) systems represent a dynamic and rapidly evolving landscape, marked by technological advancements, regulatory challenges, and societal implications. Understanding the present status of AV technology and its trajectory is crucial for anticipating future developments and their impact on urban mobility. Rajasekaran (2023) provides a comprehensive review and analysis of the current state and challenges of autonomous vehicles. The study begins by categorizing different types of AVs and the sensors and technologies that enable their operation. Key technologies include a network of sensors and cameras that feed data to complex computer algorithms, allowing AVs to detect their surroundings, make decisions, and avoid hazards. The paper also addresses the challenges hindering the widespread adoption of AVs, such as safety concerns, regulatory hurdles, and public acceptance. Additionally, the potential benefits of AVs are explored, highlighting their capacity to improve transportation efficiency, reduce traffic congestion, and enhance accessibility for individuals with disabilities. Parekh et al. (2022) delve into the current state of research and development in AV systems, focusing on environment detection, pedestrian detection, path planning, motion control, and vehicle cybersecurity. The review aims to compare different proposed technologies and their approaches to solving key challenges in autonomous driving. The study emphasizes the need for these technologies to be accurate and reliable enough to gain public trust. It also explores public perception and acceptance of AVs, discussing both the opportunities and obstacles associated with autonomous driving technology. The paper sheds light on future possibilities, suggesting a continued trajectory of innovation and improvement in AV systems. In summary, the current state and innovations in autonomous vehicle systems are characterized by rapid technological advancements, increasing patent activity, and ongoing challenges related to safety, regulation, and public acceptance. The research by Rajasekaran, Traore, and Parekh et al. provides a multifaceted view of this landscape, highlighting the progress made in key areas of AV technology and the potential for future developments. As AV technology continues to evolve, it is poised to significantly transform urban mobility, offering solutions to longstanding transportation challenges and opening new possibilities for efficient, safe, and accessible transportation. Emerging Trends and Future Directions The landscape of autonomous vehicle (AV) systems is continuously evolving, with emerging trends and future directions shaping the trajectory of this transformative technology. The integration of advanced computational methods, multidimensional analysis of impacts, and the development of enabling technologies are key areas driving the future of AVs. Ren, Huang, and Gabbar (2022) provide an insightful review of the current trends of deep learning in autonomous vehicles. Deep learning, a subset of machine learning, has become increasingly significant in the development of AV systems. The authors identify seven essential technologies that need to evolve and be refined for AVs to reach their full potential: path planning, computer vision, sensor fusion, data security, fault diagnosis, control, and communication and networking. The paper highlights the contributions of deep learning in each of these areas, offering insights into important aspects of this emerging field. The authors also identify five key directions for future research in AV design, emphasizing the need for continued innovation and exploration in deep learning applications. Othman (2022) conducts a multidimensional analysis of autonomous vehicles, focusing on their future in mobility. The study analyzes the impact of AVs on various aspects, including fleet size, vehicle utilization, cost of mobility, public transit service, public behavior, transportation network, land use, economy, environment, society, and public health. The paper reveals that while AVs offer multiple benefits, they also pose new risks. The extent to which AVs can affect our planet largely depends on regulatory actions, as the broader implications of AVs are dependent on how the technology is adopted. This analysis provides a comprehensive view of the potential benefits and challenges of AV deployment, highlighting the intertwined relationship between various implications of AVs. Damaj, Yousafzai, and Mouftah (2022) explore future trends in connected and autonomous vehicles, focusing on enabling communications and processing technologies. With advancements in information and communication technologies, connected and autonomous vehicles (CAVs) can offer improved transportation services. The paper examines state-of-theart CAV systems, with a focus on On-board Computational Unit (OBCU) hardware architectures, communication technologies, deployment challenges, and performance aspects. The exploration critically identifies important area transformations and anticipates future trends influencing CAV communications and processing requirements. The authors propose the design of a future generic OBCU architecture that can be customized with appealing features for use in CAVs. In summary, the emerging trends and future directions in autonomous vehicle systems are characterized by the integration of advanced computational methods such as deep learning, a comprehensive understanding of the multidimensional impacts of AVs, and the development of enabling technologies for connected and autonomous vehicles. These areas are crucial in shaping the future of AVs, offering insights into how this technology can be harnessed to create safer, more efficient, and sustainable transportation systems. As the field of AVs continues to evolve, these trends and directions will play a pivotal role in guiding research, development, and policy-making in autonomous mobility. Communication Technologies and Vehicle-to-Infrastructure Integration The integration of communication technologies and vehicle-to-infrastructure (V2I) systems is a crucial aspect of the development and operation of autonomous vehicles (AVs). This integration is pivotal in enhancing the safety, efficiency, and overall functionality of AVs in urban environments. Hbaieb, Ayed, and Chaari (2021) discuss the role of the Internet of Vehicles (IoV) in revolutionizing automotive services, particularly in the context of smart and autonomous cars. IoV is a key concept that enables vehicles to communicate both internally and externally, allowing them to interact with other vehicles and their environment. This paper focuses on wireless technologies and communication systems that provide various connectivities such as Vehicle-to-Vehicle (V2V), V2I, Vehicle-to-Sensor (V2S), and Vehicle-to-Internet (V2I). The authors propose a novel planning scheme for internet-connected and autonomous driving vehicles, outlining the principal components and their distribution across the architecture. This includes identifying information flows, required exchanged data, and basic functionalities needed to build autonomous driving services. The paper emphasizes the importance of holistic hardware and software architecture, involving in-car gateways, to facilitate these interactions. Butt et al. (2022) provide a comprehensive review of the integration of enabling wireless technologies and sensor fusion for next-generation connected and autonomous vehicles. The article covers data acquisition using various sensing devices such as RADAR, LiDAR, and cameras, and the multi-modal sensor fusion of the acquired data after signal processing. It also reviews the communication and networking infrastructure for intra- and inter-vehicle communication and related technologies. The research identifies challenges and future directions in these areas, highlighting the critical role of communication infrastructure in transmitting necessary information to peers and receiving critical information for timely decisions. Ding et al. (2022) explore the application of 5G time-sensitive network integration in intelligent vehicle-infrastructure systems. With the rapid evolution of 5G technology, autonomous driving technology is moving towards commercial trials and higher levels of automation. The paper proposes a method for dynamic bandwidth adjustment and Time-Sensitive Networking (TSN) channel division based on a 5G+TSN network. This method is applied to a cloud-side collaborative vehicle networking system, which also incorporates AI and digital twin technology to generate 3D rendering video streams for driving assistance. The system is tested in various application scenarios to verify its feasibility, demonstrating the potential of 5G and TSN in enhancing vehicle-infrastructure coordination. In summary, the integration of communication technologies and V2I systems in autonomous vehicles is a rapidly evolving field, with significant implications for the future of urban mobility. The research by Hbaieb et al., Butt et al., and Ding et al. highlights the importance of advanced communication systems, sensor fusion, and network integration in enabling safe, efficient, and intelligent operation of AVs. As these technologies continue to develop, they will play a crucial role in shaping the interaction between AVs and urban infrastructure, paving the way for more connected and automated transportation systems. Autonomous Vehicles' Role in Urban Transportation Ecosystems The integration of autonomous vehicles (AVs) into urban transportation ecosystems is a subject of significant interest, with implications for urban planning, environmental sustainability, and societal dynamics. Understanding the role of AVs in these ecosystems is crucial for navigating the challenges and opportunities they present.\n\nRahman and Thill (2023) provide a comprehensive review of the impacts of connected and autonomous vehicles on urban transportation and the environment. Their study, based on a systematic review of 130 articles, employs a SWOT (Strengths, Weaknesses, Opportunities, and Threats) analysis to critically analyze key findings. The review suggests that AVs will influence urban transportation and human mobility by reducing vehicle ownership, public and active travel, traffic delay, and congestion, while increasing accessibility, mobility, Vehicle Miles Traveled, and revenue generation for commercial operators. In the long term, AVs are expected to encourage dispersed urban development, reduce parking demand, and enhance network capacity. Additionally, AVs are projected to reduce energy consumption and greenhouse gas emissions, contributing to environmental protection. However, concerns about personal safety, security, and privacy remain significant. Ferreras (2013) discusses autonomous vehicles as a critical tool to address the 21st-century urban transportation grand challenge, as identified by the United States National Academy of Engineering. The paper presents a holistic approach to solving public and private transportation challenges using unmanned cars and intelligent information systems. This approach addresses the integration of different modes of transportation, particularly in large metropolitan areas. The combination of high-performance driverless cars with intelligent information systems is posited as a powerful tool for optimizing urban transportation, potentially creating more eco-friendly, safe, and sustainable transportation environments. Fafoutellis and Mantouka (2018) examine the major limitations and concerns regarding the integration of autonomous vehicles in urban transportation systems. The paper points out the advantages of AVs, such as enhanced safety, sustainability, and accessibility, while also addressing significant concerns like privacy, data protection, cybersecurity, and ethical issues. The study highlights the legislative gaps concerning the usage and ownership of driverless cars and the responsibility in case of accidents. Additionally, the paper discusses the complex ethical issues arising from the programming of AVs to act in predefined ways in unexpected situations. The human adoption of AVs is also identified as a critical factor, with the transition to driverless cars potentially taking time for people to feel comfortable. In summary, the role of autonomous vehicles in urban transportation ecosystems is multifaceted, with potential benefits in terms of efficiency, sustainability, and accessibility. However, challenges related to safety, security, privacy, ethical considerations, and human adoption need to be addressed. The research by the above authors provides valuable insights into these aspects, highlighting the need for comprehensive planning and regulatory frameworks to facilitate the successful integration of AVs into urban transportation systems. As AV technology continues to evolve, its role in shaping future urban mobility will be significant, offering opportunities for more connected, efficient, and sustainable urban environments."}
{"doc109": "## Discussion Of Findings Impact Of Autonomous Vehicles On Urban Traffic And Planning.\n\nThe advent of autonomous vehicles (AVs) is poised to significantly impact urban traffic and planning, encompassing technological, economic, and environmental dimensions. Understanding these impacts is crucial for urban planners, policymakers, and stakeholders in the transportation sector. The integration of AVs into urban traffic systems necessitates a reevaluation of existing traffic management strategies. A study by Iravani, Anderson and Bevan (2018) on rethinking traffic congestion solutions in cities highlights the potential of AVs to complement or disrupt current transport planning tools, such as land use measures, transportation demand management, and transportation system management (Title Unknown). AVs, with their advanced navigation and communication capabilities, can significantly alter traffic flow patterns, requiring innovative approaches to traffic congestion solutions. The effective use of these tools must be overhauled with the advent of automated mobility, necessitating policy recommendations for each tool. Additionally, new safety challenges posed by integrating AVs into traffic must be addressed, requiring advancements in traffic signal systems and road infrastructure. The economic implications of AVs are multifaceted. On one hand, AVs promise to reduce the overall cost of transportation by improving fuel efficiency and reducing the need for parking infrastructure. On the other hand, the initial cost of AV technology and the required infrastructure investments pose significant economic challenges. Katerinin and Sanzhapov (2019) discuss the optimization of traffic light regulation parameters on urban road networks to minimize negative environmental impacts, which also has economic implications. The integration of AVs into this optimization process could lead to more efficient traffic management, potentially reducing the economic burden of traffic congestion and associated environmental costs. AVs have the potential to significantly impact the urban environment, particularly in terms of reducing greenhouse gas emissions and improving air quality. Rong et al. (2018) propose a continuum dynamic traffic assignment model for AVs in a polycentric urban city, considering the environmental impact of traffic emissions. This model includes the cost of CO emissions in the transportation cost, highlighting the potential of AVs to contribute to environmental sustainability. The shift towards AVs could lead to a decrease in vehicle emissions, contributing to cleaner and healthier urban environments. However, this transition also requires careful consideration of the environmental impact of manufacturing and disposing of AVs and their components. In summary, the impact of autonomous vehicles on urban traffic and planning is complex and multifaceted, encompassing technological, economic, and environmental considerations. The integration of AVs into urban transportation systems offers opportunities for improved traffic management, economic efficiency, and environmental sustainability. However, it also presents challenges that require innovative solutions and policy interventions. As AV technology continues to evolve, its impact on urban traffic and planning will become increasingly significant, shaping the future of urban mobility. Technological, Economic, and Environmental Considerations The integration of autonomous vehicles (AVs) into urban traffic systems brings a host of technological, economic, and environmental considerations that are pivotal in shaping the future of urban mobility. Skrickij, \u0160abanovi\u010d, and \u017duraulis (2020) delve into the recent issues and expectations surrounding autonomous road vehicles. They highlight the critical technologies underpinning AVs, including advancements in automated driving, sensor technology, and data processing capabilities. These technological developments are essential for minimizing traffic accidents, optimizing fuel consumption, and alleviating traffic congestion. However, the study also points out the need for these technological solutions to be developed in tandem with legal and regulatory frameworks, as well as considerations for user acceptance and human-robot interaction. The integration of AVs into urban traffic systems thus requires a holistic approach that addresses technological advancements alongside these broader societal and regulatory aspects. Gaon and Seidman (2021) explore the economic implications of a future without human driving. AVs hold the promise of more efficient, comfortable, and safer transportation, potentially transforming urban economies. The economic benefits of AVs include reduced costs associated with traffic accidents, lower fuel consumption due to optimized driving patterns, and decreased need for parking infrastructure. However, the transition to AVs also presents economic challenges, such as the need for significant investment in infrastructure and the potential impact on employment in driving-related industries. The economic viability of AVs in urban settings will depend on their ability to integrate seamlessly into existing transportation networks and the broader urban economy. Rong et al. (2018) propose a continuum dynamic traffic assignment model for AVs in urban cities, taking into account the environmental impact of traffic emissions. This model incorporates the cost of CO emissions into the transportation cost, highlighting the potential environmental benefits of AVs. By optimizing traffic flow and reducing reliance on internal combustion engines, AVs can contribute to lower greenhouse gas emissions and improved air quality in urban areas. However, the environmental impact of manufacturing, maintaining, and disposing of AVs and their components must also be considered. The transition to AVs offers an opportunity to create more sustainable urban transportation systems, but this requires careful planning and consideration of the full environmental lifecycle of these vehicles. The integration of autonomous vehicles into urban traffic systems involves a complex interplay of technological, economic, and environmental factors. Technological advancements in AVs need to be aligned with legal and regulatory frameworks, economic viability, and environmental sustainability. As AV technology continues to evolve, its impact on urban traffic and planning will become increasingly significant, offering opportunities for more efficient, safe, and sustainable urban mobility. Addressing Urban Traffic Challenges with Autonomous Technology The integration of autonomous technology into urban transportation systems presents unique opportunities and challenges in addressing urban traffic issues. Autonomous vehicles (AVs) and connected transportation systems are at the forefront of transforming urban mobility, offering solutions to longstanding traffic problems while introducing new complexities. Madrid (2023) explores the transformative potential of electric and autonomous public transportation in urban environments. The study highlights public optimism regarding these technologies, tempered by concerns about safety and reliability. Traffic data analysis from areas with AV trials shows improved traffic flow and reduced accidents, indicating potential gains in road safety and congestion reduction. However, AVs face challenges in adverse weather and complex urban settings. The study emphasizes the need for standardized safety regulations and adoption incentives to fully realize the benefits of electric buses and autonomous vehicles in public transit. These advancements in public transportation technology could lead to reduced emissions, improved air quality, and cost-effective transit solutions.\n\nSushma and Kumar (2022) discuss the challenges and implementation aspects of autonomous vehicles. The development of AVs involves integrating various sensors, navigation software, and control algorithms. However, the application of autonomous driving in urban environments is complex, involving not only automotive technology but also human behavior, traffic management strategies, ethics, and policies. One of the significant technical challenges is the detection of obstacles at high speeds and long distances. The study underscores the need for continued research and development to overcome these challenges and achieve the goal of fully automated, flaw-free vehicles. Seuwou, Banissi, and Ubakanma (2019) analyze the role of connected and autonomous vehicles in smart cities. They highlight how CAVs are essential for sustainable urban development as part of intelligent transportation systems (ITS). Smart mobility initiatives in cities aim to address severe urban problems such as traffic congestion, pollution, and energy consumption. CAVs can streamline city operations, saving money and making urban areas more efficient. However, the integration of CAVs into urban transportation systems requires careful planning and consideration of various factors, including infrastructure compatibility, data privacy, and public acceptance. Autonomous technology offers promising solutions to urban traffic challenges, with the potential to improve road safety, reduce congestion, and enhance the efficiency of public transportation. However, the successful integration of AVs into urban traffic systems requires overcoming technological challenges, ensuring public safety and reliability, and addressing regulatory and ethical considerations. As urban areas continue to evolve, the role of AVs and connected transportation systems will be crucial in shaping the future of urban mobility, offering a pathway towards more sustainable and efficient cities. Evolution and Future of Traffic Management in Autonomous Era The evolution and future of traffic management in the era of autonomous vehicles (AVs) present a paradigm shift in how urban traffic is controlled and organized. This shift involves not only technological advancements but also requires a rethinking of policies and strategies to integrate AVs effectively into urban environments. Matowicki and P\u0159ibyl (2020) emphasize the need for balanced policies that integrate autonomous vehicles into city traffic management. As cities increasingly adopt Smart City technologies, the integration of AVs becomes a critical component of urban planning. The study suggests that while AVs can make cities smarter, safer, and more energy-efficient, they also complicate traffic management. Current tools and policies may become inefficient in the face of this new technology. The authors argue for the development and enforcement of new sets of rules and policies to protect cities and their citizens in the digital and automated era. This includes considering the impact of AVs on climate change and traffic conditions in densely urbanized city centers. The study highlights the importance of analyzing and prioritizing the impact of AV functionalities individually for each city and traffic situation. Ye et al. (2020) explore the intelligent management of on-street parking in the context of autonomous vehicles. The increasing connectivity between vehicles and infrastructure, coupled with the deployment of AVs, presents unique challenges and opportunities for on-street parking management. The study develops a simulation-optimization approach for intelligent curbside management, aiming to minimize average traffic delay by balancing curb lanes for driving or parking. The results demonstrate a decrease in traffic delay by 9%-27% compared to benchmark cases. This study indicates the interplay between curb parking and traffic management in the AV era, suggesting that intelligent curb management can be a crucial factor in optimizing urban traffic flow. In summary, the evolution and future of traffic management in the autonomous era require a holistic approach that encompasses technological innovation, policy development, and strategic planning. The integration of AVs into urban traffic systems offers opportunities for improved efficiency and safety. However, it also presents challenges that necessitate careful consideration and planning. As AV technology continues to advance, its impact on traffic management will become increasingly significant, shaping the future of urban mobility. Visioning the Future of Urban Planning with Autonomous Vehicles. The advent of autonomous vehicles (AVs) is set to revolutionize urban planning, presenting both opportunities and challenges for the future of city development. Visioning exercises and studies provide insights into how AVs could reshape urban landscapes, influencing everything from transportation policies to city design. Staricco et al. (2019) conducted a visioning exercise focusing on the impacts of AVs on the Italian city of Turin. Their study highlights how different forms of regulation of AV circulation and parking can impact the sustainability and livability of the city. The exercise involved a focus group and interviews with experts and stakeholders to validate three visions and assess their advisability and sustainability. The study underscores the importance of defining long-term visions and identifying transition paths to achieve the desired future with AVs. It also emphasizes the need for urban planners to lead this transition, considering the potential impacts on circulation, parking, and overall urban development. Narayani and Kumar (2021) explore the potential of AVs as a key to sustainable mobility and safe accessibility in future cities. Their study examines current trends and future predictions in technological advancements, focusing on the economic, environmental, and social impacts of AVs. The research includes optimization models and simulations to understand future trends and the scope of autonomous mobility. The study acknowledges the criticisms and technical constraints associated with AVs but suggests that further investigation in this domain will be instrumental in developing a vision focused on AVs as a key to sustainable mobility in future urban planning. Gavanas (2019) analyzes the challenges posed by the implementation of autonomous road vehicles for passenger transport in European cities. The paper is based on a systematic review of research and policy, identifying challenges related to urban development, policy priorities, lack of data for planning, and the potential for AVs to be used as data sources by planners. The study concludes that addressing these challenges is essential for the full exploitation of AVs' potential to promote sustainable urban development. It highlights the need for urban planners to consider the possible impacts of AVs on cities and future challenges for urban planning. In summary, envisioning the future of urban planning with autonomous vehicles involves considering a range of factors, including policy development, technological advancements, and sustainable urban design. The integration of AVs into urban landscapes offers opportunities for improved mobility, reduced environmental impact, and enhanced city livability. However, it also presents challenges that require careful planning and strategic decision-making. As AV technology continues to evolve, its role in shaping the future of urban planning will become increasingly significant, offering a pathway towards more sustainable, efficient, and livable cities."}
{"doc110": "## Standards, Regulations, And Their Role In Urban Autonomous Mobility\n\nThe integration of autonomous vehicles (AVs) into urban mobility systems necessitates a comprehensive understanding of the standards and regulations that govern their operation. These standards and regulations play a crucial role in ensuring the safety, efficiency, and sustainability of urban autonomous mobility. Richter et al. (2022) discuss the need for sustainable investment strategies in smart cities, particularly in the context of urban mobility and autonomous vehicles. The study develops a simulation-based comparison between different cities and AV adoption scenarios to understand which aspects of cities lead to positive AV implementation outcomes. The analysis represents a first attempt to explore the impact of AVs on a large scale across different cities worldwide. The paper suggests that promoting AV-shuttle use in certain city archetypes could deliver significant advantages in terms of improvements in key performance indicators (KPIs). The study underscores the importance of aligning emerging technologies with long-term sustainability strategies in urban mobility. Kovacic, Mutavd\u017eija, and Buntak (2022) provide a review and bibliometric analysis of the new paradigm of sustainable urban mobility, focusing on electric and autonomous vehicles. The research shows that while authors focus on the advantages and disadvantages of autonomous electric vehicles in the urban mobility system, there is an insufficient number of studies considering the need to plan the transition towards incorporating these vehicles into the urban system. The paper highlights the importance of developing a culture of sustainability among urban residents and planning the infrastructure transition to accommodate autonomous electric vehicles. This includes addressing challenges related to infrastructure compatibility, data privacy, and public acceptance. In summary, the role of standards and regulations in urban autonomous mobility is critical in shaping the future of urban transportation. The integration of AVs into urban landscapes offers opportunities for improved mobility, reduced environmental impact, and enhanced city livability. However, it also presents challenges that require careful planning, strategic decisionmaking, and the development of appropriate regulatory frameworks. As AV technology continues to evolve, its impact on urban mobility will become increasingly significant, offering a pathway towards more sustainable, efficient, and livable cities.\n\n## Conclusions"}
{"doc111": "The integration of autonomous vehicles (AVs) into urban landscapes presents a transformative shift in traffic management, urban planning, and environmental sustainability. AVs have the potential to significantly reduce traffic congestion, enhance road safety, and optimize traffic flow. In urban planning, they necessitate a reevaluation of infrastructure needs, potentially leading to more efficient land use and reduced need for extensive parking facilities. Environmentally, AVs offer the promise of reduced greenhouse gas emissions and improved air quality, particularly when integrated with electric vehicle technology. However, these benefits are contingent upon addressing technological challenges, ensuring public safety, and developing effective regulatory frameworks. The future urban landscape with AVs is envisioned as a more efficient, safer, and environmentally sustainable environment. This future includes seamlessly integrated transportation systems where AVs complement public transit, contributing to a reduction in private vehicle ownership and urban sprawl. Urban spaces could be redesigned to prioritize pedestrian areas and green spaces, as the need for parking and wide roads diminishes. The adoption of AVs is also expected to foster smarter cities, where data-driven management of urban mobility leads to more responsive and adaptive city planning. To optimize the integration of AVs into urban environments, comprehensive policy and industry recommendations are essential. Policymakers should focus on developing standardized safety regulations, incentivizing the adoption of AVs, and ensuring equitable access to this new form of mobility. Urban planners are encouraged to consider AVs in long-term city planning, rethinking infrastructure and land use. For the industry, investing in research and development to overcome technological barriers and improve public trust in AV technology is crucial. Collaboration between government, industry, and academia is vital to address these challenges effectively. The study concludes that AVs hold significant potential for reshaping urban mobility, but their successful integration requires a multi-faceted approach involving technological innovation, policy development, and societal acceptance. Future research should focus on long-term impacts of AVs on urban landscapes, including changes in land use patterns, economic impacts, and social implications. Studies on the interaction between AVs and other forms of transportation, as well as their role in achieving broader sustainability goals, are also essential. Additionally, exploring the ethical and legal implications of AVs will be crucial as this technology continues to evolve and become an integral part of urban life.\n\n## References\n\nAbdulsattar, H., Siam, M. R. K., & Wang, H. (2020). Characterisation of the impacts of autonomous driving on highway capacity in a mixed traffic environment: an agent\u2010based approach. *IET Intelligent Transport Systems,* 14(9), 1132-1141. DOI: 10.1049/IETITS.2019.0285 Ahmed, H. U., Huang, Y., Lu, P., & Bridgelall, R. (2022). Technology developments and impacts of connected and autonomous vehicles: An overview. *Smart Cities,* 5(1), 382404. DOI: 10.3390/smartcities5010022 Butt, F. A., Chattha, J. N., Ahmad, J., Zia, M. U., Rizwan, M., & Naqvi, I. (2022). On the integration of enabling wireless technologies and sensor fusion for next-generation connected and autonomous vehicles. DOI: 10.1109/ACCESS.2022.3145972 Chen, G., & Fraichard, T. (2007). A Real-Time Navigation Architecture for Automated Vehicles in Urban Environments,\" 2007 IEEE Intelligent Vehicles Symposium, Istanbul, Turkey, 2007, pp. 1223-1228, doi: 10.1109/IVS.2007.4290285."}
{"doc112": "Chen, L., Li, Y., Huang, C., Xing, Y., Tian, D., Li, L., Hu, Z., Teng, S., Lv, C., Wang, J., Cao, D., Zheng, N., & Wang, F. (2023). Milestones in Autonomous Driving and Intelligent Vehicles\u2014Part I: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors,\" in IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 53, no. 9, pp. 5831-5847, Sept. 2023, doi: 10.1109/TSMC.2023.3276218.\n\nConsilvio, A., Di Febbraro, A., Sacco, N., & Torre, A. (2019). On exploring the potentialities of autonomous vehicles in urban spatial planning,\" 2019 6th International Conference on Models and Technologies for Intelligent Transportation Systems (MT-ITS), Cracow, Poland, 2019, pp. 1-7, doi: 10.1109/MTITS.2019.8883388.\n\nDamaj, I., Yousafzai, J., & Mouftah, H. (2022). Future trends in connected and autonomous vehicles: enabling communications and processing technologies,\" in IEEE Access, vol. 10, pp. 42334-42345, 2022, doi: 10.1109/ACCESS.2022.3168320. DOI: 10.1109/ACCESS.2022.3168320 Ding, P., Liu, D., Shen, Y., Duan, H., & Zheng, Q. (2022). Edge-to-cloud intelligent vehicleinfrastructure based on 5g time-sensitive network integration,\" 2022 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB), Bilbao, Spain, 2022, pp. 1-5, doi: 10.1109/BMSB55706.2022.9828687. https://doi.org/10.1061/9780784413210.036."}
{"doc113": "Fafoutellis, P., & Mantouka, E.G. (2019). Major limitations and concerns regarding the integration of autonomous vehicles in urban transportation systems. In: Nathanail, E., Karakikes, I. (eds) Data Analytics: Paving the Way to Sustainable Urban Mobility. CSUM 2018. Advances in Intelligent Systems and Computing, vol 879. Springer, Cham. https://doi.org/10.1007/978-3-030-02305-8_89.\n\nFerreras, L. E. (2013). Autonomous Vehicles: a critical tool to solve the XXI century urban transportation grand challenge. *Urban Transportation Systems*. DOI: 10.1061/9780784413210.036.\n\nGaon, A., & Seidman, G. (2021). A future without human driving. Georgetown Journal of Law and Public Policy, 18(503), DOI: 10.2139/SSRN.3803909 Gavanas, N. (2019). Autonomous road vehicles: Challenges for urban planning in European cities. *Urban Science,* 3(2), 61. DOI: 10.3390/URBANSCI3020061 Goel, M., Warsi, N., Batra, B., & Singla, A. (2022). A review paper on development of evehicles. International Journal for Research in Applied Science & Engineering Technology (IJRASET), 10(12). DOI: 10.22214/ijraset.2022.47995 Hbaieb, A., Ayed, S., & Chaari, L. (2021). Internet of vehicles and connected smart vehicles communication system towards autonomous driving, 03 June 2021, PREPRINT (Version 1) available at Research Square. DOI: 10.21203/RS.3.RS-493419/V1 Hiramatsu, T. (2022). Impact of autonomous vehicles on the choice of residential locality. *Transportation Planning and Technology,* 45(3), 268-288. DOI: 10.1080/03081060.2022.2105339 Iravani, H., Anderson, A., & Bevan, A. (2018). Autonomous vehicles: rethinking traffic congestion solutions in cities. *Journal of Geotechnical and Transportation* Engineering, 4(1), 25-29. "}
{"doc114": "Kassens-Noor, E., Wilson, M., & Yigitcanlar, T. (2021). Where are autonomous vehicles taking us?. *Journal of Urban Technology,* 28(3-4), 1-4. DOI: 10.1080/10630732.2021.1985318 Kim, D.-H., Mendoza, R. R. L., Chua, K. F. R., Chavez, M., Concepcion, R. S., & Vicerra, R. \n\nR. (2021). A systematic analysis on the trends and autonomous vehicles and the proposed solutions for level 5 automation,\" 2021 IEEE 13th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM), Manila, Philippines, 2021, pp. 1-6, doi: 10.1109/HNICEM54116.2021.9731982.\n\nKonstantin, K. and Bulat, S. (2019). Optimization of the traffic light regulation parameters on the urban road network in order to minimize the negative environmental impact. International Scientific Conference \"Construction and Architecture: Theory and Practice for the Innovation Development, 138(2019), 4, https://doi.org/10.1051/e3sconf/201913801024."}
{"doc115": "Kova\u010di\u0107, M., Mutavd\u017eija, M., & Buntak, K. (2022). New paradigm of sustainable urban mobility: Electric and autonomous vehicles\u2014A review and bibliometric analysis. *Sustainability,* 14(15), 9525. DOI: 10.3390/su14159525 Li, L., Li, J., & Zhang, S. (2021). State-of-the-art trajectory tracking of autonomous vehicles. *Mechanical Sciences,* 12(1), 419-432. DOI: 10.5194/MS-12-419-2021 Lin, Y.T., Hsu, T.M., Zhang, Z.H., & Lin, B.H. (2020). Adaptive Trajectory Generation of Autonomous Vehicle in Urban Environments,\" 2020 International Automatic Control Conference (CACS), Hsinchu, Taiwan, 2020, pp. 1-6, doi: 10.1109/CACS50047.2020.9289755. \n\nLu, Q., Tettamanti, T., H\u00f6rcher, D., & Varga, I. (2020). The impact of autonomous vehicles on urban traffic network capacity: an experimental analysis by microscopic traffic simulation. *Transportation Letters,* 12(8), 540-549. DOI: 10.1080/19427867.2019.1662561 Madrid, J. A. (2023). Electric and Autonomous Public Transportation: Challenges and Opportunities. *International Journal of Advanced Research in Science, Communication* and Technology (IJARSCT), 3(1), 810-813. DOI: 10.48175/ijarsct-11963 Matowicki, M., & P\u0159ibyl, O. (2020). The need for balanced policies integrating autonomous vehicles in cities,\" 2020 Smart City Symposium Prague (SCSP), Prague, Czech Republic, 2020, pp. 1-7, doi: 10.1109/SCSP49987.2020.9134030.\n\nMcCarroll, C., & Cugurullo, F. (2022). Social implications of autonomous vehicles: a focus on time. *AI & Society,* 37(2), 791-800. DOI: 10.1007/s00146-021-01334-6 Mudrak, G., Semwal, S.K. (2021). Autonomous Vehicle Decision Making and Urban Infrastructure Optimization. In: Arai, K. (eds) Intelligent Computing. Lecture Notes in Networks and Systems, Vol. 284. Springer, Cham. https://doi.org/10.1007/978-3-03080126-7_83 Narayani, A. R., & Kumar, K. K. (2021). A vision for sustainable mobility through autonomous vehicles in city planning. In IOP Conference Series: Materials Science and Engineering, 1130(1), p. 012037. IOP Publishing. DOI: 10.1088/1757-899X/1130/1/012037 Othman, K. (2022). Multidimension analysis of autonomous vehicles: the future of mobility. *Civil Engineering Journal,* 7, 71-93. DOI: 10.28991/cej-sp2021-07-06 Parekh, D., Poddar, N., Rajpurkar, A., Chahal, M., Kumar, N., Joshi, G. P., & Cho, W. (2022). "}
{"doc116": "A review on autonomous vehicles: Progress, methods and challenges. *Electronics,* 11(14), 2162. DOI: 10.3390/electronics11142162 Rahman, M. M., & Thill, J. (2023). Impacts of connected and autonomous vehicles on urban transportation and environment: a comprehensive review. *Sustainable Cites and Society,* 96, DOI: 10.1016/j.scs.2023.104649 Rajasekaran, S. B. (2023). Review and analysis of autonomous vehicles - current state and challenges. *Journal of Engineering and Applied Sciences Technology, 5*(1), 1-3. DOI: 10.47363/jeast/2023(5)187 Ren, J., Huang, R. N., & Gabbar, H. A. (2022). The current trends of deep learning in autonomous vehicles: a review. *Journal of Engineering Research and Sciences, 1*(10): 56-68. DOI: 10.55708/js0110008 Richter, M. A., Hagenmaier, M., Bandte, O., Parida, V., & Wincent, J. (2022). Smart cities, urban mobility and autonomous vehicles: How different cities needs different sustainable investment strategies. Technological Forecasting and Social Change, 184, 121857. DOI: 10.1016/j.techfore.2022.121857 Rong, B., Zhao, H., Cui, S., & Zhang, C. (2018). Continuum dynamic traffic assignment model for autonomous vehicles in a polycentric urban city with environmental consideration. Mathematical Problems in Engineering, *2018,* 1-15. https://doi.org/10.1155/2018/8345979.\n\nSeuwou, P., Banissi, E., Ubakanma, G. (2020). The future of mobility with connected and autonomous vehicles in smart cities. In: Farsi, M., Daneshkhah, A., Hosseinian-Far, A., Jahankhani, H. (eds) Digital Twin Technologies and Smart Cities. Internet of Things. Springer, Cham. https://doi.org/10.1007/978-3-030-18732-3_3 Skrickij, V., \u0160abanovi\u010d, E., & \u017duraulis, V. (2020). Autonomous road vehicles: recent issues and expectations. *IET Intelligent Transport Systems,* 14(6), 471-479.DOI: 10.1049/ietits.2018.5513 Staricco, L., Rappazzo, V., Scudellari, J., & Vitale Brovarone, E. (2019). Toward policies to manage the impacts of autonomous vehicles on the city: a visioning exercise. *Sustainability,* 11(19), 5222. DOI: 10.3390/su11195222 Sushma, R., & Kumar, J. S. (2022). Autonomous vehicle: Challenges and implementation. *Journal of Electrical Engineering and Automation,* 4(2), 100-108. DOI: 10.36548/jeea.2022.2.004 Szab\u00f3, D. (2020). Driverless, or carless future? Socio-technical scenarios of autonomous urban mobility in the Czech Republic. *Transactions on Transport Sciences,* 11(1), 5-17. DOI: 10.5507/tots.2020.003 Ye, Q., Stebbins, S. M., Feng, Y., Candela, E., Stettler, M., & Angeloudis, P. (2020). Intelligent Management of On-street Parking Provision for the Autonomous Vehicles Era,\" 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC), Rhodes, Greece, 2020, pp. 1-7, doi: 10.1109/ITSC45102.2020.9294527."}
{"doc117": "![0_image_1.png](0_image_1.png) environment: A comprehensive review Md. Mokhlesur Rahman a,b, Jean-Claude Thill c,* \na Department of Urban and Regional Planning, Khulna University of Engineering & Technology, Khulna 9203, Bangladesh b The School of Information Studies, 343 Hinds Hall, Syracuse University, Syracuse, NY 13244, United States c *Department of Geography and Earth Sciences & School of Data Science, University of North Carolina at Charlotte, 9201 University City Blvd, NC 28223, United States* The article discusses the short, medium, and long-term effects of Autonomous Vehicles (AVs) on the urban transportation and environment by means of a systematic review of the extant literature on the subject matter. A \ncorpus of 130 articles was collected from multiple sources using selected keywords. The review critically analyzes key findings of these papers in the light of a SWOT (Strength, Weakness, Opportunity, and Threat) analysis. \n\nAlthough the technology remains to be commercially deployed, broad consensus is found in the literature. First, AV would influence urban transportation and human mobility by reducing vehicle ownership, public and active travel, traffic delay and congestion, travel costs, and by increasing accessibility, mobility, Vehicle Miles Traveled, and revenue generation for commercial operators. Second, AVs would have long-term effects by encouraging dispersed urban development, reducing parking demand, and enhancing network capacity. Third, AVs would reduce energy consumption and protect the environment by reducing Greenhouse Gas emissions. Fourth, AVs would reduce traffic crashes involving human errors and increase the convenience and productivity of passengers by facilitating for multitasking. However, most people are very concerned about personal safety, security, and privacy. Finally, the study identifies critical research gaps and advances priority directions for further research. \n\nhas the potential to bring dramatic changes to the transportation system, to urban mobility in terms of where people live, where they work, shop and recreate individually and collectively, and hence to the spatial structure of urban environments. This study investigates the impacts of Connected and Autonomous Vehicles (CAVs) on urban transportation and on the geography of urban environments by conducting a state-of-the-art review of the literature. "}
{"doc118": "A number of high tech firms and more traditional automobile companies have been working assiduously to develop Automated Vehicles \n(AVs), which can arguably be seen as a new mobility option (Moorthy et al., 2017; Narayanan et al., 2020). While institutional bottlenecks and socio-technological challenges continue to frustrate the meaningful commercial deployment of AVs (Day, 2021), it is often anticipated that AVs would deeply change human mobility, the built environment, the socio-economic fabric of cities, and city planning and governance \n(Fayyaz et al., 2022; Grindsted et al., 2022; Lee et al., 2022). Meanwhile, decision makers and city planners should prepare policies and plans consistent with a mobility landscape where AVs occupy a prominent position. To date, much research has been conducted on the potential People have used the automobile as a primary mode of travel within and between urban areas since the mid-twentieth century (Howard & \nDai, 2014). Nowadays, it has become an integral part of urban life. \n\nTechnological advancements such as the introduction of Internal Combustion Engines (ICEs), transmission systems, electric motors, steering and cruise control, and emission control technologies are easing people's life and reorganizing city structure (Kim, 2018). While providing benefits to populations, automobiles are also adversely affecting human societies and their environment. The massive use of Single-Occupancy Vehicles (SOVs) is associated with travel delays, traffic congestion, traffic crashes, energy consumption, air pollution, and urban sprawl. \n\nMutation of the transportation system by shifting from ICEs to Electric Vehicles (EVs), and by introducing Intelligent Transportation Systems \n(ITS), ride-sharing, on-demand services, and Travel Demand Management (TDM) measures has shown evidence to reduce energy use and carbon emission, traffic crashes and congestion (Bansal & Kockelman, 2017; Howard & Dai, 2014). However, a combination of these strategies \n* Corresponding author. "}
{"doc119": "E-mail addresses: mrahma18@syr.edu (Md.M. Rahman), jfthill@uncc.edu (J.-C. Thill). \n\nhttps://doi.org/10.1016/j.scs.2023.104649 Received 1 January 2023; Received in revised form 11 May 2023; Accepted 11 May 2023 Available online 20 May 2023 2210-6707/\u00a9 2023 Elsevier Ltd. All rights reserved.\n\nARTICLE INFO \nimpacts of AVs on people's travel behaviors and on the urban built environment to facilitate the process (Fagnant & Kockelman, 2015; Fraedrich et al., 2019; Kapser & Abdelrahman, 2020; Meyer et al., \n2017). Considering the preeminence of people's safety and security in shaping travel patterns, previous studies have also explored urban futures with AVs from the perspectives of personal safety, privacy, and security. These studies have serious drawbacks including a heavy reliance on assumptions, simulations and hypothetical driving settings, which may deviate from real-world situations. Nonetheless, they are significantly contributing to the current body of literature aimed at unraveling the possible responses to AV adoption in human travel patterns and in the urban built environment. Thus, it is timely to have a comprehensive overview of the current literature and to synthesize the existing knowledge domain. "}
{"doc120": "Some of the early reviews of the extant literature systematically evaluated the short-term (i.e., within 3 - 5 years) \u2013such as travel time, convenience, people's productivity, and medium-term (i.e., within 6 - 10 years) effects \u2013such as car ownership, privacy, cyber security, of AVs, but disregarded the long-term (i.e., more than 10 years) effects on the urban built environment, such as people's household and employment location decisions and parking demand (Ahmed et al., 2022; Bahamonde-Birke et al., 2018; Kopelias et al., 2020; Othman, 2022; Tafidis et al., 2021; Tengilimoglu et al., 2023). Although the phasing of the effects is still unsettled, may remain in question for some time, and is subject to adjustments (Hancock et al., 2019; Milakis, 2019), it is assumed that short-term effects will be realized starting with the introduction of AVs for public use rather than in the more distant future. On the other hand, long-term effects will continue for a long time period after adoption of AVs. However, researchers have argued that long-term effects of AVs are uncertain and largely depend on the level of market penetration of AVs and on the evolution of vehicle travel demand (Milakis et al., 2017). Mid-term effects fall in between short- and long-term effects of AVs. To the best of our knowledge, no prior review has explored the current status of AV adoption and the anticipated evolution over a certain time horizon. In this study, we aim to understand current scenarios and potential benefits and costs of AVs after reviewing relevant published scholarship. Considering the timeliness of the research topic and gaps in the literature, the following research questions are investigated in this systematic review: \n\n1) What is the current status of AV research and adoption in different study contexts around the globe? \n\n2) What are the impacts of AVs on human mobility, transportation system, energy and environment, and the built environment? "}
{"doc121": "3) What are the impacts of AVs on people's safety from traffic, privacy from cyber-attacks, travel convenience, and productivity? \n\n4) What are the research gaps in the existing literature that warrant further investigation? \n\n2\nThus, the present review makes significant contributions to the literature by consolidating existing bodies of literature. Its main contributions are threefold. First, the paper critically reviews the state-of the-art literature on the short, medium, and long-term effects of AVs on urban transportation and mobility. Second, it looks at the possible longer-term adjustments to the geography of the built and natural environments of urban regions in the wake of shifts towards more AVs as future markets for AVs become more grounded. Finally, the paper identifies key concepts and provides a foundation for future research by pinpointing research gaps in the literature. "}
{"doc122": "The rest of the paper is structured as follows. Our study approach is presented in Section Two. The third section discusses the definition, concept, evolution, and adoption of AVs in different countries. The potential impacts of AVs are presented in the fourth section. Under Section Four, Subsection 4.1 outlines the impacts of AVs on transportation and human mobility, Subsection 4.2 explains the impacts of AVs on traffic safety and convenience to people, Subsection 4.3 summarizes the impacts on energy and environment, and Subsection 4.4 discusses impacts on the urban built environment. Research problems and directions for future study are discussed in the Fifth Section. Finally, conclusions are drawn in Section Six. \n\n## 2. **Study Approach**\n\nThis systematic literature review is conducted to identify, evaluate, and critically analyze relevant scholarship on the current status and impacts of AVs. To this end, a literature search is conducted to select published articles and reports to be included in the review process. The articles and reports are selected based on (1) whether the article/report was written in English, (2) whether the study was conducted within the last five years, and (3) whether the study has investigated the impacts of AVs, Shared Autonomous Vehicles (SAVs), and CAVs, on transportation and mobility, environment, and urban form. However, a few studies conducted before 2015 are included in this systematic review to provide a comprehensive overview of possible scenarios and technological developments related to AVs, SAVs, and CAVs. ScienceDirect, Scopus, SAGE Journals, SpringerLink, Taylor & Francis, and Web of Science, the website of different organizations, and Google Scholar are the primary sources to search for suitable articles and reports. "}
{"doc123": "The search identified 360 articles and reports. However, after careful assessment of each item, only 130 items were deemed directly pertinent to the search terms and objectives of the study. They form the basis of this systematic review. Of these items, 18.84%, 7.25%, and 4.35% of the articles have been published in the following three periodicals, respectively: Transportation Research Part C: Emerging Technologies, Transportation Research Part A: Policy and Practice, and Transportation Research Record. About 87% of the articles and reports were published from 2015 to 2020. Also, 46.27% and 18.66% of articles/reports pertained to North American and European countries, respectively. In addition, 8.21% and 3.73% of studies have been conducted in Asian countries and Australia, respectively. Moreover, about 11.94% of them are review studies and 11.19% have been conducted in multiple countries. During the selection process of articles/reports, the researchers were careful to select them from different study contexts to get a comprehensive review. These research items are critically analyzed to understand the current and future implementation of AVs and their impacts on transportation and mobility, environment, and urban form. However, we would like to acknowledge that the vast majority of studies \n(about 69%) are conducted in a Global North setting. Although we attempted to generalize findings from different studies, considering the socioeconomic, cultural, and geographic diversity in the Global South and North contexts, all research findings may not equally apply to all national contexts. \n\nThe key concepts and themes discussed in the extant literature are presented in Fig. 2. Many studies focused on the impacts of AVs on energy consumption (26.15%) and traffic delay and congestion (23.85%) \nfollowed by Vehicle Miles Traveled (VMT) (20%) and Greenhouse Gas \n(GHG) emission (20%). Also, a considerable number of studies have explored the effects of AVs on parking demand (19.23%), travel costs and revenue generation (19.23%), safety, security, and personal privacy \n(18.46%). In contrast, a few studies discussed the possible integration of shared mobility, AV, and EV (3.85%), impacts of AVs on employment opportunity (6.15%), infrastructure capacity (8.46%), and public transportation (9.23%). \n\nFig. 3 shows the data sources of the reviewed articles/reports. The results indicate that 29.17% and 25.69% of studies conducted webbased household surveys and simulations (e.g., field test, experimental driving), respectively, to collect data. In contrast, only 1.39% and 6.25% \nof studies used data from census and national surveys, respectively. Most of these studies used data from census and national surveys to generate "}
{"doc124": "![2_image_2.png](2_image_2.png)\n\n## 3. **The Concept And Evolution Of Autonomous Vehicles**\n\nAV (also known as a self-driving car, driverless car, robotic car) is able to drive and navigate without direct human inputs by using sensing technology (e.g., radar, Global Positioning System (GPS), and computer vision) and advanced control systems (i.e., sensors) (Howard & Dai, 2014; Narayanan et al., 2020). These automated vehicles are expected to bring revolutionary changes in people's mobility, transportation systems, and land-use patterns (Brown et al., 2014; Meyer et al., 2017). A \ndistinctive feature of AVs is to have some level of automation to assist drivers or to replace drivers to take full control of the vehicle (Narayanan et al., 2020). According to the Society of Automotive Engineers \n(SAE International, 2018), the level of vehicle autonomy ranges from Level 0 (i.e., no autonomy) to Level 5 (i.e., full vehicle autonomy) according to technical specifications (Fig. 5). "}
{"doc125": "The National Highway Traffic Safety Administration (NHTSA) of the United States Department of Transportation (USDOT) proposed a safety rule in 2016 that all vehicles produced after 2020 would be equipped with Vehicle to Vehicle (V2V) communication technology to send and receive safety messages (Administration, 2016b). Although NHTSA has yet to mandate any V2V safety measures, it is expected that vehicles would gradually be equipped with safety equipment (i.e., short-rage communication, safety messages) to protect lives. Moreover, NHTSA has adopted the standard of vehicle automation prescribed by SAE (Administration, 2016a, 2017). These interventions from a top-tier transportation safety agency demonstrate their seriousness towards vehicle automation for curbing traffic crashes. \n\nIt is anticipated that on-demand mobility services and vehicle automation will grow rapidly in the coming decades (Jones & Leibowicz, 2019). The annual global sales of AVs would grow to $173.15 billion by 2030, with a 65.31% contribution from shared mobility (Sullivan, 2018). Thus, AV is a reality now and it is expected that it would become a daily travel mode for many people shortly (i.e., 10 - 30 years) (Stocker & Shaheen, 2018; Zakharenko, 2016). \n\nDespite enormous efforts by different companies and agencies to bring AVs to market, AVs are yet to be a regular transportation mode. Some studies have investigated the current implementation status of AVs and their future evolution across the world (Bansal & Kockelman, 2017; Nieuwenhuijsen et al., 2018). For example, Zhang and Wang \n(2020) estimated that the market share of AVs may vary from 20 to 90% \nby 2040 in Atlanta, the United States (US). Conducting a web-based survey of 246,642 Japanese residents between November and December 2015, Shin et al. (2019) reported that 53% of respondents expect AVs to be on the market in 15 years, whereas 40% expect a 6-to 10-year timeframe. Considering 2030 as the year of introduction of level 4 and 5 AVs, Trommer et al. (2018) calculated that the market share of AVs (level 4 and 5) would be 17% in Germany and 11% in the US, by 2035. Another study predicted that the market share of AVs would be about 80% in Korea in 2060 (Kim et al., 2015). Litman (2017) commented that level 5 AVs would be able to operate commercially and legally in the 2020s within certain jurisdictions and with limited performance. However, most benefits of AVs will be prominent and significant in the 2050s to 2060s when AVs would be common and affordable. "}
{"doc126": "Based on this discussion, an expected timeline from planning to full implementation of AVs is portrayed in Fig. 6. This implementation timeline is compiled on several articles such as Litman (2017), Bansal and Kockelman (2017), Kim et al. (2015), Shin et al. (2019), \nNieuwenhuijsen et al. (2018), and Zhang and Wang (2020). The figure illustrates that AVs would be available for people's regular use incrementally over the coming decades. Literature shows that countries around the world are resolute to test and employ AVs. At the same time, city planners are putting in place strategies to adjust to a new reality. However, most urban policymakers are yet to start formulating plans for AV adoption due to a lack of real-world experience (Gonz\u00b4alez-Gonzalez \u00b4\net al., 2019). Thus, it is necessary to understand the merits and demerits of AVs through their impacts on people, communities, and cities for informed decision-making. \n\n## 4. **The Potential Impacts Of Avs**\n\nAVs would have both positive and negative effects on people and society. To better understand the potential impacts of AVs and their associated advantages and disadvantages, a SWOT (Strength, Weakness, Opportunity, and Threat) analysis is performed after reviewing the existing literature, following (Litman, 2017; University of Kentucky, 2020). This SWOT analysis provides a framework and helps us organize and discuss the Strengths, Weaknesses, Opportunities, and Threats of AVs in a single structure. The SWOT analysis also reveals the internal (e. g., users) and external (e.g., pedestrians) factors associated with AV adoption. While Strengths and Weaknesses respectively indicate the advantages and disadvantages of AVs for their users, Opportunities and Threats illustrate their advantages and disadvantages for other people and the surrounding environments. With the underpinning provided by Fig. 7, we discuss the anticipated positive and negative effects of AVs in four segments. First, Subsection 4.1 explains the impacts on human mobility and transportation systems. Second, Subsection 4.2 summarizes the impacts on traffic safety and on convenience to people. Next, Subsection 4.3 outlines the impacts on energy and the natural environment. Finally, the impacts on the urban built environment are illustrated in Subsection 4.4. "}
{"doc127": "## 4.1. Impacts On Human Mobility And Transportation Systems\n\nThe main anticipated strengths associated with AVs include delay and congestion reduction, increased accessibility and mobility, travel cost savings, and revenue generation for ride-sharing companies (Fig. 7). \n\nThe opportunities afforded by AVs include the reduction in vehicle ownership and the integration of SAV and EV. On the other hand, the main weaknesses of AVs are higher vehicle purchase costs and higher VMT, while critical threats would consist in an increase in travel demand and a reduction in public and active transportation. Based on the findings from the extant literature articulated in Fig. 7, this section discusses the potential impacts of AVs on human mobility and transportation system. The aspects related to human mobility encompass vehicle ownership, VMT, and accessibility and mobility. The transportation aspects discussed here include public transportation, traffic delay and congestion, travel costs and revenue generation, and integration of shared mobility, AV, and EV. User's travel costs and revenue generated by transportation companies can influence overall transportation systems. Similarly, integration of shared mobility, AV, and EV can change the overall landscape of transportation systems. 4.1.1. *Vehicle ownership* The introduction and adoption of commercial AVs are likely to reduce the need for households to own cars by way of an increase in ride-\nFig. 5. Level of vehicle autonomy. "}
{"doc128": "![4_image_1.png](4_image_1.png)\n\nsharing services (e.g., SAVs) (Clements & Kockelman, 2017 ; Krueger et al., 2016 ; Tirachini et al., 2020 ). Fagnant and Kockelman ( 2014 ) reported that each SAV can serve 31-41 passengers per day and therefore many people can do away with owning a car. A sharper reduction could even be achieved at a higher rate of SAVs adoption in areas with low household density and more long-distance trips ( Fagnant & Kockelman, 2018). Since a driver is not required for AV operation, it can be assumed that a household of 3-4 people could own a single private AV and share that vehicle for their travel purposes. Thus, like SAVs, personal AVs would likely reduce household vehicle ownership. Additionally, privately owned AVs could even be rented out to generate income when they are not driven by the owners and could further reduce vehicle ownership (Sparrow & Howard, 2017). Along this line, Arbib and Seba \n(2017) forecasted that the number of vehicles would drop from 247 million in 2020 to 44 million in 2030 in the US due to the expected popularity of AVs. Consequently, it can be anticipated that the fleet of cars and trucks would be reduced by 70%. Using the 2011 Atlanta travel survey data, Zhang et al. (2018) found a reduction in vehicle ownership among over 18% of households. Each of these households would experience a drop of about 1.1 vehicles, while maintaining their current travel pattern. Thus, as reported in Table 1, AVs and SAVs have the potential to reduce vehicle ownership without affecting people's existing travel demand. \n\nResearch has shown that dynamic ride-sharing (i.e., serving multiple travelers with similar origins, destinations, and departure times) can significantly reduce the number of vehicles. For example, Levin et al. "}
{"doc129": "(2017) found that dynamic ride-sharing would reduce vehicle ownership, provide low-cost service, and attract more people by combing multiple trips with the same travel route and destination neighborhood. Additionally, accepting some flexibility in activity scheduling can reduce vehicle ownership (i.e., allowing up to 15-minute delays in arrival at the destination can reduce private AV ownership by 18.3 to 24.1%) (Zhang et al., 2018). \n\n## 4.1.2. Vehicle Miles Traveled\n\nWith better accessibility and mobility, more empty-vehicle travel, and the relocation of parking spaces outside of the city center, AVs would increase per capita travel distance and VMT (Trommer et al., \n2018; Wadud et al., 2016; Zhang & Wang, 2020). People would choose to live further away from their workplace due to lower transportation costs and to the drop in the opportunity cost of travel time by multitasking, which all would lead to additional VMT (Childress et al., 2015; Gelauff et al., 2019). Thus, AVs are anticipated to increase travel distance and VMT, as summarized in Table 2. "}
{"doc130": "Some studies have mentioned that the average travel distance by AVs would not be significantly higher than a conventional car or taxi (Ma et al., 2017; Moorthy et al., 2017). They argued that increased VMT can be compensated by a reduction in the total number of vehicles required for passenger transport and by optimizing trip chaining (Ma et al., 2017). VMT could also be reduced by increasing dynamic ride-sharing \n(Fagnant & Kockelman, 2018; Milakis et al., 2017). Fagnant and Kockelman (2018) observed that a 20 to 30 % increase in shared trips would reduce VMT by 4.4 miles per shared-trip (i.e., a 4.2 % reduction). Thus, increasing SAVs, particularly within a high-density area, may reduce empty VMT (Fagnant & Kockelman, 2014; Levin et al., 2017). Furthermore, the implementation of a flexible work schedule could reduce the average VMT per traveler (Greenblatt & Saxena, 2015; Kyriakidis et al., \n2015). A flexible work schedule will allow workers to work at variable work rosters and SAV drop-offs and pick-ups can be coordinated to reduce empty VMT. \n\n| scope to achieve a more socially sustainable transportation system                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Impact of AV on vehicle ownership.  Study Car ownership reduction  (Kim, 2018) 44% reduction in ownership per household  (Zhang et al., 2018) 9.5% reduction in private vehicles  (Fagnant &  10-fold reduction in private vehicles  Kockelman, 2014)  (Arbib & Seba, 2017) 80% reduction in vehicles  (Fagnant &  10-fold reduction in private vehicles  Kockelman, 2018)  (Levin et al., 2017) -One SAV could replace 3.6 private vehicles  -Each SAV can carry up to 4 people with 1000 SAVs and  serve 31.4-person trips with 2000 SAVs in the system  (Fagnant &  10% penetration reduces vehicles by 4.7% (23.7% in 50%  Kockelman, 2015)  and 42.6% in 90% penetration)  (Zhang et al., 2018) Private vehicle ownership reduced from 9.5% (no delay) to  12.3% (15 min delay).  (Narayanan et al.,  Occupancy increases from 1.2 to 3, 10 vehicles are  2020)  replaced by 1.18 SAVs  (Loeb & Kockelman,  Low-range and slow charge Shared Autonomous Electric  2019)  Vehicles (SAEVs) replace 3.75 vehicles, long-range and  fast charge SAEVs replace 8 - 11.5 vehicles  (Milakis et al., 2017) 67% to over 90% reduction  (Frey, 2017) -30,000 AVs will displace 50% peak commuters for 2  million people in the US  -4 million AVs will replace 50% of all commuter traffic  (Ma et al., 2017) Each SAV replaces over 13 private vehicles or traditional  taxis.  (Chehri & Mouftah,  30% reduction in vehicle number  2019)  (Cyganski et al., 2018) 35% reduction in personal car use and 11.6% to 8.6%  reduction in car drive with a reduced fleet size in 2030  than 2010  (Chen et al., 2016) -an 80-mile and a 200-mile range Level 2 SAEVs could  replace 3.7 and 5.5 private cars, respectively  -Level 3 fast charger can replace 5.4 vehicles for 80-mile  and 6.8 vehicles for 200-mile | Table 2  Impact on travel distance and VMT.  Study Impact on travel distance/VMT  (Narayanan et al., 2020) Trip length: -15% to +14%, VMT: -45% to +89%  (Gelauff et al., 2019) 5 - 25% increase in VMT  (Fagnant & Kockelman,  Up to 10% increase in travel distance  2014)  (Fagnant & Kockelman,  2 - 9% increase in VMT  2015)  (Zhang et al., 2015) 15.3 - 62.3% increase in daily VMT  (Zhang et al., 2018) Median VMT increase of 26.5 miles per household, total  VMT increase of 13.3%  (Loeb & Kockelman,  6.05 - 14.2% increase in empty VMT per SAV  2019)  (Wadud et al., 2016) 2 - 10% increase in VMT  (Tirachini et al., 2020) VKT increase of SAV: 7 to 10 km/passenger, VKT increase  of buses: 0.4 to 1.1 km/passenger  (Childress et al., 2015) 11 - 20% more empty VMT by SAVs  (Loeb et al., 2018) SAEV on average generate 19.6 - 31.5% more vacant  VMT  (Levin et al., 2017) Personal AV has a 2.5% lower VMT than a personal  conventional vehicle  (Harper et al., 2016) 2 - 14% increase in annual VMT  (Ma et al., 2017) 15% increase in VMT  (Carrese et al., 2019) 100% penetration of ride-sharing reduces VMT up to  19%  (Auld et al., 2018) 42% increase in travel distance  (Alam & Habib, 2018) 15% (20%) share of SAV increases VKT by 1.73% (14%)  (Horl, \u00a8 2017) 28.01% and 30.57% empty VMT in Taxi and taxi pool,  respectively for 1000 AVs on the fleet  (Zhang &  5 - 14% VMT increase  Guhathakurta, 2017)  (Arbib & Seba, 2017) VMT increased by 50% in 2030 over 2015 |\n\n(Hess, 2020; Milakis et al., 2017). "}
{"doc131": "According to the US Bureau of Transportation Statistics, about 25.5 million Americans face travel restrictions due to disabilities (Brumbaugh, 2018). Among them, about 3.6 million do not leave their homes due to low vehicle ownership, lack of driver's license, and unemployment. They mostly depend on other family members and friends for reaching activity sites away from home. Information on the travel strategies of US people with disabilities (ages 18-64) is collected from the 2017 National Household Travel Survey (NHTS) and presented in Fig. 8. It is estimated that 70.6% of them curtail their day-to-day travel, whereas 44.3% depend on others for travel. Also, it is reported that 21.6% of them have given up driving and 14.4% use less public transport. Moreover, 14.4% of people use special transportation facilities (i. \n\ne., dial-a-ride or reduced-fare taxi). The deployment of AV technologies offers the opportunity to better serve this market through shared mobility services. AV technologies can substantially raise the mobility of people who are unable to drive and travel otherwise due to disabilities \n(Brumbaugh, 2018). \n\n## 4.1.4. Public Transportation"}
{"doc132": "It has been argued that AVs are the most disruptive technologies in the transport sector, having the potential to weaken public transit ridership (Hess, 2020; Kapser & Abdelrahman, 2020; Meyer et al., \n2017). The availability of shared vehicles and the use of SAVs may be particularly effective at curtailing public transportation, as well as active transportation (Clements & Kockelman, 2017; Cyganski et al., 2018; Narayanan et al., 2020). Thus, AVs may be regarded as a major existential threat to present and future transit systems (Handsfield, 2011). \n\nHowever, when seen as a shared mobility option, AVs could be integrated with an efficient public transport system to ensure the sustainability of urban transportation systems (Narayanan et al., 2020; Sparrow & Howard, 2017). Public transport carries a large number of passengers from one station to another, but some other transport option may facilitate the transfer of people between home / workplace and the stations. AVs can solve this last-mile problem and attract passengers away from private vehicles to public transit (Moorthy et al., 2017; Sparrow & Howard, 2017). Thus, AVs should be mobilized so they would not disrupt the current transport system but increase its efficiency and cost-effectiveness instead. \n\nFurthermore, patterned after the successes of Transit-Oriented Development (TOD), Robocar-Oriented Development (ROD) (Templeton, 2012) could be promoted in areas surrounding transit stations. ROD \nwould be a high residential density and mixed-use development with minimal auto facilities. People would mainly use AVs and SAVs to travel to transit stations as a short-distance shuttle service would. There would be convenient drop-off and pick-up zones very close to stations. Multilevel drop-off or pick-up zones also could be built to optimize space utilization where land value is comparatively higher. There would be a vehicle-waiting zone from where personal and shared AVs would drop and pick up riders. Thus, through a strategic partnership with AVs, public transport would avert a declining market share and a more sustainable transportation system could be achieved. "}
{"doc133": "4.1.5. *Traffic delay and congestion* AVs have the potential to reduce traffic delay and congestion by promoting ride-sharing options, and by smoothing traffic flows using Adaptive Cruise Control (ACC) measures and traffic monitoring systems \n(Alam & Habib, 2018; Daziano et al., 2017; Krueger et al., 2016). A \nhigher rate of automation, dedicated lanes for AVs/CAVs, and dynamic control of the fleet size could significantly reduce travel time and delay by increasing roadway capacity and throughput of vehicles and by reducing empty trips (Amirgholy et al., 2020; Levin et al., 2017; Zhang et al., 2015). Under a 100% AV scenario in 2060, Kim et al. (2015) calculated that about 3 million vehicle hours will be saved in the Seoul Metropolitan Area (SMA), which is equivalent to saving one hour for each trip to the SMA in 2013. Thus, SAVs in a dynamic ride-sharing situation could be an effective policy option to reduce traffic delay and congestion, as also reported in Table 3. \n\nResearchers also reported that an heterogeneous traffic stream (i.e., a mixture of PAVs and SAVs) could increase delay and congestion by reducing the average speed on the network (Narayanan et al., 2020). Carrese et al. (2019) reported that SAVs would yield a positive impact for intra-urban trips, but suburban commuters may experience extra traffic congestion due to the sizeable relocation of residents to the suburbs. Some people also believe that AVs are unlikely to reduce congestion and travel time in suburban, exurban, rural areas and in urban commercial districts due to higher travel demand and empty VMT in these particular areas (Meyer et al., 2017; Piao et al., 2016; Schoettle \n& Sivak, 2014b; Van Brummelen et al., 2018). To sum up, considering the potential for congestion reduction by AVs, policymakers should implement appropriate policy measures to achieve a higher rate of AV \npenetration and vehicle ride sharing. For example, a service of large SAVs (e.g., vans, buses) could be implemented to reduce traffic congestion and empty VMT by transferring groups of passengers simultaneously. 4.1.6. *Travel costs and revenue generation* Many researchers have reported that the automation of vehicles may lower travel costs for users by reducing vehicle operation and maintenance costs (e.g., fuel, insurance fees) (Kopelias et al., 2020; Nunes & \nHernandez, 2020; Zakharenko, 2016) (Table 4). SAVs could further reduce travel costs by avoiding parking fees and by reducing fleet size \n(Loeb et al., 2018). AVs ride-sourced by Transport Network Companies (TNCs) are much cheaper to users than solo driving because there are no labor costs and depreciation and insurance are lower (Compostella et al., 2020). Although the initial purchase is a major sunk cost, total lifetime costs remain minor when amortized over service life spanning as much as 400,000 miles. AVs also could reduce the opportunity cost of travel \n\n![6_image_0.png](6_image_0.png)"}
{"doc134": "| Table 3  Impact on traffic delay and congestion.  Study Impact on delay/congestion/speed  (Fagnant &  Drop of 15% in freeway congestion delay at 10% AV  Kockelman, 2015)  penetration  (Carrese et al., 2019) At 100% penetration of SAV, travel time reduction of 10 -  19%  (Levin et al., 2017) -Personal AV (PAVs) can reduce average travel time by  73% over personal car  -160% increase in SAVs reduces travel time by 70%  (Amirgholy et al.,  A higher market share and optimal lane management  2020)  strategy reduce delay up to 78%, limit increase of travel  time to 5%, and reduce delay cost by 66%  (Atiyeh, 2012) 35 - 39% less congestion and 8 - 13% higher traffic speeds  at 50% penetration  (Zhang et al., 2015) Average waiting time reduced by 98.4% with a 45.45%  increase in SAVs  (Zhang et al., 2018) -V/C ratio increased by 6.79 - 8.44% due to increased  travel demand  -V/C ratio increased by 4.99% and 4.39% on expressways  and minor arterials, respectively  (Papadoulis et al.,  Travel time increased by 20% in a 100% penetration rate  2019)  (Auld et al., 2018) 30%-50% reduction in the opportunity cost of travel time  (Qi et al., 2018) -10.7% time saving due to driving assistance via HMI  (human-machine interface)  -Increase of time by 3.2% due to partially automated  driving  (Chehri & Mouftah,  Urban travel time reduction of 30%  2019)  (Martinez & Viegas,  30% congestion reduction with full adoption of SAVs  2017)  (Kockelman et al.,  78% reduction in travel time at a 100% AVs penetration  2017)  (Wellik & Kockelman,  3.4 to 8.1% increase in travel time to work at 100% AV  2020)  scenario   | Table 4  Impacts of AVs on travel costs and revenue generation.  Study Impacts on travel costs and revenue generation  (Fagnant & Kockelman,  SAVs reduce average trip costs by 30 to 85%  2014)  (Van den Berg &  2 to 40% reduction in total travel costs by AVs compared  Verhoef, 2016)  to no-AV condition  (Milakis et al., 2017) Social benefits/AV/year could reach $3900 at 90% AV  adoption  (Wadud, 2017) At least a 15% reduction in the total cost of ownership  from full automation  (Moorthy et al., 2017) Travel cost of AV ($13.71) is less than personal vehicle  ($14.01), higher reduction of travel time in AV ($18.20)  than personal vehicle ($15.9)  (Fagnant & Kockelman,  Fleet operator paying $70,000/SAV could earn 19  2018)  %/year while offering services at $1.00/mile for a nonshared trip (i.e., 33% less from traditional taxi fare)  (Greenblatt & Saxena,  Cost/mile is lower for SAV (30 - 50 US\u00a2/mile) than  2015)  private vehicles (80 US\u00a2/mile)  (Gelauff et al., 2019) Up to 10% of welfare benefits due to population  relocation and land-use changes  (Narayanan et al., 2020) Opportunity cost of travel time reduced from 10 to 31%,  household savings per year increased by $5600, and  revenue generation increased by 19%  (Fagnant & Kockelman,  -$2,000 to $4,000/year/AV safety benefits, travel time  2015)  reduction, fuel efficiency, and parking benefits  -Parking saving $3.2, $250 savings per AV, 756 million  hours travel time saving, 102 million gallons fuel saving  (Compostella et al.,  -Cost reduced by 4 - 10%/year after commercial  2020)  introduction  -50% decrease in maintenance and insurance costs  reduce $0.04 per VMT  -Decreasing AV cost to $3,333 per vehicle lowers cost by  $0.06 per mile  (Nunes & Hernandez,  Revenue increased by 30% with increasing occupancy  2020)  from 1.67 to 2.2 and 75% with increasing occupancy  from 1.67 to 2.92, whereas single AV lowered profits by  37%  (Chehri & Mouftah,  Travel costs reduced by 50%  2019)  (Martinez & Viegas,  SAV reduce travel cost by 45%/km than public transport  2017)  (Clements &  Higher share of CAV saves $3,800/American/year by  Kockelman, 2017)  reducing costs related to insurance, crashes, vehicle  repair, personal travel, legal services, etc.  (Kockelman et al., 2017) 75% reduction of crash costs, $1,357 per year cost  savings per driver   |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|\n| time as people can spend time on other activities (e.g., reading, talking  with friends, e-work) while riding in a vehicle (Van den Berg & Verhoef,  2016). On the other hand, some studies have also reported that AVs  would increase third-party liability insurance coverage (Xu & Fan,  2019). Uncertainty persists though, as policymakers have yet to decide  whether travelers or manufacturers would pay higher insurance premium for AVs due to newly perceived cyber risks besides risks of traffic  crashes (Yeomans, 2014). Thus, there is still tremendous uncertainty on  whether the overall costs of AV ownership and use would be lower,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |   |\n\ntime as people can spend time on other activities (e.g., reading, talking with friends, e-work) while riding in a vehicle (Van den Berg & Verhoef, 2016). On the other hand, some studies have also reported that AVs would increase third-party liability insurance coverage (Xu & Fan, 2019). Uncertainty persists though, as policymakers have yet to decide whether travelers or manufacturers would pay higher insurance premium for AVs due to newly perceived cyber risks besides risks of traffic crashes (Yeomans, 2014). Thus, there is still tremendous uncertainty on whether the overall costs of AV ownership and use would be lower, considering diverse insurance expenses such as third-party insurance, comprehensive vehicle insurance, public liability insurance, product liability insurance, and self-insurance. (Abu Bakar et al., 2022). \n\nThe adoption of AVs would increase the welfare benefits of citizens and the revenue generation of commercial transportation operators (Narayanan et al., 2020). It has been estimated that AVs could yield up to 5 billion Euros in savings per year in the Netherlands alone under full automation by reducing generalized transport costs and with expected changes in modal split (Gelauff et al., 2019). Fagnant and Kockelman (2015) found a total of $196 billion economic benefits with a 90% AV \nmarket share in the US due to cost reduction for congestion, crashes, travel time, fuel use, and parking fees. It has been noted also that these benefits, although small compared to commercial taxi operation, will disproportionately be enjoyed by households in the wealthiest percentiles under full automation in personal cars (Wadud, 2017). "}
{"doc135": "In summary, the extant literature shows that AVs and SAVs are likely to reduce transportation costs and increase revenue generation for commercial fleet operators. Thus, researchers have suggested to expand funding for R&D and formulating guidelines for AVs to accelerate AV use (Fagnant & Kockelman, 2015). \n\n4.1.7. *Integration of shared mobility, AV, and EV* \nSAVs would be more popular than other vehicles operated by TNCs due to cheaper, safer, and more efficient transport options. Researchers have indicated that SAVs can further influence people's travel behaviors by embracing cutting-edge EV technologies (Kova\u02c7ci\u00b4c et al., 2022; Loeb & \nKockelman, 2019; Offer, 2015; Zhang et al., 2020). Hence, SAEVs will be efficient (travel costs, energy use, emission, and empty VMT would be low) and reliable (Dlugosch et al., 2022; Golbabaei et al., 2021; Huber et al., 2022; Pan et al., 2021; Roca-Puigros ` et al., 2023). Chen et al. \n\n(2016) mentioned that long-range and fast charging SAEVs can serve 96 - 98% of trip requests with a rather small average wait time of 7 - 10 minutes per trip. In contrast, short-range and slow charging SAEVs would be unable to serve 55% of trip requests due to poor response time and an additional 5.4% of trips due to trip length constraints (Loeb & \nKockelman, 2019). In addition, simulating a similar scenario for Austin, TX, Chen et al. (2016) found that empty VMT could drop to 3 - 4%, \naverage wait times could shrink to 2 - 4 minutes per trip, and each SAEV \nwould replace 5 - 9 private vehicles. Thus, SAEVs have the potential to further reduce vehicle ownership, empty VMT, response time, and wait time. In short, long-range and fast charging SAEVs are important for the successful deployment of vehicle automation. "}
{"doc136": "By coupling with a renewable power source, SAVs also provide environment-friendly transport options. An SAEV can reduce energy use by 90 - 100% compared to ICEs due to efficient travel and electrification of vehicles (Milakis et al., 2017). Conducting agent-based modeling, Zhang and Wang (2020) found that each SAEV can reduce carbon emission by 75% in California. They also observed that SAEVs are likely to reduce travel costs by reducing vehicle operation costs. Thus, the integration of AVs and EV technologies with adequate vehicles has a synergistic effect on reducing VMT, vehicle ownership, travel cost, and GHG emissions (Offer, 2015). Researchers have mentioned that future transportation would consist of shared and on-demand mobility, CAVs, and EVs to provide improved transportation services to populations. \n\nFig. 9 illustrates this paradigm shift in the transportation system with the advent of technologies where a proper integration of SAEVs will provide reliable transportation. \n\n## 4.2. Impacts On Traffic Safety And On Convenience To People"}
{"doc137": "Key strengths of AVs include people's travel safety, increased convenience, and productivity of riding time, and reduced driving stress, as indicated in Fig. 7. Prominent weaknesses AV users would confront include personal privacy breaches, technology misuse, and systems failure. On the other hand, one of the main threats people would experience is increased criminal activities. This subsection describes the potential impacts of AVs on passengers' safety, security, productivity, and convenience factors. \n\n## 4.2.1. Traffic Safety\n\nThe extant literature indicates that AVs would reduce the exposure of passengers to traffic crashes (Duan et al., 2020; Karbasi & O'Hern, 2022; Trommer et al., 2018; Underwood & Firmin, 2014; Vahidi & Sciarretta, 2018). Equipping vehicles with ADDS, higher levels of automation (i.e., level 3 or higher), and a high rate of AV adoption would all increase people's safety (Milakis et al., 2017). It is estimated that AVs can avoid more than 90% of all crashes that involve human errors by adding collision avoidance technologies (Chehri & Mouftah, 2019; Daziano et al., 2017; Nunes & Hernandez, 2020). More than 40% of fatal crashes due to human factors can be avoided by using AV technologies (Fagnant \n& Kockelman, 2015). Conducting a simulation study in England, Papadoulis et al. (2019) reported that CAVs would reduce traffic crashes by 12 to 94% with a 25 to 100% penetration rate. The majority of these crashes, particularly at a higher rate of penetration, would be eliminated by designing the control system of vehicles to avoid collisions in traffic merging and diverging areas due to high variations of vehicular speeds and to lane change occurrences. Using data from crash reports from 2005 to 2008, Najm et al. (2010) estimated that V2V and Vehicle to Infrastructure (V2I) communication could reduce crashes by 72 to 83%. Thus, vehicle automation and various connectivity technologies are likely to reduce vehicle crashes (Begg, 2014). "}
{"doc138": "Conducting online surveys, researchers found that 37.30 to 88.80% \nof respondents would like to adopt AVs owing to their capability to reduce the number and severity of crashes and to improve emergency response to crashes (Piao et al., 2016; Schoettle & Sivak, 2014a, 2014b). \n\nAlthough AVs could reduce the number of crashes caused by human errors, they are also prone to accidents themselves due to faulty system design (Bansal et al., 2016). Additionally, AVs would pose a threat to personal security and privacy in smart city contexts due to the reliance on electronic sensors and devices to exchange information. The main sources of concern are cyberattacks, maliciously controlled vehicles, and software hacks by harnessing technologies (Milakis et al., 2017). 4.2.2. *Convenience, productivity, and privacy* Many researchers have mentioned that AVs would increase the convenience, efficiency, and productivity of riders while incurring low transportation costs (Clements & Kockelman, 2017; Hess, 2020; Vahidi & Sciarretta, 2018). People would be involved in a variety of productive activities (e.g., reading, messaging, talking on the phone, resting or relaxing) rather than passing time idling or stressing out, which makes the journey more meaningful and useful (Piao et al., 2016; Schoettle & \nSivak, 2014b). Wadud and Huda (2019) reported that car passengers engage in 3.6 different types of activities in each leg of a journey. \n\n![8_image_0.png](8_image_0.png)"}
{"doc139": "Talking or texting friends and looking out of the window are the most appealing tasks among people traveling in AVs (Howard & Dai, 2014; Schoettle & Sivak, 2014b). Thus, automated driving can significantly increase the convenience and efficiency of the journey by engaging people in various activities. \n\nAVs can also increase the convenience to passengers by reducing waiting time, particularly during peak hours via dynamic ride-sharing \n(Fagnant & Kockelman, 2014; Fagnant & Kockelman, 2018). Fagnant and Kockelman (2018) found that total service time (i.e., wait, pick-up/drop-off, and in-vehicle) could be reduced from 15 minutes to 14.7 minutes via dynamic ride-sharing. Although SAVs would reduce total service time by a trivial amount (about 2% savings), they can reduce average wait time significantly. Fagnant and Kockelman (2014) found that average wait time could be reduced by 51% when the trip generation rates are doubled and fleet size increased by 92% compared to the base case scenario. In contrast, wait time increased by 86.6% \nwhen trips are halved, and fleet size is reduced by 49%. Similarly, wait time increased by 206.67% when trips are quartered, and fleet size is reduced by 74.34%. Thus, a large enough number of SAVs is necessary to generate enough benefit in the convenience and service quality through a reduction in overall wait time. \n\nMany researchers have found that AVs would open the door to breaches of passengers' privacy by increasing the level of surveillance and monitoring of their mobility patterns, which may threaten people's sense of security and privacy and discourage people to buy and share AVs (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Hess, 2020; Howard & Dai, 2014; Konig \u00a8 & Neumayr, 2017). Consequently, a segment of people would feel disenfranchised and be reluctant to use AVs and SAVs (Hulse et al., 2018). Similar to privacy issues, people are concerned about the misuse of technology by unscrupulous individuals (software hackers) (Kyriakidis et al., 2015; Van den Berg & Verhoef, 2016). Many surveyed riders recommend to increase the security and maintain their privacy to increase AV and SAV use (Gurumurthy & Kockelman, 2020; Panagiotopoulos & Dimitrakopoulos, 2018; Salonen, 2018). "}
{"doc140": "As presented in Table 5, AVs are set to reduce energy use by decreasing vehicle ownership and weight, and operating vehicles efficiently by limiting acceleration and deceleration using ACC with lane assist systems and Vehicle-to-Everything (V2X) communication \n(Haboucha et al., 2017; Han et al., 2023; Loeb et al., 2018; Mersky & \nSamaras, 2016). Energy use could be further reduced by implementing the ride-sharing services of AVs, particularly in the urban areas where travel demand is higher (Greenblatt & Saxena, 2015; Ross & Guhathakurta, 2017). A coordinated flow of CAVs could also increase the energy efficiency of ICE vehicles in mixed traffic situations by establishing a harmonized relationship with the surrounding traffic even at a lower level of CAV market penetration (Vahidi & Sciarretta, 2018). Thus, prior knowledge on the roadway environment (e.g., speed limit, grade, curve), avoidance of frequent starts and stops, efficient lane change, coordinated and smooth traffic flow, proper signal phasing and timing, vehicle weight reduction and right-sizing, and vehicle sharing, could all reduce transport energy consumption significantly (Vahidi & Sciarretta, 2018; Wadud et al., 2016). \n\nIn contrast, some researchers have also found that AVs and ridesharing schemes could potentially increase energy consumption because of increased travel demand, VMT, and traffic speed, and in case automobile-oriented developments are encouraged at the outskirts of urban regions (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Ross & Guhathakurta, \n\n| Table 5  Impact on energy use.  Study   | Impacts on energy use                                                                                                                                                                                                                                                            |\n|-----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| (Fagnant &                              | Each SAV will reduce energy use by 12%                                                                                                                                                                                                                                           |\n| Kockelman, 2014)                        |                                                                                                                                                                                                                                                                                  |\n| (Kopelias et al., 2020)                 | CAVs reduce fuel use by 30 - 90%                                                                                                                                                                                                                                                 |\n| (Qi et al., 2018)                       | 12 - 22% energy savings from driving assistance via HMI  and partially automation                                                                                                                                                                                                |\n| (Atiyeh, 2012)                          | Fuel economy increased by 23 - 39% for all vehicles in  freeway travel stream                                                                                                                                                                                                    |\n| (Chen et al., 2018)                     | As high as a 90% improvement in fuel economy by each  AV                                                                                                                                                                                                                         |\n| (Narayanan et al.,                      | SAV energy consumption reduced by 37 to 80%                                                                                                                                                                                                                                      |\n| 2020)                                   |                                                                                                                                                                                                                                                                                  |\n| (Moorthy et al., 2017)                  | Public transit with last-mile AV would save energy up to  37% over personal vehicle                                                                                                                                                                                              |\n| (Arbib & Seba, 2017)                    | About 30% reduction in energy use in 2030 compared to  2020                                                                                                                                                                                                                      |\n| (Kim, 2018)                             | About 56% reduction in 2030 compared to 2016                                                                                                                                                                                                                                     |\n| (Manzie et al., 2007)                   | Only 7s traffic look-ahead ability (i.e., long distance  information transmission via telematic capability)  improves fuel economy by 33%                                                                                                                                        |\n| (Greenblatt & Saxena,                   | A 10% decrease in single-occupancy VMT reduces energy                                                                                                                                                                                                                            |\n| 2015)                                   | use by about 3%.                                                                                                                                                                                                                                                                 |\n| (Bullis, 2011)                          | 4-m inter-track spacing reduces fuel consumption by 10 -  15%                                                                                                                                                                                                                    |\n| (Milakis et al., 2017)                  | -Up to 45% fuel savings by control algorithms and  optimization systems  -About 90 - 100% of energy saving by battery SAEVs                                                                                                                                                      |\n| (Vahidi & Sciarretta,                   | 2 - 50% energy savings due to advanced knowledge of                                                                                                                                                                                                                              |\n| 2018)                                   | road grade, proper signal phasing and timing, cooperative  car following and lane selection                                                                                                                                                                                      |\n| (Wadud et al., 2016)                    | 0 - 45% reduction in energy use due to congestion  mitigation, platooning, eco-driving, light-weighting, right  sizing, reduced footprint of infrastructure and 0 - 60%  increase in energy use due to higher speed, increased  features in vehicles, and people's travel demand |\n| (Brown et al., 2014)                    | AVs could reduce energy use by over 90%. However,  under rise in service demand and speed of AVs, energy use  could increase to 173%                                                                                                                                             |\n| (Chehri & Mouftah,                      | ACC, eco-driving, and inter-vehicle communication                                                                                                                                                                                                                                |\n| 2019)                                   | reduce fuel use by 2 - 4%                                                                                                                                                                                                                                                        |\n| (Liu et al., 2017)                      | 11 to 55% reduction by CAV                                                                                                                                                                                                                                                       |\n| (Ross & Guhathakurta,                   | Over 50% of energy savings by ride-sharing of full AVs                                                                                                                                                                                                                           |\n| 2017)                                   |                                                                                                                                                                                                                                                                                  |"}
{"doc141": "2017). Vehicle automation can also generate longer and more energy-intensive commutes, replace energy-efficient public transportation, induce urban sprawl, and thus increase energy use (Hess, 2020). Additionally, reduction in the opportunity cost of travel time can increase fuel use substantially by increasing long-distance trips (Auld et al., 2018). Thus, the net effect of AVs on transport energy use is uncertain, which warrants further investigation (Milakis et al., 2017). \n\nAlthough automation would reduce overall energy use, oil demand for electricity generation will increase to charge AVs. Kim (2018) estimated that to charge 44 million AVs with a battery of 70kWh, the industry would require 3080 GWh per day extra energy by 2030 in the US, \nassuming each AV charge once a day. About 33 more nuclear power plants of equal size to Palo Verde nuclear power plant in Arizona would be required with 24 hours of operation each day to generate that amount of electricity. Thus, the policymakers should take appropriate actions to manage additional energy demand considering the anticipated impacts on the electrical grids. \n\n## 4.3.2. Ghg Emissions"}
{"doc142": "Researchers found that AV technologies can significantly reduce GHG emissions (Duan et al., 2020; Fakhrmoosavi et al., 2022; Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Le Hong & Zimmerman, 2021). CAVs, SAVs, and on-demand mobility options can further reduce emissions by lowering the number of engine start, energy consumption, and vehicle ownership (Coulombel et al., 2019; Wadud & Anable, 2016). The integration of EVs and SAVs presents an added potential to sharply reduce emissions. Jones and Leibowicz (2019) found that the adoption of SAVs could be more impactful in controlling vehicle emissions than a carbon tax policy, despite higher VMT. The estimations of emission reduction by different types of AVs are presented in Table 6. Overall, AVs show the potential to reduce emissions and improve air quality. However, a lower share of AVs (i.e., 30%) could instead increase emission due to a slight rise in traffic demand and in traffic speed, and to aggressive acceleration after a stop to reach cruise speed again (Rafael et al., 2020). \n\nAVs operated as shuttle services (6 kg CO2-equivalent per passenger) \nemits lower carbon in the whole life than the AVs operated as a personal vehicle (10 kg CO2-equivalent per passenger) (Moorthy et al., 2017). However, the net effect of AVs on GHG emissions remains ambiguous (Milakis et al., 2017). Travel demand reduction due to shared mobility is canceled out by the increased travel distance and empty running (Wadud et al., 2016). Thus, further research is more likely needed to determine the actual effect of AVs on emission reduction (Rafael et al., \n2020). \n\n## 4.4. Impacts Of Avs On The Urban Built Environment"}
{"doc143": "The SWOT analysis (Fig. 7) indicates that AVs would have the opportunity to reduce parking demand, but would also increase roadway capacity. However, the main threats AVs may cause include increased demand for transport infrastructure and urban expansion. Based on the existing literature, this subsection recognizes the potential impacts of AVs on the urban built environment. \n\n## 4.4.1. Spatial Patterns Of Urban Growth\n\nMany studies have argued that the advent of AVs would influence the layout of urban areas (Biloria, 2023; Cugurullo et al., 2021; Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Meyer et al., 2017; Van den Berg & \nVerhoef, 2016). By reducing travel costs, AVs may affect residential and work locations, leading to intensified urban sprawl and the inefficient use of land (Fraedrich et al., 2019; Krueger et al., 2019; Zakharenko, 2016). An agent-based simulation study in Korea found new development scattered throughout the region along with growth near existing urban centers stemming from households' preference for urban amenities in a scenario where 100% of vehicles are assumed to be AVs compared to the business as usual scenario over the next five decades (Kim et al., 2015). The adoption of AVs may increase city radius by 3.5%, developed land area by 7.1%, and residential area by 7.6% (Zakharenko, 2016). Under currently prevailing policies and conditions, AVs may single-handedly result in urban expansion in the order of 10 - 30% (Litman, 2017). Thus, to facilitate the emergence of AVs without hampering urban living and development, policymakers should endeavor to better understand the potential impacts of AVs on the spatial distribution of land uses. "}
{"doc144": "Conducting a web-based survey, Carrese et al. (2019) found that about 40% of respondents would move to the suburbs under the AV \nregime in Rome, Italy. Similarly, Wellik and Kockelman (2020) reported a 5.3 to 5.5% reduction in the number of households living in the metropolitan region of Austin, TX at a 100% AV scenario compared to a 0% AV scenario over a 27-year timespan (2013 - 2040). They also mentioned a 5.8 to 6.2% growth in the number of households living in the non-metropolitan regions of Austin. Thus, AV would influence people's residential locations by increasing accessibility, mobility, and convenience, and by reducing the opportunity cost of travel time. \n\nExperts confirmed that, in conjunction with triggering the emergence of new peripheral centers (edge cities), AVs would also densify the existing urban fabric by reallocating space for residential, economic, and leisure activities (Gonz\u00b4alez-Gonzalez \u00b4 et al., 2019; Milakis et al., 2018). \n\nSpace released from on- and off-street parking could be used for building wider sidewalks, bicycle paths, delivery bays, new public facilities, activity centers, and high-quality recreation spaces (Clements & Kockelman, 2017; Martinez & Viegas, 2017). Since AVs can reduce car ownership, it is likely that less space will be used for streets, parking lots and garages, and possibly expand high density and mixed use developments (Dennis et al., 2017; KPMG International, 2019). Thus, AVs are likely to change the urban landscape by densifying the existing built areas. "}
{"doc145": "A majority of the literature points that AVs would lead to dispersed urban development by reducing travel costs and enhancing the mobility of people. Polycentric development may be seen surrounding the central urban areas due to new development induced by AVs. Consequently, it is likely that city land area and residential and commercial land uses would increase. At the same time, a densification would be observed in the city core by allocating space released from parking spaces for new residential, commercial, and recreational development. \n\n## 4.4.2. Parking Demand\n\nBesides influencing the physical extent of urban areas, AVs are expected to affect urban form by reducing the demand for parking in the established neighborhoods and centers (Clements & Kockelman, 2017; Kopelias et al., 2020; Van den Berg & Verhoef, 2016). As indicated in Table 7, AVs would reduce overall parking demand quite drastically. As a case in point, a recent simulation study estimated a 10% reduction in parking land area by 2020 in the Atlanta core after introducing SAVs \n(Zhang & Wang, 2020); reductions would mushroom to 42 and 75% by 2030 and 2040, respectively. Conducting a study in Los Angeles County, (Chester et al., 2015) observed that about 14% of the county area are currently used for parking. However, this parking area could be reclaimed, particularly in the city center, and repurposed for building "}
{"doc146": "| parking land area by 2020 in the Atlanta core after introducing SAVs  (Zhang & Wang, 2020); reductions would mushroom to 42 and 75% by  2030 and 2040, respectively. Conducting a study in Los Angeles County,  (Chester et al., 2015) observed that about 14% of the county area are  currently used for parking. However, this parking area could be  reclaimed, particularly in the city center, and repurposed for building                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Emission reduction by AVs.  Study Emission reduction  (Milakis et al., 2017) Up to 94% reduction in GHG emission  (Greenblatt & Saxena,  87 - 94% reduction in GHG emissions per mile  2015)  (Kopelias et al., 2020) CAVs reduce GHG emission by 5 to 94%  (Wadud et al., 2016) 20% reduction in carbon emission  (Rafael et al., 2020) 30% reduction of both NOx and CO2 emissions  (Fagnant &  5.6 to 49% reduction in GHG, 34% CO, 19% SO2, 18%  Kockelman, 2014)  NOx, 49% VOC, and 6.5% PM10 emission reduction by  each SAV  (Narayanan et al.,  10 to 94% emission reduction by SAVs  2020)  (Greenblatt &  63 - 82% GHG reduction per mile compared to private  Shaheen, 2015)  gasoline vehicles  (Vahidi & Sciarretta,  1 - 18% emission reduction due to cooperative control  2018)  (Iglinski \u00b4 & Babiak,  40 - 60% reduction in GHG emission  2017)  (Chehri & Mouftah,  66% GHG emission reduction  2019)  (Martinez & Viegas,  40% reduction in carbon emission  2017)  (Liu et al., 2017) 3 to 19.09% reduction in emission  (Eilbert et al., 2017) Up to 215% reduction in emission | Table 7  Impact of AV on parking demand.  Study Impact on parking space  (Fagnant & Kockelman,  Average reduction of 11 parking spaces per SAV  2014)  (Narayanan et al., 2020) 48 to 90% reduction in parking land area  (Milakis et al., 2017) Up to 90% reduction in parking land area  (Zhang et al., 2015) Up to 90% reduction in parking land area at a 2% SAV  penetration and about 8.6% reduction in parking land  area per SAV  (Kondor et al., 2018) 50% reduction of parking land area by SAVs  (Kim, 2018) 40% reduction of parking lots  (Chehri & Mouftah,  40% reduction in overall parking land area and 44%  2019)  reduction in parking spots  (Zhang & Guhathakurta,  4.5% reduction in parking land area at a 5% SAV  2017)  adoption and over 20 parking spots reduction per SAV |\n\nhigh-quality and attractive spaces for economic activities to increase land productivity (Gonz\u00b4alez-Gonzalez \u00b4 et al., 2019; Zakharenko, 2016). \n\nWellik and Kockelman (2020) reported a 19.4 to 62.9% increase in developable land in Austin at a 100% AVs scenario over a 0% AVs scenario due to reduction in parking demand. "}
{"doc147": "In contrast, some studies have also suggested the possibility of an increase in parking demand due to the increase in people's travel demand and in case of ride-sharing services are deficient (Zakharenko, 2016; Zhang & Wang, 2020). However, people's willingness to share vehicles, the availability of AV ride-sharing services, and higher penetration rates of SAVs can significantly reduce parking demand (Milakis et al., 2017; Zhang et al., 2015). Thus, researchers (Narayanan et al., 2020) have suggested to take policy actions to augment the use of SAVs and thereby reduce overall vehicle parking demand. \n\nMost previous studies have argued that higher penetration of AVs and SAVs may lower parking demand in residential areas and in business districts by reducing car ownership and increasing ride-sharing. Moreover, AVs may self-park in less expensive areas outside of city centers and reduce parking demand in the city core (Fagnant & Kockelman, 2015). For people living at the outskirts of the city and choosing to own an AV, parking at the edges of the city center may be attractive and may reduce vehicular traffic in the city. Commuting traffic could use a multi-storied parking deck to reduce space utilization in the urban core. \n\nConvenient drop-off and pick-up locations near residences and workplaces would also effectively provide great convenience to travelers. "}
{"doc148": "## 4.4.3. Infrastructure Capacity\n\nThe extant literature reveals that vehicle automation can increase road and intersection capacity by vehicle platooning, using Cooperative Adaptive Cruise Control (CACC), and by exchanging information between vehicles using Vehicle Awareness Devices (VAD) (Kopelias et al., \n2020; Meyer et al., 2017; Zhang et al., 2018). Study results summarized in Table 8 show that AVs are likely to increase roadway capacity of existing facilities more efficiently without adding any lanes (Fernandes \n& Nunes, 2012). This would curtail the need for roadway expansion. \n\nHowever, capacity could be affected by traffic heterogeneity, which could disrupt communication among vehicles (Milakis et al., 2017). "}
{"doc149": "Greater capacity benefits could be achieved even at a lower penetration of AVs if the non-ACC vehicle populations are equipped with VADs which can serve as the lead vehicles for the CACC vehicles \n(Shladover et al., 2012). In contrast, Narayanan et al. (2020) mentioned that AVs should be more than 20% of the vehicle population to achieve \n\n| Table 8  Impact of AV on roadway capacity.  Study Capacity increase  (Fernandes & Nunes,  367%  2012)  (Van den Berg &  7 - 200%  Verhoef, 2016)  (Narayanan et al.,  43 to 273% on highway, 40% on urban roads, 9.39 to  2020)  39.21% with 100% penetration, 215% at 100%  penetration with connectivity and 9.38% without  connectivity  (Milakis et al., 2017) 40% (100%) penetration of AVs increases capacity by  over 10% (200%).  (Shladover et al., 2012) -10%, 50%, and 90% penetration of CACC increase  capacity 1%, 21% and 80%, respectively.  -20%, 30%, and 50% to 60% penetration of vehicles with  Vehicle Awareness Devices (VAD) increase capacity by  7%, over 10%, and 15%, compared with cases without  VADs  (Tientrakool et al.,  About 43 to 273% capacity increase by CAVs due to  2011)  sensors and communication technologies  -34.85 to 83.5% reduction in gaps between vehicles due to  communication technologies and onboard sensors  (Shladover et al., 2012) A 100% increase in capacity when each vehicle is  equipped with short-range communication radios (e.g.,  CACC, VAD)   |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\nan increase in roadway capacity. Thus, a large enough number of CAVs is essential in the market to increase communication between them and thereby to increase roadway capacity over a mixed traffic situation (i.e., non-, semi-, full AV). "}
{"doc150": "## 5. **Discussion And Directions For Future Study**\n\nInvestigating the current status of implementation, researchers reported that AVs will be available for people's regular use incrementally over the coming decades. The findings from the existing literature show that AV would influence urban transportation and human mobility by reducing vehicle ownership, public and active travel, traffic delay and congestion, travel costs, and increasing accessibility, mobility, VMT, and revenue generation for commercial operators. Some studies also mentioned that AVs can further influence people's travel behaviors by embracing cutting-edge EV technologies and providing shared and ondemand mobility services. Investigating the long-term effects, researchers reported that AVs would encourage dispersed urban development, reduce parking demand in city centers and residential areas, and enhance the capacity of the road network. Some studies also observe that AVs have the potential to reduce energy consumption and protect the environment by reducing GHG emissions. Investigating people's safety, security, and privacy, the extant literature reported that most people are very concerned about personal safety, security, and privacy from strangers, cyberattacks, maliciously controlled vehicles, and software hacks. On the other hand, researchers mentioned that AVs are able to reduce traffic crashes involving human errors and increase the convenience and productivity of passengers by providing amenities for multitasking opportunities. \n\nResearchers also believe that SAVs are well positioned to have greater positive impacts on transportation and on the urban environment than private AVs (University of Kentucky, 2020). SAVs in a dynamic ride-sharing situation could be an effective policy option to reduce vehicle ownership, traffic congestion and travel time, and improve overall performance of the transportation system (Loeb et al., \n2018; Zhang et al., 2015). Researchers proposed to formulate appropriate funding mechanisms and policies to encourage ride-sharing and on-demand mobility among travelers to increase use of SAVs (Ross & \nGuhathakurta, 2017). Thus, pertinent policies in transportation (e.g., \nautomation of transit, integration of transit and non-motorized transport, encourage shared and micro mobility), infrastructure (e.g., \nadjustment, and redesign of existing roads), and urban planning (e.g., update of urban development plans, land-use plans, parking policies and design, green belts) are essential to realize the benefits of AVs. Moreover, the law and order situation needs to be improved to provide safety and security to passengers while sharing AVs. "}
{"doc151": "The extant literature provides consistent and compelling evidence that AVs have the potential to bring dramatic changes to urban transportation systems, to their use by populations and to the spatial structure and conditions of the urban built environment. Previous review papers systematically evaluated the short and medium-term effects of AVs on transportation and human mobility and overlooked their long-term effects on the urban built environment. This updated systematic literature review identified, evaluated, and critically analyzed relevant scholarship to understand the current status and impacts of AVs on urban transportation and urban built environments. \n\nWhile significant progress has been made in unraveling the impacts of the commercial deployment of AV technologies, previous studies display some prominent limitations. Several of them are discussed below to identify research gaps and provide guidance for future studies. The research agenda includes two strands of recommendations, one on issues that have been overlooked, one on shortcomings of research conducted so far. \n\n## 5.1. Shortcomings In Research"}
{"doc152": "1) AVs are not currently available for people to use; thus, many simulation studies estimating impacts of AVs are solely based on assumptions (e.g., same vehicles and speeds, similar travel behaviors, vehicles shared by household members only), imaginaries of riders in simulated urban setting (e.g., grid city, typical city), and limited testing (Compostella et al., 2020; Fagnant & Kockelman, 2015; Zhang et al., 2018). Sometimes, vehicles are operated in a homogeneous traffic environment with little interaction with neighboring vehicles (Piao et al., 2016). Moreover, lower levels of autonomy (i.e., \nLevel 1, 2 or 3) were used to understand people's perceptions and assess the impacts of fully automated vehicles (Level 4 or 5) (Rahman et al., 2017; Xu et al., 2018). Thus, to be reflective of real-world decision environments and gauge the real-world impacts of AVs, future studies should investigate the impacts of AVs considering heterogenous populations of users and heterogenous traffic environments allowing interactions with other vehicles, inclement weather conditions, and full automation of vehicles (Level 5). \n\n2) Conducting stated preference surveys, some studies have investigated travel patterns of persons with prior knowledge on AVs and with technological affinity, while disregarding other segments of people (Haboucha et al., 2017; Kapser & Abdelrahman, 2020; Konig \u00a8\n& Neumayr, 2017). Some studies consider travel by private AVs only, while others consider SAVs only, each representing only part of a larger and more complex transportation system (Duan et al., 2020; Krueger et al., 2016; Salonen, 2018). Thus, future studies should draw samples from all segments of people and investigate people's travel patterns by AVs and SAVs to gain a holistic overview of the complex shifts in the socio-technological system grounded in AV \ntechnologies. \n\n3) Some studies have considered certain travel activities only such as work trips, shopping trips, or long distance leisure trips, while ignoring vehicle operations for fueling and parking to estimate the impact of AVs (Compostella et al., 2020; Ma et al., 2017). Also, in some cases, only a generalized network is studied, for instance excluding local last-mile transportation issues (i.e., travel to and from transit station) (Moorthy et al., 2017), or a small section of the whole network of a typical city is considered (Papadoulis et al., \n2019). Thus, studies would be more generalizable by considering the whole transport network of a city to account for travel activities over the complete range of distances and urban contexts to understand the full scope of impacts of AVs. "}
{"doc153": "4) Most studies only considered the sunk costs of ownership to estimate the travel costs by AVs, disregarding the vehicle operation and maintenance costs (Wadud, 2017). Some studies only consider fare collection to estimate the revenue generation by SAVs, while ignoring the maintenance and refueling costs (Duan et al., 2020; Nunes & Hernandez, 2020). Thus, a comprehensive estimation of travel costs and revenue generation comprising of all factors is necessary to better assess decision making by customers and commercial operators. \n\n5) Some studies have simulated the evolution of AVs in different contexts based on various assumptions (e.g., different levels of autonomy and market penetration of AVs, customers' willingness to pay for AVs, small geographic area of analysis, etc.). However, as discussed in Section 3, there is inconsistency in their predictions of the temporal evolution of AVs. Moreover, the evolution of AVs in different contexts could be different considering the socioeconomic condition of the regions/countries and the acceptance of information and communication technologies. Thus, a comprehensive study considering multiple study contexts to understand the temporal evolution of AVs remains needed. \n\n## 5.2. Overlooked And Understudied Aspects"}
{"doc154": "1) Although researchers have mentioned that AVs would increase the accessibility and mobility of all people, including disabled, elderly, children, and people without driving licenses, there is a lack of empirical evidence on the implications of AVs on diversity and social disparity. Thus, empirical studies investigating the impacts of AVs on transport equity should be conducted to achieve social sustainability of transportation system. \n\n2) Although studies have identified a number of positive effects (e.g., \ndensification, economic growth) and negative effects (e.g., urban expansion, higher trip length) (Gelauff et al., 2019; Kim et al., 2020; Milakis et al., 2018) of AV technologies, there is still little evidence on how AVs would effects people's residential and employment location decisions, recreation spaces, parking spaces, supply of infrastructure, and overall urban layout patterns (Kim et al., 2020; Krueger et al., 2019), and the trade-offs that may arise from these diverse and possibly conflicting outcomes. Thus, future research should investigate the long-term effects of AVs on urban land-use patterns to promote AV adoption without disturbing urban living environment and by ensuring efficient use of land. \n\n3) Regulatory frameworks and business models pertaining to AVs and SAVs are still unsettled, which would influence vehicle ownership, residential and workplace locations (Kim et al., 2020; Zafar et al., \n2022). Similarly, researchers have seldom discussed different challenging aspects of carpooling in CAVs such as scheduling, passenger matching, privacy, communication, new norms, policies, infrastructure, and new attitudes (Nemoto et al., 2023; Zafar et al., 2022). "}
{"doc155": "Additionally, there is a scant research on insurance pricing strategies that could be leveraged to estimate the impacts of these emerging technologies on the transportation system. Adequate field testing and civil society and professional involvements are necessary to realize the benefits of automation and to formulate policies (Crayton \n& Meier, 2017; University of Kentucky, 2020). Further research would identify and validate urban and transport policy measures to promote attractive and livable cities considering the introduction of AVs by conducting adequate field tests and by involving relevant stakeholders (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019). \n\n4) Door-to-door services provided by AVs would reduce walking and cycling trips, increase physical inactivity and related health problems (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019). Yet, to the best of our knowledge, there is no empirical study to investigate the impacts of AVs on public health (Crayton & Meier, 2017; Sohrabi et al., 2020). \n\nAlthough many studies have investigated the impacts of AVs on transport energy use and on emissions, the impacts of AVs on noise and light pollutions are rarely explored, which may partly indicate their environmental outcomes (Silva Gomez \u00b4 et al., 2022). Thus, there is a dearth of knowledge and a need to study and evaluate the possible impacts of AVs on public health and environment considering the change in human travel behaviors and urban built environment. "}
{"doc156": "5) Finally, as noted earlier, the overwhelming majority of studies have treated the case of Global North countries where AV technologies and institutional settings are usually regarded as closer to commercial deployment and implementation. The case of Global South countries is poorly understood at this time. Given the sharp rift that separates these two sets of countries, it can hardly be argued that experiences of latter countries will mimic those in the Global North. \n\nResearch on how AVs could touch urban transportation and environments in the Global South is desperately needed to chart pathways towards a sustainable future protecting their natural environment while affording them social and economic opportunities. \n\n## 6. **Conclusion**"}
{"doc157": "This state-of-the-art comprehensive literature review investigated the short, medium, and long-term effects of AVs on urban transportation and urban environments. To understand the advantages and disadvantages associated with AVs, this review study critically analyzed previous papers and summarized the key findings based on a SWOT analysis \n(Fig. 7). The important takeaways from this study include that AVs would encourage dispersed urban development, would reduce parking demand, and would enhance network capacity. AVs would reduce energy consumption and protect the environment by reducing GHG \nemissions. Additionally, AVs would reduce traffic crashes involving human errors and increase the convenience and productivity of passengers. However, most people are very concerned about personal safety, security, and privacy due to increased surveillance and monitoring of their movement and the possibility of cyber-attacks by hackers. \n\nThus, there is agreement among various studies that AVs have the potential to influence urban transportation systems and human mobility by reducing car ownership, public and active travel, congestion, travel costs, and by increasing accessibility, mobility, VMT, and revenue generation for commercial operators. Analyzing results and methodologies, we identified key limitations of previous studies, gaps in our knowledge base, and provided a blueprint with some directions for future research. This research supports decision makers in taking appropriate strategies and actions to manage transportation infrastructure, human mobility, urban built environment, energy consumption and environment and improve safety and security of people. \n\n## Declaration Of Competing Interest"}
{"doc158": "Bansal, P., & Kockelman, K. M. (2017). Forecasting Americans' long-term adoption of connected and autonomous vehicle technologies. *Transportation Research Part A:* \nPolicy and Practice, 95, 49\u201363. \n\nBansal, P., Kockelman, K. M., & Singh, A. (2016). Assessing public opinions of and interest in new vehicle technologies: An Austin perspective. Transportation Research Part C: Emerging Technologies, 67, 1\u201314. \n\nBegg, D. (2014). *A 2050 Vision for London: What are the implications of driverless transport?* \nT. J. P. Ltd.. https://www.transporttimes.co.uk/Admin/uploads/64165-transport-t imes_a-2050-vision-for-london_aw-web-ready.pdf Biloria, N. (2023). Autonomous mobility in the built environment. In P. Droege (Ed.), \nIntelligent Environments (Second Edition): Advanced Systems for a Healthy Planet (pp. "}
{"doc159": "Chen, T. D., Kockelman, K. M., & Hanna, J. P. (2016). Operations of a shared, autonomous, electric vehicle fleet: Implications of vehicle & charging infrastructure decisions. *Transportation Research Part A: Policy and Practice, 94*, 243\u2013254. \n\nChen, Y., Young, S., Qi, X., & Gonder, J. (2018). A First-Order Estimate of Automated Mobility District Fuel Consumption and GHG Emission Impacts. In *Road Vehicle* Automation, 4 pp. 113\u2013123). Springer. \n\nChester, M., Fraser, A., Matute, J., Flower, C., & Pendyala, R. (2015). Parking infrastructure: A constraint on or opportunity for urban redevelopment? A study of Los Angeles County parking supply and growth. *Journal of the American Planning* Association, 81(4), 268\u2013286. "}
{"doc160": "Shared autonomous electric vehicle: Towards social economy of energy and mobility from power-transportation nexus perspective\u2729\nRathor Sumitkumar, Ameena Saad Al-Sumaiti \u2217\nAdvanced Power and Energy Center, Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates A R T I C L E I N F O\n\n| Keywords: Autonomous Connected Coupled power and transportation network Electric vehicle Shared   |\n|---------------------------------------------------------------------------------------------------|\n\nIn addressing the detrimental impacts of greenhouse gas emissions and decarbonization targets, the imperative shift towards electrification in the transportation sector is underscored, with additional advantages arising from shared features. Nevertheless, technological progress, particularly in the realm of connected and autonomous features, brings forth notable benefits but also introduces challenges related to safety, cost, and implementation. The convergence of connectivity, autonomy, shared mobility, and electric propulsion leads to the concept of shared autonomous electric vehicles. In practical integration scenarios several concerns encompassing the transportation network, power network, and user satisfaction. This paper conducts a thorough analysis of various aspects of shared autonomous electric vehicles, rigorously evaluating the feasibility of their integration within a coupled power and transportation network. The analysis highlights allocation, routing, charging, battery swapping, social-economic considerations, and modelling as pivotal areas warranting focused research attention in the realm of shared autonomous electric vehicles."}
{"doc161": "| A B S T R A C T   |\n|-------------------|\n\n## 1. Introduction\n\nPreventing catastrophic consequences for our planet requires urgent and decisive action to reduce greenhouse gas emissions. Governments and private institutions around the world have committed to various goals to minimize these emissions. Compared to 1990 levels, the European Union [1] has vowed to lower GHG emissions by at least 55%. Similarly, the United States [2], Japan [3], and India [4] have pledged to lower their GDP's emissions intensity by 35%\u201355%, all by the year 2030. The worldwide transportation industry is responsible for around 14% [5] of GHG emissions. In contrast, the electric power sector is responsible for about 42% of all GHG emissions, according to the Intergovernmental Panel on Climate Change (IPCC) [6]. The US's main source of GHG emissions is transportation, with over 12 million barrels of oil burned daily. Based on current estimates, global energy consumption is predicted to increase by 28% from 2015 to 2040 [7]. The majority of this energy will be produced by burning fossil fuels in power plants, resulting in harmful environmental consequences such as air pollution, rising temperatures, and climate change. The amount of carbon dioxide (CO2\n) emitted by burning fossil fuels has risen nearly four-fold from 8.7 Gt in 1959 to 37.6 Gt in 2022 [8]. However, over the past few decades, numerous innovations have aimed at creating more sustainable and efficient travel communities prioritizing safety [9] as well in the direction of power generation by integrating more and more renewable energy sources (RES). The past fifty years have seen significant progress in the quest for a more sustainable transportation sector, from advancements in fuel-efficient technologies to developing low-carbon transportation alternatives. The penetration level of electric vehicles (EVs) is increasing day by day after changes in taxation policies and subsidies, low charging rates, highperformance vehicles, and awareness among the public. The segment in internal combustion engines (ICE) or EVs and the feature of advanced driver assistant systems (ADAS) or fully autonomous attracted users towards the new growing market of autonomous vehicles (AV) [10]."}
{"doc162": "Besides that, the addition of internet connectivity in the EV/ICE vehicle segments provides more convenient utilization of vehicles on the road. Internet connectivity over the cellular network/Wifi allows communication with infrastructures or V2X communication. Such communication helps with understanding and decision-making based on real-time traffic information, payment services, roadside assistance, etc. Such vehicles are already on the road, known as connected vehicles\n(CV) [11]. Lastly, apart from public transport, vehicle sharing and subscription concepts such as carpooling, bike sharing, renting, etc.,\n\u2729 **This work is supported in part by ASPIRE, under the ASPIRE Virtual Research Institute (VRI) Program, Award Number VRI20-7. This is to acknowledge the**\nvalue of NEP 3.0 in supporting the leadership of the second author.\n\n\u2217 **Corresponding author.**\nE-mail address: ameena.alsumaiti@ku.ac.ae **(A.S. Al-Sumaiti).**\nhttps://doi.org/10.1016/j.rser.2024.114381 Received 29 May 2023; Received in revised form 29 February 2024; Accepted 21 March 2024 Available online 4 April 2024 1364-0321/\u00a9 2024 Elsevier Ltd. All rights reserved.\n\nR. Sumitkumar and A.S. Al-Sumaiti are introduced by private companies and original equipment manufacturers (OEMs) to reduce the total cost of ownership (TCO) [12]."}
{"doc163": "The gaining popularity of shared vehicles (SV) and different business models increases adoption and convenient transportation. The vehicle is shared among multiple customers, meaning that individuals from different households or locations use the same vehicle to reach their respective destinations. This shared model is designed to enhance transportation efficiency, reduce traffic congestion, and lower the overall environmental impact of commuting. Combining all forms of the abovediscussed vehicle and transportation technology introduced the concept of shared autonomous electric vehicle (SAEV), also known as connected autonomous shared electric (CASE) vehicles. Ref. [13] stated that SAEV\nis a competitive technology for urban mobility. With the increasing market share of electric vehicles, breakthroughs in battery technology, and the promise of automation, SAEV systems are expected to replace traditional gasoline-powered, human-driven car-sharing systems worldwide, offering increased flexibility in pick-up locations and freeing passengers from driving and seeking parking. Overall, SAEVs have the potential to improve the transportation system by reducing congestion, improving air quality, increasing accessibility, saving costs, increasing safety, and increasing efficiency. However, integrating SAEVs into the power network (PN) and transportation network (TN) also comes with several challenges that must be addressed.\n\nOne of the significant challenges of integrating SAEVs into TN is the need for significant infrastructure changes. This includes building charging stations for EVs and dedicated lanes or routes for autonomous vehicles [22]. Without the necessary infrastructure, SAEVs may struggle to operate efficiently and reliably. Another challenge is developing and implementing regulations that govern the use of SAEVs, including safety standards, liability issues, and privacy concerns. Local and national governments must also coordinate to ensure consistent regulations across different regions and jurisdictions. SAEVs have the potential to complement existing public TN, but this requires careful planning and coordination. This includes developing systems for integrating SAEVs with buses, trains, and other modes of public transit and ensuring that SAEVs are accessible and affordable for all community members. Effective data management is critical for ensuring the safety and efficiency of SAEVs, as they generate vast amounts of data, including information about traffic patterns, vehicle performance, and passenger behaviour. Managing this data effectively can optimize PN\nand TN more broadly. Since SAEVs rely on electric power, they require significant energy [23]. This raises concerns about energy consumption, storage, and the environmental impact of generating electricity.\n\nAddressing these concerns will require developing more efficient and sustainable methods for generating and storing electricity and optimizing the use of existing power grids. The successful integration of SAEVs into TN and PN will require a coordinated effort across multiple sectors and stakeholders. While there are challenges to overcome, the potential benefits of SAEVs make this effort worthwhile. It is essential to ensure that SAEVs are safe, accessible, and sustainable for everyone in the community. From the above-discussed challenges, in this article, the integration of SAEVs into TN and PN are discussed with detailed taxonomy, several research works, comparisons, research gaps, and challenges."}
{"doc164": "The previous research on SAEV operation integrated either in PN\n[24] or TN [24,25], carbon footprints [23], sustainable cities [26] and optimization has been limited and not extended to coupled power, and transportation networks (CPTN). This is a significant gap, as CPTN\ndesign planning is critical for infrastructure development and interdependency. Previous studies on the role of SAEV in PN or TN focused on individual users rather than considering the interconnected nature of these networks. Recently, there has been a surge in the publication of research studies on SAEV. Therefore, adopting a holistic approach to consolidate the current knowledge base is crucial. Some of the review work includes morning commutes with endogenous shared autonomous vehicle [27], transportation systems management considering dynamic wireless charging [28,29], logistics and transport [30],\nand blockchain in the autonomous vehicle supply chain [31]. Cybersecurity for SAEV [32]. However, they do not discuss the taxonomy and interdependency of CPTN in the context of SAEV. Table 1 **highlights the**\nexisting literature review articles on SAEV with critical criteria compared with the study reported in this article. Therefore, this paper aims to suggest the concept of SAEV to both the PN and TN communities to encourage collaboration and the creation of a correlation between these coupled problems. By doing so, the potential benefits and challenges of SAEV in the context of CPTN would be better understood, and more effective strategies to improve the overall performance which helps in the development of critical infrastructure systems.\n\n## 1.1. Significance Of Saev Study From Cptn Perspective\n\n| Ref.      | CASE   | Taxonomy   | Power network   | Transportation network   | CPTN    |     |         |            |         |    |    |    |\n|-----------|--------|------------|-----------------|--------------------------|---------|-----|---------|------------|---------|----|----|----|\n| C         | A      | S          | E               | Charging                 | Network | BSS | Traffic | Trip order | Routing |    |    |    |\n| [15]      | \u2713      | \u2713          | \u2713               | \u2713                        | \u2713       | \u2713   | \u2713       |            |         |    |    |    |\n| [16]      | \u2713      | \u2713          | \u2713               | \u2713                        | \u2713       | \u2713   | \u2713       | \u2713          |         |    |    |    |\n| [17]      | \u2713      | \u2713          | \u2713               | \u2713                        | \u2713       | \u2713   |         |            |         |    |    |    |\n| [20]      | \u2713      | \u2713          | \u2713               | \u2713                        | \u2713       | \u2713   | \u2713       |            |         |    |    |    |\n| This work | \u2713      | \u2713          | \u2713               | \u2713                        | \u2713       | \u2713   | \u2713       | \u2713          | \u2713       | \u2713  | \u2713  | \u2713  |"}
{"doc165": "The exploration of SAEVs within the framework of CPTN is of considerable significance for the prospective evolution of urban mobility and sustainability. The integration of SAEV with a CPTN holds the promise of advancing energy sustainability. This synergy enables optimized energy consumption through effective routing algorithms [33], dynamic charging infrastructure, grid services [34], last mile services [35] contributing to reduced environmental impact and enhanced overall energy conservation. Additionally, the integration of SAEV with a CPTN presents a paradigm shift towards environmental protection. By reducing emissions with minimum conventional vehicles and through electrification [36] adding more renewable energy sources [37], this synergy not only mitigates air pollution but also nurtures sustainable practices, contributing to a healthier and greener urban environment.\n\nBy conducting sensitivity analysis, the researchers determine the optimal battery size and the number of charging stations to minimize costs.\n\nThe findings in [38] suggest that vehicles with a range of 50\u201390 miles and 66 chargers per square mile (25 per square km), equipped with an 11 kW connection, can offer services at a cost ranging from $0.29 to $0.61 per mile ($0.18\u2013$0.38 per km). This cost is approximately 10 times lower than that of conventional taxis and is even more economical than services provided by non-electric vehicles. Additionally, the researchers estimate that SAEVs could lead to a 73% reduction in greenhouse gas emissions compared to current taxis, given the current power grid, owing to increased vehicle efficiency. Autonomous driving has the R. Sumitkumar and A.S. Al-Sumaiti potential to generate revenue ranging from $300 billion to $400 billion by 2035, according to recent research that unveils the essential factors for success in the rapidly evolving passenger car market [39]. Within the interconnected landscape of CPTN, surrounding both power grids and transportation networks, a comprehensive understanding of SAEV dynamics becomes imperative. A critical analysis of their influence on power grid reliability, load distribution, and charging infrastructure emerges as crucial for the seamless integration of SAEVs into existing urban frameworks. The research findings have the potential to offer valuable insights into the optimization of charging strategies, alleviation of traffic congestion, and the advancement of sustainable urban practices. In the ongoing shift towards intelligent and interconnected urban systems, the investigation into SAEVs within CPTN serves as a guiding framework for the establishment of efficient, dependable, and environmentally conscious urban transportation networks. The study in [40] employs a comprehensive agent-based model to analyse SAEV fleet management dynamics, considering factors like battery range and charging infrastructure. Results reveal that SAEVs can efficiently replace privately owned vehicles, with charging infrastructure optimization and financial viability, making them competitive and environmentally friendly in urban transportation scenarios, showcasing their potential mode share ranging from 14 to 39%. Through an agentbased simulation in [41] across the Rouen Normandie metropolitan area, the study reveals the strong correlation between SAEV performance and charging infrastructure, highlighting the importance of faster-charging facilities, strategic placement-based on demand hubs, and careful battery capacity selection. The results emphasize the positive influence of battery-swapping infrastructure on enhancing SAEV\nservice performance, providing valuable insights for the future development of SAEV mobility systems. Another study in [42] mentioned the potential of SAEV, revealing that a fleet comprising only 10%\u2013 14% of private vehicles can deliver comparable transport services in Tokyo. The research employs a simulation methodology, assessing the influence of fleet size on service quality and break-even prices."}
{"doc166": "Additionally, the system's capability to supply operating reserve during grid operator requests is demonstrated, highlighting the efficiency and resilience of SAEV systems under various operational conditions. The survey conducted in [43] for Brisbane, Australia, reveals an openness to change, with cost being a key determinant, influencing preferences for SEAVs and highlighting demographic factors impacting acceptance, such as wealth, commuting status, and lifestyle preferences. Another study in [44] examines the potential benefits of a SAEV by addressing the last mile service in public transit between Ann Arbor and Detroit Wayne County Airport. Analysing environmental, cost, and performance metrics, the research suggests that integrating SAEV for last-mile transit services could enhance sustainability by promoting a mode shift from private to public transit options, with energy savings of up to 37% compared to personal vehicle options in the case study.\n\nThe integrated analysis of vehicle electrification conducted in [9\u201345],\nreveals that widespread electrification, coupled with automation and shared mobility, could lead to substantial reductions in petroleum consumption and CO2 emissions, resulting in significant health benefits and emphasizing the importance of policies to promote the transition to SAEV.\n\n## 1.2. Methodology And Citation"}
{"doc167": "The review methodology is discussed in this section, where the keyword search is done using Web of Science and Scopus search engines. Initially, common keywords such as ''shared autonomous electric vehicles'' or SAV, ''shared autonomous vehicle'' or CASE, and ''connected autonomous shared electric'' were used, resulting in numerous references. The search was then extended to include terms related to power, transport, and CPTN. The keywords with combinations are illustrated in Fig. **1. The review process was divided into three phases.** In the first phase, 329 scientific journal articles published in English were identified and screened for relevance. Duplicate articles and those outside the scope of the study, such as unmanned aerial vehicles, drones, autonomous vehicle sensors, etc., were eliminated, leaving 185 articles. Around 80 articles were removed for not representing the area and respective studies. Lastly, 109 articles were selected for the study, and a ''snowball'' technique was used to locate an additional 24 relevant articles and reports. Furthermore, 34 additional references were considered to enhance the understanding of recent literature on the topic.\n\n## 1.3. Contribution And Organization\n\nThe research work contributes to the field in the following ways: 1."}
{"doc168": "Article offers a thorough understanding of the connected autonomous shared electric concept. 2. Article explains key concepts, features, and technical terms associated with SAEV technology. 3. It adapts the conventional vehicle routing problem for the SAEV context.4. It identifies research problems and provides future research recommendations related to SAEV and CPTN.\n\nThe article's structure is organized as follows: Section 2 **delves into**\nthe concept of SAEV vehicles and innovations in the field. Section 3 presents a fleet management and taxonomy of SAEV vehicles. In Section **4, the integration of SAEVs in the PN is discussed, while Section** 5 focuses on SAEVs in the TN; Section 6 **explores and compares SAEVs**\nin CPTN. Section 7 **sheds light on critical reviews and future research** direction. Finally, Section 8 **draws conclusions based on the insights** gained in this review.\n\n## 2. Shared Autonomous Electric Vehicle"}
{"doc169": "The automotive industry is evolving rapidly, driven by technological advances, new mobility service models, and the adoption of connected services, autonomous vehicles, shared mobility, and electrification technologies. This transformation is causing manufacturers and industry players to struggle to plan for the scale of change required in their business models. However, OEMs can offer customers more personalized, convenient, and transparent sales and maintenance journeys through advanced technology and connected vehicle data. The benefits of integration of SAEV are numerous and include, 1. **Reduced Traffic Congestion and Improved Air Quality: SAEV**\nwith connected features can alleviate traffic congestion by optimizing routes and minimizing the number of vehicles on the road. Additionally, their reliance on EV technology, which produces zero emissions, contributes to improved air quality in urban areas, positively impacting public health.\n\n2. **Electricity Market Engagement of SAEV: SAEV equipped with**\nample battery capacity can actively participate in the electricity market through diverse mechanisms. This involvement includes offering services with bidirectional power flow, providing grid support during peak load periods, enhancing grid flexibility, integrating renewable energy sources, and incorporating specific revenue models.\n\n3. **Load Balancing and Demand Response: SAEVs, through efficient**\ncoordination and integration into demand response programs, play a pivotal role in load balancing on the power network. Their intelligent scheduling of charging times and locations, along with the ability to adjust charging schedules based on grid needs, helps distribute the electrical load evenly and supports grid stability by mitigating strain during peak demand or supply fluctuations."}
{"doc170": "Fig. 1. **Review methodology.**\n4\n5. **Safety and Efficiency: Incorporating ADAS and safety features**\nsuch as sensors, actuators, and LiDAR technology, hold promise in reducing accidents attributable to human error. The integration of these technologies facilitates the efficient detection and response to road hazards, thereby improving overall safety.\n\nFurthermore, SAEVs can optimize routes and minimize the time spent searching for parking, offering users a convenient and safer transportation solution.\n\n6. **Power Curtailment: SAEV can play a crucial role in mitigating**\nissues associated with power curtailment in the electric grid when effectively coordinated and coupled in CPTN, particularly in regions with abundant renewable energy sources."}
{"doc171": "SAEV also referred to as a CASE vehicle, is part of the CASE\ninitiative taken up by OEMs such as Toyota, Mercedes, Nissan, General Motors, Ford, Volkswagen, Tata, etc., for future mobility and fight against climate change [46]. Similar CASE projects like connected autonomous vehicles (CAV) and shared autonomous vehicles (SAV) are also research areas focused on by certain OEMs. Fig. 2 **illustrates the**\ndifferent features of the CASE vehicle, and details are highlighted in the below paragraphs. Table **2. compares the available vehicles in the** market with key criteria comparison of autonomous, shared, electric, and connected. Autonomous vehicles can sense their environment and operate without human involvement, with Waymo One and Easymile EZ10 being fully autonomous at Level 4/5. Shared vehicles, such as Waymo One and BlueSG, can be rented or shared by multiple users, reducing the need for individual ownership. Electric vehicles, such as the Tesla Model S, and Renault Zoe, are powered by electricity and produce zero emissions, making them environmentally friendly. All vehicles in the table are connected, allowing for features such as real-time traffic information and remote diagnostics. Fig. 3 **shows the** features and highlights of SAEV.\n\n## 2.1. Connected Vehicle\n\nCV can communicate with other devices outside the vehicle, enabling various features such as infotainment, safety, roadside assistance, diagnostics efficiency, navigation, and payments. Although CV"}
{"doc172": "| Available vehicle in market with CASE features. Vehicle Company Autonomous   | Shared    | Electric   | Connected   |     |     |\n|------------------------------------------------------------------------------|-----------|------------|-------------|-----|-----|\n| Tesla Model S                                                                | Tesla Inc | Level 2/3  | No          | Yes | Yes |\n| Waymo One                                                                    | Waymo     | Level 4/5  | Yes         | No  | Yes |\n| Easymile EZ10                                                                | Easymile  | Level 4/5  | Yes         | Yes | Yes |\n| BlueSG                                                                       | BlueSG    | Level 2/3  | Yes         | Yes | Yes |\n| Renault Zoe                                                                  | Renaut    | Level 2/3  | No          | Yes | Yes |\n\nmay seem futuristic, many cars today have internet connectivity. For instance, Waze has partnered with ExxonMobil and Shell to provide contactless fuel payments, and Google Maps allows drivers in Austin, Texas, to pay for parking using Google Pay [47]. CV provides numerous benefits, including enhanced driver safety, time savings, and reduced emissions. Additionally, these vehicles offer customers personalized, convenient, and transparent sales and maintenance journeys. By incorporating connected features and data into infotainment systems, fully autonomous driving may be possible. Shared ownership is made less complex with connected functionality, and personal virtual assistants offer on-demand support [48]. To generate profit and improve customer experiences, traditional manufacturers must integrate dealer and OEM processes and employ a highly skilled workforce capable of interpreting data. Tesla, a brand that prioritizes data visibility and consumer needs, leads the industry in this regard. The below paragraph highlights the available literature on connected vehicles.\n\nAccording to the study in [49] security and privacy of data associated with CV technology significantly influence trust, attitude, behavioural intention to use, and perceived usefulness. This research also examined respondents' socio-demographic and other characteristics linked to CV acceptance and its predictors, with implications of both theoretical and practical applications in the industry. Another article [50] emphasizes the importance of testing CV technology and developing a test platform based on a driving simulator to evaluate the impact of CV technology on safety features and driving behaviour in various scenarios such as fog, tunnel, and work zones. The results indicate that CV technology positively enhances safety and driving"}
{"doc173": "![4_image_0.png](4_image_0.png)\n\nFig. 2. **Connected autonomous shared electric.**\nbehaviour, and the test platform can serve as a reference for researchers in related fields. Finally, the article [51] explores the development of lane change (LC) detection and prediction models using real-world data collected by CVs. The study leverages an auto-encoder for LC detection and a transformer-based model for LC prediction, outperforming conventional methods in accuracy and computational efficiency. The findings suggest that LC can be accurately predicted up to two seconds in advance, and the transformer model holds practical application potential. Overall, these studies provide important insights into CV technology's use, testing, and development. The study in [52] applied a deep reinforcement learning approach for vehicle lane change decisions to provide autonomy to the vehicle. However, most of the literature failed to address the issue of data privacy, cyber-attacks, and safetyrelated issues. The research in [53] introduces a novel energy-efficient autonomous driving strategy for EVs that optimizes energy consumption by considering both lane-change and car-following behaviours, utilizing deep reinforcement learning, and incorporating a rule-based safety checker, resulting in significant energy savings in dynamic traffic scenarios while maintaining safety and traffic efficiency.\n\n## 2.2. Autonomous Vehicle"}
{"doc174": "According to a survey [54], 34% of consumers believe vehicles will become fully autonomous by 2030. Last year, companies such as NVIDIA, Audi, Ford, BMW, and Tesla launched full AV. These vehicles use sensor technology and create a virtual environment by image processing to detect and identify obstacles and objects on the road and advanced control systems to interpret the sensory information and execute the movement. The Society of Automotive Engineers\n(SAE International) created a vehicle automation classification system outlining five levels of driving automation. These levels, ranging from zero to five, describe the degree of automation and human involvement required in the driving process. Level zero (L0) is no automation, while level one (L1) involves driver assistance. Level two (L2) entails partial automation, while level three (L3) involves conditional automation.\n\nLevel four (L4) pertains to high automation, and level five (L5) represents full automation, where no human interaction is required at all [55]. This classification system provides a clear understanding of the degree of automation and human involvement associated with different levels of driving.\n\nAutonomous features such as forward collision warning and auto brake can make the vehicle more receptive and safe to drive, resulting in fewer collisions and insurance claims involving injury. However, there are flaws in some business cases, such as the vulnerability of autonomous vehicles to criminal targeting due to their automatic braking features. The capacity of autonomous vehicles to navigate and make decisions in unforeseen circumstances is restricted, and it is extremely difficult to program intuition-based decision-making into them. Nonetheless, established industry leaders like Tesla, Amazon, and Google are currently in the preliminary stages of autonomous driving research. Conventional automotive manufacturers are integrating more sophisticated features into their current vehicles [54]. The following paragraph outlines significant sources of information related to autonomous technology."}
{"doc175": "Ref. [56] presented a study that analysed 10,374 AV-related comments from a micro-blogging website. Results indicate that users' sentiments depend on AVs safety and convenience and their impact on society, such as unemployment. Computer vision is a widely used approach to detect road boundaries and lanes through a vehicle's vision system. This technology involves utilizing a camera mounted on the vehicle to capture the front view and then implementing various algorithms to identify lanes and objects. The algorithm for detecting lane marks and objects can be customized to suit specific needs. The author of article [57] discusses the development of a cooperative controller for autonomous vehicles that utilize the entire road width without detecting lanes. The controller employs a nonlinear model predictive control\n\n![5_image_0.png](5_image_0.png)\n\nstrategy to manage multiple self-driving vehicles, ensuring optimal progress on the road with minimal control efforts while meeting design constraints. According to simulation results, the proposed lane-free approach can enhance traffic flow performance compared to conventional lane-based roadways, reducing passenger travel time, lowering energy consumption, and increasing road capacity, depending on road density and track layout. Ref. [58] targeted the development of a real-time obstacle avoidance system for the autonomous navigation of unmanned ground vehicles. The system utilizes sequential RGB data with training conducted using a simulator. It shows promising results for future implementation in a real-world prototype. The study in [59] suggests a predictive trajectory planning framework for autonomous vehicles utilizing a partially observable Markov decision process (MDP) and deep reinforcement learning (DRL) to generate safe, comfortable, and energy-efficient trajectories. Additionally, Ref. [60] comprehensively examines misbehaviour detection in CAV, starting with a new definition of misbehaviour. It examines state-of-the-art solutions, provides a detailed taxonomy of machine learning algorithms, and reviews available tools and data sets. CAVs are an emerging technology that is transforming the transportation industry worldwide. As of 2023, several CAVs are available globally, each with unique features and capabilities. It is worth noting that while some CAVs are fully autonomous, others still require human intervention in certain situations. Also, the availability and use of CAVs vary by region and country, depending on local regulations and infrastructure."}
{"doc176": "## 2.3. Shared Vehicle\n\nAccording to a recent survey [61], 66% of respondents believe that the most significant advantage of a future with autonomous ondemand vehicles is the financial savings associated with not owning a car. Shared electric vehicles (SEVs) play a significant role in the social economy by promoting sustainability, reducing carbon emissions, and improving energy efficiency. Shared EV services provide an affordable and environmentally friendly transportation option, increasing accessibility for individuals who may not have the means to afford private electric vehicles. By encouraging the adoption of electric mobility, shared EVs contribute to reducing GHG emissions, which improves air quality and helps mitigate the impacts of climate change. Additionally, shared EV platforms often incorporate smart charging infrastructure, enabling the optimal utilization of renewable energy sources and reducing strain on the electric grid. These services also contribute to job creation within the electric vehicle industry and drive technological advancements. Embracing shared electric vehicles supports a greener and more sustainable social economy, promoting environmental stewardship and facilitating the transition towards a low-carbon future. The sharing and subscription models are becoming increasingly popular, with OEMs positioning themselves as fleet owners. However, balancing profitability in a changing marketplace will be a significant challenge for OEMs. Mobility-sharing services include public transit, micro-mobility [62], car-based modes, bikesharing, and ride-sharing, with brands like Lyft, Uber, Bird, Scoop, and Moovit leading the way. The focused research area in different articles is autonomous mobility on demand (AMoD) [63], ride-hailing service (RHS) [64], ride-sharing [65], dial-a-ride (DaR) [66], etc. The following paragraph highlights literature available in shared vehicles with autonomous/connected under ICE and EV segments.\n\nThe article [67] discusses the potential benefits and drawbacks of autonomous and electric vehicles and how shared mobility systems could help alleviate costs. The study proposes a fleet optimization multi-class user problem considering AVs and EVs in private and shared mobility systems, using meta-heuristic algorithms to solve the complex optimization problem. Results from a case study in Ann Arbor, Michigan, highlight the trade-offs in implementing these technologies and provide valuable insights for planning. The author in [68] presents a dynamic ride-hailing sharing problem with the heterogeneous vehicle and users' category, and classifying ride-hailing vehicles as express and premier types. A lexicographic multi-objective function with three-level objectives is proposed to maximize the platform's profit, minimize the number of unmatched requests, and minimize the total driving distance of SAEV. A modified artificial bee colony algorithm is proposed to solve the mixed integer nonlinear program formulated for the sub-problems."}
{"doc177": "The article [69] explores the problem of vehicle sharing and task allocation in customer service operations, where workers spend most\n\n![6_image_0.png](6_image_0.png)\n\nof their time on-site, and vehicles are often idle. The study [70] investigates the factors that affect public trust and acceptance of shared autonomous vehicles (SAVs), including autonomy level, anthropomorphic characteristics, and human-related, environmental, and societal factors. The results show that autonomy level and anthropomorphic characteristics indirectly increase public acceptance via trust, while other factors also positively contribute to public acceptance. The study also suggests incorporating anthropomorphic features and a relatively high autonomy level in SAVs to build public trust and acceptance."}
{"doc178": "## 2.4. Electric Vehicle\n\nEVs have gained significant attention in recent years as a promising solution for reducing GHG emissions from transportation. Unlike traditional gasoline-powered cars, EVs are powered by electric motors and rechargeable batteries, offering several benefits, including zero tailpipe emissions, improved energy efficiency, and lower fuel costs [71]. Moreover, as RES [71], such as solar and wind power, become more prevalent, EVs can be charged using clean energy, reducing their environmental impact. While there are still challenges to overcome, such as the availability of charging infrastructure and the high cost of batteries, the rapid technological advances and the growing demand for sustainable transportation options suggest that EVs will play an increasingly important role in future mobility. Apart from pure EVs, the trend of hybrid electric vehicles (HEVs) to overcome the range anxiety issue of owners is also gaining more popularity. HEVs include a gasoline-based powertrain and an electric motor powertrain to produce the required tractive force. OEMs are giving other attention to the manufacturing of hydrogen [72] or fuel cell-based vehicles known as FCEVs, where hydrogen is the primary source utilized. Fuel cells convert hydrogen into electricity, later stored in batteries to power the electric motor. Another vehicle category is based on ultra-capacitor (UC) applications, also known as super-capacitors. UCs, having high power and longer life features, are suitable for EV applications [71]. Numerous research works have been carried out in the direction of EV\ndesign and development, charging management [73], energy management, charging cost minimization [62], planning problems, RES and EV behaviour in the grid [74,75], integration, and user acceptance. The research on SAEV is similar to the above-mentioned EV-related research; however, some of its characteristics make it different and require an evolution from the implementation point of view. The research paper [76] presents a cloud-based multi-objective energy management strategy for hybrid battery systems in electric vehicles, enhancing safety and efficiency while reducing energy loss and aging costs, validated through real-world data and processor-in-the-loop tests, outperforming existing learning-based strategies.\n\n## 3.1. Vehicle Routing Problem"}
{"doc179": "The VRP has numerous applications in diverse industries, including logistics, transportation, waste management, and delivery services. The capacitated VRP, or the classical VRP, aims to find optimal delivery routes for vehicles with identical characteristics and a single central depot. The goal is to minimize costs while ensuring that each customer is visited once by a vehicle and that the capacity of each vehicle is not exceeded. Over time, researchers have introduced additional reallife aspects and characteristics to extend this problem, resulting in several VRP variants [77]. For example, the heterogeneous fleet VRP (HFVRP) [78] varies in capacities, while the VRP with time windows (VRPTW) requires [79] deliveries to be made within specific intervals. Fig. 4 **illustrates the key tasks under the VRP approach. In the VRP with**\npickup and delivery (VRPPD) [80], goods are picked up and dropped off by the same vehicle, so both locations must be included in the same route. This problem is typically presented as a mathematical model, and many algorithms, such as exact algorithms [81], heuristics, and metaheuristics [82], have been devised to tackle it. Tackling the VRP holds the potential for substantial cost reductions, heightened operational efficiency, and diminished environmental footprint. The incorporation of SAEV scheduling into VRP necessitates minimal adjustments, encompassing the integration of charging stations, pause duration, recharging intervals, vehicle-specific energy consumption, charger ratings, capacity considerations, and relocation strategies, among others. **Table** 3 compares literature work on considering modified VRP's taxonomy.\n\n## 3.2. Trip Order Assignment\n\nThe operational research problem of dial-a-ride, ride-hailing services, carpooling, and taxi booking relies on the trip order assignment problem [15]. Efficiently assigning incoming trip requests to available drivers (or AV) while minimizing waiting times for passengers and maximizing completed trips is the main objective of the trip order assignment problem faced by ride-hailing services. However, this is a complex task as it involves considering multiple factors, including drivers (or AV) proximity to passengers, estimated time for trip completion, driver availability, and passenger preferences [92]."}
{"doc180": "The assignment of trip orders to vehicles is a crucial component of solving the VRP with added constraints and factors. This process involves considering multiple factors, such as the distance to be travelled, the time required to complete the trip, the number of stops, and the priority of the trip. The primary objective is to minimize the total\n\n| Table 3 Taxonomy of work reported on modified VRP. Ref Vehicle VRP Trip order   | Parking and   | Rebalancing   | Deport, destination,   |                     |                    |                            |\n|---------------------------------------------------------------------------------|---------------|---------------|------------------------|---------------------|--------------------|----------------------------|\n| type                                                                            | assignment    | charging      | origin                 |                     |                    |                            |\n| [83]                                                                            | ICE           | \u2713             | \u2713                      | -                   |                    |                            |\n| [84]                                                                            | ICE           | \u2713             | \u2713                      | Exact and heuristic |                    |                            |\n| [85]                                                                            | SAEV          | \u2713             | \u2713                      | \u2713                   | \u2713                  | Reinforcement learning     |\n| [86]                                                                            | SAEV          | \u2713             | \u2713                      | \u2713                   | Agent based model  |                            |\n| [87]                                                                            | SAEV          | \u2713             | \u2713                      | \u2713                   | \u2713                  | MILP using CPLEX           |\n| [88]                                                                            | SAEV          | \u2713             | \u2713                      | \u2713                   | \u2713                  | Branch-and-price algorithm |\n| [89]                                                                            | SAV           | \u2713             | \u2713                      | \u2713                   | LP                 |                            |\n| [90]                                                                            | AV            | \u2713             | \u2713                      | \u2713                   | Multi agent system |                            |\n| [91]                                                                            | SEV           | \u2713             | \u2713                      | \u2713                   | \u2713                  | Reinforcement learning     |\n\ndistance travelled by all vehicles while ensuring that each trip is completed within the given time frame. There are two main approaches to assigning trips: heuristic methods [93], such as the nearest neighbour or farthest insertion method, and mathematical programming techniques, such as integer linear programming (ILP) [94]. While ILP guarantees an optimal solution, it can be computationally demanding for large-scale problems. Hence, finding a balance between computational complexity and solution quality is necessary. Dynamic programming, agent-based simulation models, and machine learning approaches are also applied in dial-a-ride problems while keeping trip order assignment objectives."}
{"doc181": "The conventional VRP considering trip order assignment problem differs slightly from the SAEV vehicle scheduling problem. The additional constraints of battery specification, charging time, and specific power consumption of vehicles also need to be considered.\n\n## 3.3. Parking And Recharging Time\n\nThe conventional VPR problem considers the one or multiple depots where vehicles will be parked along with finding the optimal routes [95]. The problem for SAEV, AEV, or SEV involves planning routes and recharging time, which is a crucial consideration in solving redEV routing problems (EVRP) apart from parking problems [77]. In EVRP, EVs must be recharged before continuing their journey once they reach a certain threshold value of a state of charge (SoC). The time required for recharging depends on several factors such as the battery capacity, charging rate of a battery, charger rating, and SoC at the start of the charging [96]. Consequently, the time spent on recharging can significantly impact the vehicle's schedule. Parking time must also be considered, as EVs must park while recharging. Factors affecting parking time include charging stations' availability [91] and the number of vehicles waiting to recharge [97]. Therefore, optimizing parking and recharging time is critical to ensure EVs efficient and effective operation [98]."}
{"doc182": "## 3.4. Vehicle Re-Balancing\n\nVehicle re-balancing, or redistribution/repositioning, is a critical aspect of user request-based services such as dial-a-ride, ride-hailing services, and public transport [99]. In such a research area, there is a need to re-balance vehicles to ensure sufficient vehicles are available at each location to meet the demand [100]. Vehicle re-balancing involves moving vehicles from where they are plentiful to where they are scarce [101]. By doing so, the problem of the under-utilization of vehicles can be avoided. Compared with ICE vehicles, the EVs in ridehailing services create complexity and constraints. The re-balancing involves moving a vehicle from one node to another subjected to power consumption by the vehicle and reduction in SoC [102]. Addressing the intricacies of vehicle re-balancing presents challenges owing to the unpredictable nature of demand and charging patterns. However, diverse methods exist to optimize this process. Notably, the application of data analytics, as in [103], and machine learning algorithms, as explored in [85], proves instrumental in accurately predicting demand and charging patterns. The effective implementation of vehicle re-balancing is pivotal to the success of SAEV, as it plays a key role in maintaining a balance between the demand for EVs and their availability at each location [104].\n\n3.5. Depots, origin, and destination Another problem in transportation operational research is the origin and destination of users, also known as the pick-up and drop, which are critical factors when planning routes [105]. The depot serves as the starting and ending point for each vehicle's route, and it is also where the vehicles are parked when not in use [106]. In the case of SAEV,\nthe depots serve as charging stations where idle vehicles are kept in parking and charging [107]. Consequently, the placement of the depot plays a pivotal role in determining the solution to the problem. For example, when the depot is situated considerably from the demand locations, it can result in extended travel times, heightened energy consumption, and elevated costs. Hence, the strategic selection of an optimal depot location is imperative to guarantee the efficient and effective operation of EVs. Moreover, the EVRP introduces additional complexity by allowing multiple depots. This further complicates the problem, underscoring the importance of judiciously determining the number and locations of depots. This decision is critical in adequately meeting demand while simultaneously minimizing the overall cost of the system. Routing the SAEV vehicle with a specific capacity with multiple pick-up points [108] based on the user's request and drop-off points may further complicate the problem."}
{"doc183": "## 3.6. User Requests And Capacity Flow\n\nCompared with conventional VRP problems [109], user requests and capacity flow heavily influence SAEV vehicles in terms of efficiency and effectiveness. User requests pertain to the distribution and number of trip requests made by passengers. At the same time, capacity flow refers to the SAEV system's ability to meet such requests via vehicle allocation and scheduling [104]. Efficient allocation and scheduling algorithms must be developed and implemented to minimize waiting times, travel distances, and energy consumption. This involves optimizing vehicle routing, charging schedules, and vehicle allocation using sophisticated algorithms [17]. Additionally, real-time data on user requests and vehicle availability must be monitored and analysed to adjust the SAEV system's capacity flow and meet users' needs. Addressing these challenges can lead to reliable, sustainable, and efficient transportation through SAEV vehicles, benefiting users and society.\n\n## 4. Saev In Power Network"}
{"doc184": "SAEV has emerged as a promising solution to curb the carbon footprint of transportation and enhance urban mobility. Besides their potential benefits in reducing traffic congestion and improving air quality, SAEV can contribute to electrical PN [110]. As the prevalence of EVs increases, it is essential to charge them efficiently and avoid overloading the power grid. Coordinating the charging schedules and reducing the peak load on the grid by using SAEV can optimize power consumption. This way, SAEV can facilitate a more efficient and sustainable electrical PN that promotes the widespread adoption of EV [111]. Nevertheless, implementing SAEV in the PN requires careful planning and coordination between the transportation and energy sectors to ensure the infrastructure can support this emerging technology.\n\n![8_image_0.png](8_image_0.png)\n\nFig. 5. **SAEV in power network: Modified IEEE 33 bus RDS.**\nFig. 5 **illustrates the modified IEEE 33 bus radial distribution system** with charging and battery swapping stations, highlighting electricity price, base load, charging power demand, and PV power generation."}
{"doc185": "Table 4 **compares the research article carried out work on SAEV, EV,** AEV, and SAV while considering power network, network constraint, and related parameters. Integrating SAEV vehicles into the PN raises several questions, including the location of charging stations, waiting times, charger ratings, electricity prices [112], and more. Researchers have conducted numerous studies on electric vehicle charging problems [38] and scheduling, considering the electrical PN and associated constraints. Although the problem of scheduling SAEV vehicles for charging is similar to scheduling EVs, factors such as waiting times, charging costs, and re-balancing costs are crucial considerations. The following subsections focus on literature examining the challenges associated with SAEV in the PN.\n\n## 4.1. Electricity Price\n\nThe behaviour of SAEV in PN is significantly influenced by the cost of electricity. Elevated electricity prices are anticipated to result in decreased demand for charging services, leading to reduced utilization of charging infrastructure, increased transportation costs for users, or diminished profits for operators. These shifts have consequential implications for the reliability and stability of the power grid, as well as the economic feasibility of investments in charging infrastructure. The yearly electricity expenses for the EV and AEV\nwere computed based on factors such as daily operational hours, vehicle electricity consumption, charging station efficiency, and electricity prices [113]. Additionally, the introduction of RES into the power grid adds further complexity to the relationship between electricity prices and charging behaviour. The availability of renewable energy is subject to variations based on weather patterns and other factors [114]. This complexity underscores the significance of uncertainties in electricity generation, charging power demand, and human behaviour towards adopting SAEV. Ref. [115] performed a Puget Sound case study through agent-based simulation, the study evaluates the benefits of active SAEV\ncharging management, emphasizing the role of battery capacity, charging infrastructure, and renewable energy sources in optimizing performance, reducing costs, and enhancing system efficiency. Results underscore the potential of strategic charging to mitigate peak demand and lower overall energy-related expenses, particularly in scenarios with larger battery sizes and real-time pricing structures. The author in [116] proposes a dedicated EV mobility model for an SV to optimize charging schedules and pricing strategies to maximize profit while participating in a distribution power market, showcasing the potential of shared EVs to reshape load profiles and contribute to environmental sustainability without compromising company profitability. The research in [38] introduces a methodology for optimizing the charging of SAEV through V2G technology, concurrently optimizing routing and relocation. The proposed model, demonstrated in a Tokyo case study, efficiently reduces charging costs without a significant impact on waiting times, highlighting the potential for substantial savings with increased electricity price variability."}
{"doc186": "## 4.2. Infrastructure And Optimal Location Of Cs\n\nThe emergence of SAEVs signifies a fundamental transformation in conventional transportation methods, exerting an influence on passenger distribution across diverse routes and reshaping the dynamics of travel demand. In parallel, the incorporation of effective charging infrastructure becomes paramount to sustain the widespread acceptance of electric vehicles within the CPTN, ensuring smooth operations and minimizing environmental impact. Furthermore, the interaction between SAEVs and the existing transportation framework demands a thorough examination of how these autonomous electric vehicles can either complement, supplement, or potentially replace traditional modes of public transportation. A comprehensive analysis of these implications not only illuminates the potential advantages and challenges but also underscores the need for optimizations to harness SAEVs for the advancement of the CPTN. To ascertain the optimal location for a SAEV charging station within the PN, a comprehensive analysis of various factors becomes imperative. This assessment encompasses considerations such as charging demand, power availability, proximity to major transportation hubs and popular destinations, as well as the potential impact on surrounding infrastructure and the environment. Through this thorough examination, the goal is to identify the ideal location that ensures efficient and reliable charging of SAEVs while minimizing any adverse effects on the TN and power grid.\n\nRef. [13] contributes to this field by presenting an optimization model designed for planning the deployment of charging facilities within a SAEV. The model takes into account demand uncertainty and optimizes both long-term planning decisions, such as charging facility sizing and configuration, and short-term operational decisions, including vehicle assignment, relocation, and charging strategies. The effectiveness of this approach is demonstrated through testing in Shanghai on a largescale case study. The results indicate that deploying both normaland fast-charging infrastructure not only enhances the system's profitability but also improves its overall operational performance. The study in [120] introduces a framework to optimize charging infrastructure development, considering interactions between shared mobility, autonomous driving, and electrification, and evaluates optimal configurations for EV adoption in New York City taxis, revealing that future fleets with full EV adoption benefit from more scattered charging stations, reducing CO2 emissions significantly. The study in [119] presents a charging system planning framework for an AEV ride-hailing fleet in urban areas, utilizing the BEAM agent-based simulation model to assess R. Sumitkumar and A.S. Al-Sumaiti"}
{"doc187": "| Table 4 Power network SAEV study. Ref. Objective   | Type of                                                                                       | Power network                                                  | Network                                               | Optimal                  | Battery   | Charger   | Charging   |\n|----------------------------------------------------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------|-------------------------------------------------------|--------------------------|-----------|-----------|------------|\n| vehicle                                            | constraint                                                                                    | location of CS                                                 | swapping                                              | congestion               | time      |           |            |\n| [38]                                               | Charge scheduling and relocation based on electricity price                                   | SAEV                                                           | Tokyo region in the JEPX wholesale electricity market | Charging rate            | \u2713         |           |            |\n| constraints                                        |                                                                                               |                                                                |                                                       |                          |           |           |            |\n| [117]                                              | Planning of AMoD strategies charging facilities                                               | AEV for                                                        | -                                                     | -                        | \u2713         |           |            |\n| ridehailing                                        |                                                                                               |                                                                |                                                       |                          |           |           |            |\n| [118]                                              | Relocation cost and                                                                           | SAEV                                                           | -                                                     | -                        | \u2713         |           |            |\n| waiting time                                       |                                                                                               |                                                                |                                                       |                          |           |           |            |\n| [87]                                               | SAEV VRP based on traffic charging schedules, and a specific energy consumption with swapping | SAEV                                                           | -                                                     | Battery power constraint | \u2713         | \u2713         | \u2713          |\n| [119]                                              | Siting and sizing charging infrastructure for SAEV charging demands                           | SAEV                                                           | -                                                     | -                        | \u2713         | \u2713         |            |\n| [120]                                              | Optimal charging station                                                                      | ICE/AEV/SAEV                                                   | Capacity constraints,                                 | -                        | \u2713         | \u2713         |            |\n| configuration                                      | budget constraints                                                                            |                                                                |                                                       |                          |           |           |            |\n| [121]                                              | Congestion in road                                                                            | SAV                                                            | -                                                     | -                        |           |           |            |\n| network                                            |                                                                                               |                                                                |                                                       |                          |           |           |            |\n| [122]                                              | Joint optimization capacity, parking and charging and daily operating cost                    | SAV                                                            | -                                                     | -                        |           |           |            |\n| [123]                                              | Charging and routing                                                                          | AEV                                                            | 13-node transportation                                |                          |           |           |            |\n| problem in real-time.                              | ridehailing                                                                                   | network, adopted from the Salt Lake City transportation system | Charging constraints, limit constraints               | \u2713                        | \u2713         |           |            |\n\ncomplex passenger and transportation behaviours, identifying charging demands and optimizing charging station placement and sizing for economic and carbon emission impacts in the San Francisco Bay Area. Ref. [124] introduces a hybrid simulation\u2013optimization model for siting and sizing cost-effective charging infrastructure for SAEVs, utilizing real-world trip data from ShareNow in Berlin to assess the impact of charging strategies and fleet size on charging patterns, required number of chargers, and fleet performance, emphasizing the importance of considering the spatial distribution of installation costs and charging demands in urban mobility transformations.\n\n## 4.3. Charging Time"}
{"doc188": "Integrating SAEVs into the PN is heavily influenced by their charging time, which is critical in their utilization. The charging time of SAEVs affects the power demand on the grid and the availability of vehicles for service, which can affect user satisfaction. Therefore, the charging infrastructure must be designed to efficiently charge a large number of SAEVs while ensuring their availability for service and minimizing their impact on the power grid. However, fast charging of SAEVs can create additional strain on the power grid and slow power charging can affect the waiting time for users, cost, and supply\u2013demand issues of SAEVs. Ref. [125] proposes a closed queuing network model to optimize the performance of EV sharing systems by computing the optimal fleet size and number of chargers in each neighbourhood. The profit is concave concerning fleet size and the number of chargers, and installing more chargers can reduce fleet size and increase the availability of vehicles. The simulation shows that two slow chargers may perform better than one fast charger when the variance of charging time is relatively large. Reference in [126] examines the benefits of coupling charging and repositioning events in on-demand SAEV services to improve service quality, reduce empty travel, and enhance fleet utilization. The study used an agent-based model and found that coupling charging and repositioning events lowered rider's waiting times, increased daily trips per SAEV, and reduced empty travel. Ref. [125] proposes a closed queuing network model to optimize the performance of EV sharing systems by computing the optimal fleet size and number of chargers in each neighbourhood. The profit is concave concerning fleet size and the number of chargers, and installing more chargers can reduce fleet size and increase the availability of vehicles. The simulation shows that two slow chargers may perform better than one fast charger when the variance of charging time is relatively large.\n\nReference in [126] examines the benefits of coupling charging and repositioning events in on-demand SAEV services to improve service quality, reduce empty travel, and enhance fleet utilization. The study used an agent-based model and found that coupling charging and repositioning events lowered rider's waiting times, increased daily trips per SAEV, and reduced empty travel. Integrating SAEVs into the PN\nis heavily influenced by their charging time, which is critical in their utilization. The charging time of SAEVs affects the power demand on the grid and the availability of vehicles for service, which can affect user satisfaction. Therefore, the charging infrastructure must be designed to efficiently charge a large number of SAEVs while ensuring their availability for service and minimizing their impact on the power grid. However, fast charging of SAEVs can create additional strain on the power grid and slow power charging can affect the waiting time for users, cost, and supply\u2013demand issues of SAEVs. Ref. [125] proposes a closed queuing network model to optimize the performance of EV sharing systems by computing the optimal fleet size and number of chargers in each neighbourhood. The profit is concave concerning fleet size and the number of chargers, and installing more chargers can reduce fleet size and increase the availability of vehicles. The simulation shows that two slow chargers may perform better than one fast charger when the variance of charging time is relatively large. Reference in [126] examines the benefits of coupling charging and repositioning events R. Sumitkumar and A.S. Al-Sumaiti in on-demand SAEV services to improve service quality, reduce empty travel, and enhance fleet utilization. The study used an agent-based model and found that coupling charging and repositioning events lowered rider's waiting times, increased daily trips per SAEV, and reduced empty travel. Ref. [127] proposes a parallel mobile charging service to charge SEVs at their parking spots, instead of relocating them to charging stations. The proposed approach optimizes mobile charging vehicle routes using a mixed-integer nonlinear optimization model and takes advantage of SEV clusters and mobile charging to simultaneously charge multiple SEVs. An adaptive large neighbourhood search algorithm is developed to solve large-scale instances, and the clusterbased parallel acceleration time ratio is introduced to demonstrate the advantages of parallel services in utilizing overlapping time windows.\n\n## 4.4. Battery Swapping Station (Bss) 11"}
{"doc189": "The earlier subsection discussed how the charging time affects the supply\u2013demand of SAEV to users, specifically during peak hours. BSS\ninvolves the replacement of depleted batteries with fully charged ones, facilitating a rapid replenishment process that reduces downtime and increases the availability of vehicles for the provision of ancillary services [128]. Additionally, using RES to charge the batteries at BSS\ncan further minimize the carbon footprint of SAEVs. However, deploying BSS involves a significant investment in infrastructure, and standardizing the battery packs while swapping procedures remains challenging.\n\nRef. [129] presents a combined operation for BSS and AMoD service, using an expanded network flow model to optimize swapping scheduling and vehicle re-balancing for EV fleets. Simulation experiments based on real-world data from New York City (NYC) demonstrate the effectiveness of this proposed integrated operation model. Ref. [41] proposes a periodic fluid model to optimize battery purchasing and charging policy at a BSS facing time-varying demand and prices, balancing battery investment and operating, including charging cost and customer waiting cost. The optimization problem involves identifying an optimal amount of battery fluid and determining an optimal charging rule using Pontryagin's maximum principle. The combined effect of demand patterns and electricity prices on battery investment decisions is quantified. Ref. [130] proposes a bi-level optimization model that considers the interaction between BSS and AMoD systems, focusing on optimizing the quality-of-service aware battery swapping price. The upper level optimizes swapping pricing to reflect battery inventory. In contrast, the lower level proposes a unified network flow model to characterize the operational decision of the AMoD fleet, with an iteration-based algorithm used to attain results. Real-world data from NYC Taxi were used to validate the effectiveness of the algorithm. In [131] an innovative online state monitoring method based on transferred multi-task learning is proposed in this paper, utilizing convolutional neural networks for information sharing and task-specific layers to enhance state/temperature monitoring accuracy, with comprehensive experiments showcasing its effectiveness, including applications under extreme conditions and retired electric vehicle batteries.\n\n## 4.5. Ancillary Services"}
{"doc190": "The emergence of SAEVs has the potential to bring about significant changes in the transportation sector and offer a unique chance to enhance the stability and reliability of the power grid through the provision of ancillary services. Ancillary services, which include frequency regulation, voltage control, and reactive power support, play a critical role in balancing electricity generation and consumption. SAEV\nbatteries act as energy storage devices to deliver ancillary services, which can reduce the need for traditional power plants to provide these services. However, integrating SAEVs into the power grid as a source of ancillary services poses several technical, economic, and regulatory challenges that must be addressed. The ancillary services are studied in [42] using a simulation methodology to evaluate SAEV,\nand charge scheduling based on the dedicated charging stations for each participant using a heuristic approach. The impact of large number of vehicles in terms of the quality of transportation services and break-even prices. Ref. [132] presents a system-level design for providing ancillary services for electric power grids by in-vehicle batteries, specifically EVs, in a sharing service. The design uses an autonomous vehicle-to-grid (V2G) architecture based on the physics-based model to regulate the impact of EV charging/discharging on the grid. It is evaluated with numerical simulations and hardware-in-the-loop tests.\n\nRef. [133] proposes a mixed integer linear programming model to optimize EV management in a one-way car-sharing system integrated with V2G technology, aiming to maximize revenue from system users and V2G profits. To avoid the disruption of transportation services, the use of BSS can minimize waiting time [134], charging time, and charging. At the same time, the BSS can serve as an ancillary service provider by utilizing the spare batteries kept in charge.\n\n## 5. Saev In Transportation Network"}
{"doc191": "In the TN, multiple studies were conducted on AV, EV, SAV, dial-aride problems, public transportation systems, etc. However, the problem for SAEV is slightly different due to the inclusion of constraints and the nature of EV. The dial-a-ride problem refers to the mathematical optimization problem of deciding a set of vehicle routes to serve pick-up and drop-off requests. This problem is complex due to the many possible routes and the need to optimize for multiple factors such as vehicle capacity, travel time, and operating costs. However, advances in machine learning and optimization algorithms have led to the development of more efficient and effective solutions to this problem, which can help improve the reliability and accessibility of the first and last-mile services in ride-hailing and other transportation systems. First and last-mile service in ride-hailing or dial-a-ride problems refers to the challenge of providing transportation options that connect passengers from their origin to the ride-hailing pick-up point and from the ride-hailing drop-off point to their final destination. This issue is particularly prevalent in urban areas, where passengers may need to travel long distances to reach public transportation or where certain areas may be inaccessible by public transportation altogether.\n\nAs a result, the first and last-mile services play critical roles in providing affordable and efficient transportation solutions to urban residents. The study in [87] highlights the potential benefits of emerging mobility services like ride-hailing and SAV in improving transportation system efficiency and reducing environmental costs, specifically in the firstmile last-mile services. However, the study also reveals the need for strategic deployment, intelligent management of these technologies, and current limitations in SAEV technology for widespread deployment in real-world systems. Improving battery range and travel speed beyond a certain threshold could outperform driver-based shuttle solutions.\n\nFig. 6 **illustrates the Sioux Falls transportation network of 24 nodes**\nwith SAEV charging stations and wind power sources. Table 5 **compares**\nthe literature work carried out on SAEV, EV, ICE, etc., on specific TN, constraints, and solution approaches used."}
{"doc192": "## 5.1. Traffic Congestion\n\nIt is stated in Section 1 **that SAEV is a form of shared transportation**\nthat reduces the number of vehicles on the road, and hence less traffic is experienced during peak hours. Moreover, SAEVs can be programmed to optimize routes and avoid congested areas, reducing traffic. However, the success of SAEVs in reducing traffic congestion also depends on their adoption rate and integration into the TN. Without widespread adoption and proper infrastructure, SAEVs may not have the desired impact on reducing traffic congestion. The research paper [135] proposes a network design model for optimizing the government lane\n\n![11_image_0.png](11_image_0.png)"}
{"doc193": "Fig. 6. **SAEV in transportation network: Sioux Falls Network.**\nexpansion scheme for EV TN. The model considers the charging time, range anxiety, and uncertain transportation demand while aiming to minimize the total travel time of drivers and optimize the lane expansion scheme under an investment ceiling. The proposed algorithm based on the active set algorithm and column generation effectively solves the model, and sensitivity analysis is carried out for different investment levels and control parameters.\n\nThe research paper [136] proposes an integrated framework that addresses the charging and route selection strategies for SAEVs to cope with the problem of urban traffic congestion. The proposed algorithms effectively divert traffic to roads with less vehicle volume and reduce passengers' travel time by 28% during peak hours, providing a solution to prevent urban traffic congestion and shorten the travel times of EV\npassengers. The research paper [137] examines the impact of SAVs on a city-size traffic system using traffic flow theory, simulation-based dynamic traffic assignment, and a computer experiment. The simulation results indicate that implementing SAV positively affects traffic performance, and an increase in the SAV demand share leads to an overall improvement in the network performance (see Table 5).\n\n## 5.2. Waiting Time, Users' Satisfaction And Cost"}
{"doc194": "SAEV adoption has the potential to have a favourable impact on costs, customer satisfaction, and waiting times in TN. According to the following research, SAEVs can shorten travel times by optimal routing and ease traffic. This reduces waiting times. Also, SAEVs offer a practical and cost-effective alternative to owning a personal vehicle, which may improve user satisfaction. The article [138] proposes a multi-agent multi-task dynamic dispatch based on MDP for optimal task allocation of SAEV in an AMoD system. The proposed approach includes a new instant reward function and a state-value function estimated by the back propagation-deep neural network to improve dispatching performance. Numerical results show significant improvements in revenue and user satisfaction. Ref. [139] proposes an integrated ride-sharing strategy with transit, and customizes queuing-theoretic algorithms for vehicle dispatch and idle relocation. The proposed method is tested through experiments with synthetic and Long Island-NYC case study instances, demonstrating consistently reduced travel and passenger journey times, and operating costs by up to 60%. The investigation conducted in [140] tackles the challenge of combined passenger and parcel transportation utilizing a mixed fleet of electric and gasoline vehicles. This complex scenario is formulated as a MILP model, strategically constructed on a time-expanded network. To address large-scale instances of the problem, the researchers introduce a network decomposition-based meta-heuristic. The effectiveness of this approach is assessed through its application to real-world instances, revealing that it efficiently and proficiently resolves the combined transportation problem. The findings suggest its potential applicability in aiding taxi companies with mixed fleets in optimizing route planning strategies. The author in [88] addresses the routing optimization problem for SAEVs by considering uncertain travel time, service time, and charging schedules.\n\nThe objective is to minimize operational costs using a branch-andprice algorithm. Results show that the proposed algorithm outperforms a commercial solver, and sensitivity analyses indicate the impact of various factors on the SAEV service. The study provides insights for other applications, such as urban logistics. The research paper [141]\nproposes a model that combines electric car-sharing and bicycle-sharing to optimize the distribution of SEV, considering subsidy cost and user satisfaction while considering multiple dynamic constraints. The genetic algorithm is used to solve the model, and the results show a significant reduction in relocation costs and increased user satisfaction.\n\n## 6. Saev In Coupled Power And Transportation Network"}
{"doc195": "The previous two sections covered research on the independent study of the integration of SAEVs in TN or PN. However, the outcomes R. Sumitkumar and A.S. Al-Sumaiti\n\n| Table 5 SAEV study in transportation network. Ref. Objective   | Type of                                                                                                    | Transport network   | Traffic                | Waiting                                  | User's   | Reposition             | Capacity          | Solution approach   |\n|----------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|---------------------|------------------------|------------------------------------------|----------|------------------------|-------------------|---------------------|\n| vehicle                                                        | congestion                                                                                                 | time                | satisfaction           | constraint                               |          |                        |                   |                     |\n| [38]                                                           | Optimal relocation and                                                                                     | SAEV                | Tokyo Person Trip      | \u2713                                        | \u2713        | \u2713                      | \u2713                 | Mixed-integer       |\n| charging with timevarying electricity price                                                                | Survey 2008                                                                                                | linear program      |                        |                                          |          |                        |                   |                     |\n| [117]                                                          | Better designs on both fleet management strategies and charging infrastructure                             | AEV for             | New York City Taxi     | \u2713                                        | \u2713        | -                      |                   |                     |\n| ridehailing                                                    | data                                                                                                       |                     |                        |                                          |          |                        |                   |                     |\n| [118]                                                          | Relocation cost and                                                                                        | SAEV                | Seoul                  | \u2713                                        | \u2713        | \u2713                      | \u2713                 | Graph neural        |\n| waiting time                                                   | network (GNN) based deep learning model                                                                    |                     |                        |                                          |          |                        |                   |                     |\n| [87]                                                           | Route optimization of EVs with congestion, charging schedules, and a realistic energy consumption with BSS | SAEV                | Yanta Administrative   | \u2713                                        | \u2713        | \u2713                      | \u2713                 | MILP using          |\n| District in Xi'an, China                                       | CPLEX+adaptive large neighborhood search (ALNS) algorithm                                                  |                     |                        |                                          |          |                        |                   |                     |\n| [119]                                                          | Site and size charging systems to satisfy the fleet's charging demands                                     | SAEV                | San Francisco Bay Area | \u2713                                        | \u2713        | Agent-based simulation |                   |                     |\n| [120]                                                          | Optimal charging station                                                                                   | ICE/AEV/            | New York City taxis    | \u2713                                        | \u2713        | \u2713                      | Genetic algorithm |                     |\n| configuration                                                  | SAEV                                                                                                       |                     |                        |                                          |          |                        |                   |                     |\n| [121]                                                          | Congestion in road                                                                                         | SAV                 | Sioux Falls network    | \u2713                                        | \u2713        | \u2713                      | Tabu Search       |                     |\n| network                                                        |                                                                                                            |                     |                        |                                          |          |                        |                   |                     |\n| [122]                                                          | Joint optimization of vehicle capacity and parking Long-term infrastructure planning                       | SAV                 | Sioux Falls network    | \u2713                                        | \u2713        | \u2713                      | \u2713                 | MILP                |\n| [123]                                                          | Routing and charging of numerous AEVs in real-time.                                                        | AEV for             | 13-node transportation |                                          |          |                        |                   |                     |\n| ridehailing                                                    | network, adopted from the Salt Lake City transportation system                                             | \u2713                   | \u2713                      | Multi-agent reinforcement learning model |          |                        |                   |                     |\n\nof SAEV allocation in transportation or SAEV charge scheduling in a PN\nmay not be feasible when implemented in a practical CPTN. The interdependency between PN and TN must be formulated with predefined boundaries and mathematical models. Fig. 7 **illustrates coupled power** (modified IEEE 33 bus RDS) and transportation (25 nodes) networks with the representation of a geographic information system (GIS), road map, and power map. Very few research works conducted SAEV\nintegration in CPTN. In Fig. **7, the node-link is represented. In a nodelink connection, specific nodes (presented with BSS or charging station)**\nthat are dispersed across the traffic links and serve as components of the traffic flow are used to connect SAEVs to the power grid. Another way to represent CPTN is using a network flow model where the steadystate distribution of vehicular flow on the node and edge of the TN and power flow in the distribution network are determined by using traffic assignment problem and optimal power flow problem [142]. **Tables** 6 and 7 **compare the articles available in the direction of CPTN in terms** of vehicle type, PN and TN networks type, solution approaches, and other taxonomies."}
{"doc196": "TN models such as the Beckmann model, Nesterov model, and user equilibrium models have been studied in some of the literature. The optimal power flow is a strong need to validate the study conducted on the CPTN with SAEV integration. DC-OPF and AC-OPF are wellknown adopted methods. However, DCOPF simplified the problem, assumed a lossless system with a constant voltage angle, and ignored reactive power. Once both network models are created, there is a need to identify the coupling points. Following is some of the research on SAEV in the CPTN. The study of [126] examines the benefits of coupling charging and repositioning events for on-demand SAEV services in Austin, Texas. Results show that this strategy can reduce rider wait times, decrease empty travel, and improve fleet utilization. A sparser charging station design can also lower investment costs while keeping waiting times low. The research in [149] focuses on a novel business model that combines SEV and a ride-sourcing platform to provide transport and energy services. Two market competition models are developed to analyse the strategic interactions between the distribution network operator (DNO) and the SEV platform operator. The impacts of integrating the discharging service on the cruising traffic are studied using a CPTN. The research [150] focuses on the optimal operation of a cyber\u2013physical system consisting of a large fleet of SAEV and charging hubs. The study considers practical features of power and transportation systems and proposes a mixed integer linear programming model.\n\nResults show that power market considerations can yield significant savings, and a simplified myopic approach can handle larger fleet sizes and hub capacities with reduced computation time.\n\nThe study in [151] evaluates the emissions of SAEVs and compares them to ICE using real-world data from ride-hail service operations."}
{"doc197": "Results show that SAEVs are over five times less carbon intensive than ICE in the Californian power grid. Aligning SAEV charging with renewable generation and smart charging strategies can substantially reduce emissions, generating up to 95% less emissions than other charging strategies. Introducing a carbon tax can also enhance the costeffectiveness of emission mitigation. Ref. [152] proposes a charging station control strategy for energy management and voltage regulation in an autonomous microgrid with EVs connected to the charging stations. The strategy considers the dynamic behaviour of EVs, solar irradiance, wind speed, and load fluctuations. The proposed control strategy is assessed in two different modes: excess power mode and deficient power mode.\n\nR. Sumitkumar and A.S. Al-Sumaiti\n\n| Table 6 SAEV study in CPTN. Ref. Objective   | Vehicle                                                                                            | Power network                                             | Network constraint                             | Solution approach                                                       | Transport network    |                                       |\n|----------------------------------------------|----------------------------------------------------------------------------------------------------|-----------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------|----------------------|---------------------------------------|\n| type                                         |                                                                                                    |                                                           |                                                |                                                                         |                      |                                       |\n| [143]                                        | Minimize system operating cost coupled operation of power and transportation operator              | EV                                                        | -                                              | Power balance, ramp up/down, charge/discharge limits, power angle       | Mixed-integer linear | -                                     |\n| program                                      |                                                                                                    |                                                           |                                                |                                                                         |                      |                                       |\n| [144]                                        | Optimally determine charging station, charging service fees for minimizing                         | EV                                                        | Power distribution network Xi'an city in China | Active/reactive power balance constraints, voltage, generator capacity, | Bi-level and DRL     | Transport network Xi'an city in China |\n| [145]                                        | Minimize the total social                                                                          | SAEV                                                      | Power distribution                             |                                                                         |                      |                                       |\n| cost of CPTN                                 | network Xi'an city in China                                                                        | Voltage drop, power balance, generation limit, line limit | DRL and model predictive control (MPC)         | Transport network Xi'an city in China                                   |                      |                                       |\n| [138]                                        | Maximizing revenue from                                                                            | SAEV                                                      | -                                              | -                                                                       | Kuhn\u2013Munkres         |                                       |\n| SAEV services                                | Algorithm and Edmond\u2013Karp Algorithm                                                                | Chengdu city, Sichuan Province, China                     |                                                |                                                                         |                      |                                       |\n| [146]                                        | Minimizing total                                                                                   | EV                                                        | IEEE 30 bus system                             | Power balance,                                                          |                      |                                       |\n| operating cost                               | voltage drop, CS limits                                                                            | Stochastic multiagent simulation -based                                                           | 30 node network                                |                                                                         |                      |                                       |\n| [147]                                        | Waiting time minimization, fast charging allocation traffic congestion, while maintaining voltage. | EV                                                        | IEEE 33 bus RDS                                | Voltage, charging                                                       | Sequential decisionmaking problem and                      |                                       |\n| station limits                               | DRL method                                                                                         | 25-intersection traffic network                           |                                                |                                                                         |                      |                                       |\n| [148]                                        | Join optimization of power and transport network                                                   | SAEV                                                      | Dallas-Fort Worth, TX                          | Transmission, transformer constraints, initial final charge             | -                    | Dallas-Fort Worth, TX                 |\n| [38]                                         | Optimal Charge scheduling and relocation based on electricity price                                | SAEV                                                      | Tokyo region JEPX wholesale electricity market | Charging rate constraints, no congestion constraints                    | Mixed-integer linear | Tokyo Person Trip                     |\n| program                                      | Survey 2008                                                                                        |                                                           |                                                |                                                                         |                      |                                       |"}
{"doc198": "![13_image_0.png](13_image_0.png)\n\nR. Sumitkumar and A.S. Al-Sumaiti\n\n| Table 7 SAEV in CPTN. Ref. Charging time   | Charger congestion   | Traffic congestion   | Waiting time   | User satisfaction   | Reposition   | Capacity constraint   |\n|--------------------------------------------|----------------------|----------------------|----------------|---------------------|--------------|-----------------------|\n| [143]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   | \u2713            | \u2713                     |\n| [144]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   | \u2713            |                       |\n| [145]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   | \u2713            | \u2713                     |\n| [138]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   |              |                       |\n| [146]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   |              |                       |\n| [147]                                      | \u2713                    | \u2713                    | \u2713              | \u2713                   | \u2713            |                       |\n| [148]                                      | \u2713                    | \u2713                    | \u2713              |                     |              |                       |\n| [38]                                       | \u2713                    | \u2713                    | \u2713              | \u2713                   | \u2713            |                       |"}
{"doc199": "## 6.1. Optimal Location Of Cs And Pick-Up/Drop Points In Cptn\n\nSince the planning problem defines the pick-up/drop locations and the number of stops for SAEV, the optimal location of charging stations is an important study. To ensure the efficient use of resources, the ideal location of charging stations should be determined by analysing the EV charging demand and power network capacity. Additionally, it is essential to locate charging stations near pick-up/drop locations to reduce travel distances for SAEVs and avoid traffic congestion. Furthermore, integrating the charging infrastructure into the power network can optimize its use of RES. It is important to consider the geographical, economic, and social factors to provide all users fair access to charging stations and pick/drop locations [153]. Finding the location of the charging station involves a study on the charging demand requested by SAEVs. Majorly, two research approaches were utilized, one was based on computational geometry (geographical nodes in TN and physical connection with PN), and the other was based on travel surveys (based on population density and simulations). The study in [126] explores the benefits of coupling charging and repositioning events to improve the performance of on-demand SAEV services. Using an agent-based model for the Austin, Texas region, the study found that this strategy reduces user waiting time, and empty travel due to repositioning or charging and improves fleet utilization. The results suggest that operators can adopt this framework to minimize waiting time for travellers while reducing investment costs through sparser charging stations.\n\n## 6.2. Allocation And Uncertainties Of Saev And Cptn"}
{"doc200": "The allocation of SAEV to a user's request is determined based on the availability of the nearest node to minimize waiting time for customers and travel costs. It is crucial to model uncertainties to achieve an optimal solution for SAEV allocation and charge scheduling.\n\nConsideration of uncertainties is imperative in both the PN and TN. In the TN, uncertain parameters encompass factors such as the number of requests from each location within a specified time window, traffic congestion, accidents, etc. Ref. [154] studied the AMoD system, which uses SAEVs for delivery purposes, and the optimized parking, recharging, and rebalancing tasks are demonstrated. MDP is used to model the decision-making process, and two optimization models based on combinatorial optimization theory are built to optimize multi-action dynamic dispatching. Results show that combining combinatorial optimization with reinforcement learning theory can effectively solve the multi-action dynamic dispatching problem of SAEVs in the AMoD\nsystem.\n\n## 6.3. Modelling Objectives And Constraints In Cptn"}
{"doc201": "The role of SAEV in a CPTN is based on the aimed problem formulation, which may lie in the planning or operational stage, as illustrated in Fig. **8. The planning problem aims to determine pick-up/dropoff locations, depots, reconfigure the electrical network, and identify**\noptimal locations for charging stations, among other factors. On the other hand, operational problems involve modelling uncertainties in user behaviour, and the electric network including price, load demand, RES generation, relocation, travel cost minimization, charging cost minimization, allocation, and charge scheduling. There have been very few studies conducted on SAEVs in CPTN. PN and TN constraints are considered depending on the type of study. PN constraints mainly include power balance constraints, voltage constraints, charger limits, line limits, and ramp rates. In contrast, TN constraints include vehicle capacity, travel time, waiting time, trip cancellations, and the number of requests. The article by [155] explores the challenges SAEV fleets pose to network operators and shows that these challenges can be reduced by accounting for operational constraints and exogenous loads. The study concludes that coordination between SAEV and PN operators can mitigate the need for PN capacity upgrades and maintain the network's reliability.\n\nThe literature review has identified diverse modelling approaches employed for the planning problem, namely Mixed queueing network mod [156], Discrete-event simulation [157], Flow-based integer programming model [158], Aggregate model [159], Time-expanded location graphs [160]. For the operational stage, the modelling is followed by methods such as the theory of discrete choice model [43],\nagent-based model [88], structural equation [161], theory of planned behaviour [162], technology acceptance model [163], analytical and simulation model [42] discrete graph-based model [164], unified network flow mode [13], etc. In the context of SAEVs in urban transportation networks, the study by [165] utilizes a Python-based agent-based simulation model, offering a tailored and expandable solution. This model integrates data-driven analytics and predictive analytics, reflecting real-world usage patterns and enabling proactive relocation and charging decisions. Similarly, [102] proposes a directed graphbased modelling approach for a joint rebalancing and V2G coordination strategy in CPTN, showcasing efficiency in reducing passenger waiting times and supporting V2G. The strategy is validated with real taxi service data from New York City, demonstrating operational effectiveness and reduced computational time. In [166], an analytical and agent-based traffic model for a multi-stage charging and discharging strategy for SAEVs is proposed, aligning fleet charging with low-cost hours to achieve significant savings and climate damage avoidance. The model addresses real-world considerations and explores trade-offs between peak power rate fees and societal emissions damages, emphasizing sustainable and cost-effective SAEV fleet operation. Lastly, [130]\npresents a unified network flow model and a bilevel optimization model addressing the interdependence between SAEVs and BSSs. This model optimizes SAEV scheduling and BSS operation management, validated with real-world data from New York, contributing to the efficient and cost-effective integration of electric vehicles into shared mobility systems. 6.4. Contemporary solutions addressing SAEV's energy management and state monitoring In the dynamic realm of contemporary transportation, the emergence of SAEVs has presented an array of transformative challenges, with energy management and real-time state monitoring being pivotal concerns. The integration of AI, connectivity, electrification, and big data opens up an opportunity to revolutionize individual mobility. The impending introduction of full AU, particularly in restricted level-4 domains, represents a crucial juncture, transforming automobiles from\n\n![15_image_0.png](15_image_0.png)"}
{"doc202": "simple consumer products into accessible networks available either ondemand or through subscription models. This transformative shift is envisioned to unfold progressively, integrating EVs with AV capabilities and nurturing innovative business models like AV Subscriptions. The industry's profit potential is poised for significant growth, influenced by the network effect restructuring the automotive value chain. However, thoughtful consideration of regional disparities, weather conditions, and nuances in vehicle segmentation is imperative for formulating effective investment strategies during this transformative phase. The trajectory of level-4 AV adoption post-2021 is expected to surpass consensus expectations, impacting both automakers and suppliers. Essentially, the Car of the Future not only pledges to address current mobility challenges but also to fundamentally redefine the nature of personal transportation. It has been revealed that shared EVs can absorb more than 50% of the annual surplus renewable energy generation in the high-renewable scenario projected for 2030, preventing potential curtailment. Additionally, the V2G capabilities of SAEVs can contribute services to the power grid, such as spinning reserve, peak power generation, and operating reserve [167]. Several studies have developed a simulation methodology for SAEVs, illustrating that a fleet of SAEVs could replace 7 to 10 private cars, offering cost-effective transport services with low break-even prices and the potential to supply operating reserve to the electric grid, indicating significant grid-scale storage and spinning reserves in a wide implementation scenario [42\u2013168].\n\nExploration encompasses promising technologies like solid-state batteries, digital twin applications, wide bandgap technologies in power electronics, and the integration of Li-Fi technology, providing insights into potential improvements in EV performance, cost, and environmental impact by 2030. The pursuit of optimal energy consumption in SAEVs has triggered innovation in advanced battery technologies, where the investigation of high-energy-density batteries and solid-state solutions holds promise for extending range and reducing charging times. Concurrently, the integration of predictive analytics and machine learning algorithms into SAEV operations emerges as a pivotal strategy, enabling dynamic energy management through the analysis of historical data and real-time conditions. Another notable aspect of this discourse revolves around V2G integration, a paradigm shift that positions SAEVs not merely as consumers but as contributors to the energy grid during idle periods, thereby enhancing grid stability and revenue generation. On the state monitoring front, the incorporation of sophisticated sensor technologies, including LiDAR, radar, and cameras, facilitates real-time tracking of vehicle conditions, strengthening safety measures and fortifying the foundation of autonomous decision-making. Simultaneously, the synergy of connectivity and IoT solutions ensures continuous monitoring of vehicle health, enabling remote diagnostics and proactive maintenance measures. Moreover, the application of blockchain technology emerges as a beacon of trust, guaranteeing the integrity and security of the data generated by SAEVs. By dedicating a focused section to these contemporary solutions, we not only gain insight into the current technological landscape but also lay the groundwork for a sustainable and intelligent future of SAEV mobility, wherein efficiency, safety, and environmental consciousness converge to redefine the parameters of modern transportation.\n\n## 7. Critical Reviews And Future Research Recommendations 7.1. Critical Reviews"}
{"doc203": "1. **Approaches for modelling charging demands in published literature can be broadly categorized into two major groups. The**\nfirst category employs a computational geometry-based method that disregards the organizational aspects of the TN and assumes charging demands at geographical nodes. Some studies rely on statistics from travel surveys or population densities, while others utilize simulations or data-driven methods to predict EV charging demand. The second category comprises origin\u2013\ndestination flow-based methods that specifically consider limitations on the SAEV driving range within the TN. Few scholars have explored interdisciplinary issues in SAEV charging station planning, which involves connecting the electric PN and TN\nthrough charging infrastructure.\n\n2. **Extensive research has been conducted on the financial benefits of employing SAEVs for autonomous mobility-on-demand**\nservices.\n\n3. **The necessity for charging infrastructure spread across the service territory is crucial for SAEVs due to their limited driving**\nrange. However, this operational infrastructure's reliance on the local PN may increase investment and operational costs, as well as GHG emissions, particularly if electricity production involves burning coal or natural gas."}
{"doc204": "4. **Limited research attention has been directed towards the planning of charging systems within the framework of the SAEV**\nchallenge. There exists a necessity to delve into the intricate relationship between various SAEV parameters, including vehicle capacity, battery rating, and consumption, and critical charging factors such as the number of charging points at stations, occupancy rates, and charger ratings. This exploration should extend to encompass passenger distribution aspects, considering\nR. Sumitkumar and A.S. Al-Sumaiti factors like density, travel demands, starting and end points, duration, and stops. This interconnected web of SAEV parameters, charging infrastructure, and passenger distribution constitutes a complex problem that can be characterized as the distributioncharging-transportation problem, especially in the context of on-demand mobility services provided by SAEVs.\n\n5. **The research field has seen fewer publications on charging system planning for SAEVs. It is essential to investigate further the**\nrelationship between SAEV parameters (vehicle capacity, battery rating, specific power consumption, etc.) and charging factors (number of charging points in charging stations, occupancy rate, charger rating, pricing policy, etc.).\n\n6. **While separate research has delved into trip order, charge schedule, depot parking, and repositioning, incorporating the redistribution objective at the decision stage is crucial, given its**\nsignificant impact on the performance of mobility-on-demand services."}
{"doc205": "Much research has been conducted on PN modelling and solution approaches. However, combined PN and TN studies need more precision modelling and solution approaches. The future research recommendations are as follows.\n\n1. **In addressing the modelling challenges within the CPTN and**\nits inter-dependencies, a detailed solution involves revising the current interface equation that outlines the mutual dependence of power and the TN. This revision should encompass a more sophisticated and comprehensive modelling approach to enhance accuracy.\n\n2. **To ensure proper and equitable load distribution between the**\nPN and TN, a solution lies in implementing a coordinated load management system. This system will prevent any bus in the PN from shouldering an excessive load and ensure that roads in the TN do not experience undue traffic. This coordinated approach is instrumental in maintaining the stable and safe operation of the CPTN."}
{"doc206": "3. **Previous research predominantly addressed individual**\nchallenges in SAEV systems. A comprehensive solution involves integrating vehicle redistribution tasks into the decision-making stage of mobility services. This incorporation recognizes the significant role that vehicle repositioning plays in the overall efficiency of the system.\n\n4. **Balancing charging cost, user satisfaction, and profit when selecting vehicles for specific passengers necessitates the creation**\nof multi-dimensional and cumulative reward systems. These systems should accurately reflect the matching degree between each SAEV and its designated delivery task, ensuring a holistic approach to decision-making.\n\n5. **Given the uncertainties surrounding critical factors in CPTN**\nmodelling, such as renewable energy source availability, decision-making, traffic congestion, and accidents, a robust solution involves incorporating uncertainty modelling techniques. Techniques like stochastic optimization and robust optimization are essential for accurately representing and addressing uncertainties in CPTN modelling."}
{"doc207": "6. **Evolving ancillary service provisions, specifically voltage and**\nfrequency support using V2G, require a solution that considers the long-term impact on SAEV battery degradation. This involves ongoing research and development to enhance the effectiveness and sustainability of these ancillary services.\n\n7. **The challenge of computation tractability in the real-time implementation of various services discussed in the paper requires**\na comprehensive solution. This solution should address issues related to solution resolution, intervals, memory requirements, data processing, integrity, and security. Effective solutions in these areas will contribute to the overall efficiency and reliability of the CPTN.\n\n8. **Achieving the ambitious decarbonization target set by government agencies requires comprehensive studies into replacing ICE**\nwith EV and SAEV. This requires micro-level modelling and a thorough life cycle assessment of SAEV during production and operational stages (charging/discharging/driving/idle). It ensures a holistic understanding of climate change and sustainability of SAEV contributing to critical insights to the realization of decarbonization goals."}
{"doc208": "## 8. Conclusion\n\nIn summary, this review article offers valuable insights to the global research community concerning the implementation of shared autonomous electric vehicles in coupled transportation and electrical public networks. The article conducts a thorough examination to establish a comprehensive taxonomy for operating transportation systems in a shared, automated, and electric context. The primary objective is to analysed and compare the integration of power and transportation while considering the social and energy implications of innovative technologies. The analysis is strategically organized around three key areas: the transportation network, the power network, and the interconnections between them. Each dimension undergoes meticulous exploration, including a review of achievements to date, an assessment of current state-of-the-art approaches' pros and cons, and a delineation of future opportunities. The study's findings provide methodological insights that can significantly enhance interdisciplinary research efforts by focusing on the intersections of these two complementary fields. The paper particularly discusses various novel technologies, recognizing that while some are in advanced stages of development, others are still in early stages or have lower probabilities of adoption within the next three decades. This nuanced analysis lays a foundation for researchers and practitioners to navigate the evolving landscape of SAEVs and their integration into broader transportation and energy systems.\n\n## Credit Authorship Contribution Statement"}
{"doc209": "[48] **Al Isawi OA, Al Jaafari KA, Al Sumaiti AS. Impact of integrating renewable**\nenergy systems on the smart grid-transportation nexus operation under electric vehicle cyber-attacks. In: 2023 IEEE PES conference on innovative smart grid technologies-middle east. ISGT middle east, IEEE; 2023, p. 1\u20136.\n\n[49] **Acharya S, Mekker M. Measuring data sharing intention and its association with**\nthe acceptance of connected vehicles. Transp Res F 2022;89:423\u201336.\n\n[50] **Sekeran M, Rostami-Shahrbabaki M, Syed AA, Margreiter M, Bogenberger K.**\nLane-free traffic: History and state of the art. In: 2022 IEEE 25th international conference on intelligent transportation systems. ITSC, IEEE; 2022, p. 1037\u201342."}
{"doc210": "[75] **Zhou W, Cleaver CJ, Dunant CF, Allwood JM, Lin J. Cost, range anxiety and future electricity supply: A review of how today's technology trends may influence**\nthe future uptake of BEVs. Renew Sustain Energy Rev 2023;173:113074.\n\n[76] **Li W, Cui H, Nemeth T, Jansen J, \u00dcnl\u00fcbayir C, Wei Z, Feng X, Han X,**\nOuyang M, Dai H, et al. Cloud-based health-conscious energy management of hybrid battery systems in electric vehicles with deep reinforcement learning. Appl Energy 2021;293:116977.\n\n[77] **Xiao Y, Zhang Y, Kaku I, Kang R, Pan X. Electric vehicle routing problem:**\nA systematic review and a new comprehensive model with nonlinear energy recharging and consumption. Renew Sustain Energy Rev 2021;151:111567."}
{"doc211": "[108] **Nair GS, Bhat CR, Batur I, Pendyala RM, Lam WH. A model of deadheading**\ntrips and pick-up locations for ride-hailing service vehicles. Transp Res A\n2020;135:289\u2013308.\n\n[109] **Ruiz E, Soto-Mendoza V, Barbosa AER, Reyes R. Solving the open vehicle**\nrouting problem with capacity and distance constraints with a biased random key genetic algorithm. Comput Ind Eng 2019;133:207\u201319.\n\n[110] **Rajamoorthy R, Arunachalam G, Kasinathan P, Devendiran R, Ahmadi P,**\nPandiyan S, Muthusamy S, Panchal H, Kazem HA, Sharma P. A novel intelligent transport system charging scheduling for electric vehicles using grey wolf optimizer and sail fish optimization algorithms. Energy Sources A 2022;44(2):3555\u201375."}
{"doc212": "[149] **Ding Y, Li S, Jian S. Optimal pricing and fleet management for shared**\nelectric vehicle in coupled power and transport networks. Transp Res C\n2022;141:103727.\n\n[150] **Melendez KA, Das TK, Kwon C. Optimal operation of a system of charging hubs and a fleet of shared autonomous electric vehicles. Appl Energy**\n2020;279:115861. **http://dx.doi.org/10.1016/j.apenergy.2020.115861.**\n[151] **Li Y, Li X, Jenn A. Evaluating the emission benefits of shared autonomous**\nelectric vehicle fleets: A case study in California. Appl Energy 2022;323:119638.\n\n[152] **Gupta A, Suhag S. Charging station control strategy considering dynamic**\nbehaviour of electric vehicles with variable state of charge regulation for energy management of autonomous micro-grid. J Energy Storage 2023;59:106460."}
{"doc213": "The rapid improvements in communication and self-driving technology in recent years have made connected autonomous cars an essential component of urban road transit. Connected autonomous vehicles excel in eliminating uncertainties arising from human driving behaviors. Consequently, they alleviate the issue of 'phantom congestion', a phenomenon that significantly impacts traffic efficiency, safety and sustainability while simultaneously enhancing overall traffic flow stability and safety. Moreover, the increasing adoption of connected autonomous vehicles has led to improved driving efficiency, resulting in reduced energy emissions and decreased environmental pollution. This paper endeavors to conduct an extensive review concerning the effects of CAVs on mixed traffic flows, with a primary emphasis on their impact on traffic efficiency and congestion. \n\nAdditionally, secondary aspects such as stability, safety, and environmental repercussions will be addressed. The article begins with a concise historical account of connected autonomous vehicles and their related technologies. Subsequently, an investigation was conducted into their impact on the mixed traffic environment, along with corresponding policy recommendations. Finally, potential avenues for future research were identified. \n\n## 1. **Introduction**"}
{"doc214": "In the past few years, substantial progress in communication technology, artificial intelligence, and autonomous driving tech has spurred the emergence of self-driving automobiles, connected vehicles, and associated breakthroughs. Autonomous vehicles (AVs) \nconstitute a novel category of automobiles that rely on internal sensors and computing systems to autonomously make driving decisions. AVs can be considered as computer-controlled entities [1] or defined as vehicles equipped with integrated computers [2]. The origins of autonomous driving technique can be traced back to the early 1900 s. The fundamental concept involves the substitution of certain or all human driving tasks with electronic and mechanical systems [3]. During that era, technological progress primarily revolved around basic cruise control systems, including autonomous speed regulation, braking mechanisms, and lane control [4]. \n\nDuring the period of rapid development of connected self-driving cars, V2X real-time communication technology can better optimize the traffic flow and enable a new phase of self-driving research [1]. \n\nHuman driving behavior often exhibits uncertainty and instability, resulting in traffic flow characterized by unpredictability [5]. "}
{"doc215": "phenomenon known as \"phantom congestion\" [6]. The congestion we face on today's roads is a major challenge when it comes to controlling and managing traffic flow. Connected autonomous driving shows its potential in optimizing traffic flow [3]. However, the real-time communication system in these vehicles, while highly accessible, also exposes them to risks like cyber-attacks and information leaks. Examples include potential attacks on external systems leading to communication failures or manipulation of critical data, which can result in unsafe driving behaviors [7]. \n\nCompared to traditional human-driven cars, connected autonomous vehicles can exchange data between vehicles and infrastructure in real-time and without delays. This exchange greatly enhances reliable support for driving decisions, countering potential threats stemming from the instability of human driving behavior. Consequently, these vehicles can swiftly respond to traffic conditions, improving driving efficiency and to some extent, reducing congestion and the occurrence of accidents [8]. The improvement in traffic capacity and communication speed also positively impacts the resource utilization of autonomous driving, which also aids in decreasing unnecessary energy emissions, promoting environmental sustainability [9]. \n\nCurrently, connected autonomous vehicles (CAVs) have gained significant prominence in research. While numerous articles have explored the technological advancements and potential impacts of CAVs, there remains a limited body of literature comprehensively addressing their potential effects on mixed traffic flow, and corresponding integrated policy recommendations. Thus, the paper focuses primarily on the current state of CAV, its implications on hybrid traffic flow, particularly emphasizing the core issue of CAVs' impact on traffic efficiency. It also offers fundamental policy recommendations for the development of CAV. Finally, potential future research directions are proposed. "}
{"doc216": "The primary contribution of this paper lies in shifting focus away from solely examining specific subsets of CAVs' impact on mixed traffic flow. Instead, it simultaneously considers traffic efficiency, traffic flow stability, safety, environmental friendliness, and energy consumption from an integrated perspective, comprehending their interconnections. This comprehensive assessment of the collective performance of hybrid traffic flow facilitates the delivery of thorough and dependable data to policymakers. Such an approach is beneficial for the strategic deployment of CAV implementation. \n\nThe paper follows this structure: Section 2 gives an overview of the developmental history of AVs and CAVs, along with relevant technological foundations. Section 3 explores the core implications of CAV on hybrid traffic flow\u2014traffic Productivity\u2014covering measurement factors and vehicle control. Section 4 discusses other impacts of CAVs on hybrid traffic flow, emphasizing stability, security, and environmental factors. Section 5 presents policy recommendations associated with CAV development and compares policies from representative countries. Section 6 outlines potential future research directions. Section 7 provides a concise summary of the entire document. \n\n## 2. **Overview Of Connected Autonomous Vehicles** 2.1. History Background"}
{"doc217": "The earliest recorded accounts of autonomous automobiles date back to the early 1920 s [10], with General Motors introducing the concept in 1939 [3]. During the 1980 s, researchers directed their efforts towards developing an automated highway system [11,12], which laid the foundation for integrating self-driving cars with highway infrastructure. From the 1980 s to the early 2000 s, the U.S. \n\nDepartment of Defense's Advanced Research Projects Agency (DARPA) contributes to the developments of advancing autonomous vehicle technology. DARPA launched the \"Grand Challenges Program,\" expanding autonomous vehicle competitions from desert environments to simulated urban settings, significantly expediting the progress of autonomous vehicles, as detailed by Pendleton [10] \nand Shladover [3]. \n\nCurrently, numerous enterprises are actively engaged in the realm of autonomous driving, primarily categorized into traditional automobile manufacturers, internet technology firms, and emerging startups specializing in autonomous driving. In the United States, Google initiated its self-driving project back in 2009, garnering significant attention within the industry. By 2016, Waymo emerged as an autonomous driving technology entity independent of Alphabet, introducing the Waymo One autonomous ride-hailing application. Over recent years, Waymo has consistently expanded its suite of services. Tesla, on the other hand, concentrates on the holistic "}
{"doc218": "| Table 1  Development of representative autonomous car companies.  Firms Competitive landscapes   | Major developments                                                             |                                                                                           |\n|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n| Waymo[13]                                                                                        | Autonomous driving network about car travel services,                          | Received its driverless deployment permit from the California Public Utilities            |\n| autonomous driving technology                                                                    | Commission (CPUC) in In August 2023                                            |                                                                                           |\n| Tesla[14]                                                                                        | Design, development, manufacture and sales of electric                         | Announced a $1 billion investment in 2023 to develop a Doj project designed               |\n| autonomous vehicles and power transmission components                                            | to manage large amounts of data, especially video data from Tesla              |                                                                                           |\n| Nissan[15]                                                                                       | Advanced autonomous driving assistance system,                                 | Tried a driverless taxi service in parts of Suzhou, China in 2023, with technical         |\n| autonomous vehicle manufacturing                                                                 | support from Wenyuan Zhixing (WeRide)                                          |                                                                                           |\n| Pony ai[16]                                                                                      | Autonomous mobility services, autonomous trucks,                               | Pony.ai, in partnership with Toyota and using the startup's self-driving                  |\n| intelligent driving of passenger cars                                                            | technology and ride-hailing services, plans to mass-produce robotaxis in China |                                                                                           |\n| Mercedes-Benz                                                                                    | Advanced electric vehicle manufacturing, autonomous                            | Launch of independently developed operating system MB.OS to enhance                       |\n| [17]                                                                                             | driving software system                                                        | intelligent driver assistance features or L3 conditional autonomous driving  capabilities |\n| Volkswagen                                                                                       | Autonomous vehicle manufacturing, autonomous driving                           | It plans to roll out roughly ten ID Buzz electric vehicles with an autonomous             |\n| Group[18]                                                                                        | technology                                                                     | driving system created in collaboration with Mobileye by the end of 2023.                 |\n\ndevelopment cycle of electric autonomous vehicles and their power transmission components. \n\nIn China, both Apollo and Pony.ai direct their efforts toward advancing autonomous driving technology and manufacturing autonomous vehicles, concurrently propelling the growth of autonomous ride-hailing platforms. In Japan, traditional automotive giants like Nissan and Toyota have commenced their foray into autonomous driving operations. Their approach primarily revolves around a blend of collaborations with technology companies and self-directed research to advance their autonomous driving technology. "}
{"doc219": "Across Europe, Mercedes-Benz, renowned for its advanced automobile manufacturing, has recently begun prioritizing its autonomous driving initiatives. Their latest independent development, the MB.OS operating system, aims to augment intelligent driving assistance functions and Level 3 conditional autonomous driving capabilities. The following table offers a more lucid representation of the current developmental landscape of key autonomous driving companies from various regions.. \n\nAccording to reports, it is predicted that self-driving cars will make up about 50% of all road trips by 2045 [19,20]. The transportation landscape is rapidly changing due to new technologies, for example, smartphones, social networks and AI-equipped autonomous vehicles [21\u201323]. Car automation is one of the top ten disruptive technologies of the future, according to Manyika [24]. \n\nIn 2020, the autonomous driving car industry reached a significant milestone in its commercial integration into a broader market, largely driven by the intensifying competition among enterprises within the autonomous driving sector [25,26]. Various studies indicate that the AV market is moving towards a state of maturity by the middle of this century. Based on previous developments and deployments in intelligent vehicle technologies, it is anticipated that by 2040, self-driving cars will constitute approximately 50% of the total car sales and contribute to around 40% of automotive travel. Report does, however, also highlight the fact that major advantages like reduced traffic, autonomous travel options for low-income populations, improved safety, and lower emissions can only be felt to the fullest extent when the number of AV reaches a critical mass and their prices are affordable for most people [20]. At this juncture, there might even be a need to impose restrictions on the utilization of specific human-driven vehicles. Therefore, comprehending future challenges and promptly capitalizing on the opportunities they present is paramount for the prospective advancement of intelligent urban transportation [27]. "}
{"doc220": "## 2.2. Autonomous Technology\n\nAfter continuous development, self-driving cars have been classified into different levels based on various standards. According to the National Highway Traffic Safety Administration (NHTSA) standards, self-driving cars can be categorized into five levels [28]. Fig. 1 shows the five levels of autonomous vehicles. Level 0 signifies a car with no self-driving capability, requiring the driver to fully control the vehicle. Level 1 indicates some degree of assistance, such as assisted braking or cruise control. Level 2 represents \"partially automated\" vehicles. Level 3 is termed \"conditionally automated\", allowing the automated system to operate relatively independently under certain conditions. Level 4 signifies a high level of automation, indicating that under suitable environmental conditions, a self-driving car can autonomously execute predetermined driving tasks without requiring human intervention or manual operation. \n\nFinally, Level 5 represents \"fully automated\" vehicles, capable of taking over all driving responsibilities from a human driver. However, it's worth noting that while this classification serves as one criterion for assessing self-driving cars' levels, academia has yet to establish a strict definition. As a result, any level of \"automation\" is considered an attribute of self-driving cars [27]. "}
{"doc221": "Irrespective of the degree of autonomy, achieving autonomous driving entails a spectrum of functionalities, including positioning, sensing, planning, controlling, and management [30]. Positioning and sensing rely on information gathering and acquisition. When an autonomous vehicle can communicate with other vehicle infrastructures to coordinate its operations, it is referred to as a connected automated vehicle [3]. In contrast, when a manually-driven vehicle communicates with other cars and infrastructures to gather data and coordinate operations, it is regarded as a connected vehicle (CV) [30]. Consequently, connected vehicle technologies complement, advance, and synergize with the implementation of autonomous vehicle technologies to a certain extent [3]. \n\nThus, connected drive technologies are integral parts of self-driving car program [28]. It improves driving efficiency by allowing CV \nto communicate in real time with infrastructure and other CV. This communication can be categorized into several modes, including vehicle-to-vehicle communication (V2V), vehicle-to-infrastructure communication (V2I), and vehicle-to-cloud communication (V2C). Additionally, Fang et al. [31] have suggested that vehicle-to-pedestrian (V2P) and vehicle-to-network (V2N) communication can also be considered part of this networked Intelligent Transportation System (ITS). All these communication mechanisms collectively fall under the term \"vehicle-to-everything\" (V2X), which is synonymous with the Internet of Vehicles [32]. Autonomous vehicles and \n\n| Study on traffic efficiency of mixed traffic flow.  Study Model / Framework Conclusion  [44] Car follower model Self-stabilizing effect can enhance the stability of heterogeneous traffic flow and alleviate traffic congestion.  Increasing the proportion of autonomous vehicles could also help stabilize heterogeneous traffic flows  [46] Mixed traffic flow model Demonstrate that self-driving cars can improve traffic efficiency and reduce energy consumption using three  metrics-traffic assessment  [48] Synergistic drive strategies CDS-L  Networked autonomous driving reduces traffic fluctuations and improves traffic efficiency  and CDS-G  [54] General vehicles follow the frame The permeability and spatial distribution of connected vehicles are intimately related to traffic stability. Connected  vehicles can significantly enhance the stability of traffic flow and improve traffic efficiency  [55] Cellular automata model As autonomous vehicle penetration and fleet size increase, overall capacity increases, reducing congestion   |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|"}
{"doc222": "| Table 3  metrics of mixed traffic flow efficiency.  Study Index   | Conclusion                                                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                 |\n|-------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [46]                                                              | Traffic flow, average speed and quantity of vehicles                                                                                                                                                                     | The outcomes of simulations demonstrate that self-driving cars can lower energy usage  and increase traffic efficiency. Elevated degrees of automation and an increased  quantity of autonomous vehicles have the potential to enhance transportation  effectiveness and minimize energy usage. |\n| [47]                                                              | 19 factors, divided into 4 categories: vehicle characteristics,                                                                                                                                                          | Policymakers should be aware of the variables that may affect how autonomous                                                                                                                                                                                                                    |\n| travel behavior, network characteristics, and policies            | vehicles affect traffic flow, as the impact of these vehicles varies depending on a  number of metropolitan characteristics. Additionally, different scenarios for linked  autonomous driving exist in different cities. |                                                                                                                                                                                                                                                                                                 |\n| [56]                                                              | Uniform performance indicators composed of traffic                                                                                                                                                                       | Overall traffic performance, including single-vehicle and multi-vehicle safety as well as                                                                                                                                                                                                       |\n| efficiency, multi-vehicle safety and single-vehicle safety        | traffic efficiency, has improved with increased market penetration. Furthermore, selfdriving cars have a bigger effect on traffic performance overall on cloudy days than on  bright ones.                                                                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                 |\n| [57]                                                              | Automation level, penetration, and kind of vehicle                                                                                                                                                                       | CAVs have a gradual and non-linear influence on traffic efficiency and safety, with the  greatest benefits occurring at MPR ranges of 20 to 40%.                                                                                                                                                |\n| [59]                                                              | Permeability, vehicle connectivity, road capacity and speed                                                                                                                                                              | The road capacity is significantly increased by the high permeability. Furthermore,  vehicle connectivity allows for quick travel times while preserving a small gap between  vehicles.                                                                                                         |\n\ninterconnected vehicles overlap in certain technological aspects [1]. Vehicular Ad hoc Network (VANET) technology is used in connected vehicles, which need the installation of an On-Board Unit (OBU) within the car. Vehicles within its communication range can communicate with one another using the Dedicated Short Range Communication (DSRC) standard protocol [33,34]. VANET \ntechnology can support both safety-related and infotainment applications, with the main distinction between the two being the level of security measures employed; safety-related applications typically adhere to more stringent security standards [1]. \n\nCommunication in CAVs relies on wireless technologies [32]. DSRC facilitates communication between autonomous vehicles and infrastructure through On-Board Units (OBUs) in vehicles that receive signals and Roadside Units (RSUs) exchanging information with OBUs from various sources [31]. DSRC deployment can help mitigate traffic congestion and accidents caused by human driving, playing a crucial role in accident prevention on roadways. Huang and Lin [35] suggests that DSRC is particularly suitable for early collision estimation and avoidance in highway scenarios. However, DSRC-based V2X communication has limited scalability and cannot provide satisfactory probabilistic characteristics as vehicle density increases [36,37]. Furthermore, the limited transmission range inherent in DSRC renders it inadequate for delivering high-capacity, low-latency communication channels essential for sophisticated V2X applications like autonomous driving. Consequently, V2X technology amplifies the advantages of autonomous driving and promotes the application of autonomous vehicles in actual traffic [38,39]. "}
{"doc223": "In the field of communication methods among CAVs, cellular connectivity plays an important role. Specifically, Cellular Vehicle-toEverything (C-V2X) communication stands as a crucial foundational technology, contributing significantly to the establishment of interconnected and automated traffic systems. Inter-vehicle communication enables more precise and efficient autonomous driving behavior, allowing vehicles to exchange driving intentions (such as lane changes, braking) and provide perception beyond the capabilities of AV sensors, ensuring more reliable navigation. Consequently, vehicle data has become a critical resource, occupying a significant position in the driving network, requiring new network architectures to support this growth [40]. Despite the advancements in 3GPP LTE and 4 G V2X (version 14 C-V2X), their incapability to deliver high throughput and low latency for advanced applications falls short of meeting the practical demands of CAVs. As a result, 5 G C-V2X emerges as a more promising and viable choice [32]. The millimeter-wave frequency band, edge computing, network slicing, virtualization, and advanced antenna systems within 5 G C-V2X \ntechnology have the potential to offer more reliable low-latency communication and higher data rates, enabling the realization of more \n\n| Nation                                                                                                   | Year                                                                                                                                                                                                                    | Document   | Content   |\n|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------|-----------|\n| Automated Vehicles Comprehensive Plan[18]                                                                | Identify three goals for the development of the U.S. autonomous vehicle  industry: promoting cooperation and transparency, modernizing the regulatory  environment, and preparing the transportation system             |            |           |\n| Occupant Protection Safety Standards for Autonomous                                                      | Emphasizes that autonomous vehicles must provide the same level of occupant                                                                                                                                             |            |           |\n| Vehicles[139]                                                                                            | protection as traditional vehicles driven by humans, and makes it clear that  fully autonomous vehicles may no longer need manual equipment                                                                             |            |           |\n| Regulations on Administration of Intelligent  Connected Vehicles in Shenzhen Special Economic  Zone[140] | Allow L3 AV to be tested on open roads in administrative areas with relatively  complete CVIS infrastructure                                                                                                            |            |           |\n| Autonomous Driving Law (Draft)[141]                                                                      | Supplements to the existing Road Traffic Law and Compulsory Insurance Law  have established a legal framework for L4-level autonomous driving, allowing  it to operate normally on public roads throughout the country. |            |           |\n| Autonomous Driving Law (Draft)[142]                                                                      | A legal framework has been established for level 4 autonomous driving to  enable it to operate normally on prescribed public roads across the country                                                                   |            |           |\n\n![4_image_0.png](4_image_0.png)"}
{"doc224": "advanced CAV functionalities. The sensitivity of connected autonomous driving to network security makes security a critical attribute within C-V2X, including specific elements such as authentication identification, integrity, user privacy, and availability [40] . However, most information within C-V2X is disseminated in a temporary broadcast form, posing certain risks in such communication methods, necessitating the formulation of further standards and specifications to achieve communication security in C-V2X.\n\nThe connectivity and autonomy offered by connected autonomous driving are poised to revolutionize the transportation paradigm in several ways, with profound social and economic impacts. These include enhanced safety, increased stability and comfort, time savings, more efficient road utilization [41] .\n\n3. Impacts of connected autonomous vehicles on alleviating congestion and traffic efficiency Connected autonomous vehicles (CAVs) constitute a profoundly transformative technology with vast potential across multiple domains. This potential includes a substantial reduction in traffic accidents, particularly those involving pedestrians or cyclists, the improvement of traffic flow stability and fluidity to enhance overall traffic system efficiency, and a reduction in pollution emissions [32] . Currently, extensive research has focused on exploring the efficiency, congestion alleviation, safety, pollution and stability of CAVs within their operating environment."}
{"doc225": "However, based on the most recent findings, CAVs will comprise 75% of global automobiles before the mid-21st century [42] . The escalating adoption of CAVs is shaping a landscape where road traffic will comprise a diverse mix of HDVs and CAVs [43] . The homogeneous traffic flow composed solely of human-driven vehicles will gradually evolve into heterogeneous traffic flow, coexisting with both connected autonomous vehicles and human-driven vehicles [44]. Due to differences in driving logic and technology, their interactions with each other and the external environment are dissimilar, making heterogeneous traffic flow more complex than homogeneous traffic flow, where uncertainties, unobservability, and uncontrollability in HDVs make it difficult to estimate traffic states. The reaction time and compliance with changes in driving states due to the development level of CAV technology also contribute to this complexity [45]. Fig. 2 illustrates a connected system of mixed traffic flow, showcasing the interconnections between networked autonomous vehicles themselves, pedestrians, infrastructure, and networks. \n\nTherefore, how CAVs influence heterogeneous traffic flows has garnered attention from a group of scholars. Scholars have specifically focused on the role of CAVs in enhancing traffic efficiency within mixed traffic flows. Traffic efficiency correlates with various factors, such as velocity, transit time, and traffic volume [46]. CAVs influence traffic efficiency in multiple ways, including CAV penetration rates, vehicle control, dedicated lane design, and road planning [47]. By optimizing traffic flow from different aspects, they elevate traffic efficiency. The advantage of connected autonomous driving lies in its real-time interaction with infrastructure and other networked vehicles, engaging in cooperative driving [48]. Powerful networked autonomous systems can intelligently plan lane changes, braking, acceleration, and deceleration, reducing traffic fluctuations caused by uncertainties and sudden changes inherent in human driving\u2014a state of inefficient stop-and-go movement [49]. Systematic planning and vehicle collaboration effectively enhance traffic efficiency, alleviating traffic congestion. \n\n## 3.1. Research Models And Measurement Indicators Of Connected Autonomous Vehicles"}
{"doc226": "The real-time communication and precision computing of connected autonomous driving enable shorter response delays and increased travel speeds, minimizing the influence of human drivers' personality traits, preferences, and skills, thereby allowing for enhanced vehicle throughput [2]. To evaluate the effect of CAV on traffic efficiency, numerous scholars have suggested a variety of metrics and study approaches, including as network models, cellular automata, following models, reinforcement learning algorithms, and more. The cellular automata model, with its unique advantage of discrete grid-based dynamics in time and space, evaluates various vehicles and speeds based on cells within the model [50]. Zhang et al., for instance, introduced an advanced cellular automata model based on the classical NS model. This enhanced model integrates the physical characteristics of vehicles and simulates mixed traffic flow involving both electric and fuel-based vehicles. Their research analyzed how the presence of electric vehicles affects traffic flow safety across different penetration rates [51]. Based on three-phase traffic theory framework and the traditional three-phase traffic flow theory KKW model, Zeng et al. created a cellular automaton model for highway ramp systems under accident conditions, which was used to analyze the effects of traffic accidents on traffic flow and comprehend the patterns of congestion propagation [52]. Additionally, the Lagrangian-based multi-valued cellular automaton model has been utilized to analyze multi-lane traffic flow. Lower density coupled with a higher number of lanes results in increased traffic volume [53]. \n\nXie et al. derived, using a general vehicle-following framework, that the stability of heterogeneous traffic is closely linked to the penetration rate and spatial distribution of connected vehicles, emphasizing how interconnected vehicles enhance traffic flow stability and efficiency. Furthermore, they proposed a distributed feedback control-based driver assistance strategy that positively influences traffic flow stability and efficiency [54]. However, most existing studies on heterogeneous traffic flow models have not adequately considered the self-stabilizing effects. Gong and Zhu introduced a car-following model considering the self-stabilizing effects of AV in heterogeneous traffic flow. They verified using both linear and nonlinear techniques that self-stabilizing effects may improve heterogeneous traffic flow stability and reduce traffic congestion. Additionally, a higher percentage of autonomous cars helps to stabilize \n\n![5_image_0.png](5_image_0.png)"}
{"doc227": "the flow of diverse traffic [44]. The local strategy CDS-L and global strategy CDS-G, which are based on shared CV information, have also been confirmed to dampen traffic fluctuations and enhance traffic efficiency [48]. Zeng et al. simulated the effects of intelligent networked vehicles on energy consumption and traffic congestion using a cellular automaton model of heterogeneous traffic flow on a dual-lane roadway. The results showed that as CAV penetration rates and convoy sizes rise, so does total traffic capacity, which reduces congestion [55]. \n\nIn Chen's study, a mixed traffic flow model was established using three metrics\u2014traffic volume, average speed, and vehicle count\u2014to assess traffic efficiency. The simulation results indicated that autonomous driving vehicles could enhance traffic efficiency and reduce energy consumption [46]. Narayanan outlined 19 factors influencing the traffic flow efficiency of connected autonomous driving vehicles, categorized as vehicle characteristics, travel behavior, network features, and policies. Noteworthy factors included CAV dedicated lanes, CAV market penetration rates (MPR), and intersection control [47]. Hou proposed a comprehensive performance assessment framework for CAV in mixed traffic and a unified performance metric reflecting the overall traffic performance, demonstrating significant CAV-induced improvements in overall traffic efficiency and safety [56]. \n\nGu\u00b4eriau and Dusparic [57] investigated CAV's impact on three networks (urban, national, and highways) regarding traffic efficiency and safety, concurrently evaluating three CAV indicators: automation level, penetration rate, and vehicle type. Their findings indicated a progressive and nonlinear impact of CAV on traffic efficiency and safety, achieving maximum benefits at MPRs ranging from 20% to 40% [56]. Overall, in heterogeneous traffic flow composed of CAVs and HDVs, most studies have focused on traffic performance itself, with few reviews addressing policy-related indicators. Consequently, a significant portion of research has concentrated solely on subsets of traffic efficiency, failing to comprehensively summarize related influencing factors. There is a need for a more inclusive set of metrics to provide decision-making support for the development and regulation of CAVs. "}
{"doc228": "When studying the traffic efficiency of mixed traffic flow, the market penetration rate (MPR) of CAVs stands as a crucial influencing factor. Different MPRs may result in varied impacts on traffic efficiency. In scenarios with lower market penetration rates, the positive benefits of CAVs may be challenging to realize [58]. Do et al. reviewed CAV simulation studies and found that higher penetration rates greatly enhance road capacity. Moreover, vehicular connectivity enables rapid passage while maintaining minimal inter-vehicle distances, where road capacity and speed serve as critical metrics for traffic efficiency [59]. Houshmand, using actual traffic data from Boston, examined the effect of allocating system central routes under different CAV penetration rates in mixed traffic flow. The results indicated that even at low CAV penetration rates, traffic congestion can be alleviated [60]. Hou suggested in their study that variations in MPR exert diverse impacts on the efficiency of mixed traffic flow. When MPR is below 20%, its effect on traffic efficiency is minor, yet it significantly enhances traffic safety. Therefore, in researching the influence of CAVs on mixed traffic flow, it's essential to consider these various factors together [56]. \n\n## 3.2. Vehicle Control And Traffic Efficiency Enhancement Strategies In Connected Autonomous Vehicles\n\nVehicle control can be categorized into two aspects: longitudinal control, aimed at maintaining the desired speed and following distance, and lateral control, focused on directing lane changes [61]. Networked autonomous driving, through real-time communication and coordinated cooperation, reduces response time and precisely plans actions to enhance vehicle control. While considerable research has been conducted on the longitudinal control of CAVs in this domain, studies on lateral control are relatively dispersed. "}
{"doc229": "However, reasonable lane changes show promise in enhancing traffic efficiency and alleviating congestion in dense traffic scenarios, despite connected CAVs having a limited spatial impact by improving speed within traffic flow. Therefore, investigating CAVs' coordinated behaviors such as lane-changing, overtaking, and merging is important. Strategies for CAV longitudinal control can be approached through linear or nonlinear [62,63], model prediction [61,64], and deep reinforcement learning [49,65,66]. Automated lane-changing strategies for CAVs involve reinforcement learning [67\u201369], model simulation [70,71], and partially observable Markov decision processes [72]. Although some strategies are tailored for AVs, the authors assert that representative techniques and practices have significant reference value for CAVs as well. \n\nLiu et al. conducted a comprehensive review of vehicle control technologies for both AVs and CAVs, particularly emphasizing AVs' micro-level vehicle state estimation and trajectory tracking control, alongside CAVs' evolution in macro-level coordinated control. \n\nThey discussed non-predictive feedback, predictive model forecasting, and learning-based vehicle control technologies, which significantly enhance traffic efficiency, safety, and sustainability [73]. Wang et al. delved into the impact of CAV autonomous lane changing on mixed traffic flow, demonstrating, from the perspectives of micro-traffic simulation and reinforcement learning, the positive effects of lane-changing strategies at 50% or 100% market penetration rates [61]. Shi et al. proposed a distributed longitudinal control strategy based on Deep Reinforcement Learning (DRL), integrating interference signals and noise into machine learning to simulate real environments. Their approach involved a multi-agent system receiving real-time information to address signal failures, effectively mitigating traffic oscillations and thus improving traffic efficiency [49]. "}
{"doc230": "Apart from direct vehicle control, scholars have also focused on the impact of autonomous vehicle intersection control and the implementation of dedicated lanes on traffic efficiency and congestion relief [74]. Traffic density and the number of lanes significantly impact traffic flow, where lower density and more lanes result in higher traffic volume [50]. Similar to dedicated lanes for rapid transit, toll roads, and HOV lanes, specialized lanes play a crucial role in enhancing traffic efficiency, contingent upon the overall penetration rate of CAVs. He explored the implications of CAV lane policies on highway traffic efficiency in terms of capacity and throughput. Experimental combinations of different lane policies and traffic conditions revealed that at lower CAV Market Penetration Rates (MPR), CAV-dedicated lanes had no significant effect on traffic efficiency, suggesting a recommendation for implementing a \"mandatory use\" policy instead of setting multiple dedicated lanes [8]. Ye conducted a modeling study to assess the advantages and disadvantages of setting exclusive lanes for CAVs. The findings indicated that at lower CAV penetration rates, Exclusive lanes of CAV decreased the overall traffic flow throughput. However, under moderate penetration rates, dedicating lanes was more favorable for optimizing CAV advantages in traffic efficiency [75]. \n\n## 4. **Impacts Of Connected Self-Driving Cars On Stability, Safety And Environment**\n\nAlthough connected autonomous vehicles are developing rapidly, achieving a 100% adoption rate will require a lengthy process. "}
{"doc231": "Therefore, HV and CAV will coexist for an extended period, forming a complex mixed traffic flow system. In response to this shift, some scholars have begun to focus on the security and stability implications of CAVs within hybrid traffic flows rather than exclusively within a fully CAVs environment [58,76,77]. For instance, Yao considered situations in mixed CAV environments where CACC-equipped vehicles degrade into ACC-equipped vehicles and studied the security and stability within hybrid traffic flows using various security assessment metrics [78]. Furthermore, advancements in vehicle design and engine efficiency of Connected Autonomous Vehicles have effectively reduced fuel consumption and emissions [28]. Research estimates indicate that fuel consumption has nearly halved compared to figures from 30 years ago [79], resulting in reduced energy emissions and contributing to environmental sustainability. \n\nThe earlier discussion focused on the impact of CAVs on enhancing traffic efficiency and alleviating traffic congestion. Traffic efficiency serves as a crucial intermediary and focal point, enabling an exploration into the potential correlations and influences associated with the enhancement of traffic efficiency and its implications on other aspects. In this section, we will review the influence of CAVs on hybrid traffic flows, specifically examining their effects on stability, safety, and environmental conservation. \n\n## 4.1. Stability Implications Of Connected Autonomous Vehicles"}
{"doc232": "V2X communication, cloud technology, positioning and sensing will enable CAV systems to work better together. CAVs achieve this by gathering diverse data from sources like infrastructure, nearby vehicles, and cloud servers. This multi-source data acquisition significantly improves the safety and stability of autonomous driving [80]. CAVs communicate with other connected vehicles (V2V), with infrastructure (V2I), with networks (V2N), as well as with pedestrians (V2P). Collectively, these communication modes are termed V2X [5]. \n\nZheng points out in his research that a significant characteristic of traffic flow primarily consisted of HDV is its inherent instability \n[6]. Sudden events and decisions can easily result in the stop-and-go nature of traffic flow. This is also applicable to connected autonomous vehicles. This chain reaction amplifies and propagates through traffic, leading to a wave-like pattern of congestion [81]. \n\nThis fluctuating traffic condition is often referred to as \"phantom traffic\"[82] or \"traffic oscillations.\" It is typically caused by various factors, including lane changes resulting from diverging and merging [83\u201385], lane height variations [86], changes in road geometry \n[87], and fluctuations in traffic volume, among others. Additionally, driver personality [88] and stochastic behavior can also contribute to the instability of traffic flow. "}
{"doc233": "Numerous studies have explored traffic flow stability in CAV environments [89\u201391]. Talebpour and Mahmassani, for instance, employed a microsimulation framework with diverse vehicle types to assess string stability across various CAV penetration rates. They found that CAVs notably improved mixed traffic flow stability and mitigated the formation and propagation of traffic disruption [58]. \n\nYao conducted a microsimulation experiment showing that a 25% penetration of ACC vehicles effectively enhanced traffic flow stability and road capacity [78]. Lu and Aakre introduced a stability criterion for homogeneous traffic flow, establishing its stability [92]. \n\nYe and Yamamoto observed that the integration of self-driving cars significantly bolsters traffic flow stability. To investigate this, they simulated mixed traffic flow scenarios using a meta-cellular automata model. Their analysis scrutinized collision event distributions, acceleration patterns, and speed differences across various CAV penetration levels [93]. "}
{"doc234": "Zheng employed the Lagrangian coordinate system and six performance metrics to measure how autonomous cars affect system stability. The findings revealed that increasing the AV penetration rate from 5% to 50% positively impacts the stability of mixed traffic flow and human-driven vehicles [6]. In parallel research, Jin investigated the stability of mixed traffic flow under various conditions, including diverse CAV penetration rates, driver reaction times, and the number of CAVs, employing a deterministic model of mixed traffic flow. It was observed that appropriate control of CAVs significantly enhances the stability of mixed traffic flow [94]. In addition, Ghiasi et al. introduced an analytical stochastic model to scrutinize the stability and throughput of mixed traffic flow under diverse conditions, including CAV penetration rates, CAV platoon intensity, and mixed traffic headway settings [95]. \n\nIn various traffic scenarios, urban roads often pose dynamic challenges, such as sudden accidents and frequent congestion. \n\nConsequently, many scholars have expressed significant interest in evaluating CAV performance at urban intersections. Some researchers have even proposed that CAV deployment could potentially replace traditional traffic signal lights [96], leading to improved stability in mixed traffic flow. An essential aspect of achieving this enhancement involves optimizing the travel times of all vehicles within the intersection radius. This optimization ultimately increases intersection throughput and enables optimal CAV control at intersections. Consequently, recent research in this area has focused on minimizing vehicle travel times [97\u2013100]. Zohdy [101] \nintroduced a Cooperative Adaptive Cruise Control-based method to minimize intersection delays and maximize traffic throughput. "}
{"doc235": "The information connectivity and communication capabilities of connected autonomous vehicles construct an open network environment. Through V2X communication, CAVs engage in real-time information exchange, allowing them to 'see' beyond their immediate line of sight [105]. This extended perception range further enhances driving safety. With real-time communication data updates and precise decision-making, CAVs can make more reasoned judgments when faced with changing driving conditions, such as turns, inclines, obstacle avoidance, and emergency braking, thereby ensuring the safety of both drivers and passengers. However, autonomous vehicles operating in platoons are also susceptible to cyberattacks [7]. This not only poses risks of compromising user privacy but may also directly jeopardize traffic safety, such as increasing collision risks and causing traffic disruptions [106,107]. Consequently, connected autonomous vehicles exert two distinct influences on the security of heterogeneous traffic flow and other vehicle types. \n\nConcerns about CAV's own security can be categorized into two areas [32]: attacks from active and attacks from passive. Among them, passive attacks refer to an attacker eavesdropping on the CAV's position, speed, and planning information transmitted via broadcasts, which can be re-observed and stolen by the attacker after the broadcasted data is delivered to the RSU [108], adding another layer of risk to the security of the connected self-driving cars. Kang [109] explained a passive attack method in their study, where a unique and accurate information about the target vehicle is obtained from the roadside localization unit (RLU), and the information about the target vehicle is obtained from the roadside localization unit (RLU). Cheng [7] proposed a novel intelligent driving model that takes into account network attacks and heterogeneous vehicles while integrating a dynamic communication topology. Validation revealed that under network attacks, low penetration rates and high latency times lead to hazardous traffic behaviors. \n\nActive attacks may include incorrect data, spoofing of data, retransmission of previous messages to obtain a valid system key, modification of information about the data in question, or denial of service to prevent the transmission of data on a server where it is vital [32]. For instance, failures or interference with GPS signals could lead to drivers or assisted driving systems receiving incorrect information, resulting in erroneous judgments. Ghanavati discovered that fine-tuning the speeds between vehicles or exercising spatial control among them can result in traffic congestion and shockwaves of traffic flows [110]. Using a collaborative intelligent driver drive model, Wang illustrates the adverse effects of different cyber-attacks on connected autonomous driving, such as delays, sudden braking, and destruction of safety distances [111]. "}
{"doc236": "The capacity of interconnected autonomous vehicles to manage driving via real-time data transfer and sensing mechanisms significantly diminishes traffic conflicts and elevates the overall safety of traffic flow. This underscores their substantial influence on the safety of hybrid traffic configurations [56,93,112,113]. Hou proposed that an increase in MPR enhances the overall traffic performance in terms of safety for both multiple vehicles and individual vehicles, especially demonstrating a more pronounced improvement in safety performance with increased CAV penetration rates under adverse weather conditions [56]. Papadoulis et al. developed CAV decision control algorithms to explore CAV safety performance, revealing a significant positive effect of CAVs on traffic safety even at lower penetration rates [114]. Karbasi and O'Hern, utilizing the urban mobility simulator (SUMO) for traffic simulation, investigated the impact of CAVs on road safety, demonstrating that real CAVs potentially reduce the number of traffic conflicts and collisions, with vehicles equipped with collision avoidance systems offering additional safety benefits [115]. Ye and Yamamoto discovered that an increase in MPR contributes to the enhancement of safety in mixed traffic flows [115]. \n\n## 4.3. Environmental Impacts Of Connected Self-Driving Cars\n\nAccording to UN-Habitat in the newly released State of the World's Cities Report 2022, urbanization has always been an unstoppable world trend, and although the COVID-19 pandemic that erupted in late 2019 has temporarily put some obstacles in the way of urban development, urbanization is poised for a resurgence, as estimates indicate a rise of 2.2 billion in the global urban population by 2050, accounting for 68% of the total world population [116]. The inevitable result of the development of urbanization is the problem of inter-city and urban-rural road traffic, which in turn affects the sustainable development of the environment. Unsuitable modes of transport development will greatly undermine the living environment and well-being of human beings, such as the increasing urban congestion, traffic accidents and energy waste in recent years. Although energy emissions and losses are not central to the design and manufacture of CAVs, the development of CAVs has had a significant impact on energy emissions and environmental friendliness. In the course of research on urban transportation, many researchers have found that connected self-driving cars can effectively respond to this problem. "}
{"doc237": "CAV is not only a new kind of traffic unit, but also an optimization tool to improve traffic operation by suppressing or even eliminating the negative impacts of traffic oscillations, and at the same time, it holds the potential to significantly reduce greenhouse effect [117]. The combination of CAV's communication mechanism and autonomous driving technology can effectively reduce the instability of the traffic flow, create enough buffer time, and improve the traffic efficiency [81,118], which was also verified by Wang M and Milanes et al. through field experiments [119,120]. Qu and Yu et al. created a reinforcement learning-driven model for car-following, this model focuses on the present driving state, enhancing human driver behavior and ensuring precise vehicle control to minimize energy usage and diminish greenhouse effect. The trained model demonstrates increased capability in mitigating the impact of abrupt traffic disruptions when controlling the CAV, resulting in enhanced traffic flow efficiency and a consequent decline in energy usage [117]. \n\nScholars have highlighted the varying environmental and energy emission impacts of CAVs, with both positive and negative effects noted [121,122]. Simon and Alexander-Kearns contend that the outcomes hinge on different policy approaches [123,124]. Greenblatt and Shaheen stated that the overall impact of autonomous driving and on-demand mobility on energy and the environment could be positive, but these effects may vary based on policy directions [125]. Research by Wadud et al. [121] indicates that enhancing eco-driving, traffic coordination, lightweighting risk reduction, size adjustments based on occupancy, carpooling promotion, and reduced emphasis on vehicle performance all contribute to enhanced energy efficiency. Nonetheless, the identical study posits that the escalated incorporation of CAVs, propelled by reduced travel expenses, a broadening user base (comprising youth, seniors, and individuals with disabilities), increased highway velocities, and supplementary vehicle functionalities, could markedly elevate the energy impact of vehicle automation. \n\nExpanding on this foundation, some scholars have further explored the potential energy-saving benefits of networked automated driving grounded in motion principles and optimal control theory. They argue that automation enables vehicles to anticipate road conditions accurately and adjust their driving strategies, resulting in energy savings [41]. In other words, Cooperative driving enhances vehicle energy efficiency through coordinated interactions. The environmental effects of connected and self-driving automobiles were explored using the CMEM model, which demonstrated that increasing MPR of connected cars had a positive impact on reducing emissions and traffic [126]. "}
{"doc238": "Furthermore, scholars have also focused on how intersection traffic lights influence the depletion of resources. They have proposed various methods to investigate trajectory-smoothing strategies for single vehicles [127,128], multiple vehicles [129\u2013131], and platoons of vehicles [132,133] at intersections, aiming to reduce energy consumption. For instance, He et al. devised an optimal control model to offer eco-driving advice for Heterogeneous traffic comprised of electric cars and gasoline cars [133]. Building on these studies, Han et al. proposed the PTO-GFC, a trajectory optimization method that considers all vehicles within a platoon and extends to multiple platoons. This method aims to reduce energy emissions of CAVs fleets driving through signal-controlled junctions, demonstrating the significant influence of CAV in enhancing transportation efficiency and mitigating adverse impacts of environment [134]. \n\nHowever, it's crucial to note that the current focus on CAV and AV emissions primarily centers on their short-term effects, and the long-term net implications on fuel consumption remains uncertain. \n\n## 5. **Policy Recommendations Of Cav**"}
{"doc239": "AVs and CAVs constitute a dynamic and emerging field. Currently, studies related to connected autonomous driving vehicles primarily concentrate on automation technology [135]. Starting from 2015, there has been a progressive pivot towards non-technical facets, such as governance and the sustainable advancement of vehicle automation. A central concern is finding the optimal balance between deploying connected autonomous vehicles and realizing their societal benefits [136]. \n\nWhile some countries initially approached CAV development with caution and observation, the majority have now begun to respond to the inevitable wave of CAV development and the foreseeable impacts. They are addressing various issues and conflicts that arise during this process [137]. Planning and regulation by the public sector have become indispensable. While extensive research underscores the substantial influence of CAVs on traffic dynamics, road security, and environmental factors, it's important to note that this doesn't advocate for a laissez-faire approach, as it could yield further adverse repercussions [138]. A requisite is a coherent, succinct policy that ensures mutual benefits, including favorable socio-economic outcomes while duly addressing public apprehensions. The following table shows the current policies and regulations on CAV in major countries: \nBased on the contents of policy documents, it's evident that various countries have released publications advocating the development of their respective autonomous driving vehicle industries. These publications encompass visions, plans, legal frameworks, and regulatory measures aimed at fostering the advancement of autonomous driving. For instance, these initiatives involve deploying L4level autonomous driving vehicles, expanding areas for testing and operating a larger number of autonomous vehicles, and introducing comprehensive legal frameworks to oversee and regulate the operation of autonomous driving vehicles. However, owing to varying levels of development among countries, these policies exhibit differing degrees of preference and emphasis. \n\nThe efficiency of traffic flow has historically not been the responsibility of automotive manufacturers whose primary aim is profitmaking; rather, achieving traffic efficiency falls under the purview of governments and operators [143]. However, with increased automation, automotive companies also need to consider the objectives of autonomous driving systems [144]. Presently, there exist regulations that demand stability and traffic flow efficiency for CAVs [145]. Nonetheless, as evidenced in the preceding overview, the confirmed impact of CAVs on traffic efficiency necessitates policymakers' attention. Integrating traffic efficiency into policy guidance is crucial, encouraging innovation while maximizing the positive impact of CAVs. Without policy intervention, manufacturers might lean toward designing products more inclined to attract customers rather than optimizing network performance [146]. Apart from constraints placed on automotive manufacturers, policymakers should also prioritize factors affecting CAVs implication on the efficiency of hybrid traffic flows, such as CAVs proliferation, dedicated lane setups, and considerations for integrating them with shared mobility options [47]. "}
{"doc240": "Currently, numerous studies have explored the influence of CAVs on safety and stability of hybrid traffic flows, with much of the research focusing on the technological advancements of CAVs and infrastructure development. Therefore, the progress in technology and infrastructure upgrades are crucial for enhancing the safety and stability of mixed traffic flows, the government should proactively take measures to regulate the adoption of new technologies like AVs, with a particular focus on areas such as testing and deployment of CAVs, network security and privacy, liability and insurance, environmental monitoring, and more. Meanwhile, establishing stringent safety and security standards [147], focusing on data encryption, preventing network attacks, and real-time threat detection systems, as well as defining clear responsible entities and penalty criteria, are crucial. \n\nPolicymakers should prioritize exploring energy-efficient, environmentally-friendly, and sustainable strategies for the deployment of CAVs concerning their environmental impact. Emphasizing the interconnectedness of CAVs' environmental effects with other relevant impacts is crucial in identifying a balanced beneficial point within their network of effects. Although there may be benefits to autonomous vehicles' effects on pollution and energy economy, it is yet unclear how to balance these short- and long-term effects \n[144]. Therefore, the establishment of a continuous framework for evaluating the long-term impacts of CAVs on energy usage and exhaust emission is crucial. Regular policy updates based on scientific research findings and technological advancements are necessary to explore the interactions between their short-term and long-term benefits. \n\nFuture research can delve deeper into societal awareness and acceptance of CAVs, as well as their effects on public health, environmental sustainability, and the advancement of smart cities [136]. Understanding the perspectives of pedestrians and cyclists in automated driving environments is crucial as they fall under vulnerable road users. Their views are integral to the development and application of CAVs. Positive interactions with automated driving technology can influence their perception of its safety and acceptance. Hence, governments should facilitate constructive engagements between these groups and automated driving [148], enhancing their acceptance of this technology. Conducting comprehensive studies on CAVs from interdisciplinary perspectives will facilitate both horizontal and vertical analyses of their overall impact. "}
{"doc241": "## 6. **Future Research Directions**\n\nThe realm of connectivity and autonomous driving is no longer an unattainable fantasy but is instead rapidly advancing at an unpredictable pace. CAVs rely on a variety of software and hardware technologies to achieve extensive perception, intercommunication, and driver assistance. They alleviate traffic congestion, reduce traffic accidents, lower energy emissions, enhance environmental friendliness, and have the potential to alter future transportation patterns and people's modes of travel [121]. However, achieving widespread adoption of connected autonomous driving and reaching high penetration rates still requires significant investments in technology and funding, as well as strategic government planning. Currently, there are still substantial obstacles to overcome in this regard. \n\nWhen studying the implications of CAVs on the efficiency of hybrid traffic flows, expanding the control framework becomes imperative for further investigating and optimizing the intricate characteristics of mixed traffic flows. Emphasis should be placed on scrutinizing the predictive processes of advanced supervised machine learning algorithms [49]. Beyond examining singular subsets of CAV vehicle control, leveraging multimodal technologies and control architectures [73] integrating GPS, LiDAR, cameras, V2X, etc., \nwithin the research framework becomes essential. This integration counters potential omissions and failure risks from singular information sources, enabling efficient CAV driving and better adaptation to the complexities inherent in heterogeneous traffic flows. "}
{"doc242": "Given the susceptibility of CAV communications to disruptions, attention must be directed towards vehicle control technologies in scenarios involving network attacks, communication failures, and human-induced operations. Integrating real-world elements such as noise, signal interference, adverse weather, among others, into the control framework is vital, facilitating the development of a simulation environment conducive to learning and modeling. \n\nIt is essential to prioritize safety and stability during the transitional phase from HVs to CAVs within mixed traffic flow. This involves investigating the types of network attacks that target connected vehicles, understanding their potential impacts on traffic safety, assessing the inherent safety risks associated with CAVs, and analyzing the road implications resulting from their interactions with HVs. Furthermore, the influence of vehicle automation on emissions and fuel efficiency has been thoroughly investigated. Nonetheless, further testing is needed to determine the extent of its impact under various automation levels and penetration rates. As discussed earlier, forthcoming research endeavors may focus on exploring the lasting implications of autonomous vehicles on energy usage and emissions, thereby evaluating the balance between the immediate and enduring benefits of autonomous vehicles concerning energy. \n\nA thorough evaluation of the economic, public health, and societal effects of CAVs is still lacking in the research, in addition to the four areas covered in this article. For instance, there is a shortage of thorough exploration regarding the potential effects of deploying CAVs on the traditional automotive industry and the varying impacts on developed and developing countries. Furthermore, the implications of CAVs on public health presents a novel and noteworthy area of study. It prompts questions about how vehicle automation will influence human physical activity levels and the potential associated public health issues. "}
{"doc243": "The public's perception of CAV technology is crucial [149]. It significantly influences the adoption of innovative technologies such as CAV and potential societal benefits they can bring [150]. Thus, it is imperative to examine whether the public, especially disadvantaged groups, will benefits economically and socially from the development of connected autonomous vehicles. For instance, Xing et al. analyzed Pittsburgh BikePGH survey data from 2017 and 2019, revealing an increase in positive interactions between vulnerable road users and autonomous vehicles, which can positively affect their perceived safety and acceptance of this technology. Hence, government support of positive interactions between these groups and AVs is crucial to enhance their acceptance of autonomous driving technologies [148]. Conducting a more comprehensive and multi-dimensional study of CAVs can further enhance our understanding of the economic impacts and societal benefits associated with their development, ultimately promoting their sustainable and health-conscious growth. \n\n## 7. **Conclusions**\n\nThe remarkable advancement of CAV technology has prompted numerous automobile manufacturers and internet technology companies to seize this new momentum. Governments worldwide are closely monitoring these cutting-edge developments, ensuring support for the progress of their own nation's connected autonomous driving initiatives. This study emphasizes various effects of CAVs on mixed traffic flows, highlighting the fundamental problem of traffic efficiency and congestion. It could be asserted that enhanced efficiency of hybrid traffic flow due to CAVs has multifaceted implications, such as alleviating congestion, boosting driving speeds, increasing traffic capacity, enhancing flow, and reducing pollution emissions. Building upon this foundation, the implications of CAVs on the environment, safety, and stability of hybrid traffic flows are also reviewed in this study. Traffic efficiency, stability, safety, and environment impact are intricately interlinked, necessitating careful attention to their interconnectedness when formulating policy recommendations. Neglecting any aspect might lead to suboptimal policy outcomes. Finally, the paper distills the comprehensive findings and suggests potential avenues for future research. We hope this study makes a modest contribution to understanding the systemic impacts of CAVs. "}
{"doc244": "[32] David Elliott, Keen Walter, Lei Miao, Recent advances in connected and automated vehicles, Journal of Traffic and Transportation Engineering 6 (2) (2019) \n109\u2013131 (English edition). \n\n[33] Sherali Zeadally, Ray Hunt, Yuh-Shyan Chen, Angela Irwin, Aamir Hassan, Vehicular ad hoc networks (VANETS): status, results, and challenges, Telecommunication Systems 50 (2012) 217\u2013241. \n\n[34] Kenney, John B, Dedicated short-range communications (DSRC) standards in the United States, *Proceedings of the IEEE*, 99 (7) (2011) 1162-1182. [35] Chung-Ming Huang, Shih-Yang Lin, Cooperative vehicle collision warning system using the vector-based approach with dedicated short range communication data transmission, IET intelligent Transport Systems, 8 (2) (2014) 124\u2013134. "}
{"doc245": "[51] Jiahe Zhang, Yongsheng Qian, Junwei Zeng, Xuting Wei, Haijun Li, Hybrid characteristics of heterogeneous traffic flow mixed with electric vehicles considering the amplitude of acceleration and deceleration, Physica A: Statistical Mechanics and its Applications 614 (2023) 128556. \n\n[52] Junwei Zeng, Yongsheng Qian, Ziwen Lv, Fan Yin, Leipeng Zhu, Yongzhi Zhang, Dejie Xu, Expressway traffic flow under the combined bottleneck of accident and on-ramp in framework of Kerner's three-phase traffic theory, Physica A: Statistical Mechanics and its Applications 574 (2021) 125918. \n\n[53] Junwei Zeng, Yongsheng Qian, Fan Yin, Leipeng Zhu, Dejie Xu, A multi-value cellular automata model for multi-lane traffic flow under lagrange coordinate, Computational and Mathematical Organization Theory (2022) 1\u201315. "}
{"doc246": "[60] Arian Houshmand, Salomon \u00b4 Wollenstein-Betech, and Christos G. Cassandras, The penetration rate effect of connected and automated vehicles in mixed traffic routing, in 2019 IEEE Intelligent Transportation Systems Conference (ITSC), pp. 1755-1760. IEEE, 2019. \n\n[61] Yibing Wang, Long Wang, Jingqiu Guo, Papamichail Ioannis, Markos Papageorgiou, Fei-Yue Wang, Robert Bertini, Wei Hua, Qinmin Yang, Ego-efficient lane changes of connected and automated vehicles with impacts on traffic flow, Transportation Research Part C: Emerging Technologies 138, 138 (2022) 103478. \n\n[62] Hongyan Guo, Jun Liu, Qikun Dai, Hong Chen, Yulei Wang, Wanzhong Zhao, A distributed adaptive triple-step nonlinear control for a connected automated vehicle platoon with dynamic uncertainty, IEEE Internet of Things Journal 7 (5) (2020) 3861\u20133871. "}
{"doc247": "[72] Simon Ulbrich and Markus Maurer, Towards tactical lane change behavior planning for automated vehicles, in 2015 IEEE 18th International Conference on Intelligent Transportation Systems, pp. 989-995. IEEE, 2015. \n\n[73] Wei Liu, Min Hua, Zhiyun Deng, Meng Zonglin, Yanjun Huang, Chuan Hu, Shunhui Song, et al., A systematic survey of control techniques and applications in connected and automated vehicles, IEEE Internet of Things Journal (2023). \n\n[74] Solmaz Razmi Rad, Haneen Farah, Henk Taale, Bart van Arem, Serge P. Hoogendoorn, Design and operation of dedicated lanes for connected and automated vehicles on motorways: A conceptual framework and research agenda, Transportation Research Part C: Emerging Technologies 117 (2020) 102664. "}
{"doc248": "[84] Jorge A. Laval and Carlos F. Daganzo, Lane-changing in traffic streams, *Transportation Research Part B: Methodological*, 40 (3) (2006) 251-264. \n\n[85] Zuduo Zheng, Soyoung Ahn, Danjue Chen, Jorge Laval, Applications of wavelet transform for analysis of freeway traffic: Bottlenecks, transient traffic, and traffic oscillations, Transportation Research Part B: Methodological 45 (2) (2011) 372\u2013384. \n\n[86] Robert L. Bertini, Monica T. Leal, Empirical study of traffic features at a freeway lane drop, Journal of Transportation Engineering 131 (6) (2005) 397\u2013407. [87] Wen-Long Jin, Yu Zhang, Paramics simulation of periodic oscillations caused by network geometry, Transportation Research Record 1934 (1) (2005) 188\u2013196. [88] H.B. Zhu, Y.J. Zhou, W.J. Wu, Modeling traffic flow mixed with automated vehicles considering drivers' character difference, Physica A: Statistical Mechanics and its Applications 549 (2020) 124337. "}
{"doc249": "[122] Austin Brown, Jeffrey Gonder, Brittany Repac, An analysis of possible energy impacts of automated vehicles, Road Vehicle Automation (2014) 137\u2013153. [123] Karl Simon, Jeff Alson, Lisa Snapp, Aaron Hula. Can transportation emission reductions be achieved autonomously?, 2015, pp. 13910\u201313911. \n\n[124] Myriam Alexander-Kearns, Miranda Peterson, A. Cassady. The impact of vehicle automation on carbon emissions, Center for American Progress, 2016. [125] Jeffery B. Greenblatt, Susan Shaheen, Automated vehicles, on-demand mobility, and environmental impacts, Current Sustainable/Renewable Energy Reports 2 \n(2015) 74\u201381. \n\n[126] Arash Olia, Hossam Abdelgawad, Baher Abdulhai, and Saiedeh N. Razavi, Assessing the potential impacts of connected vehicles: mobility, environmental, and safety perspectives, *Journal of Intelligent Transportation Systems*, 20 (3) (2016) 229-243. "}
{"doc250": "[127] Handong Yao, Jianxun Cui, Xiaopeng Li, Yu Wang, Shi An, A trajectory smoothing method at signalized intersection based on individualized variable speed limits with location optimization, Transportation Research Part D: Transport and Environment 62 (2018) 456\u2013473. \n\n[128] Huifu Jiang, Jia Hu, An Shi, Meng Wang, Byungkyu Brian Park, Eco approaching at an isolated signalized intersection under partially connected and automated vehicles environment, Transportation Research Part C: Emerging Technologies 79 (2017) 290\u2013307. \n\n[129] Fang Zhou, Xiaopeng Li, Jiaqi Ma, Parsimonious shooting heuristic for trajectory design of connected automated traffic part I: Theoretical analysis with generalized time geography, Transportation Research Part B: Methodological 95 (2017) 394\u2013420. "}
{"doc251": "[143] Iman Mahdinia, Amin Mohammadnazar, Ramin Arvin, and Asad J. Khattak, Integration of automated vehicles in mixed traffic: Evaluating changes in performance of following human-driven vehicles, Accident Analysis & *Prevention*, 152 (2021) 106006. \n\n[144] Elina Aittoniemi, Evidence on impacts of automated vehicles on traffic flow efficiency and emissions: Systematic review, IET Intelligent Transport Systems 16 \n(10) (2022) 1306\u20131327. \n\n[145] Biagio Ciuffo, Konstantinos Mattas, Michail Makridis, Giovanni Albano, Aikaterini Anesiadou, Yinglong He, Szil\u00b4ard Josvai, et al., Requiem on the positive effects of commercial adaptive cruise control on motorway traffic and recommendations for future automated driving systems, Transportation Research Part C: \nEmerging Technologies 130 (2021) 103305. "}
{"doc252": "![0_image_1.png](0_image_1.png)\n\n![0_image_2.png](0_image_2.png) Vehicle-to-Everything (C-V2X) technology: Current trends, use cases, emerging technologies, standardization bodies, industry analytics and future directions Dhinesh Kumar R a, Rammohan A b,\u2217\na School of Electronics Engineering, Vellore Institute of Technology, Vellore, 632014, India b Automotive Research Centre, Vellore Institute of Technology, Vellore, 632014, *India* a r t i c l e i n f o a b s t r a c t Article *history:*\nReceived 25 April 2023 Received in revised form 10 June 2023 Accepted 30 June 2023 Available online 11 July 2023 Keywords:\n5GS AI\nAutonomous driving C-V2X\nEdge AI\nSDN\nThe emergence of Cellular Vehicle-to-Everything communication (C-V2X) has brought significant advancements in the field of Intelligent Transportation Systems. This review presents an in-depth analysis of the benefits offered by C-V2X technology, such as improved safety, enhanced traffic efficiency, and reduced environmental impact. The study offers an overview of state-of-the-art C-V2X architectures, protocols, use cases, emerging technologies, standardization bodies, and growth of the automotive industry verticals in C-V2X field. Additionally, this paper explores the visionary research on the Enhancing V2X Communication through Programmable Edge and Cloud Intelligence to enhance the traditional CV2X architectures. It also provides insights into the opportunities and evolving infrastructure's refereed from 3GPP and ETSI standards for spectrum management, traffic management, policy handling, safety, and sustainability. Furthermore, this paper sheds light into the potential research challenges that is being raised in the C-V2X technology and also emphasizes the potential solutions that is being addressed by researchers. Additionally, this study also gives the glimpse towards the need for further research and standardization to ensure its interoperability with other technologies.\n\n\u00a9 2023 Elsevier Inc. All rights reserved."}
{"doc253": "## 1. **Introduction**\n\nCellular Vehicle-to-Everything (C-V2X) is a wireless communication technology that enables vehicles to communicate with each other, with pedestrians, and with the surrounding infrastructure using the cellular network. C-V2X is designed to improve road safety, reduce traffic congestion, and enhance the efficiency of the transportation system. The foundation of C-V2X technology is based on the heterogeneous network environment that utilizes Long-Term Evolution (LTE) and 5G cellular communication technologies [1], which are popular for high-speed data transfer\n[2,3]. The development and standardization of C-V2X technology is carried out by several organizations, mainly by the 3rd Generation Partnership Project (3GPP), the European Telecommunications Standards Institute (ETSI), the Institute of Electrical and Electronics Engineers (IEEE) and 5G Automotive Associations (5GAA). C-V2X is expected to play a critical role in the development of Intelli-\n* Corresponding author.\n\nE-mail *address:* rammohan.a@vit.ac.in (R. A)."}
{"doc254": "gent Transportation Systems (ITS) [4] and connected vehicles in the near future. Subsequent sections will delve into the pressing societal challenges that's confronting the transportation sector in the present scenario, and how C-V2X technology can offer solutions to these issues, contributing to the attainment of a sustainable society. The important abbreviations and their meanings are given in Table 1. 1.1. The state of transportation: problems and *possibilities* Roads are the core piece of infrastructure and important metric that supports vehicle's mobility and logistics. It forms the base for the social and economic growth by interconnecting cities, ports, airports, and countries. In recent years, the extensive growth of population and progress of urbanization, rapidly increases the ownership of vehicles in all the countries [5]. According to United Nations, it said that, 30% of the world's population lived in cities in 1950; as of today, the percentage has increased to 54%. The United Nations estimates that 66% of the world's population will live in cities by 2050 [6\u20138]. Some of the specific societal trends that will affect the future transportation, they are 1. New wave of urbanizahttps://doi.org/10.1016/j.vehcom.2023.100638 2214-2096/\u00a9 2023 Elsevier Inc. All rights reserved.\n\n![1_image_0.png](1_image_0.png)\n\n| Important abbreviations and their meanings. 3GPP 3rd Generation Partnership Project 5GAA 5G Automotive Association 5GS Fifth Generation Systems ADAS Advanced Driver Assistance Systems AI Artificial Intelligence AMF Access and Mobility Management Function AUSF Authentication Server Function BMSC Broadcast Multicast Service Center C-V2X Cellular based Vehicle to Everything Communications C-ITS Cooperative - Intelligent Transport Systems DL Deep Learning DSRC Dedicated Short Range Communication eMBB enhanced Mobile Broadband EPC/EPS Evolved Packet Core / Evolved Packet System ETSI European Telecommunication Standard Institute E-UTRA Evolved Universal Terrestrial Radio Access FCC Federal Communication Commission FDM Frequency Division Multiplexing FL Federated Learning FQDN Fully Qualified Domain Name GSMA Global System for Mobile Communications Association HetNet Heterogeneous Networks IEEE Institute of Electrical and Electronics Engineers ITS Intelligent Transportation System IVHS Intelligent Vehicle-Highway Systems ITU-R International Telecommunication Union - Radio communication LIDAR Light Detection and Ranging LTE Long Term Evolution MBMS Multimedia Broadcast Multicast Service MEC Mobile Edge Computing ML Machine Learning mm-wave Millimeter Wave NEF Network Exposure Function NRF Network Repository Function NSSF Network Slice Selection Function OEM Original Equipment Manufacturer O-RAN Open RAN PLMN Public Land Mobile Network RADAR Radio Detection and Ranging RSUs Roadside Units SDN Software Defined Networking SEPP Security Edge Protection Proxy SMF Session Management Function SME Small and Medium-sized Enterprises TDM Time Division Multiplexing UDM Unified Data Management USDOT United States Department of Transportation UPF User Plane Function URLLC Ultra Reliable Low-Latency Communications V2X Vehicle to Everything V2X AS V2X Application Server VUE Vehicular User Equipment VRU Vulnerable Road User WAVE Wireless Access in Vehicular Environment   | Fig. 1. Key components of ITS.   |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------|\n| Table 2 Roadmap of six evolutionary levels in Automotive industry as depicted by SAE. Level Evolution in Levels Actions 0 No Automation During the driving environment 1 Less Advanced Levels human driver has major controls of 2 Provides one or two warnings the vehicle and monitors the driving and momentary assistance environment constantly messages 3 Most Advanced Levels Vehicle monitors the driving 4 Supports dynamic driving environment continuously and take task and driverless settings in decisions adaptively certain situations 5 Complete Automation the development of Intelligent Vehicle-Highway Systems (IVHS) for better transportation management which was officially renamed as Intelligent Transportation System (ITS) in the year 1994 by the United States Department of Transportation (USDOT) to reflect a broader mission, including all parts of public transportation and intermodal connections [11]. ITS is defined as \"a system for solving variety of problem that road traffic faces through exchange of information between road, people, automobile and city\" [4] as shown in Fig. 1. The major objectives of ITS are to evaluate, develop, analyze and integrate advanced technologies in order to achieve efficiency, conserve energy, save time, enhanced safety measures, improve sustainability and contentment for driver, pedestrians, and other traffic groups [12\u201314]. So, with the help of ITS, we can transform the unorganized transportation environment into an intelligent and connected system. To achieve the intelligence and adaptive management, the International Society of Automotive Engineers (SAE) [15] has created a roadmap of six evolutionary levels, as depicted in the Table 2. Now, we may witness the business unfolding the fashion of self-driving automobiles in the current period. For example, various business brands like as Waymo, Tesla,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                  |"}
{"doc255": "the development of Intelligent Vehicle-Highway Systems (IVHS) for better transportation management which was officially renamed as Intelligent Transportation System (ITS) in the year 1994 by the United States Department of Transportation (USDOT) to reflect a broader mission, including all parts of public transportation and intermodal connections [11]. ITS is defined as \"a system for solving variety of problem that road traffic faces through exchange of information between road, people, automobile and city\" [4] as shown in Fig. 1. The major objectives of ITS are to evaluate, develop, analyze and integrate advanced technologies in order to achieve efficiency, conserve energy, save time, enhanced safety measures, improve sustainability and contentment for driver, pedestrians, and other traffic groups [12\u201314]. So, with the help of ITS, we can transform the unorganized transportation environment into an intelligent and connected system. To achieve the intelligence and adaptive management, the International Society of Automotive Engineers (SAE) [15] has created a roadmap of six evolutionary levels, as depicted in the Table 2. Now, we may witness the business unfolding the fashion of self-driving automobiles in the current period. For example, various business brands like as Waymo, Tesla, and other automotive companies are developing to usher in the growth of self-driving automobiles. Yet, to achieve the essence of Level 4 and 5 of vehicle automation is still an aspiration to many automotive organizations and researchers. Thus, the fundamental area to achieve the complete automation in transportation is exchanging the information with all entities on the road. In this context, with the introduction of Cooperative - Vehicle to Everything based, communication adds new life to ITS mission. We can have Vehicle-to-Vehicle (V2V), Vehicle-to-Pedestrian (V2P), Vehicle-toInfrastructure (V2I), and Vehicle-to-Network (V2N) communication, which makes mobility safer and more connected in LOS and NLOS circumstances [16]. 1.2. Technology *overview* tion, creating pressure on the existing transportation infrastructure. 2. Even more stringent emission policies and regulations framed by government. 3. High pressure on public transport and logistics/delivery services due to emergence of various business outlooks. 4.\n\nEfficient usage of live and open data traffic management.\n\nThus, the direct solution for addressing the alarming issue is by improving the infrastructure and by finding various methods to make the transportation smarter, which must be economically and environmentally sustainable. So, some of the expectations we do have for the transportation environment transformation in the phase of 2 to 5 years? are [9,10]. 1. Accident free transportation 2. Adaptive support system for higher traffic flow scenarios 3."}
{"doc256": "Higher vehicle utilization and 4. More efficient/greener transport (zero emission vehicles). With the rapid evolution in Information Technology (IT), sensors, geo-location and communication technologies lead to emergence of mind-boggling applications which given a pathway for deploying strategies in a very intelligent manner by understanding the surrounding environment, which lead to The two primary technologies that support V2X are 1.802.11p\n(DSRC) and 2.C-V2X, lets look into the details one by one; 1. 802.11p (DSRC): The original V2X communications utilize Wireless Local Area Network (WLAN) enables vehicles to exchange information with each other and with traffic infrastructure.\n\nThis technology facilitates direct communication between vehicles (V2V) as well as between vehicles and traffic infrastructure (V2I). The communication occurs when two V2X senders come within range, forming a vehicular ad-hoc network. This unique characteristic eliminates the need for dedicated communication infrastructure, ensuring reliable communication and safety in remote or sparsely populated areas. WLAN, which offers low latency, is highly suitable for V2X communication. It transmits specific message types such as Cooperative Awareness Messages (CAM), Basic Safety Messages (BSM), and Decentralized Environmental Notification Messages (DENM). Additionally, it supports the transmission of other messages related to roadside infrastructure, including Signal Phase and Timing Messages (SPAT), In Vehicle Information Messages (IVI), and Service Request Messages (SRM). These messages contain minimal data volume, optimizing efficiency and performance. The radio technology employed in V2X communication is part of the WLAN IEEE 802.11 family of standards. In the United States, it is referred to as Wireless Access in Vehicular Environments (WAVE), while in Europe, it is known as ITS-G5\n[17]. To enhance the direct communication mode, vehicles can also be equipped with traditional cellular communication technologies, enabling V2N (vehicle-to-network) based services. This extension, incorporating V2N capabilities, has been successfully implemented in Europe through the C-ITS platform umbrella [18]. But, the DSRC spectrum faces potential challenges in the current era due to various factors: 1. Spectrum Scarcity: The spectrum allocated for DSRC is limited and confined to the 5.9 GHz band. This limited spectrum availability poses challenges in accommodating the increasing demand for wireless communication in the transportation sector. As more ITS applications, connected vehicles, and stringent network requirement (as shown in the Table 4 referred from\n[19]) emerge, the existing DSRC spectrum may become congested, resulting in potential interference and degraded performance. 2.\n\nSpectrum Competition: The 5.9 GHz band is also used for other purposes, such as Wi-Fi services, which can lead to competition for spectrum resources. As Wi-Fi and other wireless technologies continue to proliferate, the DSRC spectrum may face challenges in ensuring reliable and interference-free communication for ITS\napplications the relative studies are done by the author [20]. Spectrum sharing and coexistence mechanisms are necessary to mitigate the potential conflicts between different wireless systems utilizing the same frequency band. 3. Technological Advancements:\nThe rapid advancements in wireless communication technologies, such as 5G and beyond, introduce new capabilities and requirements for ITS. These technologies offer higher data rates, ultra-low latency, massive device connectivity, and network slicing, enabling advanced applications and services in the transportation sector."}
{"doc257": "However, DSRC, being a legacy technology, may struggle to keep pace with the evolving connectivity demands and technological requirements of modern ITS systems.4. Regulatory Considerations:\nThe allocation and utilization of spectrum are subject to regulatory policies and decisions. Regulatory bodies may need to reassess and reallocate spectrum resources to accommodate the changing needs of ITS communication. The static allocation of the 5.9 GHz band for DSRC may not align with evolving wireless communication requirements, potentially hindering the adoption of newer and more efficient technologies, various prior studies are done to check the system level performance of DSRC, some of the studies are [21\u201324].\n\nTo address these challenges, the industry and researchers has been exploring alternatives such as Cellular Vehicle-to-Everything (CV2X) technology.\n\n2. C-V2X: C-V2X communication utilizes cellular networks, has emerged as an advanced version of Vehicle-to-Everything (V2X)\ntechnology that is based on WLAN. Its distinction from WLANbased V2X has prompted various industry organizations, including the 5G Automotive Association (5GAA), to advocate for C-V2X,\nemphasizing its advantages while overlooking its potential drawbacks [25]. Initially defined as Long-Term Evolution (LTE) in the 3rd Generation Partnership Project (3GPP) Release 14 [26], C-V2X is designed to operate in two main modes: Direct Communication\n(V2V, V2I) and Device-to-Network (V2N). Direct Communication relies on PC5 interface. The PC5 interface refers to the point where User Equipment (UE) can directly communicate with another UE\nthrough the direct channel, eliminating the need for communication with the base station. Proximity Service (ProSe) is the feature that governs the architecture of direct communication between UEs at a system architectural level. In 3GPP Radio Access Network (RAN) specifications, the term \"sidelink\" is used to describe direct communication over the PC5 interface. Moreover, C-V2X allows the C-V2X device to utilize the cellular network connection through the Uu interface, which represents the logical interface between the UE and the base station. This mode is commonly referred to as vehicle-to-network (V2N) communication. V2N is a unique use case specific to C-V2X and is not present in 802.11p-based V2X\nsince the latter exclusively supports direct communication. Other important advantage is C-V2X offers a more flexible and scalable solution that can overcome the spectrum scarcity challenges faced by DSRC. Some of the technical ways are 1. Shared Spectrum:\nC-V2X operates within the licensed spectrum allocated for cellular networks, typically in the 4G LTE or 5G frequency bands. By utilizing shared spectrum, C-V2X can leverage the existing cellular infrastructure, including base stations and network resources."}
{"doc258": "This eliminates the need for a dedicated spectrum allocation for V2X communication, making more efficient use of the available frequency resources [27]. 2. Dynamic Spectrum Allocation: Unlike DSRC, which relies on a dedicated frequency band (5.9 GHz) for V2X communication, C-V2X can dynamically allocate spectrum resources based on demand and network conditions. With dynamic spectrum allocation, C-V2X can adapt to changing communication needs and allocate resources as required, maximizing the utilization of available spectrum. 3. Coexistence with Cellular Services:\nC-V2X is designed to coexist and operate alongside the existing cellular services. It utilizes advanced radio resource management techniques to ensure efficient sharing of the spectrum with other cellular users. By leveraging the infrastructure and spectrum already deployed for cellular networks, C-V2X can make effective use of the available resources without causing interference or congestion [28]. 4. Evolution to 5G: In 3GPP Release 15, V2X functionalities were expanded to include support for 5G. C-V2X encompasses both direct communication between vehicles (V2V, V2I) and traditional cellular-network-based communication (V2N), providing a migration path to 5G-based systems and services. With the deployment of 5G networks, additional spectrum is made available as studied in the paper [29], enabling C-V2X to benefit from the expanded frequency resources. This evolution to 5G opens up new opportunities for enhanced V2X communication and supports the growing demand for bandwidth-intensive applications in the transportation sector. Table 3 provides the comparison of the two primary technologies such as DSRC and C-V2X in terms of various physical layer parameters as referred from [30].\n\n## 1.3. Research Contributions\n\nThis article provides an overview of the current research progress on the emerging communication architectures for C-V2X."}
{"doc259": "We will analyze the latest advancements and developments in 3GPP, ETSI standards in terms of C-V2X and explore various emerging technologies, strategies, requirements, use cases, and collabo-\n\n| Comparison of DSRC and C-V2X technology. Parameters DSRC   | C-V2X                                             |                                                                           |\n|------------------------------------------------------------|---------------------------------------------------|---------------------------------------------------------------------------|\n| Origin technology                                          | 802.11p WiFi                                      | Rel.14/Rel.15, LTE Uplink                                                 |\n| Modulation                                                 | Orthogonal Frequency Division Multiplexing (OFDM) | Single Carrier - Frequency Division Multiplexing (SC-FDM)                 |\n| Transmission Time                                          | 0.4 ms                                            | 1 ms                                                                      |\n| Concurrent transmissions                                   | No                                                | Yes                                                                       |\n| Symbol Duration                                            | 8 \u03bcS                                              | 71 \u03bcS                                                                     |\n| Coding Schemes                                             | Convolution code                                  | Turbo code (High processing gain for long communication range)            |\n| Transmission scheduling                                    | Carrier Sense Multiple                            | Semi-persistent sensing                                                   |\n| Access (CSMA)                                              |                                                   |                                                                           |\n| Retransmission                                             | None                                              | Yes. It will overcome network collisions and increase communication range |\n| Time Synchronization                                       | Asynchronous                                      | Synchronous                                                               |\n\nrations between standardization bodies and industry stakeholders."}
{"doc260": "Additionally, we will discuss on future research challenges and directions. As far as current knowledge permits, this study represents the first comprehensive analysis that provides a holistic view of the potential future of C-V2X. The study aims to present a complete picture of the possibilities and potential applications of C-V2X technology, drawing upon existing research and industry insights to inform its analysis. The findings of this study contribute to the ongoing research of C-V2X for the future of transportation, and provide valuable insights for academicians and researchers.\n\n## 1.4. Organization Of The Paper\n\nThe paper is structured as follows: In section 2, we will discuss the C-V2X societal implications in terms of growth of C-V2X\nresearch. Section 3 delves into the technical evolution of C-V2X,\nand Section 4 projects the V2X use cases in detail by highlighting advancements made by 3GPP, 5GAA and ITS. Section 5, provides a detailed discussion on LTE and 5GS-based C-V2X architectures in accordance with 3GPP and ETSI releases. Section 6 focuses on emerging technologies that can enhance C-V2X performance. Section 7 showcases the standardization bodies working on C-V2X\ndevelopment. Section 8 presents industry analytics in terms of CV2X development. In section 9, we project a comprehensive view of the current research challenges faced by C-V2X, along with recommendations for steering research direction towards future scope and realizing C-V2X's potential. Finally, section 10 concludes by suggesting the ongoing trends and research in C-V2X and also highlights the growth and the improvements in C-V2X industry verticals."}
{"doc261": "## 2. C-V2X Societal Implications In Terms Of Growth Of **C-V2X** Research\n\nHere are some key potential insights on C-V2X societal implications, some studies are done in [31\u201333]: 1. Improved Road Safety:\nOne of the primary motivations for C-V2X research is to enhance road safety. By allowing vehicles to exchange real-time information, such as location, speed, and status, C-V2X enables advanced safety applications like collision avoidance, intersection management, and emergency vehicle warning systems. This technology has the potential to greatly reduce accidents, injuries, and fatalities on the road. 2. Increased Traffic Efficiency: C-V2X technology can significantly improve traffic flow and efficiency. By enabling vehicles to communicate with traffic infrastructure, traffic signals, and other vehicles, C-V2X can optimize traffic patterns, reduce congestion, and enhance overall transportation system performance.\n\nThis can lead to shorter travel times, reduced fuel consumption, and improved air quality in urban areas. 3. Enhanced Autonomous Driving: C-V2X plays a crucial role in the development of autonomous vehicles. By providing vehicles with real-time situational awareness through communication with other road users and infrastructure, C-V2X can enhance the decision-making capabilities of autonomous vehicles. This application can reduce the travel delay and more importantly it will bring sustainable transportation."}
{"doc262": "4. Integration with Smart Cities: C-V2X research aligns with the broader concept of smart cities, where various technologies are integrated to create more sustainable and efficient urban environments. C-V2X can be integrated with intelligent transportation systems, smart infrastructure, and other urban mobility solutions to enable seamless communication and coordination. This integration can improve traffic management, public transportation, emergency response, and overall quality of life in cities. Not only that, C-V2X\ncan also bring quantitative benefits to the society by improving the economic status. Table 5 presents the scenarios and net benefits from the perspective of the European Commission for ITS. The European Union has identified four different scenarios for evaluating the cost and benefits associated with various volumes and timescales of V2X adoption [34,35].\n\n## 3. Revolutionizing Vehicle Connectivity: 3Gpp'S Journey **Towards** Advanced C-V2X **Communication**\n\nIn this section, we will explore some of the most promising enhancements to C-V2X that are currently being developed by 3GPP,\nincluding Release 14, Release 15, Release 16, and Release 17 [36]."}
{"doc263": "These updates are expected to significantly improve the performance and functionality of C-V2X technology.\n\nLTE-based Vehicle-to-Everything (V2X) communication technology that is backed by Evolved Packet Core (EPC) to improve communication scalability and reliability. The V2X system is designed to deliver three distinct services: Road Safety, Traffic Efficiency, and Infotainment, all aimed at enhancing safety, reducing traffic congestion, and providing real-time information to drivers [37].\n\nV2X system offers multiple communication interfaces, including PC5 (Side link) and LTE Uu (Cellular Uplink/Downlink). The system supports four modes of message delivery, namely Unicast Delivery, Multimedia Broadcast Multicast Service (MBMS) Delivery, Localized MBMS Delivery, and Simultaneous LTE Uu, PC5 Delivery. To ensure seamless communication between vehicles and infrastructure, LTE\nV2X system has been designed for deployment in two configurations: In-Coverage (LTE Uu, PC5) and Out-of-Coverage (Uu). Where the In-Coverage (LTE Uu, PC5) allows for continuous communication between vehicles and infrastructure within cellular coverage, while the Out-of-Coverage (Uu) provides reliable communication even in areas outside cellular coverage [38,39]. In this release 14, V2X system also offers support for V2X control function, enabling secure and authorized access to V2X services. Additionally, the system incorporates IEEE 1609.2 security standards for application layer security, providing authentication, privacy, and message integrity for V2X communications."}
{"doc264": "| V2X use cases and its stringent network requirements. Scenario Communication Type                                                                              | Data Rate                                                                                                                                                                                                                                                                                                                | E2E Latency         | Reliability   | Required Communication Range (in meters)   |            |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------|---------------|--------------------------------------------|------------|\n| Remote Driving                                                                                                                                                 | V2N (Information Sharing)                                                                                                                                                                                                                                                                                                | UL/DL:25/1 Mbps     | <5 ms         | >99.999%                                   | >1000      |\n| Advanced Driving (Cooperative                                                                                                                                  | V2V, V2I, V2N                                                                                                                                                                                                                                                                                                            | 10 Mbps             | <10 ms        | >99.99%                                    | >360 - 700 |\n| Collision Avoidance) Autonomous Driving                                                                                                                        | V2V (Information Sharing)                                                                                                                                                                                                                                                                                                | 53 Mbps             | <100 ms       | >(90 - 99.99) %                            | >360 - 700 |\n| Autonomous Driving                                                                                                                                             | V2I, V2N (Information Sharing)                                                                                                                                                                                                                                                                                           | 50 Mbps             | <100 ms       | >(90 - 99.99) %                            | >500       |\n| Video Sharing                                                                                                                                                  | V2V                                                                                                                                                                                                                                                                                                                      | 10 - 700 Mbps       | <10 - 50 ms   | >(90 - 99.99) %                            | 100 - 400  |\n| Video Sharing                                                                                                                                                  | V2N                                                                                                                                                                                                                                                                                                                      | UL: 10 Mbps         | <10 - 50 ms   | >(90 - 99.99) %                            | 100 - 400  |\n| Sensor Information's                                                                                                                                           | V2V, V2I, V2N                                                                                                                                                                                                                                                                                                            | 10 - 1000 Mbps      | <3 - 100 ms   | >(95 - 99.99) %                            | 50 - 1000  |\n| Cooperative Awareness                                                                                                                                          | V2V, V2I                                                                                                                                                                                                                                                                                                                 | 10Mbps              | <100 ms - 1 s | >(95 - 99.99) %                            | >500       |\n| Coordinated Intersection Safety                                                                                                                                | V2I, V2N                                                                                                                                                                                                                                                                                                                 | UL/DL: 25 / 50 Mbps | <5 ms         | >99.99%                                    | >500       |\n| Emergency Trajectory Alignment                                                                                                                                 | V2V                                                                                                                                                                                                                                                                                                                      | 30Mbps              | <3 ms         | >99.99%                                    | >500       |\n| Platooning (Cooperative Driving)                                                                                                                               | V2V                                                                                                                                                                                                                                                                                                                      | 65Mbps              | <10-25 ms     | >(90 - 99.99) %                            | >80 - 150  |\n| Platooning                                                                                                                                                     | V2I, V2N (Information Sharing)                                                                                                                                                                                                                                                                                           | 50Mbps              | <500 ms       | 90 - 99.99%                                | >180 - 350 |\n| Table 5 Scenarios and net benefits from the perspective of the European Commission for ITS. Scenario Expectations                                              | Net Benefits in 2035                                                                                                                                                                                                                                                                                                     |                     |               |                                            |            |\n| Base case                                                                                                                                                      | - In the absence of regulatory measures, automotive OEMs determines the adoption and timing of                                                                                                                                                                                                                           | EUR 39 billion      |               |                                            |            |\n| deployment starting from premium vehicles to cheaper vehicles to cover greater number of vehicle models.                                                       |                                                                                                                                                                                                                                                                                                                          |                     |               |                                            |            |\n| 2020 European Commission (EC) mandate on V2V/V2I                                                                                                               | - Using IEEE 802.11p technology for V2V and V2I, the European Commission mandates all new vehicle                                                                                                                                                                                                                        | EUR 20 billion      |               |                                            |            |\n| models to implement the \"Day 1\" and \"Day 1.5\" services starting from 2020. - Day 1 services focuses on exchanging information, enhancing foresighted driving. Identified C-ITS Day 1 applications include: - Hazardous Location Notifications (emergency brake light, emergency vehicle approaching, pre-warning of traffic jam and road works, information of weather situations, slow and stationary vehicle) - Applications related to signage (in vehicle signs, probe vehicle data, in vehicle speed restriction, signal violation/intersection safety, traffic signal priority, green light optimal speed advisory, shock wave damping) - Day 1.5 improves service quality and share perception and awareness information. Identified C-ITS Day 2 applications include: - (information on fueling and charging stations, vulnerable road user protection, park and ride information, cooperative navigation, smart routing and traffic information, on street and off-street parking management) - A substantial roll-out of 5.9 GHz roadside equipment is required for IEEE 802.11p V2I provision (RSUs)                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                          |                     |               |                                            |            |\n| 2023 European Commission mandate on V2V/V2I                                                                                                                    | - The European Commission has mandated that all new vehicle models should implement the \"Day 1\" and \"Day 1.5\" services, as specified by the standards, beginning from 2023. These services call for the deployment of LTE PC5 technology for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication. | EUR 27 billion      |               |                                            |            |\n| Equitable 5.9 GHz use                                                                                                                                          | - The 5.9 GHz spectrum will see the coexistence of IEEE802.11p and C-V2X technologies, with the former                                                                                                                                                                                                                   | EUR 43 billion      |               |                                            |            |\n| being used for V2V communication while the latter will utilize PC5 for V2V communication. viding real-time information to drivers [44,45]. To enable efficient |                                                                                                                                                                                                                                                                                                                          |                     |               |                                            |            |\n\nenhancing the driving experience [41]. To enable efficient communication, V2X system provides multiple communication interfaces, including PC5 Interface (Side link) and Carrier Aggregation (CA) for mode 4 [42,43]. Additionally, the system incorporates a synchronization procedure for multiple carriers and supports 64QAM modulation for enhanced data transmission rates. C-V2X system also enables pool sharing between mode-3 and mode-4 user equipment, allowing for greater flexibility and efficiency. Moreover, in this release the V2X system provides faster message transmission periods, ensuring timely and accurate communication between vehicles and infrastructure.\n\nV2X system leverages LTE and NR-based communication technologies, backed by 5G-core support, to enhance communication efficiency and scalability. The system enables seamless interworking of EPS V2X and 5G systems, ensuring compatibility with existing infrastructure and enabling a smooth transition to nextgeneration V2X solutions. V2X system supports all identified V2X\nand eV2X services, providing a comprehensive suite of features aimed at enhancing road safety, improving traffic flow, and providing real-time information to drivers [44,45]. To enable efficient communication, V2X system provides multiple communication interfaces, including NR PC5 interface with Broadcast mode, groupcast mode, and unicast mode, with support for roaming and interPLMN operations. V2X system also incorporates enhanced Quality of Service (QoS) management, ensuring that vehicle-to-vehicle communication is reliable and efficient. The system supports simultaneous LTE PC5 and NR PC5 communication, enabling seamless communication across different networks and ensuring that vehicles remain connected even in areas with poor cellular coverage. In this release, V2X system offers Application Function based V2X provisioning, providing secure and authorized access to V2X\nservices. The system supports UE triggered policy provisioning, enabling users to customize their V2X services to suit their specific needs [46,43]. Additionally, it also incorporates PCF-based provisioning and authorization, ensuring that V2X communication is secure and protected against unauthorized access. 3.4. C-V2X technical improvement in 3GPP's *Release* 17 In this release, the system supports for URLLC applications for V2X services, which are essential for ensuring safety-critical"}
{"doc265": "![5_image_0.png](5_image_0.png)\n\nThe NR side link enhancements have further improved the performance of V2X communications by enabling direct communication between nearby vehicles and devices. The architecture of the 3GPP has been enhanced to support advanced V2X and safety services, which include features like improved positioning accuracy and efficient resource management. User equipment (UE) power saving techniques have been introduced to extend the battery life of V2X devices, which is particularly important for ensuring uninterrupted communication in emergency situations [47,48]. The support for advanced services such as autonomous vehicles, extended virtual reality (VR) based remote driving, drone support for V2X [49] and holographic V2X services have further expanded the scope of V2X communications. Dynamic spectrum sharing of LTE and NR technologies has enabled efficient and flexible use of radio resources for V2X communications, which helps in mitigating interference and improving the overall system performance.\n\nEnhanced side link positioning and ranging techniques have improved the accuracy and reliability of V2X communication, which is essential for enabling safety-critical applications [50]. Additionally, edge communication has been introduced to reduce latency and improve the responsiveness of V2X communications, which is particularly important for real-time applications [51,52]. In 3GPP\nrelease 17, several new features have been introduced to enhance 5G capabilities and support various verticals and deployment scenarios. These developments focus on five key areas: Reduced Capability user equipment, Non-terrestrial Networks (NTN), frequency bands beyond 52 GHz, and the multicast and broadcast service (MBS) [53,54]. The first area, Reduced Capability user equipment, enables the fulfillment of service requirements that lie between relaxed massive machine-type communication (mMTC) demands and highly stringent ultra-reliable low-latency communication (URLLC) requirements. In the realm of Non-terrestrial Networks, release 17 incorporates new network topologies based on high-altitude platforms, low Earth orbit (LEO) satellites, and geosynchronous orbit satellites. NTN serves as a complement to terrestrial networks, extending network coverage to remote areas over land and sea where terrestrial infrastructure is absent. This development encompasses NR, Narrowband-Internet of Things (NB-IoT), and LTE for Machine broadband (MBB) and massive IoT services from release 17 onwards. To expand the frequency range, release 17 extends the existing frequency range 2 (FR2) beyond 52.6 GHz up to 71 GHz. This extension facilitates the inclusion of new licensed and unlicensed frequency bands within this range. The existing NR downlink/uplink waveforms are utilized in this expansion [55]. The multicast and broadcast service (MBS) in release 17 offers improved resource efficiency and requires less operational effort compared to its 4G predecessor, Evolved Multimedia Broadcast Multicast Service. MBS primarily caters to important use cases in public safety, including mission-critical push-to-talk, over-the-air software updates, live TV, video delivery, and IoT solutions. The 5G Quality of Service (QoS) framework, applicable to 5G MBS traffic, enables differentiated packet forwarding, particularly crucial during high traffic load scenarios in the realm of public safety applications. These advancements in 3GPP release 17 strengthen 5G's support for new use cases, paving the way for enhanced connectivity and services in diverse verticals and deployment scenarios. Fig. 2 represents the 3GPP's journey towards the advanced V2X communications, with the brief of what accomplishments have been done in each release till release 17."}
{"doc266": "In the upcoming 3GPP release 18, notable additions for enhanced mobile broadband (eMBB) use cases include beamforming/MIMO, mobility enhancements, and network power savings\n[52]. These features aim to improve signal transmission and reception, enhance user mobility in the network, and optimize power consumption. Furthermore, significant enhancements are expected for non-eMBB use cases, building upon the reduced capability user equipment introduced in release 17 (as explained in Section 3.4).\n\nRelease 18 will introduce two key additions for non-eMBB scenarios: Extended Reality (XR) and National Security and Public Safety (NSPS) [56,57]. NSPS addresses critical communication requirements for national security and public safety applications, ensuring reliable and secure connectivity in emergency situations. Additionally, release 18 will introduce three cross-domain functionalities applicable to both mobile broadband (MBB) and non-MBB use cases. These functionalities include the utilization of Artificial Intelligence/Machine Learning (AI/ML) for physical layer (PHY) enhancements, AI/ML for Radio Access Network (RAN) enhancements, and full duplex communication capabilities. The RAN standardization efforts will focus on establishing a comprehensive framework for AI/ML-related PHY enhancements, encompassing AI/ML modeling, evaluation methodologies, and performance requirements/testing. One specific area where AI/ML can bring concrete enhancements is in beam management or channel estimation. Moreover, release 18 aims to bring advancements in eMBB with the introduction of Advanced Antenna Systems (AASs). These systems enhance spectral efficiency by optimizing antenna configurations and beamforming techniques. Additionally, improved Dynamic Spectrum Sharing mechanisms will be incorporated to facilitate smooth migration from previous generations to 5G networks, maximizing spectrum utilization and efficiency [51].\n\n## 4. Exploring The Endless Possibilities Of C-V2X Use **Cases**"}
{"doc267": "As the world rapidly moves towards an era of smart cities and connected devices, C-V2X technology explores the innovative use cases of C-V2X technology that can provide valuable insights into its endless possibilities and the transformative impact it can have on our daily lives. In this section, let's see how the use cases have emerged in a powerful way by referring to the 3GPP and 5GAA\nreleases.\n\nIn Release 14, there is a significant emphasis on the primary use cases of LTE-V2X, as outlined in TS 22.185 [58,59]. The release provides robust support for various types of communications including V2V, V2I, V2P, and V2N. The three main key features concentrate on 1. Road Safety 2. Road Efficiency and 3. Infotainment\n[60,61]\n- Road Safety: The primary goal of this use case is to decrease traffic accidents by enforcing rigorous network stability and latency requirements. LTE V2X uses short message services that are periodically sent by vehicles to neighboring vehicles at a locally geographical level to provide road safety services.\n\n- Road/Traffic Efficiency: One potential use case for LTE-V2X is the optimization of traffic flow by improving route design, particularly in situations like vehicle platooning. Vehicles would gather sensor data, transmit it to remote management servers in charge of route planning, and then get feedback from those servers. Compared to certain critical road safety use cases, the latency, and reliability demands for above applications are slight less. However, in scenarios involving high speeds, the network must still ensure minimal packet loss and latency."}
{"doc268": "- Infotainment: A highly flexible application of LTE-V2X involves the integration of traditional and innovative internet services to enhance the travel experience of passengers. This application combines various services such as web browsing, data sharing, downloading, and social networking. It is noteworthy that this use case is not subject to stringent network restrictions, providing a high degree of flexibility for users.\n\nThese fundamental safety services are addressed by Rel-14 V2X\n(LTE-V2X), which permits the delivery of messages such as Cooperative Awareness Message (CAM) or Basic Safety Message (BSM), as well as Decentralized Environmental Notification Message (DENM)\n[62]. CAM/BSM deliver the messages periodically to the neighboring vehicle about the heading direction, speed, geographical coordinates etc. DENM's are alerts that may contain a variety of messages depending on the circumstances that caused them to be sent, such as unexpected braking, an impending accident, or a traffic bottleneck.\n\nIn this Release 14, the key performance indicators (KPIs) for the QoS levels that enable V2X communications state that the assumed maximum speed to support the V2V communication is 500 Km/h, while the maximum for V2P and V2I is 250 Km/h. The latency requirements in general case would be 100 ms and in stringent cases it is 20 ms. The range for allocating the reasonable safety buffer would be 140 m at 140 km/h and the periodicity of the message transfer would be 10 to 50 messages per second."}
{"doc269": "V2X services that were identified in Rel. 14 TR 22.885 [63]\nare 1. Caution for Imminent Collision 2. Alert for Control Loss 3.\n\nAlert for emergency vehicles 4. Collaborative adaptive cruise control 5. V2V and V2I based emergency vehicle stop 6. Queue warning 7. Automated Parking System 8. Road Safety Services 9. Wrong way driving warning 10. V2X data transfer 11. Pre-crash sensing warning 12. V2N based traffic flow optimization 13. Curve Speed Warning 14. Vulnerable road user 15. V2X minimum QoS 16. V2P\nsupported Pedestrian Road Safety 17. Multimodal traffic control 18.\n\nRemote diagnosis 19. Enhancing the positional preciseness of the vehicles."}
{"doc270": "Release 15 expands the 3GPP support for improved V2X that is enhanced V2X (e-V2X) by trailing the success of Rel 14. According to TS 22.186 [64], the NR V2X technology supports four major applications as mentioned below, 4.2.1. Vehicle *platooning* Platooning entails maneuvering several vehicles in a group while efficiently controlling their movements. To guarantee that the vehicles are coordinated safely, the lead vehicle relays crucial information to the other vehicles in the platoon. Algorithms for platoon management make it possible for vehicles to brake or accelerate concurrently while keeping a safe gap between them. This innovation optimizes road capacity, promotes fuel efficiency, and enables more efficient transportation [65,66]. Several crucial V2V communication requirements are necessary to support platooning\n[67,68], including:\n- End-to-end communication delay between a group of vehicles should be 25 ms and 10 ms for the highest degree of automation\n- 99.99% level of highest of automation and 90% message reliability for efficient decision execution\n- Relative longitudinal location precision of less than 0.5 m - Broadcasting rate: 10 to 30 messages per second\n- Dynamic communication range management to enhance resource economy due to the variable platoon size, as well as to limit message spread for privacy concerns\n\n7\n4.2.2. Advanced *driving* The advanced driving use case is aimed at supporting semiautomated and fully autonomous driving by allowing for the exchange of data between vehicles and road infrastructure, including Roadside Units (RSUs). This service promotes the sharing of information between vehicles and infrastructure, including data obtained from local sensors and the driving intentions of the driver, with other nearby vehicles [69,70]. This facilitates vehicle coordination and the adjustment of trajectory to improve safety, Cooperative Collision Avoidance (CCA), and road efficiency [71]. The potential communication requirements [72] would be:\n\n- Extremely high bandwidth to support burst transmission of extremely large data\n- Extremely low latency, less than 10 ms for the highest level of automation\n- 99.99% message reliability is needed 8\n4.2.3. Extended *sensors* Extended Sensors are a critical enabler for enabling vehicles to share raw or processed data from local sensors with various elements on the road, such as neighboring vehicles, Roadside Units (RSUs), pedestrian User Equipment (UE), and V2X Application Servers (V2X AS). This exchange of information provides vehicles with a comprehensive understanding of the road environment, allowing them to make informed decisions and react accordingly [73,74]. The resulting benefits include reduced accidents and adaptive traffic management, making this use case a necessary feature in the era of autonomous driving. For example, even if a vehicle or pedestrian is approaching from a non-line-of-sight (NLOS) region, this use case enables all road elements to gain awareness. This is particularly useful in intersections and adverse environmental conditions such as heavy rain, fog, and snow. So, the potential communication requirement to handle this use case are,"}
{"doc271": "- High bandwidth availability\n- Ultra-low latency communication that is less than 10 ms\n- 95% message reliability\n- Support for heavy congested areas by providing required resource based on the critical or non-critical service requirements\n4.2.4. Remote *driving* With the help of V2N, it is now possible for a human operator to drive a car remotely with the evolution of cloud-based applications. Remote driving may be leveraged in a variety of situations, including 1. Backup solution for the Autonomous vehicle car 2. Enable the fleet owners to remotely control the vehicle 3. Enable cloud driven public transportation and private shuttles [75,76]. The potential network requirements to support this use case would be;\n\n- Ultra-low latency and reliable communication:\n- Reliability greater than 99.99%\n- End to End latency for the V2X communication would be less than 5 ms\n- Should support vehicular speed up to 250 Km/h\n- Data rate: Downlink: 1Mbps; Uplink: 25Mbps\nWhen there is certain difficult situation where the vehicle cannot execute the process automatically, the vehicle will stop or move to a position with the least amount of risk, at which point it will ask a remote-control operator to take over and guide it around the obstacle. The streaming sensor data for example like HD video camera, lidar, and radar that will be temporarily made available to the remote controller to comprehend the impediment and decide the direction the vehicle must take. Once the obstruction has been removed or gone, and the car will then resume the complete autonomous mode back again.\n\nOn the whole, the TS 22.186 [64] has specified some global key requirements that will be achieved they are, several degrees of automation will be covered in TS 22.186. Not only that in TS 22.186 it defines the stringent specifications that it should support maximum throughput of 1 Gbps, maximum latency of 3 ms, maximum reliability of 99.999%, and a maximum transmission rate of 100 messages per second. In the Technical Report 22.886 [58] various scenarios and use cases has been related to these stringent policies as mentioned in TS 22.186."}
{"doc272": "In 3GPP TR 22.886 has identified some potential use cases and requirements for enhancing V2X support [58]. This release enhances the various key features we discussed earlier in the previous section;\n- Improved support for non-safety V2X services such as connected sensors, vehicles and smart city, immersive user entertainment for the users and dynamic digital map update with the various alerts.\n\n- Improved version of safety related V2X services such as autonomous driving, car platooning, enhanced pedestrian alerts, networked adaptive traffic management, priority handling and other safety related services.\n\n- Support for various V2X services using multiple 3GPP Radio Access technologies such as LTE and NR, additionally by utilizing the 3GPP V2X technology such as using DSRC, ITS-G5 and ITS-Connect."}
{"doc273": "Apart from this, this particular release highly concentrates on various aspects of the applications, such as 1. eV2X support for the vehicle platooning 2. eV2X support for the remote driving 3. Adaptive precise state map sharing 4. Collective perception of the environment 5. Automated cooperative driving 6. Cooperative collision avoidance 7. Dynamic ride information sharing 8. Adaptive driving mode change 9. Emergency Trajectory Alignment 10. Enhanced QoS/QoE aspects of advanced driving, remote driving and extended sensors. 11. Predictive QoS estimation and dynamic resource sharing 12. Cloud and Edge computing-based resource allocation for critical V2X services etc [77].\n\nRel-17 aims to enhance network performance and provide more adaptive support for existing eV2X services and use cases. Building upon Rel-17 [78], 5G Advanced will offer intelligent network solutions, covering a broader range of use cases in addition to those already established in the eV2X. Artificial intelligence (AI)\ntechniques, such as Machine Learning (ML), Deep Learning (DL),\nReinforcement Learning, Federated Learning, and Computer Vision methodologies, will be a crucial aspect to the implementation of C-V2X use cases in 5G Advanced. Some prospective use cases with this release would be\n- Autonomous and advanced remote driving in metropolitan areas - Cooperative networked adaptive traffic control with AI enhancement\n- Extended V2X services based on extensive augmented reality and immersive holographic driving\n- Enhanced brain-controlled cars with powerful AI\n- Cargo drones and flying taxis as the future of transportation By the support of 3GPP release 17 [78], these booming applications will create the network requirements so stringent. In order to achieve this, network should support 1Tbps of data rate, support for 1000 Km/h vehicle mobility, 99.999% of network reliability, cm-level positioning, 10 times more energy efficient than previous release enhancements and more importantly the latency should be less than 0.1 ms. Not only that various global standardization agencies like 5GAA, ETSI ITS have identified their own set of V2X use cases. Let's see, how 5GAA has grouped their use cases\n\n## 4.5. 5Gaa Supported V2X Use Cases"}
{"doc274": "5GAA also has identified 7 major group of use cases in terms of 1. Safety 2. Vehicle Operation Management 3. Convenience 4.\n\nAutonomous Parking 5. Platooning 6. Traffic Efficiency and Environment friendliness 7. Society and Community. Certain use case examples as depicted in various volumes of 5GAA Working Group 1 [79] are, 4.5.1. 5GAA WG1 volume 1 (year: *2022)*\n- Safety: 1. Cross Traffic Left Turn Assist 2. Intersection Movement Assist 3. Emergency Brake Warning 4. Traffic Jam warning and Route Information 5. Vulnerable Road User 6. Cooperative Lane Change 7. Hazardous Location Warning and Real time situational awareness [80]\n- Vehicle Operation Management: 1. Software Update 2. Vehicle Health Monitoring\n- Advanced Driving Management: 1. High Definition Sensor Sharing 2. See Through for Passing\n- Traffic Efficiency: 1. Speed Harmonization 4.5.2. 5GAA WG1 volume 2 (year: *2022)*\nIn 5GAA WG1 Volume 2 [81], some additional use cases are added in this major group, they are\n\n9\n- Safety: 1. Cooperative Traffic Gap 2. Interactive VRU crossing\n- Vehicle Operation Management: 1. Software Update of Reconfigurable Radio System - Convenience: 1. Automated Valet Parking - Joint Authentication and Proof of Localization 2. Automated Valet Parking 3."}
{"doc275": "Awareness Confirmation 4. Cooperative Lateral parking 5. InVehicle Entertainment 6. Obstructed View Assist 7. Vehicle Decision Assist\n- Automated Driving: 1. Automated Intersection Crossing 2. Autonomous Vehicle Disengagement Report 3. Cooperation lane Merge 4. Cooperative Maneuvers of Autonomous Vehicles for Emergency Situations 5. Coordinated and Cooperative Driving Maneuvers 6. Data Collection and Sharing of HD maps 7. Infrastructure assisted environment perception 8. Infrastructure based teleoperated driving 9. Remote automated driving cancellation 10. Teleoperated Driving 11. Teleoperated driving support and support for automated parking 12. Dynamic update on the hazard information and road event collection of Autonomous vehicles\n- Platooning: Vehicle platooning in steady state\n- Traffic Efficiency and Environmental Friendliness: 1. Bus Lane sharing request 2. Bus lane sharing revocation 3. Traffic light coordination\n- Society and Community: 1. Accident Report 2. Patient transport monitoring 4.5.3. 5GAA WG1 volume 3 (year: *2023)*\nIn 5GAA WG1 Volume 3 [82], use case has enhanced in some groups compared to 5GAA WG1 Volume 2, they are\n\n- Safety: 1. Cooperative Adaptive Cruise Control\n- Automated Driving: 1. Dynamic Data Sharing 2. Adaptive and Automated Valet Parking 3. Dynamic non analyzed sensor signal sharing\n- Traffic Efficiency and Environmental Friendliness: 1. Network Adaptive Traffic Control System\nFig. 3 showcases the network requirements by the adaption of 5G and advance 5G technology for V2X communication scenarios.\n\nIn the coming section, let's also look into the ITS supported V2X\nuse cases."}
{"doc276": "## 4.6. Its Supported V2X Use Cases\n\nIn the following subsections, the potential ITS applications such as Environmental Sensing, Enforcement's, Emergency Vehicle Management, Pavement Condition Management System, and other important applications of ITS are discussed.\n\n4.6.1. Environmental *sensing* C-V2X technology has several application-oriented details that can significantly impact various aspects of transportation and the environment. Here are some key application-oriented details of CV2X Environmental Sensing: 1. Real-Time Weather and Road Condition Monitoring: C-V2X Environmental Sensing enables vehicles to collect real-time weather data, including temperature, humidity, precipitation, and visibility. This information can be shared with other vehicles and infrastructure, providing valuable insights for drivers and transportation authorities to make informed decisions. For example, vehicles can be alerted about slippery road conditions due to rain or ice, helping drivers adjust their speed and driving behavior accordingly. [83]. 2. Air Quality Monitoring:\nC-V2X can also be utilized to monitor air quality levels in realtime. Vehicles equipped with environmental sensing capabilities can detect pollutants, such as carbon monoxide, nitrogen dioxide, and particulate matter. By sharing this information with other vehicles and urban monitoring systems, C-V2X can contribute to improving air quality management in cities. For instance, drivers can receive notifications about areas with high pollution levels, encouraging them to reroute or take alternative modes of transportation. 3. Intelligent Traffic Signal Control: C-V2X environmental sensing can enhance traffic signal control systems by providing vehicles with information about traffic patterns and signal timings."}
{"doc277": "Vehicles equipped with C-V2X technology can communicate their speed, location, and expected time of arrival at intersections to the traffic signal infrastructure. This enables adaptive signal control, optimizing traffic flow and reducing congestion. As a result, drivers experience smoother journeys with reduced waiting times and lower fuel consumption. [84]. 4. Emergency Vehicle Warning Systems: C-V2X plays a crucial role in improving emergency vehicle operations. When an emergency vehicle, such as an ambulance or a fire truck, approaches an intersection, it can send alerts to nearby vehicles through C-V2X communication. These alerts can inform drivers about the approaching emergency vehicle, allowing them to yield and make way in a timely and safe manner.\n\nThis technology significantly improves emergency response times and enhances road safety. Also, with the help of C-V2X, the emergency vehicle warning can be communicated to other intersection by intimating using a digital display board to alert the users in the routed intersection [85,86]. 5. Wildlife Detection and Collision Avoidance: Environmental Sensing in C-V2X can help detect and mitigate wildlife-vehicle collisions. By utilizing sensors such as radar, vehicles can detect the presence of animals near the road and share this information with other vehicles. In areas prone to wildlife crossings, this data can be utilized to issue warnings to drivers, reducing the risk of collisions and protecting both human life and wildlife. 6. Road Infrastructure Monitoring: C-V2X environmental sensing enables continuous monitoring of road infrastructure conditions [87]. Vehicles equipped with environmental sensing sensors or hardware's can detect road hazards such as potholes, debris, or damaged signage. This information can be shared with other road users and road maintenance authorities, enabling proactive maintenance and improving overall road safety. 4.6.2. *Enforcement* Enforcement using C-V2X technology offers various applicationoriented benefits for enhancing traffic enforcement and improving road safety. Some of the interesting applications are as follows,\n\n![9_image_0.png](9_image_0.png)"}
{"doc278": "1. Speed Enforcement: C-V2X technology enables real-time communication between vehicles and infrastructure, allowing for efficient speed enforcement. Enforcement agencies can deploy C-V2Xenabled speed sensors or cameras at strategic locations to detect vehicles exceeding the speed limit. When a speeding violation is detected, a warning message can be sent directly to the offending vehicle, alerting the driver to slow down and promoting compliance with speed limits. 2. Red Light Violation Detection: C-V2X\ntechnology can be used to detect red light violations at intersections. By equipping traffic signal systems with C-V2X capabilities, enforcement agencies can identify vehicles that illegally enter intersections after the light has turned red. Violation alerts can be sent to both the violating vehicle and nearby vehicles, promoting safer driving behavior and reducing the risk of intersection collisions [83,5]. 3. Distracted Driving Monitoring: C-V2X technology can aid in detecting and monitoring distracted driving behaviors. By analysing vehicle movement patterns and sensor data collected from vehicle, identifying signs of distracted driving, such as sudden lane departures or erratic driving behavior can be detected.\n\nIf a vehicle is detected to be engaging in distracted driving, then warnings can be sent to the nearby vehicles to encourage safer driving practices. 4. School Zone Safety: C-V2X technology can improve safety in school zones by enabling targeted enforcement measures. With the help of school zone signs, crosswalks and other sensor information, C-V2X will have the ability to detect vehicles that violate school zone speed limits or fail to yield to pedestrians. Violation alerts can be sent to the offending vehicle or nearby vehicles, promoting adherence to school zone safety regulations, these typical applications of ITS to enable safety is showcased in [88,89]. 5. Parking Enforcement: C-V2X technology can assist in parking enforcement by providing real-time information about parking violations. Parking sensors equipped with C-V2X capabil4.6.3. Emergency vehicle *management* Emergency vehicle management is one of the key applications to get benefited utilizing the C-V2X technology; some of the applications are, 1. Priority Signal Pre-emption: C-V2X enables emergency vehicles to communicate with traffic signals and prioritize their passage. When an emergency vehicle is approaching an intersection, it can send a signal to the traffic light system to preemptively change the signal in favor of the emergency vehicle, ensuring faster response times and smoother traffic flow with the help of various sensors and hardwares like radar, GPS and cameras. 2. Intersection Collision Avoidance: C-V2X technology can enhance intersection safety by providing real-time alerts and warnings to both emergency vehicles and other road users. By sharing information about their location, speed, and intended path, C-V2Xenabled vehicles can detect potential collision risks at intersections and take appropriate action to avoid accidents. 3. Adaptive Traffic Congestion Management for Emergency Vehicles: C-V2X enables emergency vehicles to communicate with traffic management systems and provide real-time updates on their location, route, and estimated time of arrival. This information can be used to optimize traffic flow, adjust signal timing, and dynamically reroute other vehicles to minimize congestion and create clear paths for emergency responders, some key aspects of these applications are projected in [5,85,33]. 4. Hazardous Area Warnings: C-V2X technology can transmit warnings to vehicles in the vicinity of hazardous areas or incidents, such as accidents, road closures, or construction zones. This information can help emergency vehicles navigate safely and efficiently while providing other drivers with early alerts to avoid potential hazards [90]. 5. Data Sharing of Patients Health:\nC-V2X enables emergency vehicles to transmit critical data, such as patient health information or incident details, to command centres in real-time. This data sharing enhances situational awareness, enabling emergency responders to better prepare and allocate resources accordingly. 6. Enhanced Navigation and Routing for Emergency Vehicles: C-V2X technology can provide emergency vehicles with up-to-date information on traffic conditions, road closures, and alternative routes. This real-time navigation assistance helps emergency responders choose the fastest and safest paths to their destinations. These application-oriented details demonstrate the potential of C-V2X in revolutionizing emergency services and creating a safer and more connected transportation ecosystem [91].\n\n4.6.4. Pavement condition management *system* Some of the interesting applications of the pavement condition management systems utilizing the C-V2X technology are as follows; 1. Real-Time Pavement Monitoring: C-V2X technology allows vehicles equipped with pavement monitoring sensors to transmit real-time data about pavement conditions to a central control system. This information includes data on potholes, cracks, surface roughness, and other anomalies. By collecting this data from multiple vehicles, a comprehensive and up-to-date picture of the pavement condition can be generated, enabling timely maintenance interventions. Apart from that, Pavement Condition Management System can leverage C-V2X technology to enable users to provide feedback on pavement conditions and report issues in real-time. Using smartphone applications or in-vehicle systems, drivers can share their observations about road conditions, such as potholes or rough patches, which can be aggregated and used to prioritize maintenance activities [83,5]. 2. Early Warning System: C-V2X enables vehicles to receive real-time notifications about hazardous pavement conditions ahead. When a vehicle detects a significant pavement defect, it can transmit warning messages to nearby vehicles equipped with C-V2X technology. This proactive approach enhances road safety by alerting drivers to potential hazards, allowing them to adjust their driving behavior accordingly and avoid accidents. 3. Dynamic Routing and Traffic Management: PCMS using C-V2X technology can provide accurate information about pavement conditions to traffic management systems. By integrating this data into the overall traffic management framework, authorities can dynamically reroute vehicles away from roads with poor pavement conditions, reducing the risk of damage to vehicles and improving overall traffic flow. 4. Maintenance Planning and Resource Allocation: The real-time pavement condition data collected through C-V2X technology can be used to prioritize maintenance activities and optimize resource allocation. By analysing the collected data, authorities can identify sections of the road network that require immediate attention and allocate maintenance crews accordingly, leading to more efficient and cost-effective pavement maintenance, more information on these applications is given in\n[84,86,91,90,29]. 5. Work Zone Safety: C-V2X technology can improve safety in work zones by enabling communication between construction equipment, workers, and vehicles. Construction vehicles and workers can transmit their location and presence in work zones to approaching vehicles, providing advanced warnings and ensuring safer navigation through the construction area."}
{"doc279": "4.6.5. Some other important applications of ITS\n1. Incident Management and Emergency Response: C-V2X technology facilitates quick and accurate incident detection and response. The real-time incident alerts from C-V2X-enabled vehicles, such as accidents or road hazards, enabling faster response times and appropriate emergency services dispatch. C-V2X can also support the coordination of emergency vehicles by providing real-time location information and optimizing routes to incident scenes [92].\n\n2. Transit Management and Passenger Information: C-V2X technology can improve transit management and provide real-time information to passengers. Transit vehicles equipped with C-V2X can transmit their location, estimated arrival times, and service status to the passengers. This allows for better coordination of transit operations, accurate arrival predictions, and improved passenger experience. 3. Pedestrian Safety: C-V2X technology can enhance pedestrian safety by enabling direct communication between vehicles and pedestrians. The road side infrastructure equipped with C-V2X capabilities, allowing pedestrians to receive alerts and warnings from nearby vehicles [93]. This promotes safer interactions between vehicles and pedestrians, reducing the risk of accidents, especially at intersections and crosswalks. This information is referred from [86,75,83], where authors showcase the key perks of the emerging application in terms of ITS.\n\n## 5. 3Gpp Referred C-V2X **Architectures**"}
{"doc280": "3GPP has developed two significant architectures for Cellular Vehicle-to-Everything (C-V2X) communication. The first one is based on Long-Term Evolution (LTE) infrastructure, while the second one is based on the 5G system. These architectures provide the necessary framework for C-V2X communication, enabling vehicles to communicate with other vehicles, infrastructure, and pedestrians. In the following sections, we will delve into the specifics of each architecture to provide a detailed view of how they operate.\n\n## 5.1. Lte Architecture For V2X Communications\n\nThe LTE-V2X architecture consists of two main components: the LTE network and the V2X application platform. The LTE network is responsible for providing the necessary communication infrastructure to support V2X communications, while the V2X application platform provides the necessary protocols and interfaces to enable V2X communication [38]. The LTE architecture for V2X communications consists of several key components [94], including: - V2X\nControl Plane: The V2X Control Plane is responsible for managing the registration, authentication, and authorization of V2X devices with the LTE network. It also provides the necessary signaling to establish and release V2X communication sessions between vehicles and infrastructure. - V2X User Plane: The V2X User Plane is responsible for the transmission and reception of V2X data between vehicles and infrastructure. It uses the LTE Radio Access Network (RAN) to provide low-latency and high-reliability communication between V2X devices. - V2X Application Layer: The V2X Application Layer is responsible for providing the necessary communication protocols to enable V2X communication with the support of V2X Application Platform. It includes several sub-layers, such as the V2X message layer, the V2X security layer, and the V2X\ndiscovery layer. - V2X Transport Layer: The V2X Transport Layer is responsible for providing the necessary transport protocols to enable V2X communication. It includes the User Datagram Protocol\n(UDP) and the Stream Control Transmission Protocol (SCTP). - V2X\nNetwork Layer: The V2X Network Layer is responsible for providing the necessary network protocols to enable V2X communication. It includes the Internet Protocol (IP) and the IPv6 over LTE protocol."}
{"doc281": "The LTE-V2X architecture over the Evolved Packet Core (EPC),\nas outlined in the Rel.14 and Rel.15 versions of TS 23.285 [95], is illustrated in the Fig. 4. Fig. 4 providing a high-level overview of the LTE-V2X architecture, how the communication works in both in coverage and out of coverage scenarios. The LTE architecture for V2X communications 4 outlines the involvement of EPC entities, their specific roles, and the interfaces used in the communication process. The specification also introduces a new functional entity known as the V2X Control Function, which is responsible for managing the V2X-related parameters of User Equipment (UEs).\n\n![11_image_0.png](11_image_0.png)\n\nAccording to the specifications outlined in TS 23.285 [96], User Equipment (UE) can be configured with V2X policy and parameters in four different ways. These options involve storing the configuration on the Universal Integrated Circuit Card (UICC), preconfiguring it on the Mobile Equipment (ME), provisioning it via the V3 interface using the V2X Control Function, or configuring it through the V1 interface by the Application Server. When a UE connects to the Evolved Packet System (EPS) through a PDN connection, the V2X Control Function initiates the configuration provisioning process."}
{"doc282": "While the logical V2X Control Function facilitates the authorization procedure and provides provisions for the necessary V2X parameters, as outlined in the TS 24.386 protocol [97]. As per the protocol, UE and V2X Control Function work together to establish the required parameters and authorization for V2X communication.\n\nFig. 4 illustrates how vehicles, RSUs, and UEs can communicate with each other with the support of LTE-V2X RAN, EPC and V2X AS. The LTE C-V2X standard, introduced in Rel-15, enables the creation of ITS applications that offer messaging and other services via LTE-EPC. Rel-14 of the 3GPP defines two modes of V2X\ncommunication using a single cellular technology, namely the PC5 interface and the LTE Uu interface. The PC5 interface enables direct communication between UEs, while the LTE Uu interface typically connects UEs to an LTE eNB. UEs can use these communication modes independently, and then decide which one to use with the help of the application layer, as per TS 23.285 [95]. Furthermore, LTE-V2X supports inter-PLMN architecture, and roaming architecture apart from the system architecture as outlined in TS 23.285\n[95]. In order to determine and authorize whether the user equipment is as a Vehicle UE and/or a Pedestrian UE, the V2X Control Function and the HSS utilize protocols over the V4 interface for UE authorization. The V2X Control Function may also require service authorization information from the V2X subscription data in the HSS to operate efficiently. TS 29.388 [98] outlines the procedures and information elements exchanged between the V2X\nControl Function and the HSS over the V4 interface. If the V2X\nControl Function in the home PLMN requires authorization information from the visited PLMN, it may request it from the V2X\nControl Function in the visited PLMN. The visited PLMN's V2X Control Function may share extra information about the V2X AS, like its FQDN or IP address. Additionally, it can specify the UE's authorization to use PC5-based communications or communications over MBMS through interface M1 with an eNB and the EPC. The MBMS requires BM-SC entity participation and the presence of a MBMS-Gateway for QoS management and multicast/broadcast session announcements.\n\nTS 23.285 and TS 29.389 [99] are two significant standards in the telecommunications industry, which provide system architecture and procedures for V2X communication. As we know, TS\n23.285 focuses on LTE PC5 interface communications in C-V2X and outlines the system architecture and roaming architecture. On the other hand, TS 29.389 explains the communication protocol between two V2X Control Functions using V6 interface. Both interfaces use the diameter protocol for verification, registration, and accounting. The V2X communication configuration of a UE can be determined by configurable parameters from various sources such as the USIM application, ME, or V2X Control Function. TS 24.385\n[100] outlines a set of guidelines that use Management Objectives\n(MO) to establish V2X configuration parameters, which encompass service-related settings, radio frequencies, and radio interfacespecific parameters. In general, the V2X communication standards offer comprehensive directions for configuring all components related to V2X communication. With the use of a standardized and interoperable approach, these standards guarantee dependable and secure communication among various entities such as vehicles, infrastructure, and other connected devices."}
{"doc283": "5.1.1. LTE PC5 V2X interface *communication* For V2V and V2P services that utilize PC5 interface for communication beyond network coverage, the adaptive resource selection is the only option. Therefore, UEs must be pre-configured to utilize frequency and parameters as defined in Radio Access Technologies. However, it is important to cooperate with PLMN operators to ensure fair utilization and prioritization of radio resources, particularly when vehicles choose PLMN managed connectivity [101\u2013103].\n\nAs per TS 24.386 [104], PC5-based V2X messages contain a data PDU, Layer-3 protocol (either IP or non-IP), source Layer ID, broadcast destination Layer ID, and V2X message family.\n\nPotential applications of PC5 Interface: The PC5 interface has several applications in C-V2X networks, they are but not limited too: 1. Collision avoidance: The PC5 interface enables vehicles to exchange safety-critical information, such as speed and position, to avoid collisions.2. Traffic management: The PC5 interface enables RSUs to communicate with vehicles to provide real-time traffic information, such as road closures and accidents.3. Pedestrian safety:\nThe PC5 interface can be used to alert pedestrians of oncoming vehicles, reducing the risk of accidents. 4. Emergency services: The PC5 interface can be used to enable emergency services to quickly respond to accidents and other emergencies. 5.1.2. LTE Uu V2X interface *communication* Before the Release 14, V2X communication can only occur within the range of the User Equipment (UE). However, with the help of 3GPP Rel-14, UE can communicate with the aid of Uu interface using standardized EPS connectivity. This new feature enables the relay of communications through 3GPP Multimedia Broadcast Multicast Service, allowing UEs to connect to the V2X Application Server (AS) and to other UEs using the Uu interface. This connection allows for transmissions using the uplink and receiving either unicast or broadcast V2X messages that are intended for a specific UE from another UE using the downlink. When it comes to sending V2X messages on the downlink, there are two methods that the network can choose from 1. Single Cell Point-to-Multipoint (SCPTM) and 2. Multicast/Broadcast Single Frequency Network (MBSFN). Thus, these messages can be transmitted through two types of IP paths: 1. GBR bearer which guarantees a fixed bitrate, and 2. Non-GBR bearer, which doesn't guarantee the bit rate. To ensure efficient communication between a vehicle and a larger set of UEs in its vicinity, as well as reaching UEs located further away, dedicated QCI values for V2X messages are defined in 3GPP TS\n23.203 [105]. Unicast delivery can be achieved using GBR or NonGBR bearers, while broadcast delivery is limited to GBR bearers."}
{"doc284": "The LTE Uu interface can handle both IP and Non-IP based V2X\nmessages. When transmitting Non-IP messages, UE first encapsulates them in IP packets. The Uu interface can be used to configure V2I and V2N service categories through network configurations, and specific QCI values can be defined to ensure efficient communication flow over Uu. The V2X Application Server (AS) can also use the Uu interface to set mandatory parameters for a UE, as specified in TS 23.285 [106]. To send non-IP based V2X messages, the usual approach is to use User Datagram Protocol (UDP) and IP,\nexcept when Transmission Control Protocol (TCP) is expressly specified. These messages are directed to a designated address for the V2X AS. For effective communication, the V2X Control Function enables subscription mechanisms for Uu communications, making it feasible to aim at V2X AS that serve clusters of nearby UEs situated in particular physical locations. The V2X AS transmits V2X messages via unicast or broadcast using the MBMS delivery method.\n\nThe V2X AS address can be obtained through the V2X AS discovery procedure, which can use pre-configured V2X AS information or the / MBMS procedure as specified in TS 24.386 [107]. To support V2X communication, user subscription data is very much necessary for PC5 counterpart authentication and access controls, if the data is requested, Uu interface provides the information.\n\nOne approach to minimize the delay in V2X communication is to utilize a localized MBMS method. This technique restricts the transmission of V2X messages to their intended UEs, without requiring any alterations to existing protocols. Instead, preconfigured data, including IP multicast address, MBMS-Gate Way IP address, and Broadcast-Multicast Service Centre (BM-SC) IP address, are conveyed to the BM-SC through the xMB and MB2 interfaces, as specified in TS 29.116 [108] and TS 29.468 [109], respectively. When the BM-SC receives this data, the MBMS bearer is activated, allowing the V2X AS to send the message to the UE\nthrough the MBMS bearer. TS 29.061 [110] defines the standardized communication protocols between the BM-SC and MBMS-GW."}
{"doc285": "## 5.2. 5G System Based V2X Communication Architecture\n\nThe 5G system architecture for V2X communications is specified by 3GPP in the Rel.16 which includes several key components as shown in the Fig. 5. The first component is the User Equipment\n(UE), which refers to the devices used for communication, such as a car, smartphone, or other IoT device. The UE communicates with the 5G network using radio access technology such as New Radio (NR) or LTE. The second component is the Radio Access Network (RAN), which includes the base stations (gNBs) that provide wireless connectivity to the UEs [111,112]. The RAN is responsible for handling the radio interface and is used to transmit and receive data between the UE and the core network. The third component is the Core Network (CN), which provides the services and functionality necessary to support V2X communication. The CN includes the 5G core, which is responsible for managing network resources, routing traffic, and providing services such as authentication and authorization [113,29,114].\n\nOne important feature of the 5G architecture for V2X communications is the use of a dedicated V2X Service Area (VSA), which is a specific part of the 5G network that is optimized for V2X communications. This ensures that V2X messages are delivered with low latency and high reliability, which is critical for safety-critical applications. In addition to these features, the 5G system architecture for V2X communications also includes the support for network slicing, which allows network operators to create customized network slices for specific V2X use cases [115,116]. This enables operators to optimize network resources and provide the required level of performance and reliability for each use case [117,76]."}
{"doc286": "The 3GPP has created the 5GS architecture for V2X communications, which can be used over the existing LTE PC5 and E-UTRA\nUu interfaces. This makes it compatible with Rel-15 PC5 and Uu reference points. NR PC5 and NR Uu interfaces are also supported in the 5GS architecture, which cater to UEs with NR V2X capabilities. The V2X AS, which represents the AF, is responsible for providing service parameters for V2X communications [118,119]. The 5G V2X architecture is based on the fundamentals established in Rel-14 and Rel-15 for LTE V2X and is compatible with LTE CV2X. The architecture also enables Cross-Radio Access Technology\n(CRAT) scheduling, by supporting the interfaces such as LTE - PC5 and NR - PC5 interface. TS 23.287 [120] defines the reference model for inter-working between EPS V2X and 5GS V2X in the 5G architecture.\n\nThe Fig. 6 shows how different types of communication scenarios using NR technology are integrated into the overall system architecture for V2X communication, using various reference points and network functions as defined in TS 23.287 [120]. The system uses 5G technology, and certain network functions involved in V2X\ncommunication are highlighted in violet. The orange arrows indicate how communication is facilitated with the help of uplink, downlink and side-link facilitated by the 5G NR V2X interfaces. Although there isn't a dedicated LTE V2X Control Function in the 5G\nsystem, it can be used when connecting with 5G nodes that have LTE connectivity or when scheduling communication between different types of Radio Access Technologies. The Fig. 6 shows the platoon scenario (in our case just assumed: car) and how groupcast mode is handled using a standardized approach. In this scenario, it's important to note that it's the upper layer (control layer),\nnot the MAC layer, that's responsible for managing the allocation of group-cast addresses [121].\n\nWhen there is no dedicated LTE V2X Control Function, the responsibility of transmitting a UE's authorization status to the NGRAN node falls on to the 5GC handling. The V2X authorization and provisioning functions are decentralized and spread across various 5GC components involved in V2X communication. The Policy Control Function (PCF) is an essential part of configuring V2X policy and parameters, including QoS, QoS profile, radio functionalities, NR - Uu and NR - PC5 configuration parameters, over the CP plane Non-Access Stratum (NAS) signaling, supported by the PLMN. If any issues arise with the policy or functionalities provided by the PCF for V2X communications, the UE can initiate a User Equipment based Policy Provisioning procedure to connect with the PCF and address the issue."}
{"doc287": "To enable V2X communications over the Uu and PC5 interfaces to the UE, the standard specifies various methods for providing or updating the V2X configuration parameters. These methods are as follows: 1. pre-storing the parameters in the Mobile Equipment (ME), 2. configuring them in UICC, 3. simultaneously storing them in the ME and configuring them in the UICC, 4. receiving them from the V2X Application Server (AS) through the Policy Control Function (PCF) or V1, and 5. obtaining them directly from the PCF.\n\n5.2.1. NR PC5 V2X *communication* The NR PC5 interface supports group cast communications among adjacent UEs, where the application layer is responsible for managing groupcast groups and configuring parameters such as Application ID and Layer 2 ID. In Rel-16, connectionless groupcast utilizes the MCR sidelink parameter, ensuring high reliability and low latency for nearby vehicles. V2X applications can utilize customized QoS profiles via the Per-Flow PC5 QoS Model, where preconfigured information is available if required. Additionally, NRPC5's Quality of Service support is improved and matched with Uu\n\n![14_image_0.png](14_image_0.png)"}
{"doc288": "interface quality profile through specific values of the 5G QoS Identifier parameter for the V2X communications.\n\nAs of Rel-16, a UE can use both NR - PC5 and LTE - PC5 for V2X\nservices, depending on a variety of factors. These factors include the availability of services, the user's subscription, their authorization, and the communication configurations profiles of the V2X\napplication being used. With the support of NR - V2X interface, newer vehicles can now communicate with older vehicles that may only support LTE - PC5. The EPS architecture has been updated to support V2X communication over the NR - PC5 interface. A User Equipment that has NR-V2X support can simultaneously use unicast, groupcast, and broadcast modes [122]. To align it with the features provided by 5GS, the 3GPP updated the V2X architecture for NR-PC5. UE V2X configuration parameters for NR-PC5 communication are obtained through a session-less policy management mechanism, using policy provisioning via PCF. This involves the UE presenting a list of V2X capabilities to the 5GC, which then prompts the PCF to configure V2X policies on the UE. These policies include radio-related parameters like suitable spectrum, authorized Radio Access Technology can be LTE or NR, application oriented, and QoS profile for NR PC5 interface [123,124]. 5.2.2. NR Uu V2X *communications* The NR Uu interface is a radio interface that connects the User Equipment (UE) with the Next-Generation Radio Access Network (NG-RAN) node in the 5G System (5GS) architecture. It is used for V2X communication, which enables vehicles to communicate with other vehicles, infrastructure, and pedestrians [125]. Here are the technical details of the NR Uu V2X interface in terms of its working in the 5GS architecture.\n\nThe NR Uu interface uses the Orthogonal Frequency Division Multiplexing (OFDM) modulation scheme with multiple subcarriers and sub-channels. It supports both Frequency Division Duplex (FDD) and Time Division Duplex (TDD) modes. The interface uses a new protocol stack designed for 5G networks, which includes the NR radio access network protocol stack and the 5G Core network protocol stack. The NR radio access network protocol stack includes the Physical layer, MAC layer, RLC layer, and PDCP layer. The 5G Core network protocol stack includes the Application layer, Transport layer, Session layer, and Network layer. The NR Uu interface supports advanced Radio Resource Management\n(RRM) mechanisms, which optimize the allocation and management of radio resources based on the UE's Quality of Service (QoS)\nrequirements, network conditions, and available radio resources. The RRM mechanisms include dynamic scheduling, link adaptation, and power control. The interface also supports QoS parameters for 5G services, which are used to prioritize traffic and ensure the required level of service quality. The QoS parameters include throughput, latency, and reliability requirements [126\u2013128]."}
{"doc289": "The NR Uu interface supports advanced security mechanisms, including mutual authentication, key management, and encryption.\n\nThese mechanisms ensure the security and privacy of 5G communications. The interface also supports beamforming, which is a technique used to enhance the signal strength and quality by focusing the transmission beam towards the UE. This technique enhances the coverage and capacity of the 5G network [129]. In the V2X context, the NR Uu interface provides a reliable and efficient communication interface between the UE and the NG-RAN node. The interface allows vehicles to communicate with other vehicles, infrastructure, and pedestrians. The UE sends and receives V2X messages using the NR Uu interface, which are processed by the NG-RAN node and forwarded to the appropriate destination.\n\nThe V2X messages include safety-related messages, traffic management messages, and infotainment messages. The interface also supports cross-RAT scheduling, which enables V2X communication over different RAT's (NR PC5 and LTE PC5) [130,131]."}
{"doc290": "The 5G System (5GS) is equipped with additional configuration options to streamline V2X communications over NR Uu interface. These options include support for IP and Unstructured PDU Session Types. Rel-16 provides flexibility in choosing the transport protocol, enabling applications to select the most suitable one. The 5GS\nalso offers other configuration parameters like DNN, SSC Mode, SNSSAI, and 5QIs [44]. In order to simplify the implementation of a separate network slice specifically for V2X services and allow for easy roaming across multiple operators, a new SST has been introduced in TS 23.501 [132]. Furthermore, the 5G system can now support V2X applications with various configuration specifications based on the quality of service (QoS) profile, which can enhance the overall V2X experience. The V2X Application Server (AS) can communicate with the 5GS and provide specific requirements for the V2X service. The V2X AS can also suggest alternative Quality of Service (QoS) profiles for the NG-RAN through the Policy Control Function (PCF). The Session Management Function (SMF)\nis informed if the NG-RAN supports the suggested alternative QoS\nprofiles. If it does, the SMF sends the AQPs to the NG-RAN. This feature helps the NG-RAN to be more adaptable to the V2X service and provides more QoS options for delivering the service\n[61,133,134,76,135].\n\n5.2.3. 5GS application layer for V2X\nThe 5GS provides application layer support for V2X through the use of V2X application protocols, which are implemented using standard 3GPP protocols such as the Service Capability Exposure Function (SCEF) and the Application Function (AF). The SCEF enables V2X application servers to access network capabilities and to receive notifications about V2X services from the network. The AF acts as an intermediary between the application servers and the network, providing service-level information to the network and managing the allocation of network resources [136,137]. In addition, the 5GS includes support for the V2X application layer using HTTP-based protocols, such as the Constrained Application Protocol\n(CoAP), which are used for machine-to-machine communications.\n\nThe 5GS also supports the use of the Session Initiation Protocol\n(SIP) for voice and multimedia communications, as well as the Diameter protocol for authentication and authorization."}
{"doc291": "To enable the use cases of C-V2X that require support for extremely low latency, high reliability, and high throughput, various advanced technologies such as Software Defined Networking, Edge Computing, Cloud Computing, Blockchain, and AI-based support for V2X are rapidly emerging.\n\n## 6.1. Empowering C-V2X With Edge Computing\n\nThe 3GPP standards define Edge Computing as a technology that provides computing resources and services at the edge of the network, closer to the devices and applications [138]. For C-V2X,\nEdge Computing can help reduce the latency of the communication and provide a more reliable and secure service. Edge Computing for C-V2X involves deploying computing resources, such as servers and storage, at the edge of the cellular network, in close proximity to the C-V2X devices. This allows for faster processing of the data generated by the devices, as well as faster response times to the requests sent by the devices, some of the previous studies\n[139\u2013141] showcases the potential of edge computing in C-V2X. Several architectures for Edge Computing, including Distributed Edge Computing, Centralized Edge Computing, and Hybrid Edge Computing are realized in the studies [142\u2013146]. In Distributed Edge Computing, computing resources are distributed across RSUs in the network. In Centralized Edge Computing, all computing resources are centralized in a single RSU or a data center. Hybrid Edge Computing combines the benefits of both distributed and centralized architectures [147,113]. In addition, several Edge Computing services, such as the ITS Edge Service (ITES), the ITS Mobility Edge Service (ITMES), and the ITS Security Edge Service (ITSES)\nare realized from the studies but not limited too [148\u2013150]. These services provide various functions, including traffic management, data processing, and security services. In addition, Edge Computing can predominantly help with data management and security. By processing the data at the edge of the network, the amount of data that needs to be transmitted to the core network can be reduced, which in turn reduces the risk of data breaches and cyber-attacks."}
{"doc292": "According to the studies, Service Communication Proxy (SCP) acts as an SDN controller. The SCP is responsible for managing and controlling the flow of data between the network and the V2X applications. The SDN controller communicates with the C-V2X network elements through standard northbound APIs and manages them by configuring their forwarding rules. This architecture enables the dynamic and automated management of network resources, which can improve network performance and efficiency. The SDN-based C-V2X architecture allows for dynamic network slicing, which enables the network to be sliced into multiple virtual networks, each optimized for specific types of V2X services. This enables the network to efficiently allocate resources based on the specific needs of each V2X service, which can improve overall network performance and reduce latency [157]. The SDN-based C-V2X architecture also includes a Network Slicing Selection Function (NSSF), which is responsible for selecting the appropriate network slice based on the service requirements of the V2X application, many studies related to this is provided by authors in [158\u2013161]. The NSSF can use various parameters, including the QoS requirements, service type, and UE location, to determine the optimal network slice for a given V2X service. In addition, the SDN-based C-V2X architecture supports the use of Network Functions Virtualization (NFV), which enables network functions to be deployed and scaled in a more flexible and efficient manner. This can help reduce the overall cost of deploying and operating the network, while also improving its scalability and flexibility.\n\n## 6.3. Integration Of Ai For C-V2X Enhancements\n\nVarious use cases for AI in C-V2X, including: 1. Predictive Maintenance 2. Intelligent Traffic Management 3. Road Safety 4. Autonomous Driving. Some of these studies are already done in the papers [162,117,163]. Some of the technical enhancements in terms of AI integration in cellular networks, such as, 1. Advanced Machine Learning models 2. Deep Neural Networks 3. Computer Vision 4. Reinforcement Learning models 5. Federated Learning and Natural language Processing (NLP). To support the integration of AI with SDN, some of the possible solutions are already studied in [164\u2013166], such as: 1. Network Slicing: Network slicing can be used to dynamically allocate network resources to support specific C-V2X use cases, such as autonomous driving or predictive maintenance. 2. Virtualization: Network virtualization can be used to create virtual network functions that can be dynamically allocated to support specific C-V2X use cases. 3. Network Automation: Network automation can be used to automate network management tasks, such as resource allocation and traffic routing, to support AI-enabled C-V2X applications. 6.4. Enhancing V2X communication through programmable edge and cloud *intelligence* SDN, NFV and Edge Intelligence emerge as the principal technologies as discussed above, which will play a pivotal role in seamlessly integrating and managing communication networks characterized by their heterogeneity. The conceptual architecture which is presented in the Fig. 7, involves the utilization of SDN to leverage software-based approaches in separating network control from the forwarding (or data) plane. This decoupling process effectively separates routing and control procedures from specialized hardware-dependent forwarding operations. By enabling this decoupling, network control dynamics can be programmatically managed using software, with an abstract perspective of the physical infrastructure. A centralized network controller takes charge of the network intelligence, maintaining a comprehensive overview of the network, and making informed decisions on policies related to automated network optimization and management, among other aspects. This adoption of softwarization in the network architecture extends the application range of 5G systems, enabling the implementation of RAN dis-aggregation, many prior works in regards to this were studied by the authors [167\u2013171,102]. In this dis-aggregated setup as shown in the Fig. 7, Radio Units (RUs) functions as the basic trans-receivers, while control and processing operations are performed through software utilizing open interfaces and APIs. This development is evident through the availability of numerous open source SDN solutions specifically designed for mobile networks, including ONOS (Open Networking Operating System) [172], CORD (Central Office Re-architected as a datacenter) [173], O-RAN [174], ONAP (Open Network Automation Platform) [175], Aether [176], and SD-RAN (Software Defined Radio Access Network) [177]. As studied by one of the authors in\n[178], SDN controllers can be deployed in the cloud, which can use machine learning algorithms to predict traffic conditions, optimize network resource allocation, and detect network anomalies."}
{"doc293": "The integration of cloud enables the collection of global data from the data plane; accordingly, network policies can be adapted periodically as per the applications and services defined by network operators. These updated policies are then sent back to the core network configurations, and the new policies are adapted back to the data plane, ensuring smooth functioning of the system. Realtime response to changing conditions can be achieved by deploying micro-services to the cloud, which can be triggered by events detected by edge devices or SDN controllers, containerization technologies, such as Docker or Kubernetes as studied in [179]. Furthermore, with the integration of Network Function Virtualization\n(NFV) in the cloud, enhances the management and orchestration capabilities of software-defined networks, providing scalability and flexibility to the network. This is achieved by virtualizing network services and functionalities, separating them from the underlying hardware on which they are executed. Each functionality is implemented as a software-based Virtual Network Function (VNF) in cloud. This approach enables efficient resource allocation and enables the dynamic deployment and scaling of network functions as needed [180,181].\n\nIn the presented conceptual architecture 7, the incorporation of Mobile Edge Computing (MEC), as per the definition proposed by the ETSI [182] and 3GPP in Release 15 and 16, will bring forth the significant advantages by bridging the gap between hardware and software solutions, thereby placing computational resources closer to end-users [183]. Where the edge server, act as a local database, continuously receives real-time information pertaining to vehicle and base station configurations. This information includes details such as Vehicle ID, Speed, Geo-Location, Traffic Status, Subscriber Info, Network Rules, Modulation, Correction Codes, Beam formation mode, and resource requirements, some of the inspired works which showcased the potential of integrating the MEC are\n[184\u2013186]. Edge Server can be deployed with the AI models on edge devices such as network switches, routers, and base stations to reduce latency and improve real- time decision-making capabilities. In terms of the application module, the edge server can optimize various tasks, such as Mobility Management, Traffic Management, Authentication, Transmission, and resource allocation schemes, along with Cluster Information. This optimization is achieved by utilizing locally stored information in the database and by capitalizing on control plane network optimization supported by the core network and cloud computing. To effectively implement edge AI in the context of Cellular Vehicle-to-Everything (CV2X) communication, specialized hardware such as Graphics Processing Units (GPUs), Field-Programmable Gate Arrays (FPGAs), or Tensor Processing Units (TPUs) is required to accelerate AI model computations. For in-depth analysis and reviews of different MEC architectures and integrating Edge Intelligence is studied by the authors in [187\u2013190], interested readers can refer.\n\n## 6.5. Block Chain Technology For The Enhancements Of C-V2X"}
{"doc294": "Blockchain technology can help C-V2X communications in various ways, as it can provide a secure and decentralized platform for data sharing and authentication. Here are some technical details [191,192] of how blockchain technology can help C-V2X as per 3GPP: 1. Data Sharing: Blockchain technology can be used to securely and transparently share data between connected vehicles 17\n\n![17_image_0.png](17_image_0.png)\n\nand infrastructure, ensuring the authenticity and integrity of the data [193]. For example, vehicle location data and traffic flow data can be shared on the blockchain to improve traffic management and reduce congestion. 2. Authentication: Blockchain technology can be used to authenticate and authorize connected vehicles and infrastructure, ensuring that only authorized entities can access and use the network. For example, blockchain-based identity management systems can be used to securely identify and authenticate vehicles and their owners. 3. Security: Blockchain technology can be used to provide a secure and tamper-proof platform for storing and sharing sensitive data, such as vehicle maintenance and repair records. This can help prevent fraud and ensure the safety of vehicles and their passengers [194]. 4. Smart Contracts: Blockchain technology can be used to automate the execution of smart contracts, which can enable more efficient and secure transactions between connected vehicles and infrastructure. For example, smart contracts can be used to automatically pay for tolls or parking fees, or to facilitate insurance claims."}
{"doc295": "## 6.6. Security Mechanisms For C-V2X\n\n5G-based security mechanisms for cellular-based V2X communication systems are designed to provide robust protection against cyber threats and ensure the confidentiality, integrity, and availability of V2X data and applications [195]. Here are some of the security mechanisms [83]: 1. Secure Bootstrapping: Secure bootstrapping is a process of establishing a secure connection between the communicating parties. In 5G and advanced 5G-based cellular V2X, secure bootstrapping can be performed using the 5G-AKA\n(Authentication and Key Agreement) protocol, which uses mutual authentication and key exchange to establish a secure connection.2. Cryptography: Cryptography is a technique used to secure data by transforming it into a secure format. In 5G-based cellular V2X, cryptography is used to protect data in transit and at rest.\n\nAdvanced cryptographic techniques such as homomorphic encryption, quantum-safe cryptography, and post-quantum cryptography can be used to provide additional protection against future cyber threats. 3. Security-by-Design: Security-by-Design is a design approach that incorporates security into the development of V2X systems and applications from the outset. In 5G-based cellular V2X,\nsecurity-by-design can be used to ensure that V2X systems and applications are secure by default and remain secure throughout their lifecycle [196]. 4. Security Auditing and Monitoring: Security auditing and monitoring are essential for detecting and responding to security incidents. V2X - security auditing and monitoring can be used to monitor V2X traffic, detect anomalies, and respond to security incidents in real-time continuously with the help of Edge AI technology [197]."}
{"doc296": "## 7. C-V2X Standardization **Bodies**\n\nThis section will give the brief idea on the key standardization bodies working towards the development and promotion of CV2X include: 1. 3GPP (Third Generation Partnership Project) [198]:\nThis is a collaboration between various telecommunications standards organizations that develops specifications for cellular networks, including C-V2X. 2. ETSI (European Telecommunications Standards Institute) [199]: ETSI is a standardization body that develops globally-applicable standards for Information and Communication Technologies (ICT), including C-V2X. 3. SAE International (Society of Automotive Engineers) [200]: SAE International is a global association of engineers and technical experts in the aerospace, automotive, and commercial vehicle industries. It has developed standards for C-V2X technology, including message sets and data dictionary. 4. IEEE (Institute of Electrical and Electronics Engineers) [201]: IEEE is a professional association for engineers, and it is involved in the development of standards for C-V2X\ntechnology. 5. GSMA (Global System for Mobile Communications Association) [202]: GSMA is a trade body that represents mobile network operators worldwide. It works with other standardization bodies to promote the adoption of C-V2X technology. 6. ITS America [203]: ITS America is a non-profit organization that promotes the development and deployment of intelligent transportation systems (ITS) in the United States. It works with other organizations to promote the adoption of C-V2X technology. 7. CVTA (Connected Vehicle Trade Association) [204]: CVTA is a non-profit organization that promotes the development and deployment of connected vehicle technologies, including C-V2X. 7. 5GAA (5G Automotive Association) [205]: 5GAA is a global, cross-industry organization that promotes the development and deployment of connected and automated driving. It includes automakers, technology companies, and telecommunications companies, and it promotes the adoption of C-V2X technology. 8. ISO (International Organization for Standardization) [206]: ISO is an independent, non-governmental international organization that develops and publishes standards for various industries, including automotive. ISO has published standards for intelligent transport systems (ITS), including C-V2X. 9.\n\nITU (International Telecommunication Union) [207]: ITU is a specialized agency of the United Nations that is responsible for information and communication technologies. It has developed standards for the use of cellular networks in ITS, including C-V2X."}
{"doc297": "10. TIA (Telecommunications Industry Association) [208]: TIA is a trade association that represents the telecommunications industry in the United States. It has published standards for the implementation of C-V2X technology in the U.S. 11. FCC (Federal Communications Commission) [209]: FCC is an independent agency of the U.S. government that regulates interstate and international communications by radio, television, wire, satellite, and cable. It has established rules and regulations for the use of radio frequency spectrum for C-V2X and other ITS applications in the U.S.\n\n## 8. Industry Analytics In Terms Of C-V2X **Development**\n\nThe C-V2X development industry is currently experiencing significant growth, driven by the increasing demand for connected and autonomous vehicles. According to a report by MarketsandMarkets, the global C-V2X market size is expected to grow from USD 536 million in 2020 to USD 2,411 million by 2025, at a compound annual growth rate (CAGR) of 35.9% during the forecast period [210,211]. The market growth is being driven by several factors, including increasing demand for road safety, the need for efficient traffic management systems, and the growing popularity of autonomous vehicles. In addition, the adoption of 5G networks is expected to further accelerate the development of C-V2X technology, as 5G networks offer faster data transfer speeds and lower latency, enabling more reliable and real-time communication between vehicles and other devices."}
{"doc298": "Regional Insights: In 2021, Asia Pacific had a market share of USD 259 million for automotive V2X. The main players working on vehicle-to-everything development in this region are telecommunication technology providers and automobile OEMs [212,213].\n\nIt is anticipated that Japan and China will dominate technological advancement in the Asia Pacific region [214,215,31]. For instance, level 4 autonomous vehicles, which can nearly always drive without human control, are being tested in a vehicle-to-everything pilot zone of the Yongchuan district in Chongqing [216,215]. The market is predicted to grow strongly throughout Europe. Numerous research projects, business alliances, and cooperative testing for vehicle-to-everything connection were seen in the area. For instance, the development and deployment of intelligent transport systems on European roads is the focus of the CAR 2 CAR\ncommunication [18] consortium, which is made up of numerous technology developers and automakers. Due to increased vehicleto-everything technology implementation by major automakers in this region, North America is anticipated to have significant market growth. With the U.S. State Route 33 Smart Mobility Corridor, Honda is working in collaboration with the Ohio Department of Transportation to create the V2X environment with the largest density of its kind [217]. Similarly, Audi announced a trial programme for cellular vehicle-to-everything installations starting in Q3 of 2020 in collaboration with the Virginia DOT [218]. The Alliance for automobile Innovation (AAI) estimates that in 2019, over 60% of the automobile market share in the United States would be held by firms who have already deployed or have announced deployments of C-V2X. These elements will therefore fuel the market's expansion in this area [219]. Partnerships and collaborations: Several companies are investing heavily in the development of C-V2X technology. The company with the second-highest number of patents for this technology, after Qualcomm (3893 patents), is LG Electronics. It is now ranked second by having almost 3000 patents and stands first in terms of short-range or WLAN-based V2X patents. Huawei stands third by having around 2248 patents [220]. Some other list of key companies profiled in the V2X business are Autotalks Ltd. (Israel), Cohda Wireless (Australia), Kapsch TrafficCom (Austria), LG Electronics (South Korea), Ford Motor Company (U.S.), Infineon Technologies AG (Germany), Continental AG (Germany), Qualcomm Technologies, Inc. (U.S.), Savari Inc. (U.S.), Lear Corporation (U.S.), NXP Semiconductors (Netherlands), Harman International (U.S.), Denso Corporation (Japan), Aptiv (Ireland).\n\n## 9. Research Challenges And **Directions**"}
{"doc299": "Interference management is one of the critical research challenges in the successful implementation and adoption of C-V2X\ntechnology. Interference can arise from various sources, including other wireless communication systems, environmental factors, and user behavior. The interference can significantly impact the performance of the communication system and lead to degraded signal quality, reduced coverage, and compromised safety [221]. To address this challenge, researchers are exploring various interference mitigation techniques such as adaptive power control, interference cancellation, frequency hopping, AI based interference predictions, and beamforming. Adaptive power control adjusts the transmission power of the communication signal to reduce interference while ensuring reliable communication [222]. Interference cancellation techniques use advanced signal processing algorithms to eliminate or mitigate the effects of interference. Frequency hopping techniques dynamically change the transmission frequency to avoid interference from other wireless systems [223]. Beamforming techniques use advanced antenna arrays to focus the transmission and reception of the signal in specific directions by the help of AI techniques [224], reducing interference from other directions.\n\nHowever, these interference mitigation techniques have their limitations and trade-offs. For example, adaptive power control can impact the system's reliability, while interference cancellation techniques can be computationally expensive and require accurate channel information. Frequency hopping can increase latency, while beamforming requires precise knowledge of the user's location and direction. Moreover, interference management in CV2X communication systems requires coordination and cooperation among the different stakeholders, including vehicle manufacturers, infrastructure providers, and wireless carriers.\n\n## 9.2. Channel Estimation"}
{"doc300": "Channel estimation refers to the process of estimating the characteristics of the wireless channel between the transmitter and receiver, such as signal strength, delay, and Doppler shift. Accurate channel estimation is essential to ensure reliable and efficient communication in C-V2X. In the case of C-V2X, channel estimation faces several challenges. First, the wireless channel characteristics can vary rapidly due to the high mobility of vehicles, making accurate channel estimation challenging. Second, the C-V2X communication system operates in a complex and dynamic environment with numerous interfering signals and multi-path propagation. This makes the estimation of the wireless channel characteristics more challenging. To address these challenges, researchers are exploring various channel estimation techniques, such as pilotbased channel estimation, channel tracking, and channel prediction\n[225]. Pilot-based channel estimation uses known pilot symbols transmitted along with the data to estimate the channel characteristics. Channel tracking uses feedback from the receiver to adjust the channel estimates in real-time based on the changing channel conditions. Channel prediction uses machine learning algorithms to predict the future channel conditions based on past observations [226].\n\nPossible solutions for channel estimation in the future may include the use of advanced antenna technologies, such as massive multiple-input and multiple-output (MIMO) and beamforming, to improve the estimation of the wireless channel characteristics\n[227]. The use of artificial intelligence (AI) and machine learning (ML) algorithms can also improve the accuracy and efficiency of channel estimation by leveraging historical data and predicting future channel conditions. Additionally, the development of standardized and accurate channel models can help improve the estimation of the wireless channel characteristics in C-V2X.\n\n## 9.3. Challenges Behind The Edge And Cloud Ai Adoption In C-V2X"}
{"doc301": "One of the significant research challenges in edge and cloud AI\nfor C-V2X is developing models that can effectively process and analyze heterogeneous data generated by different vehicles and infrastructure. The models must be efficient and lightweight to ensure they can run in real-time and not negatively impact the communication system's performance. Another challenge is ensuring the privacy and security of data processed by edge and cloud AI models. The models may process sensitive information, such as the location and behavior of vehicles, which could be exploited by attackers [228]. Therefore, researchers need to develop secure and privacy-preserving AI models and algorithms that can process data while preserving the privacy and confidentiality of sensitive information. Moreover, integrating edge and cloud AI with the underlying communication system is another challenge. This integration must be seamless and transparent, ensuring minimal impact on the communication system's performance and reliability. Possible solutions for edge and cloud AI in the future may include the development of efficient and lightweight AI models and algorithms optimized for edge and cloud devices. Researchers can explore the use of federated learning, which involves training AI models on distributed edge and cloud devices [229], to help enhance the performance and privacy of edge and cloud AI in C-V2X communication. Furthermore, the use of hybrid edge and cloud computing architectures, such as fog computing, can help optimize the performance and efficiency of edge and cloud AI in C-V2X communication [230\u2013232]. Additionally, researchers can explore the integration of edge and cloud AI with blockchain technology to enhance the security and privacy of data processed by these models.\n\n## 9.4. Challenges Behind The Integration Of Network Slicing For C-V2X\n\nNetwork slicing is another significant research challenge. As we know, Network slicing refers to the partitioning of a single physical network into multiple virtual networks, each with different characteristics and service requirements. This allows network resources to be allocated dynamically based on the specific requirements of each virtual network. In the case of C-V2X, network slicing can be used to support diverse services and applications with different quality of service (QoS) requirements, such as low latency and high reliability [233\u2013235]. For example, safety-critical applications such as collision avoidance require high reliability and low latency, while infotainment applications such as streaming video may require high bandwidth. However, the implementation of network slicing in C-V2X faces several challenges. First, the design and configuration of network slices require accurate and timely information about the network conditions and the service requirements of each application. This requires efficient and reliable data collection and analysis mechanisms. Second, the allocation of network resources to different network slices must be dynamic and adaptive, based on the changing network conditions and service requirements. This requires advanced algorithms for resource management and optimization with the state-of-the-art AI mechanisms."}
{"doc302": "## 9.5. Security\n\nOne of the primary security challenges in C-V2X is ensuring the confidentiality and integrity of data transmitted between vehicles and infrastructure. The data transmitted may include sensitive information, such as the location of the vehicle, its speed, and its direction, which could be intercepted, modified, or spoofed by attackers. Additionally, attackers may launch denial-of-service attacks, such as jamming or flooding the network, which could cause severe disruptions to the communication system [236]. To address these challenges, researchers are exploring various security solutions, such as secure key management, encryption, digital signatures, and secure communication protocols. These solutions can help ensure the confidentiality, integrity, and authenticity of data transmitted in C-V2X communication. Another significant security challenge in C-V2X is ensuring the security of the underlying infrastructure, including the roadside units, cellular networks, and cloud servers. Attackers may attempt to compromise these systems and use them to launch attacks on C-V2X communication. To address this challenge, researchers are exploring secure architecture designs with edge and cloud AI, intrusion detection and prevention systems, and security management frameworks [237\u2013239].\n\nFurthermore, the standardization of security protocols and mechanisms is essential to ensure the interoperability and security of C-V2X communication across different vendors and systems."}
{"doc303": "Possible solutions for security in the future may include the use of advanced cryptographic algorithms and secure hardware modules to ensure the confidentiality and integrity of data transmitted in C-V2X communication. The use of machine learning and AI algorithms for intrusion detection and prevention can help enhance the security of the underlying infrastructure. Additionally, the development of secure communication protocols and standards can help ensure the interoperability and security of C-V2X communication across different vendors and systems [240,241].\n\n## 9.6. Other Research Challenges\n\nIn addition to the aforementioned research challenges, there are several other obstacles that need to be addressed to ensure the successful implementation and adoption of C-V2X. These challenges include: 1. Scalability: With the growing number of connected vehicles, the vehicular network needs to be able to handle a large volume of data traffic. This requires scalable architectures and efficient resource management to ensure the network can operate effectively. Several works are ongoing with these issues, some of the interesting works done by authors are [242\u2013246] 2."}
{"doc304": "Latency: The transmission of data between vehicles and infrastructure needs to be fast and reliable. Achieving low latency in vehicular networks is a major challenge due to the high mobility of vehicles and the need for real-time communication. Enhanced architectures and advanced AI models should be developed to dwell with the standard C-V2X architecture to improve the latency, some of the potential solutions related to latency was addressed in [247\u2013250] were they use the concept of computation offloading, effective capacity prediction, Multi tier edge computing for c-v2x resource offloading and AI based probability detection methods for C-V2X. Other very important issue is 3. Power Consumption: As vehicular networks require a lot of power to operate, which can be a challenge in resource-constrained environments [83]. Developing energy-efficient solutions that minimize power consumption without compromising performance is important for the long-term sustainability of intelligent vehicular networks, several researchers are trying to find optimal solutions, some of the interesting recent studies are [251\u2013259]. 9.7. Focus on V2X development and directions in terms of *industry* perspective The automotive industry verticals should prioritize several key areas in V2X development to enhance the overall ecosystem. These include the utilization of common standardization protocols to ensure interoperability among devices, as well as a robust security framework to safeguard against potential cyber threats. Infrastructure is also a critical component, as it provides the necessary network connectivity for V2X communication. Furthermore, testing and validation of V2X technology are necessary to ensure safety and reliability, while regulatory support can aid in establishing legal frameworks and guidelines for V2X deployment. Finally, collaboration among stakeholders is essential for promoting innovation, knowledge-sharing, and the development of effective solutions [260]. By focusing on these areas, the automotive industry can improve product quality, enhance economic growth, and provide safer and more efficient transportation solutions.\n\n## 10. **Conclusion**\n\nV2X communication technology has emerged as a promising technology with the potential to revolutionize the automotive industry. This study provides a comprehensive overview of the current trends in the growth of C-V2X technology and highlights the significant advantages in terms of applications and use cases that the automotive industry will experience in the near future. The findings provide a detailed analysis of the potential benefits of CV2X technology and its implications for the automotive industry, emphasizing its transformative impact on the way vehicles communicate with each other and the surrounding infrastructure. The study underscores the importance of C-V2X technology in bringing about significant benefits in terms of safety, efficiency, and comfort as highlighted in this study. However, the successful implementation and adoption of this technology require overcoming several challenges, including standardization, security, infrastructure, testing, validation, and regulatory support. It is crucial for the industry to focus on these segments to ensure the development of a robust V2X ecosystem. Furthermore, strategic initiatives such as collaboration, investment in research and development, and leveraging emerging technologies like edge AI and advance 5GS can further enhance the V2X industry's growth and impact on the economy. The study provides valuable insights into the potential of C-V2X technology and emphasizes the need for a concerted effort from industry stakeholders to ensure its successful implementation and adoption."}
{"doc305": "[15] P.H. Feiler, B.A. Lewis, S. Vestal, The sae architecture analysis & design language (aadl) a standard for engineering performance critical systems, in: 2006 Ieee Conference on Computer Aided Control System Design, 2006 Ieee International Conference on Control Applications, 2006 Ieee International Symposium on Intelligent Control, IEEE, 2006, pp. 1206\u20131211.\n\n[16] A. Vinel, N. Lyamin, P. Isachenkov, Modeling of v2v communications for cits safety applications: a cps perspective, IEEE Commun. Lett. 22 (8) (2018)\n1600\u20131603.\n\n[17] European Telecommunications Standards Institute (ETSI), Intelligent Transport Systems (ITS), Access layer specification for Intelligent Transport Systems operating in the 5 GHz frequency band, ETSI Standard EN 302 663, ETSI\n(2020), http://www.etsi.org/deliver/etsi_en/302600_302699/302663/01.02.00_\n20/en_302663v010200a.pdf."}
{"doc306": "[58] 3rd Generation Partnership Project (3GPP), 3rd generation partnership project, technical specification group services and system aspects, general packet radio service (gprs) enhancements for evolved universal terrestrial radio access network (e-utran) access, stage 2, 3GPP TS 23.401 Version 16.5.0, https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails. aspx?specificationId=2989, 2021. (Accessed 19 April 2023).\n\n[59] European Telecommunications Standards Institute, Digital cellular telecommunications system (phase 2+) (gsm), universal mobile telecommunications system (umts), lte, multimedia broadcast/multicast service (mbms), protocols and codecs, audio codec processing functions, amr speech codec, general description, ETSI TS 122.185 V14.3.0, https://www.etsi.org/deliver/etsi_\nts/122100_122199/122185/14.03.00_60/ts_122185v140300p.pdf, 2021. (Accessed 2 March 2023).\n\n[60] M. Boban, A. Kousaridas, K. Manolakis, J. Eichinger, W. Xu, Connected roads of the future: use cases, requirements, and design considerations for vehicle-toeverything communications, IEEE Veh. Technol. Mag. 13 (3) (2018) 110\u2013123."}
{"doc307": "[80] 5G Automotive Association (5GAA), C-v2x use cases and service level requirements - volume i, 5GAA website, https://5gaa.org/c-v2x-use-cases-andservice-level-requirements-volume-i/, 2019. [81] 5G Automotive Association (5GAA), C-v2x use cases and service level requirements - volume ii, 5GAA website, https://5gaa.org/c-v2x-use-cases-andservice-level-requirements-volume-ii/, 2022. [82] 5G Automotive Association (5GAA), C-v2x use cases and service level requirements - volume iii, 5GAA website, https://5gaa.org/c-v2x-use-cases-andservice-level-requirements-volume-iii/, 2023.\n\n[83] S. Chen, J. Hu, L. Zhao, R. Zhao, J. Fang, Y. Shi, H. Xu, C-v2x industrial developments and applications, in: Cellular Vehicle-to-Everything (C-V2X), Springer, 2023, pp. 329\u2013357.\n\n[84] S. Chen, J. Hu, L. Zhao, R. Zhao, J. Fang, Y. Shi, H. Xu, Key technologies related to c-v2x applications, in: Cellular Vehicle-to-Everything (C-V2X), Springer, 2023, pp. 235\u2013270."}
{"doc308": "[88] C.-W. Peng, C.-C. Hsu, W.-Y. Wang, S.-C. Huang, Traffic signal state broadcasting over c-v2x communication technique for autonomous shuttle service, in: Robot Intelligence Technology and Applications 7: Results from the 10th International Conference on Robot Intelligence Technology and Applications, Springer, 2023, pp. 245\u2013251.\n\n[89] R. Maity, M. Jivthesh, P.S. Maitra, G. Sanjeevi, M. Gaushik, S.S. NB, K.U. Menon, Maximising highway safety through ai-enabled detection of pedestrians and animals in v2x environments, in: 2023 International Conference on Wireless Communications Signal Processing and Networking (WiSPNET), IEEE, 2023, pp. 1\u20137.\n\n[90] X. Guo, C. Piao, Sensing Strategy of Autonomous Emergency Braking Based on V2x in Non-line-of-Sight Scenarios, Advances in Urban Engineering and Management Science, vol. 1, CRC Press, 2022, pp. 258\u2013262."}
{"doc309": "[127] N. Bonjorn, F. Foukalas, P. Pop, Enhanced 5g v2x services using sidelink device-to-device communications, in: 2018 17th Annual Mediterranean Ad Hoc Networking Workshop (Med-Hoc-Net), IEEE, 2018, pp. 1\u20137.\n\n[128] C. Campolo, A. Molinaro, F. Romeo, A. Bazzi, A.O. Berthet, 5g nr v2x: on the impact of a flexible numerology on the autonomous sidelink mode, in: 2019 IEEE 2nd 5G World Forum (5GWF), IEEE, 2019, pp. 102\u2013107.\n\n[129] R.G. Lazar, C.F. Caruntu, C. Patachia-Sultanoiu, Simulated and practical approach to assess the reliability of the 5g communications for the uu interface, in: 2022 14th International Conference on Communications (COMM), IEEE,\n2022, pp. 1\u20136."}
{"doc310": "[155] C. Zoghlami, R. Kacimi, R. Dhaou, A study on dynamic collection of cooperative awareness messages in v2x safety applications, in: 2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC), IEEE,\n2022, pp. 723\u2013724.\n\n[156] Z. Li, T. Yu, T. Suzuki, K. Sakaguchi, Building an sdvn framework for rsu-centric cooperative perception with heterogeneous v2x, in: 2023 IEEE 20th Consumer Communications & Networking Conference (CCNC), IEEE, 2023, pp. 1\u20137.\n\n[157] S.D.A. Shah, M.A. Gregory, S. Li, R. dos Reis Fontes, L. Hou, Sdn-based service mobility management in mec-enabled 5g and beyond vehicular networks, IEEE Int. Things J. 9 (15) (2022) 13425\u201313442."}
{"doc311": "[231] P.S. Perumal, M. Sujasree, S. Chavhan, D. Gupta, V. Mukthineni, S.R. Shimgekar, A. Khanna, G. Fortino, An insight into crash avoidance and overtaking advice systems for autonomous vehicles: a review, challenges and solutions, Eng. Appl. Artif. Intell. 104 (2021) 104406.\n\n[232] S. Chavhan, D. Gupta, C. Nagaraju, A. Rammohan, A. Khanna, J.J. Rodrigues, An efficient context-aware vehicle incidents route service management for intelligent transport system, IEEE Syst. J. 16 (1) (2021) 487\u2013498.\n\n[233] C. Guo, C. Wang, L. Cui, Q. Zhou, J. Li, Radio resource management for c-v2x:\nfrom a hybrid centralized-distributed scheme to a distributed scheme, IEEE J."}
{"doc312": "[238] Z. Bai, G. Wu, M.J. Barth, Y. Liu, E.A. Sisbot, K. Oguchi, Cooperverse: a mobileedge-cloud framework for universal cooperative perception with mixed connectivity and automation, arXiv preprint arXiv:2302.03128, 2023. [239] F. Linsalata, E. Moro, M. Magarini, U. Spagnolini, A. Capone, Open ranempowered v2x architecture: challenges, opportunities, and research directions, arXiv preprint arXiv:2303.06938, 2023.\n\n[240] T. Yoshizawa, D. Singel\u00e9e, J.T. Muehlberg, S. Delbruel, A. Taherkordi, D. Hughes, B. Preneel, A survey of security and privacy issues in v2x communication systems, ACM Comput. Surv. 55 (9) (2023) 1\u201336.\n\n[241] F. Lone, H.K. Verma, K.P. Sharma, A systematic study on the challenges, characteristics and security issues in vehicular networks, Int. J. Pervasive Comput."}
{"doc313": "| Keywords:  Autonomous vehicles  Obstacle detection  Sensor fusion  Multi-sensor technologies  Deep learning   |\n|---------------------------------------------------------------------------------------------------------------|\n\nThis paper delivers an exhaustive analysis of the fusion of multi-sensor technologies, including traditional sensors such as cameras, Light Detection and Ranging(LiDAR), Radio Detection and Ranging(RADAR), and ultrasonic sensors, with Artificial Intelligence(AI) powered methodologies in obstacle detection for Autonomous Vehicles \n(AVs). With the growing momentum in AVs adoption, a heightened need exists for versatile and resilient obstacle detection systems. Our research delves into study of literatures, where proposed approaches assimilate data from this diverse sensor suite, integrated through Deep Learning(DL) techniques, to refine AV performance. Recent advancements and prevailing challenges within the domain are thoroughly examined, with particular focus on the integration of sensor fusion techniques, the facilitation of real-time processing via edge and fog computing, and the implementation of advanced artificial intelligence architectures, including Convolutional Neural Networks(CNNs), Recurrent Neural Networks(RNNs), and Generative Adversarial Networks(GANs), to enhance data interpretation efficacy. In conclusion, the paper underscores the critical contribution of multi-sensor arrays and deep learning in enhancing the safety and reliability of autonomous vehicles, offering significant perspectives for future research and technological progress. \n\n| ABSTRACT   |\n|------------|"}
{"doc314": "## 1. **Introduction**\n\nThe advancement of AVs is significantly changing the landscape of transportation, promising improvements in mobility and traffic safety \n(Parekh et al., 2022). A key aspect of this transformation is the ability to detect and avoid obstacles, a task that is central to the safe operation of AVs (Yu and Marinov, 2020). This challenge often requires the integration of various sensor technologies, each contributing unique data. \n\nCameras provide visual input, while technologies like Light Detection and Ranging (LiDAR) and Radio Detection and Ranging (RADAR) offer other critical environmental information (Yeong et al., 2021). By combining these diverse data sources, a more accurate and comprehensive view of the vehicle's surroundings can be achieved. Despite the potential of these technologies, there are issues quite challenging to address. Issues like sensor noise, inconsistent data, and redundant information can complicate the process. However, advancements in data processing methods are opening doors to more precise environmental interpretation and decision-making for autonomous navigation. The urgency of improving transportation safety is underscored by a disconcerting statistic from the World Health Organization (WHO), which https://doi.org/10.1016/j.engappai.2024.108550 Received 21 January 2024; Received in revised form 3 April 2024; Accepted 1 May 2024 Available online 9 May 2024 0952-1976/\u00a9 2024 Elsevier Ltd. All rights reserved."}
{"doc315": "reports an average of 2.4 road traffic deaths every minute worldwide (World Health Organization, 2023). This highlights the global need for safer transportation systems. Fig. 1 below offers a comparative view of how different sensor technologies contribute to vehicle perception, setting the stage for our discussion on innovative solutions in AV obstacle detection. \n\nDeep Learning (DL) has revolutionized obstacle detection in AVs, enabling the processing of complex and extensive data sets for more effective obstacle identification and avoidance (Sanil et al., 2020). This advancement leads to more refined detection and avoidance of obstacles. One of the key elements of this evolution is the use of Convolutional Neural Networks (CNNs), which have become vital for ensuring the safe navigation of AVs (Muhammad et al., 2020). Utilizing CNNs, these frameworks effectively recognize and classify potential hazards, including vehicles and pedestrians, through feature extraction from images (Devi et al., 2022; Liu et al., 2017; Rashid et al., 2019; Lee et al., \n2018). Other DL networks also support advanced object detection frameworks such as You Only Look Once (YOLO), Single Shot MultiBox Detector (SSD), and Faster Region-based Convolutional Neural Network \n(Faster R\u2013CNN), etc. Expanding this capability, DL networks like Fully Convolutional Networks (FCN) and U-shaped Network (U-Net) have been employed for semantic segmentation (Mancini et al., 2016; Tran and Le, 2019). The integration of multi-modal sensor data, gathered from diverse sources like cameras, LiDAR and RADAR, is another area where DL contributes significantly (Koci\u00b4c et al., 2018; Fayyad et al., \n2020). Approaches like Multimodal Unsupervised Image-to-Image Translation (MUNIT) and FusionNet play a pivotal role in autonomously filtering and optimally integrating this raw sensor data. This approach amplifies the AV's capabilities in identifying and navigating around obstacles, even in complex environments. Lastly, the application of Recurrent Neural Networks (RNNs) and their variations, Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) networks, plays a crucial role in temporal analysis (Yuan et al., 2019; Jeong, 2022; Qian et al., 2022). This analysis is key to understanding and predicting the dynamics of the environment, like the movement of pedestrians or other vehicles, thereby enhancing the AVs' ability to proactively evade potential obstacles. \n\nThe role of sensor fusion in AV is fundamental. It facilitates the combination of data from various sensors to offer a more reliable, complete, and unambiguous understanding of the environment than could be achieved by any of these sensors working in isolation. Selfdriving vehicles are typically equipped with multiple sensor technologies such as cameras, RADAR, LiDAR, ultrasonic sensors, and Inertial Measurement Units (IMUs), etc (Escamilla-Ambrosio and Lieven, 2005; Kim et al., 2018). Each of these sensors provides different types of data. For instance, cameras provide high-resolution images and are excellent for colour discrimination and texture analysis, but they are heavily affected by lighting conditions and have difficulty estimating distances. LiDAR, on the other hand, offers accurate distance measurements and can function in various lighting conditions, but it lacks the ability to discern colour and texture. RADAR sensors are proficient at detecting the velocity of other objects even in poor visibility conditions, yet they have lower spatial resolution. Ultrasonic sensors are effective for close-range detection but offer limited field of view (Yu and Marinov, 2020; Liu et al., 2020). Lastly, IMUs provide information about the vehicle's velocity, orientation, and gravitational forces, supporting the overall navigation system (Azam et al., 2020). Sensor fusion techniques aim to leverage the strengths of each sensor type to overcome their individual limitations, enhancing the robustness and reliability of the AV \nperception systems. Through data fusion, the vehicle can obtain a detailed, comprehensive, and accurate understanding of the surrounding environment. Sensor fusion in AV can be categorized into low-level \n(raw data) fusion, mid-level (feature) fusion, and high-level (decision) \nfusion. Low-level fusion combines the raw data from various sensors to generate a unified representation of the environment. This fusion method provides a comprehensive view of the surroundings but faces challenges due to the differences in the nature, format, and quality of data from different sensors. Mid-level fusion focuses on the extraction and combination of features from sensor data. Features can be specific patterns, structures, or objects identified within the data. While less comprehensive than low-level fusion, this method is more robust to sensor noise and variability. High-level fusion, on the other hand, focuses on decision making. Here, individual sensors make independent decisions, and these are then fused to provide a final decision. This fusion level is less affected by sensor errors but may lack the detail provided by the other two fusion methods. In the pursuit of achieving this level of sensor fusion, different fusion levels and associated models play a pivotal role. Fig. 2 below offers a glimpse into the data fusion architecture employed in AV. "}
{"doc316": "Table 1 provides an overview of various fusion levels in obstacle detection research, highlighting the combination of sensors (such as LiDAR, visual, and thermal cameras), the types of objects detected (e.g., 3D cars, 2D pedestrians), and the specific datasets utilized (including KITTI and KAIST Pedestrian Dataset). It encompasses studies from early to late fusion stages, offering a concise summary of contemporary methodologies and applications in this field. \n\nThe compilation of research works in Table 1 is meticulously selected based on a set of defined criteria aimed at presenting a comprehensive overview of sensor fusion strategies within obstacle detection research. This selection is guided by the objective to highlight the innovative and \n\n![1_image_0.png](1_image_0.png)"}
{"doc317": "![2_image_0.png](2_image_0.png)\n\n| Table 1  Fusion strategies and sensor combinations in obstacle detection research.  Fusion  Reference Sensors Object Type Dataset(s)  Level  used  Early Wu et al. (2023) 3D-LiDAR,  visual  camera  3D Object (Car,  van, truck,  pedestrian,  cyclist)  KITTI  Early Abbasi et al.  LiDAR, HDmap  3D Car KITTI  (2022)  Early Zhang et al.  LiDAR, RGB  3D Object Self-recorded  (2021)  Camera  data  Late Yadav et al.  Visual  (2021)  camera,  thermal  camera  Multiple 2D  Self-recorded  objects  data  Early,  Middle,  Late  Broedermann  LiDAR,  et al. (2023)  visual  camera  Multiple 2D  KITTI  objects  Early,  Middle,  Late  2D Pedestrian KAIST  Pedestrian  Dataset  Early,  Middle,  Late  Dasgupta et al.  Visual  (2022)  camera,  thermal  camera  Cordts et al.  Visual  (2016)  camera,  LiDAR  Multiple 2D  Cityscape  objects  Early,  Middle,  Late  Geng et al.  LiDAR,  (2020)  visual  camera  2D Car KITTI  Early,  Ahmed et al.  Visual  Late  (2019)  camera,  thermal  camera  2D Pedestrian KAIST  Pedestrian  Dataset   |\n|---|\n\ndiverse approaches that have significantly contributed to the field focusing on papers published from 2019 to 2023 to ensure inclusion of the latest advancements in sensor fusion techniques for obstacle detection. The chosen studies distinctly illustrate the use of various fusion levels, including early, middle, late, and hybrid stages. This choice is fundamental to understanding the full range of data integration techniques and their capacity to enhance obstacle detection. We have sought studies showcasing a variety of sensor combinations (e.g., LiDAR, visual, and thermal cameras) and their application in detecting a wide range of object types (from 3D cars to 2D pedestrians). This diversity underscores the adaptability of fusion techniques to different detection challenges and environmental conditions. Moreover, dataset utilization has been a significant factor in our inclusion criteria, favouring studies that not only utilize recognized datasets like KITTI and the KAIST Pedestrian dataset but also those that draw from proprietary or self-compiled data (Yadav et al., 2021; Broedermann et al., 2023; Dasgupta et al., 2022; Cordts et al., 2016). This approach underscores the efficacy and adaptability of sensor fusion strategies, attesting to their robustness and practical viability across a variety of datasets. Consideration is also given to the research's contribution to the field, with a focus on studies that have introduced innovative methods or have been particularly influential in advancing obstacle detection research. This aspect ensures that the selected works provide insight into the evolution and current state of the art in the field. Fig. 3 provides flowchart for the review strategy. "}
{"doc318": "Within the dynamic realm of AVs, the integration of deep learning with sensor fusion for obstacle detection emerges as a critical area of exploration. Real-world driving environments, characterized by their complexity and variability, necessitate the development of sophisticated and adaptable methods to ensure the safety and efficiency of navigation. \n\nThis research paper conducts an in-depth examination of deep learning algorithms synergy with multi-modal sensor data to enhance obstacle detection capabilities. It provides a thorough analysis of current approaches and introduces novel experiments, aiming to shed light on advanced strategies that can be adapted to various driving contexts. As autonomous driving technologies are poised to revolutionize the transport sector, this study offers crucial insights paving the way for subsequent research and potentially accelerating advancements in the AV \nsector. \n\n## 2. **Brief History Of Av**"}
{"doc319": "AV have been a topic of development for many years. Initially envisioned as a futuristic concept, they have gradually become a reality thanks to technological advancements. Over time, these vehicles have evolved from simple automated systems to complex machines capable of navigating without human input. This evolution reflects the progress in areas such as artificial intelligence, sensor technology, and computer programming. The concept of self-driving cars has a history that reaches back nearly 80 years, with its first known introduction at the 1939 World's Fair in New York (Norton, 2021). Various companies have ventured into creating AVs, like Waymo, Tesla and Uber ATG as depicted in Fig. 4. \n\nThe subsequent evolution of sensor technology has been a significant driving force in the progress of AV. AVs depend on an array of sophisticated sensors to sense, comprehend, and engage with the surrounding \n\n![3_image_0.png](3_image_0.png)"}
{"doc320": "environment (Murali et al., 2022). These sensors persistently scan the environment around the vehicle, allowing a continuous flow of information to the control systems. To understand the intricate mechanisms and varied aspects of these cars, Fig. 5 provides an in-depth look into working of self-driving cars, the levels of automation they possess, as well as their advantages and disadvantages. \n\nThis evolution has been marked by several key milestones. In the early stages, the focus was primarily on developing basic automated functions, like cruise control, which laid the groundwork for more sophisticated systems. As technology advanced, particularly in the realms of computer vision and machine learning, these vehicles began to incorporate more complex features like lane-keeping assistance and collision avoidance. Each step forward in AV technology not only showcased the potential of integrating automation in vehicles but also highlighted the challenges and complexities involved in making fully autonomous driving a practical and safe reality. The AV market is experiencing significant growth, with its volume expanding from 22.99 million units in 2022 to a projected 55.12 million units by 2029. This increase represents a Compound Annual Growth Rate (CAGR) of 13.3% from 2023 to 2029. As of March 2022, vehicles with Level 3 autonomy and above represent only a small segment of the market, yet notable advancements have occurred (Murali et al., 2022). These include Waymo's initiation of the first driverless taxi service in Phoenix, Arizona in 2020, and Honda's release of the first legally certified Level 3 vehicle in March 2021. In the same year, Nuro received authorization for commercial autonomous delivery in California. December 2021 saw Mercedes-Benz gaining legal approval for a Level 3 vehicle, and in February 2022, Cruise began offering driverless taxi services in San Francisco, California. In China, public robotaxi trials have been conducted, with AutoX in Shenzhen's Pingshan District in 2020, and Baidu in Beijing's Shougang Park in 2021, which also served as a site for the 2022 Winter Olympics. Efforts from tech and automobile companies along with research from institutions like Carnegie Mellon University and DARPA, have significantly propelled the field forward. Table 2 offers a side-by-side comparison of autonomous driving milestones achieved by prominent companies and institutions. \n\nAV applications span across personal travel, cargo logistics, and public transit. While the benefits of AVs, such as enhanced safety, operational efficiency, and wide accessibility, are significant, they also come with challenges like potential technical failures, trust deficits, and cybersecurity vulnerabilities (Kim et al., 2021). The widespread adoption and success of AV largely hinge on public endorsement, stringent safety protocols, and suitable regulatory frameworks (Kroger, \u00a8 2021). "}
{"doc321": "Public perception varies, with safety and trust being prevalent concerns, while pedestrian interactions necessitate changes in behaviour and increased trust in AV systems. Implementation hinges on public acceptance, the establishment of robust safety-focused systems, and comprehensive regulatory frameworks. Fig. 6 illustrates the primary components of AVs. \n\nContemporary research focuses on improving object detection for AVs to mitigate obstructions, crucial in adverse weather conditions, cited in reference (Zhang et al., 2023a). Decision making and control serves as the AV's central processing unit, formulating navigation decisions, employing methods such as reinforcement learning and rule-based algorithms, referenced in (Likmeta et al., 2020). Communication and connectivity ensure AVs interact with their environment, utilizing protocols like Vehicle-to-Vehicle (V2V), \nVehicle-to-Infrastructure (V2I), and Vehicle-to-Pedestrian (V2P) for maintaining essential communication links, as discussed in the literature. The core aspects of AV technology are summarized in Table 3. \n\nTable 4 outlines the obstacles to AV adoption and their possible remedies. "}
{"doc322": "![4_image_2.png](4_image_2.png)\n\nAV utilizes an array of advanced sensors that provide a detailed understanding of the environment in which they are operating ( Modas et al., 2020 ; Ahmed et al., 2022 ). The two main categories of sensors are typically used in these systems: exteroceptive and proprioceptive ( Ortiz et al., 2022 ). Exteroceptive sensors are oriented towards understanding the external environment of the vehicle. They include cameras, which capture visual data in various light conditions, LiDAR sensors, which use laser beams to construct a detailed three-dimensional map of the environment, RADAR sensors, that use radio waves to determine the range, angle, or velocity of objects, and ultrasonic sensors, which use sound\n\n| Table 2  Comparative overview of autonomous driving milestones by leading companies and institutions.  Company/  Project Autonomous Miles Key Insights  Institution  Tesla, Inc. Autopilot Over a billion miles Notable usage rates, with drivers regularly utilizing the autopilot system. Level  2 autopilot includes advanced perception control system  Waymo LLC Waymo One 4 million autonomous miles by end of  Achieved fully autonomous driving in controlled settings, signifying a step  2017  towards eliminating human-AI collaboration  Uber  Uber's Self-Driving Cars 2 million autonomous miles Noted issue with drivers placing too much trust in the system  Technologies  Google LLC Waymo (Previously Google's SelfDriving Car Project)  Highest on-road autonomous miles Significant investment in deep learning research for autonomous driving  Delphi  Autonomous Driving From San Francisco to New York, 99%  Comprehensive report can be found in source  Technologies  in autonomous mode  Audi AG Audi A8 with Traffic Jam Pilot 33% of miles autonomously driven First Level 3 model with commercially available traffic jam assist. Driver is  required to remain engaged and intervene as necessary  University of  Mcity Shuttle Launch imminent Public response available via news outlets and online blogs  Michigan   |\n|---|"}
{"doc323": "![5_image_0.png](5_image_0.png)\n\nFig. 6. Key aspects of AVs. \n\n| Table 3  Detailed overview of key aspects of AV.  Aspect Description Related   | Current Research                                                                  |                                                                  |                                                                                           |\n|--------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n| Technologies                                                                   | Directions                                                                        |                                                                  |                                                                                           |\n| Perception &  Computer  Vision                                                 | Improving object  detection and  classification,  adverse weather  performance    |                                                                  |                                                                                           |\n| Decision-Making                                                                | The \"brain\" of                                                                    |                                                                  |                                                                                           |\n| & Control                                                                      | the AV that  decides how to  navigate  How AVs  interpret the  world around  them | LiDAR, RADAR,  Cameras, Deep  learning algorithms  Reinforcement | Developing more                                                                           |\n| learning, Rulebased systems                                                                                | sophisticated  decision-making  algorithms,  handling complex  traffic scenarios  |                                                                  |                                                                                           |\n| Communication                                                                  | How AVs                                                                           |                                                                  |                                                                                           |\n| & Connectivity                                                                 | communicate  with other  entities                                                 | V2V (Vehicle-toVehicle), V2I  (Vehicle-toInfrastructure),  V2P (Vehicle-toPedestrian)                                                                  | Enhancing  reliability and  security of  communications                                   |\n| Cybersecurity                                                                  | Protection of  AVs from  digital threats                                          | Encryption,  Intrusion detection  systems                        | Developing  advanced  protective  measures, threat  detection and  mitigation  techniques |"}
{"doc324": "| Table 4  Challenges in AV adoption and potential solutions.  Challenge Current State Proposed Solutions   | Areas for Future  Research                                       |                                                                                                                                                                         |                                                                             |\n|-----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n| Safety                                                                                                    | High variability                                                 |                                                                                                                                                                         |                                                                             |\n| Concerns                                                                                                  | in public  perception                                            | Exploring public  perceptions,  developing advanced  safety systems                                                                                                     |                                                                             |\n| Trust Issues                                                                                              | Uncertainty  about reliability  of technology                    | Clear  communication on  safety measures,  improved safety  systems  Transparency about  system  functionality and  limitations,  extensive testing  and demonstrations | Understanding  public trust, ensuring  robust system  performance           |\n| Regulatory                                                                                                | Diverse and                                                      |                                                                                                                                                                         |                                                                             |\n| Hurdles                                                                                                   | sometimes  conflicting  regulations in  different  jurisdictions | Studying impacts of  regulations,  exploring  international  coordination                                                                                               |                                                                             |\n| Cybersecurity                                                                                             | Potential  vulnerabilities to  cyberattacks                      | Harmonizing  regulations,  cooperation  between  stakeholders  Developing  advanced  protective  measures, threat  detection and  mitigation  techniques                | Research into new  threats and  countermeasures,  exploring ethical  issues |\n\nwaves to detect objects and estimate their distance from the vehicle. These sensors play a crucial role in environmental perception, allowing the vehicle to accurately estimate distances to nearby objects, assess light intensities and conditions, recognize road signs and markings, and capture other relevant environmental features like the movement of other road users (Jebamikyous and Kashef, 2022; Shi et al., 2021; Ma et al., 2020). Conversely, proprioceptive sensors are focused on the internal state of the vehicle. These sensors monitor various parameters that are related to the vehicle itself rather than its environment. Like, IMU are used to track the vehicle's motion and orientation, encoders measure the rotation of the wheels and other components, gyroscopes monitor the vehicle's orientation and rotation, magnetometers measure magnetic fields, often used to determine the vehicle's heading and, Global Navigation Satellite System (GNSS) receivers, which include technologies like Global Positioning System (GPS), provide precise location data (Xia et al., 2021; Ertugrul and Ulkir, 2020; Yan et al., 2021; Swaminathan et al., 2022). Fig. 7 depicts the types of sensors utilized in AVs. \n\nThe navigation system of an AV integrates various components for precise operation. An IMU sensor is crucial for measuring the vehicle's motion and orientation, aiding in the accurate localization of the AV within its environment. Complementing this, high-definition maps provide detailed geographic data that enhances navigation capabilities. "}
{"doc325": "Technologies including LiDAR, Cameras, RADAR, and Ultrasonic Sensors are employed to measure distances, capture visual data, detect objects, and gauge proximity, respectively. These instruments are pivotal for the AV's recognition and analysis of its surroundings, which is essential for informed navigation. Subsequently, this data contributes to the determination of route design and choice, ultimately guiding the AV's movement regulation for safe and efficient travel. Sensor fusion is the process of combining data from multiple sensors in a way that enhances the quality and reliability of the information (Khayyam et al., \n2020). Fig. 8 illustrates the significance of sensors in the operation of AV. \n\nThe analysis examines sensor types in AVs, assessing their error sensitivity, resilience to environmental factors, and influence on navigational certainty and system robustness. Each sensor's function within AVs and their value is briefly explained. Delving into the role of sensors ranging from LiDAR to GPS, their integration into the AV's instrumentation suite is considered, noting their accuracy, dependability, and essential data contribution. The examination brings to light the distinct strengths and constraints of the sensors, delineating their part in advancing AV navigation and safety mechanisms. The complex sensor network essential for AVs' advanced operations is clarified through this comparative perspective. In the context of deep learning-based adaptive methodologies for real-time tasks like obstacle detection, the ability of the system to intelligently process and act upon sensor input is critical \n(Ravindran et al., 2021). A combination of sensor types utilized in AVs is presented in Table 5, spotlighting their responsiveness, functionality, and practical applications. \n\nExpanding on the roles of sensor integration in AVs, the study investigates sensor specifications for varying autonomy levels. Level 1 autonomy, or Driver Assistance, primarily uses elementary sensors that support functions like adaptive cruise control and parking assistance. As vehicles progress to Level 2, or Partial Automation, there is an increased need for advanced sensors. Here, sophisticated cameras and an essential IMU enable features like lane keeping and refined vehicle motion tracking. At Level 3, Conditional Automation, a comprehensive array of sensors is required. The addition of LiDAR and advanced RADAR systems improves the detection and tracking of obstacles, while encoders provide detailed measurements of wheel speed and position, further supported by a precise GNSS receiver for exact location data. Level 4, or High Automation, demands even more advanced sensor technology. "}
{"doc326": "High-definition cameras for detailed object recognition and 360-degree LiDAR systems provide a comprehensive environmental understanding, with gyroscopes introduced for accurate orientation data. Finally, Level 5, Full Automation, incorporates the most complex and sophisticated sensor networks. A differential GNSS receiver ensures exceptional location precision, and an Inertial Navigation System (INS) maintains continuous locational and orientational information, independent of GNSS signals. This overview outlines the potential sensor combinations as vehicle autonomy levels increase. The specific sensor requirements and their roles at different autonomy stages are detailed further in Table 6. \n\n## 3.1. Camera (Vision) Sensor\n\nCameras are the essential part of perception mechanisms in AVs \n(Zaarane et al., 2020). Camera sensors, or vision systems, are integral to the operation of AVs. These sensors act as the eyes of the AV, capturing "}
{"doc327": "errors) \n\n| Sensitivity to Calibration                   | Sensitivity to                                                                           |\n|----------------------------------------------|------------------------------------------------------------------------------------------|\n| Errors                                       | Environmental Changes  Moderate (affected by                                             |\n| lead to major errors)                        | weather, but provides  stable 3D data)                                                   |\n| distortions can cause  errors)               | Low (robust against most                                                                 |\n| misalignment)                                | weather conditions)  High (lighting conditions  greatly affect output)                   |\n| can affect distance  readings)               | Low (not directly                                                                        |\n| accumulate over time)                        | affected by  environmental changes)  Moderate (affected by  surface material and  angle) |\n| system with inherent  correction mechanisms) | High (affected by urban  canyons or indoor  environments)                                |\n\nHigh (provides rich "}
{"doc328": "long-range navigation \n\n| Contribution to  Redundancy  High (provides unique  3D data)  High (provides rich  visual details)  Moderate (provides  speed and angle data)  Low (limited range and  precision)  Moderate (provides  unique acceleration and  angular velocity data)  High (provides global  positioning)   |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\ndetailed visual information from the vehicle's surroundings. Advanced computer vision algorithms then process this data, enabling the vehicle to identify and respond to obstructions. The final step involves a processor within the vehicle's AI computer system, which performs image transformation, detection, and segmentation to accurately interpret and utilize the visual data for navigation and decision-making. The constant innovation in camera technology has significantly improved the reliability and functionality of AVs. As a result, vision sensors play a crucial role in the perception and decision-making systems that supports autonomous driving. Fig. 9 displays the Valeo's 1 MP fisheye ETH, a resilient automotive camera that provides superior imagery under all circumstances (Valeo). "}
{"doc329": "Some of the unique advantages of camera includes detailed visual information about the environment, closely resembling the human vision, their ability to detect colour, which is crucial for recognizing traffic lights, road signs, lane markings, pedestrians, and other vehicular traffic (Juyal et al., 2021; Wang et al., 2022a; Severino et al., 2021; Iftikhar et al., 2022; Kim and Lee, 2022; Shahian Jahromi et al., 2019). They are highly effective for pattern recognition tasks, such as detecting and reading text or identifying objects based on their appearance. From an architectural viewpoint, camera systems in AVs can be divided into different classifications. Table 7 provides an overview of the main characteristics and features associated with various camera types. \n\nCamera systems, despite their advantages, present challenges such as sensitivity to lighting conditions, performance impact due to weather conditions, lens distortion, and the need for substantial computational resources. Intense sun glare can greatly diminish image clarity, depth perception, and colour accuracy, often leading to over-saturation. Snow Fig. 7. Sensors employed in AV. \n\nFig. 8. Role of sensors in the functioning of AV. "}
{"doc330": "| Detailed sensor requirements and their roles for different levels of vehicle  Sensor Requirement Role  Basic Camera, RADAR,  Ultrasonic Sensors, Basic  GNSS Receiver  Camera and RADAR are used  for adaptive cruise control and  collision avoidance. Ultrasonic  sensors are used for parking  assistance. GNSS Receiver for  basic navigation support.  Advanced Camera, RADAR,  Ultrasonic Sensors, Basic  GNSS Receiver, Basic IMU  In addition to the roles in Level  1, Advanced Cameras provide  lane keeping assistance. Basic  IMU aids in providing more  accurate vehicular motion  tracking.  Sensors from Level 2 are  enhanced. LiDAR and multimodal RADAR are introduced  for better obstacle detection  and tracking. Encoders provide  accurate wheel speed and  position. Advanced GNSS  provides more accurate geolocation data.  High-res Camera, Multimodal RADAR, 360-degree  LiDAR, Ultrasonic Sensors,  Advanced IMU, Encoders,  Advanced GNSS Receiver,  Gyroscope  Advanced Camera, Multimodal RADAR, LiDAR,  Ultrasonic Sensors, Advanced  IMU, Encoders, Advanced  GNSS Receiver  High-resolution cameras for  better object and signal  recognition. 360-degree LiDAR  for complete environment  perception. Gyroscope added  for more precise orientation  measurements.  High-res Camera, Multimodal RADAR, 360-degree  LiDAR, Ultrasonic Sensors,  Advanced IMU, Encoders,  Differential GNSS Receiver,  INS (Inertial Navigation  System)  In addition to sensors in Level  4, Differential GNSS Receiver  provides high-precision  location data. INS offers  continuous location and  orientation data even in GNSSdenied environments.   |\n|---|\n\nmay cause image overexposure and obscure depth information. Rainstorms lower clarity and depth accuracy and alter colour perception due to light scattering. Hazy conditions result in washed-out images, affecting both depth and colour contrast. At night time, the resolution and depth information are compromised due to low light, and colour detail is generally lost. Fog similarly impacts all aspects by scattering light, which impairs clarity, depth accuracy, and colour saturation. Robust algorithms capable of handling a wide range of lighting and weather conditions, intrinsic camera calibration for distortion correction, and efficient design and implementation to handle high-resolution image data processing in real-time are essential for optimal performance. \n\n## 3.2. Light Detection And Ranging (Lidar)"}
{"doc331": "LiDAR has emerged as a crucial technology in the field of remote sensing, proving itself to be an essential component in the development and operation of AV (Li and Ibanez-Guzman, 2020). These sensors play a crucial role in the sensory apparatus of AVs, using pulsed laser light to map out the vehicle's surroundings in three dimensions. These sensors are proficient in providing high-resolution, real-time data essential for obstacle detection and navigation (Fahey et al., 2021; Antah, 2021; Lin et al., 2021; Park and Cho, 2020; Pirhonen et al., 2022; Ibrahim et al., 2021). Table 8 provides details for key components of a LiDAR system. \n\nUnlike cameras, LiDAR is less affected by lighting conditions, offering consistent performance at both day and night. Its ability to generate precise 3D models of the environment makes it invaluable for the complex processing required for AV systems. LiDAR offers high spatial resolution and accuracy, which is essential for detailed environment modelling and obstacle detection. Fig. 10 depicts the elements of 3D \nLiDAR, data collection, and the map generation process utilized in one of Google's AV. \n\nHowever, despite its numerous advantages, one of the primary considerations in the adoption of LiDAR technology remains its cost. Historically, the high price of LiDAR systems has been a significant barrier to widespread adoption, particularly in consumer-grade applications. While the cost of LiDAR has indeed dropped significantly in recent years, making it more accessible for a broader range of applications, it remains a substantial investment. The reduction in price is attributed to advancements in manufacturing techniques, economies of scale, and intensified competition among suppliers. Nevertheless, the cost of these systems, especially those offering the highest resolution and longest range required for certain applications such as autonomous driving, can still be prohibitive for many companies and researchers. "}
{"doc332": "| Key components of a LiDAR system.  Component Function  Laser Emits pulses of light to measure distance  Scanner &  Directs the laser beams and gathers the reflected light  Optics  Photodetector Detects the reflected light pulses  Time-of-flight Measures the time taken for the light to travel to the object and  back  Data Processing Translates raw data into a 3D representation of the surrounding  environment   |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n| Table 7  Comparative summary of camera technologies in automotive applications.  Camera Type Key Characteristics Pros   | Cons                                                                                             | Typical Applications                                             |                                                                               |                                                            |\n|-------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------------------|------------------------------------------------------------|\n| Monocular (Gao et al.,  2020, 2023; Li et al.,  2023a)                                                                  | Regulated roads, image  processing, feature  extraction                                          |                                                                  |                                                                               |                                                            |\n| Binocular (Real-Moreno  et al., 2021; Gao et al.,  2023)                                                                | Simple setup, closely matches human  colour perception, advanced algorithms  for depth inference | Low computational  requirements, easy calibration,  simple setup | Lacks native depth perception, less  robust depth compared to stereo  systems | Mobile robot positioning,  navigation, obstacle  avoidance |\n| Fisheye (Mishra et al.,                                                                                                 | Ultra-wide-angle lenses, large field of                                                          | Extensive field of view, useful                                  | May introduce distortion, less detailed                                       | Near-field sensing,                                        |\n| 2022)                                                                                                                   | view, useful for near-field sensing                                                              | for near-field applications                                      | depth perception                                                              | panoramic view  applications                               |\n| Multi-view (Lv et al.,                                                                                                  | Multiple vantage points, high accuracy                                                           | High accuracy, reduced error                                     | Complex algorithms, high                                                      | High precision tasks,                                      |\n| 2021)                                                                                                                   | through reduced matching error                                                                   | in matching                                                      | computation time and power                                                    | complex environments                                       |\n| Utilizes two image sensors for native  depth perception, mimics human  binocular vision                                 | Provides depth perception,                                                                       | Higher computational needs,                                      |                                                                               |                                                            |\n| better for obstacle detection                                                                                           | calibration complexity, complex  disparity interpretation                                        |                                                                  |                                                                               |                                                            |\n\n![9_image_0.png](9_image_0.png)"}
{"doc333": "This economic factor necessitates a careful cost-benefit analysis when considering the implementation of LiDAR technology. \n\nThree principal kinds of LiDAR sensors, categorized as 1D, 2D, and 3D, have applications across various domains (Raj et al., 2020). These sensors generate Point Cloud Data (PCD) in corresponding dimensions, inclusive of the objects' intensity information. In the context of autonomous driving, 64 or 128 channel LiDAR sensors are prevalent for generating high-resolution PCD. These sensors have been summarized in Table 9. \n\nLiDAR technology is a pivotal element in AVs, fulfilling five fundamental functions. For road marking recognition, Solid-State LiDAR is utilized to discern lane indicators and traffic signs, despite challenges with visibility and marking deterioration (Wu et al., 2021; Gannavaram V and Bejgam, 2021). In terms of regulating vehicle speed, for Micro-Electro-Mechanical Systems(MEMS) LiDAR measures distances to adjust speed in response to traffic flow, which can be complicated by the intricacies of traffic (Vutla et al., 2021; Stelzer et al., 2020). Assisted parking is facilitated by Flash LiDAR, which provides accurate spatial data for complex parking tasks, although limited space and high object density can pose difficulties (A. et al., 2021). For collision prevention, Mechanical LiDAR detects imminent obstacles, initiating pre-emptive measures, with challenges arising from sensor integration and response time (Lei et al., 2023). LiDAR technologies grant AVs the ability to safely manoeuvre through complex environments by offering precise, real-time spatial data, underscoring their significance in the progression of AVs. Further information on the specific functions and associated challenges of various LiDAR systems in automotive applications is compiled comprehensively in Table 10. "}
{"doc334": "Fig. 11 showcases the LiDAR Data Processing Sequence. Moving from left to right, the images illustrate a dense LiDAR point cloud, streamlined, and minimized LiDAR data, a point cloud segmented into the roadway and obstructions, and clustered obstructions within the segmented cloud. The prominent dark area in the centre represents the AV. \n\n| Table 10  Functions, descriptions, and challenges of various LiDAR types in automotive  applications.  Function Description Primary LiDAR  Potential  Type  Challenges  Obstacle  Detects and categorizes  Identification  objects such as vehicles,  pedestrians, and other  barriers in real time.  Mechanical Interference,  false positives  Roadway  Marking  Recognition  Solid-State Poor visibility,  wear on  markings  Adaptive Speed  Utilizes distance  Regulation  measurements to adapt  speed according to  traffic conditions.  Analyses and identifies  lane markings, traffic  signals, and road signs.  Micro-ElectroMechanical  Systems  (MEMS)  Traffic  complexity  Assisted  Aids in complex parking  Parking  manoeuvres by  providing precise spatial  measurements.  Flash Space  constraints,  object density  Collision  Helps prevent accidents  Prevention  by sensing objects in the  vehicle's pathway and  taking preventive action.  Mechanical Sensor fusion,  latency   |\n|---|\n\n## 3.3. Radio Detection And Ranging (Radar)"}
{"doc335": "There are various types of RADAR sensors utilized for different purpose of AV, as described in Table 12. \n\nTo achieve comprehensive 360\u25e6 coverage around the vehicle, it is essential to install multiple RADAR sensors at various locations on the \n\n| Overview and applications of different types of LiDAR dimensions.  Type Description   | Application                                                                           |                                                                       |\n|---------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|-----------------------------------------------------------------------|\n| 1D                                                                                    | Provides linear representation of the environment by measuring distance.              | Basic distance measurement applications.                              |\n| LiDAR  2D                                                                             | Provides radial representation of the environment by measuring distance and angle.    | Enhanced spatial understanding, suitable for robotics and automation. |\n| LiDAR  3D                                                                             | Provides a 3D representation of the environment by measuring the distance, angle, and | Comprehensive spatial understanding, ideal for AV and advanced        |\n| LiDAR                                                                                 | elevation.                                                                            | robotics.                                                             |"}
{"doc336": "car. Once the data from all these sensors is collected, it needs to be integrated and processed. Fig. 14 demonstrates the strategic positioning of RADAR sensors on a car to achieve 360\u25e6 coverage. \n\nOne of the most compelling advantages of RADAR is its resilience in challenging conditions such as fog, heavy rain, and darkness situations where optical sensors might struggle due to their reliance on light waves at a reasonable cost (Sun et al., 2020). Yet, despite their robustness in adverse weather conditions, RADAR systems present inherent limitations that impact their performance and application. Primarily, the resolution of RADAR sensors falls short compared to that of LiDAR and optical cameras, limiting their ability to distinguish closely spaced objects or accurately identify smaller obstacles which is a critical consideration in densely populated urban settings. Furthermore, interference among vehicle is a growing concern as the use of RADAR in autonomous vehicles increases. With vehicles often equipped with multiple RADAR \nunits, the risk of these systems interfering with each other escalates, posing a challenge for manufacturers to address, especially given the critical safety functions these RADARs support. \n\n## 3.4. Ultrasonic Sensors"}
{"doc337": "Within the realm of AV, the primary application of ultrasonic sensors is most evident in scenarios requiring meticulous low-speed manoeuvres (Nesti et al., 2023). Their strength lies in their adeptness at discerning objects in close proximity to the vehicle (Manoj et al., 2023). Perhaps one of their most crucial attributes is their independence from light conditions. This ensures that unlike optical systems, ultrasonic sensors maintain consistent performance even under challenging visibility conditions of night time or fog (Mohammed et al., 2020). They typically have a wide field of view, allowing for the detection of objects at various angles relative to the sensor. Fig. 15 illustrates the integration of ultrasonic sensors in the operations of AV. \n\nTable 13 provides an overview of the different types of ultrasonic sensors and their typical applications. \n\nTable 14 below provides a comprehensive overview of various environmental and traffic conditions impact on the performance of ultrasonic sensors in AV. It explains the specific challenges each condition presents to these sensors and illustrates deep learning techniques that can be adapted to mitigate these effects. Additionally, it offers recommendations for further optimizing the performance of ultrasonic sensors under these specific circumstances, ensuring the safe and effective operation of AV in diverse conditions. "}
{"doc338": "## 3.5. Inertial Measurement Units (Imu) Sensors\n\nIMUs, are an integral component in the ever-evolving domain of AV \nto deduce the vehicle's orientation, its velocity, and its position changes (Zhao, 2023). IMU tracks the vehicle's acceleration and rotational rates, in three dimensions X, Y, and Z, contributing to the understanding of vehicle dynamics and movement (Khanum et al., 2023). They are integral for determining the vehicle's orientation and changes in positioning, aiding in accurate localization. Sensor components are made up of IMU sensors which are typically a mix of accelerometers, gyroscopes, and occasionally magnetometers (Abu-Alrub and Rawashdeh, 2023). An interesting capability is that the data from these sensors can be \n\n![11_image_0.png](11_image_0.png)"}
{"doc339": "An IMU can calculate the shifts in position and orientation without needing reference points from outside the system (Seel et al., 2014). Table 15 outlines the characteristics and features of IMU sensors. \n\nIn the context of fusing IMU data with other sensors data for obstacle detection, various combinations can arise. When IMU data is combined with visual inputs from a camera, there is a compensation for visual motion blur. Some potential models that can leverage this combination include multi-modal CNNs and Visual-Inertial Odometry Networks. \n\nMoving to another fusion type, pairing IMU with acoustic information obtained from an ultrasonic sensor can significantly enhance the detection of obstacles that are in close proximity. Models that could potentially benefit from this type of fusion are sequential CNN-RNN \narchitectures. Lastly, when IMU data is integrated with depth information sourced from a depth camera, there is an enhancement in the threedimensional comprehension of an environment. This is particularly useful for detecting changes in elevation. Table 16 details the fusion of IMU data with other sensor modalities for obstacle detection in AV. "}
{"doc340": "| Table 13  Varieties of ultrasonic sensors.  Type Description   | Typical Applications                                                  | Operating                                     | Sensing Range      | Common            |                       |\n|----------------------------------------------------------------|-----------------------------------------------------------------------|-----------------------------------------------|--------------------|-------------------|-----------------------|\n| Frequency                                                      | Manufacturers                                                         |                                               |                    |                   |                       |\n| Proximity Detection                                            | Detect presence or absence of an object based on                      | Detecting products on                         |                    |                   |                       |\n| Ultrasonic Sensors                                             | sound wave reflection.                                                | manufacturing lines, vehicle  parking.        | 40\u201350 kHz          | 2 cm-3m           | SensComp, Parallax    |\n| Distance Measuring                                             | Measure the distance between the sensor and an                        |                                               |                    |                   |                       |\n| Ultrasonic Sensors                                             | object by calculating the time between wave  emission and its return. | Robotics navigation, measuring                | 20\u201340 kHz          | 2 cm-6m           | MaxBotix, PING        |\n| liquid levels, toll booths.                                    |                                                                       |                                               |                    |                   |                       |\n| Ultrasonic Through                                             | Uses a separate sender and receiver. The interruption                 |                                               |                    |                   |                       |\n| Beam Sensors                                                   | of the continuous wave between them indicates an  object's presence.  | Counting items, detecting breaks              | 40\u201360 kHz          | 5 cm-5m           | Keyence, Siemens      |\n| in continuous material flow.                                   |                                                                       |                                               |                    |                   |                       |\n| Ultrasonic Reflective                                          | Detect objects by noting a change in the pattern of                   | Detecting liquid levels,                      |                    |                   |                       |\n| Sensors                                                        | returned ultrasonic waves.                                            | monitoring stack height in  production lines. | 30\u201350 kHz          | 3 cm-4m           | Banner, Turck         |\n| Doppler Effect                                                 | Measure an object's velocity by utilizing the Doppler                 | Measuring flow in pipes, traffic              | 20\u201330 kHz          | Variable based on | Endress + Hauser,     |\n| Ultrasonic Sensors                                             | Shift in the returned wave frequency.                                 | speed monitoring.                             | application        | KROHNE            |                       |\n| Open Structure                                                 | Have an open face for broader beam angles, allowing                   | Complex robotics applications for             | 25\u201345 kHz          | 2 cm-5m           | Pepperl + Fuchs, Sick |\n| Ultrasonic Sensors                                             | a more extensive sensing range.                                       | wider detection angle.                        |                    |                   |                       |\n| Closed Structure                                               | Sensing elements are enclosed in a protective                         |                                               |                    |                   |                       |\n| Ultrasonic Sensors                                             | housing, ideal for environments with dust or  moisture.               | Outdoor or industrial settings                | 30\u201360 kHz          | 2 cm-6m           | Balluff, IFM          |\n| with environmental challenges.                                 |                                                                       |                                               |                    |                   |                       |\n| Analog Output                                                  | Provide continuous analog output representative of                    | Processes requiring exact                     | 20\u201360 kHz          | 2 cm-6m           | Omron, Microsonic     |\n| Ultrasonic Sensors                                             | the distance to the target.                                           | distance tracking.                            |                    |                   |                       |\n| Digital Output                                                 | Offer binary output based on the presence or absence                  | Object detection in assembly                  | 25\u201355 kHz          | 2 cm-5m           | Telemecanique         |\n| Ultrasonic Sensors                                             | of an object within a predetermined range.                            | lines, vehicle parking sensors.               | Sensors, Panasonic |                   |                       |\n\n| Table 14  Ultrasonic sensors in AV: Performance under various conditions.  Condition Performance Impact   | Deep Learning Adaptation                                     | Recommendation                                          |                                        |\n|-----------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|---------------------------------------------------------|----------------------------------------|\n| High Traffic Areas                                                                                        | Frequent detection of obstacles due to the                   | Use neural networks trained on dense traffic scenarios  | Combine ultrasonic data with LiDAR/    |\n| proximity of multiple vehicles.                                                                           | to filter false positives and rank obstacle importance.      | RADAR to improve accuracy.                              |                                        |\n| Low Visibility (Fog, Rain)                                                                                | Moisture can attenuate ultrasonic waves,                     | Deep learning can be used to fuse ultrasonic data with  | Use sensors with protective coatings   |\n| reducing sensor range.                                                                                    | other sensors to compensate for lost information.            | and integrate with cameras.                             |                                        |\n| Tunnel or Enclosed Spaces                                                                                 | Excessive echoes due to close walls may                      | Neural networks trained on tunnel scenarios can         | Apply advanced echo discrimination     |\n| confuse readings.                                                                                         | distinguish between walls and genuine obstacles.             | algorithms.                                             |                                        |\n| Parking & Low-Speed                                                                                       | Increased relevance of ultrasonic sensors for                | Deep learning can enhance precision in determining      | Integrate with cameras for better      |\n| Manoeuvres                                                                                                | detecting close-range obstacles.                             | the exact location and nature of nearby obstacles.      | spatial understanding.                 |\n| Highway or High-Speed                                                                                     | Fast-moving objects might cause a Doppler                    | Neural networks optimized for high-speed scenarios      | Complement with long-range sensors     |\n| Conditions                                                                                                | shift or rapid entry-exit from sensing range.                | can better predict and track fast-moving obstacles.     | like RADAR.                            |\n| Changing Road Surfaces                                                                                    | Different surfaces (asphalt, gravel) can affect              | Use deep learning to adaptively change sensor           | Integrate ultrasonic sensors with road |\n| reflection patterns.                                                                                      | sensitivity based on predicted road surface.                 | surface detection systems.                              |                                        |\n| Near Pedestrians or Cyclists                                                                              | Soft materials (clothing) might absorb more                  | Neural networks can be trained to identify typical      |                                        |\n| ultrasonic waves, reducing reflection.                                                                    | patterns for pedestrians and cyclists, improving  detection. | Fuse ultrasonic data with camera and  infrared sensors. |                                        |\n| During Vehicle-to-Vehicle                                                                                 | Potential for interference from other vehicles'              | Deep learning can identify and filter out interference  | Use frequency-agile ultrasonic sensors |\n| (V2V) Communication                                                                                       | ultrasonic systems.                                          | patterns, focusing on genuine obstacle detection.       | to reduce interference.                |\n\n| Table 15  Characteristics and features of IMU.  Feature Description  Components Accelerometer, Gyroscope, (sometimes) Magnetometer  Measurement Axes Linear acceleration (X, Y, Z); Angular velocity (Pitch, Yaw,  Roll)  Output Frequency Typically, high-frequency, often hundreds to thousands of Hz  Resolution Can vary, but modern IMUs can have very high precision  Latency Generally, very low, suitable for real-time operations  Size & Weight Compact, lightweight - ideal for integration into vehicles  Cost Varied, but many cost-effective solutions available  Energy  Generally low, allowing for extended operation  Consumption   |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|"}
{"doc341": "1. Low-Level Fusion (LLF): LLF, also known as early fusion, combines raw data from various sensors directly, aiming to preserve data richness and enhance object detection and classification (Butt et al., 2022). For instance, a two-stage 3D obstacle detection architecture named 3D-Cross View Fusion (3D-CVF) illustrates LLF by integrating camera and LiDAR data at the raw level to improve obstacle detection accuracy (Yoo et al., 2020). \n\n2. Mid-Level Fusion (MLF): MLF fuses extracted features from different sensors, such as colour from cameras and spatial data from LiDAR that occurs after initial data processing (Anisha et al., 2023). This exploitation of complementary sensor characteristics is exemplified by Yue Li et al., where Symbolic Dynamic Filtering (SDF) integrates low-dimensional features from infrared sensors for dynamic target detection in communication-limited environments (Li et al., 2015). \n\n3. High-Level Fusion (HLF): HLF merges independent sensor decisions or inferences, focusing on the implications of data rather than the data itself (Dai et al., 2020). A noted application involves processing RADAR and LiDAR data separately before fusion through a non-linear Kalman Filter method for enhanced obstacle detection and state tracking (Shahian Jahromi et al., 2019). Preferred for its reduced computational demand, HLF may sometimes underutilize available sensory data. "}
{"doc342": "The integration of multi-modal sensor data through LLF, MLF, and HLF plays a pivotal role in advancing the capabilities of autonomous vehicles. By leveraging LLF, MLF, and HLF, AV systems gain a more accurate, reliable, and comprehensive environmental understanding, which is essential for safe and efficient navigation. \n\n## 4. **A Comprehensive Exploration Of Deep Learning**\n\nDeep learning, considered as an advancement of neural networks, serves as a core element of artificial intelligence and machine learning. The origin of deep learning can be traced back to 1943 when Walter Pitts and Warren McCulloch proposed the idea of Artificial Neural Networks \n(ANN), a model inspired by the operation principles of human neural networks (Rezaei et al., 2023). In modern applications, deep learning has been widely utilized in various fields such as object detection, environmental segmentation and semantic object identification, etc (Rafique et al., 2023). Self-Driving Cars (SDCs) employ a comprehensive suite of algorithms specifically tailored for obstacle detection, which frequently include deep learning methods like CNN, RNN, Deep Belief Networks (DBN), AutoEncoders (AE), You Only Look Once (YOLO), EfficientNets, and DETR (DEtection TRansformer) (Murthy et al., 2020; Sengupta et al., 2020; Abbas et al., 2019; Ma, 2022). For understanding temporal patterns in obstacle movement Long Short-Term Memory (LSTM) networks are used (Song et al., 2020). Generative Adversarial Networks (GANs) augment the primary detection capabilities by simulating potential obstacle scenarios (Aggarwal, 2021). Feature extraction and anomaly detection, essential for spotting unfamiliar obstacles, employ tools like Deep Belief Networks (DBN) (Dargan et al., 2020). "}
{"doc343": "More advanced neural techniques that contextualize obstacles, including Siamese Neural Networks, Transformers, Capsule Networks \n(CapsNet), and Vision Transformers (ViT), provide a holistic view of the vehicle's surroundings (Kang et al., 2022; Dulian and Murray, 2021; Itu and Danescu, 2022; Jeong et al., 2020). When crafting solutions for AVs, a combination of these algorithms often delivers optimal performance. Fig. 18 illustrates network designs used for obstacle recognition in AVs. \n\nCNNs play a significant role in AV proficiency by extracting key features from sensor data through convolution, excelling in tasks like image recognition and object segmentation (Triki, 2021). R-CNNs, an extension of CNNs, specialize in obstacle detection and localization in AVs. They segment an input image into region proposals, classify them, and localize detected objects, adapting to sensor data variability (Othmani, 2022). Fast R-CNNs improve computational efficiency by processing the entire image once to create a feature map, reducing the load and time for real-time AV obstacle detection (Mostafa et al., 2022; Ghosh, 2021). Faster R-CNNs further enhance this by integrating a Region Proposal Network (RPN), which generates region proposals within \n\n| Table 17  Comparative overview of sensor fusion levels in autonomous vehicles.  Sensor  Advantages Drawbacks Typical  Fusion Level  Applications  Low-Level  Fusion (  Butt et al.,  2022; Yoo  et al.,  2020)  3D obstacle  detection,  enhanced  environmental  modelling.  Mid-Level  Fusion (  Anisha  et al.,  2023; Li  et al.,  2015)  Maximizes data  richness, enhancing  detection accuracy.  High  computational  demand, precise  sensor calibration  needed.  Balances  computational load,  exploiting  complementary  sensor traits.  Potential loss of  raw data details,  requires effective  feature extraction.  Dynamic target  detection, object  classification.  High-Level  Fusion (  Dai et al.,  2020;(  Shahian  Jahromi  et al.,  2019)  Lower  computational  complexity; utilizes  independent sensor  decisions.  Risks discarding  valuable data by  focusing on highlevel decisions.  State tracking,  obstacle detection  with advanced  filtering methods.   |\n|---|"}
{"doc344": "the network, allowing for real-time obstacle detection ( Othmani, 2022 ;\nMasita et al., 2020 ; Mohamed et al., 2020 ). RNNs, designed for sequential data, utilize their memory feature to process time-series data small or overlapping objects ( Strbac et al., 2020 ; Sarda et al., 2021 ;\n\u00b4orovi\u00b4c et al., 2018 ; Zhao et al., 2019 ; Terven and Cordova-Esparza, 2023 ; A. N and U. S. V, 2021 ). These algorithms collectively enhance obstacle detection and navigation in AVs, showcasing their potential in this domain. GANs and YOLO are instrumental in generating and detecting real-time images, respectively, essential for immediate obstacle identification. Siamese Neural Networks, effective at input comparison, are key in distinguishing obstacles from non-obstacles, enhancing the AV's response accuracy. ViTs, employing self-attention, efficiently detect irregular or small obstacles, crucial for comprehensive environmental perception. EfficientNets, balancing accuracy and computational efficiency, are integral in maintaining real-time processing in AV systems. DETR and AEs further contribute to object detection and data noise reduction, respectively, refining the overall sensory interpretation ( Tang et al., 2021 ; Wang et al., 2022b ; Mujkic et al., 2022 ). These algorithms' diverse and impactful roles are detailed in Table 18 and the subsequent subsections.\n\n## 4.1. Transformer Networks\n\nIntroduced by Vaswani et al., the Transformer neural network is a pioneering architecture, specifically designed for intricate sequential data interpretation (Vaswani et al., 2017). Their application in adaptive obstacle detection in AVs is particularly notable, handling large volumes of sensor-fused data efficiently (Yuan et al., 2022). These networks stand out with their unique self-attention and multi-head attention mechanisms, enabling them to unravel intricate relationships within input sequences, thereby enhancing obstacle detection accuracy in dynamic driving conditions (Hu et al., 2022; Zhang et al., 2023b). A key advantage of Transformers over traditional RNNs and LSTMs is their ability to process data in parallel rather than sequential processing. This feature is crucial for AVs, providing a speed advantage essential for real-time decision-making in rapidly changing road scenarios. Transformers are highly scalable and flexible, capable of learning from extensive data and being employed in an end-to-end manner. This reduces the need for extensive pre-processing and feature engineering and allows them to "}
{"doc345": "| Table 18  Summary of different deep learning algorithms.  Algorithm Primary Characteristics   | Applications                                                                                                                                                      |                                                                             |\n|-----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n| Convolutional  Neural Networks  (CNNs)                                                        | Image and video  recognition, autonomous  driving, medical imaging                                                                                                |                                                                             |\n| Recurrent Neural                                                                              | Suited for sequential data as                                                                                                                                     | Natural language                                                            |\n| Networks (RNNs)                                                                               | it has a \"memory\" effect                                                                                                                                          | processing, speech  recognition, time series  prediction                    |\n| Long Short-Term                                                                               | A type of RNN that mitigates                                                                                                                                      |                                                                             |\n| Memory (LSTM)                                                                                 | the \"vanishing gradient\"  problem, allowing it to learn  long sequences  Excellent for image  recognition tasks, uses  convolution operation to  extract features | Text generation, machine  translation, time series  analysis                |\n| Generative  Adversarial  Networks (GANs)                                                      | Image generation, superresolution, image-to-image  translation                                                                                                                                                                   |                                                                             |\n| You Only Look                                                                                 | Real-time object detection                                                                                                                                        |                                                                             |\n| Once (YOLO)                                                                                   | system that recognizes  multiple objects in a single  glance  Consists of two networks  competing against each other  to improve results                          | Object detection in images,  video recognition,  autonomous driving         |\n| Siamese Neural                                                                                | Learns to differentiate                                                                                                                                           |                                                                             |\n| Networks                                                                                      | between two inputs;  excellent for tasks that  involve comparing  similarities or differences                                                                     | One-shot learning, face  recognition, signature  verification               |\n| Transformers                                                                                  | Uses attention mechanisms  that weigh the significance of  different elements in the  input data                                                                  | Machine translation, text  summarization, speech  recognition               |\n| Capsule Networks                                                                              | Uses dynamic routing to                                                                                                                                           |                                                                             |\n| (CapsNet)                                                                                     | model hierarchical  relationships in data                                                                                                                         | Object segmentation, image  recognition, pose  estimation                   |\n| Vision  Transformers  (ViT)                                                                   | Applies transformer  architectures to visual data,  representing an image as a  sequence of patches                                                               | Image recognition,  computer vision tasks                                   |\n| EfficientNets                                                                                 | Uses a scaling method that  uniformly scales all  dimensions of depth/width/  resolution using a simple yet  effective compound  coefficient                      | Image classification, object  detection, transfer learning                  |\n| DETR (DEtection                                                                               | Directly predicts the final set                                                                                                                                   |                                                                             |\n| TRansformer)                                                                                  | of detections, eliminating the  need for complex anchor or  proposal systems                                                                                      | Object detection, panoptic  segmentation                                    |\n| Deep Belief                                                                                   | Generative deep learning                                                                                                                                          |                                                                             |\n| Networks (DBN)                                                                                | model composed of multiple  layers of latent variables                                                                                                            | Image recognition, motion  capture data classification,  document retrieval |\n| Autoencoders (AE)                                                                             | Self-supervised learning  method used for learning  efficient codings of the input  data                                                                          | Dimensionality reduction,  anomaly detection,  denoising data               |\n\nintegrate diverse data types, like camera images and LiDAR point clouds, for a comprehensive environmental understanding. Despite their advantages, Transformers' computational intensity can be a constraint in resource-limited settings. This challenge demands ongoing research to develop more efficient Transformer variants, optimizing their application in AVs for enhanced real-time, adaptive obstacle detection. \n\n## 4.2. Generative Adversarial Networks (Gans)"}
{"doc346": "In 2014, Goodfellow et al. introduced Generative Adversarial Networks (GANs) (Xie et al., 2021). GANs hold significant potential for improving the development and functionality of AV by generating realistic synthetic data, essential for training DL models (Menke et al., 2022). They provide an efficient solution to the challenges of collecting and annotating extensive real-world driving data, creating diverse traffic scenarios for comprehensive AV system training. In sensor data processing, GANs facilitate the conversion of complex inputs into more interpretable formats, improving AV systems' environmental understanding. For obstacle detection, GANs enrich training datasets with varied obstacle representations under different conditions, enhancing the robustness of detection systems. This capability improves detection accuracy and reliability. \n\n## 4.3. Spatial Pyramid Pooling Networks (Spp-Net)\n\nSPP-nets represent a major advancement in AV technology, enabling CNNs to process images of varying sizes (Dewi et al., 2020). Traditional CNNs require fixed-size input images where sensor-captured scenes vary widely. SPP-nets overcome this by introducing a pooling layer that converts feature maps of any size into a fixed-length representation, preserving the original aspect ratios of input images (Wang et al., 2020). "}
{"doc347": "This capability is crucial in AV for maintaining accurate spatial relationships in a scene, such as the distances between obstacles, vital for safe navigation. SPP-nets generate fixed-size outputs from varied input sizes, allowing seamless integration with fully connected layers for crucial classification or regression tasks in complex driving scenarios \n(Park et al., 2018b). SPP-nets facilitate the conversion of diverse sensor data into standardized feature representations, enhancing the effectiveness of data integration. This leads to a more complete and coherent perception of the environment. In obstacle detection, SPP-nets effectively manage objects of different sizes and aspect ratios in the input images, which is crucial for recognizing potential hazards like pedestrians, vehicles, or unforeseen road obstructions. These networks preserve the hierarchical spatial relationships of objects, thereby enhancing the accuracy of object localization and classification. This ensures that autonomous vehicles respond correctly to dynamic and unpredictable road conditions. Fig. 19 depicts the architecture of an SPP-net. \n\n## 4.4. Single Shot Multibox Detector (Ssd)\n\nThe Single Shot Multibox Detector (SSD) algorithm plays a pivotal role in AVs due to its ability to detect objects in real time with high accuracy. Its unique approach, which involves performing detection in a single forward pass, eliminates the need for a separate region proposal phase, traditionally a bottleneck in the detection process. This efficiency is crucial in autonomous driving, where rapid response to environmental changes is vital for safety. The MultiBox feature of the SSD enables it to predict a variety of bounding box shapes and sizes at each feature map location, catering to the wide range of object sizes and aspect ratios found in driving scenarios, from distant pedestrians to large vehicles in close proximity. This adaptability is essential for coping with the variability of real-world scenes. The architecture of the SSD is specifically designed to fulfil the unique demands of real-time, accurate, and efficient object detection in AVs, making it a key component in obstacle detection and navigation (Xu et al., 2021). Its ongoing development holds promise for further enhancing its robustness and effectiveness in "}
{"doc348": "DBNs, a class of generative probabilistic models with multiple layers of stochastic variables, are integral in AV ( Iftikhar et al., 2022 ). Their ability to learn complex data representations is crucial for AVs, which process high-dimensional and noisy sensory inputs ( Dairi et al., 2018 ). DBNs efficiently encode raw sensory data into compact, abstract representations, reducing dimensionality and emphasizing salient features. This aids in simplifying decision-making and control tasks in AVs, such as identifying critical road features for safe driving decisions. The probabilistic nature of DBNs equips them to manage sensor data uncertainty and noise, ensuring robust and reliable perception under various conditions. Recent advancements have merged DBNs with other sensor data like LiDAR and RADAR, enhancing obstacle detection and classification capabilities ( Bayoudh et al., 2021 ). This fusion provides a comprehensive environmental understanding, crucial for AV safety and efficiency. Overall, DBNs' contribution to AV obstacle detection is significant, offering a potent approach to complex sensor data processing.\n\nFig. 21 illustrates DBNs' structure and functionality.\n\n## 4.6. Autoencoders (Aes)"}
{"doc349": "vehicle positions and pedestrian locations are preserved despite the reduced dimensionality. This is vital for the safe navigation of AVs. Along with this, utilizing AEs in AVs is a strategic method for managing complex, high-dimensional, and noisy data, which is indispensable for effective operation. Variational Autoencoders (VAEs), a variant of AEs, incorporate probabilistic aspects into autoencoding (Azzalini et al., \n2021; Jagadish et al., 2021; Azizpour et al., 2020). This is particularly useful for generating new data, such as training data for simulating environments in AV robustness testing. The integration of AEs with CNNs and RNNs in AVs harnesses their combined strengths: AEs for data compression, CNNs for spatial pattern recognition, and RNNs for processing sequential data and capturing temporal dependencies. This combination creates a powerful system that enhances the vehicle's real-time data processing and decision-making capabilities. Fig. 22 provides a visual representation of an AE model, illustrating its symmetrical encoder and decoder structures, with \"X\" representing the input and \"X^\" the reconstructed output. \n\n## 4.7. Detection Transformer (Detr)\n\nDETR (DEtection TRansformer) is a novel, end-to-end trainable architecture for object detection in AVs, notable for its simplicity and efficiency, as depicted in Fig. 23. It eliminates the need for complex components such as region proposals and non-maximum suppression, which are common in traditional models. This streamlining enables faster and more efficient visual data processing, crucial for real-time decision-making in dynamic AV environments. DETR employs a global attention mechanism to consider the entire scene, improving object detection, especially in complex environments like busy urban areas. "}
{"doc350": "Additionally, DETR is versatile, extending its capabilities to tasks like instance segmentation, providing detailed environmental understanding essential for safe AV navigation. Its architecture also enhances interpretability, a key factor in AV development and compliance with safety standards, by facilitating easier traceability of model decisions (Chromiak, 2021). DETR's approach represents a significant advancement in object detection technology for autonomous driving applications. \n\nVision Transformers (ViT) are becoming increasingly important in AV systems for their ability to encode long-range spatial dependencies in visual data, essential for navigating complex environments (Kang et al., \n2022). Their self-attention mechanism enables the model to assess the significance of various parts of an input image, regardless of their spatial proximity. This allows AVs to recognize distant pedestrians as crucial as closer ones, providing a level of global context awareness that traditional CNNs, with their local receptive fields, find challenging \n(El-Ghamry et al., 2023). The parallel processing capability of ViTs, enhancing training efficiency, is another significant advantage (Diaz-Chito et al., 2016). AV systems necessitate training on large, \n\n![17_image_1.png](17_image_1.png)"}
{"doc351": "SNNs are pivotal in the AV industry, excelling in similarity comparison tasks like object tracking and detection (Nandy et al., 2020). In autonomous driving, they compare sensory input data, like camera images or LIDAR point clouds, against established references, enhancing context-aware understanding of surroundings. For instance, SNNs effectively track objects within a scene, adapting to appearance changes or occlusions by comparing new inputs with previous references (Luo et al., 2022). This function is critical in dynamic urban environments for consistent object identification and safe navigation. Utilizing a twin-like structure, SNNs differentiate between similar and dissimilar pairs, producing embeddings where similar objects are closely aligned in the embedded space (Hayale et al., 2023). This ability is crucial for distinguishing between superficially similar but functionally distinct objects, such as differentiating between stationary and merging vehicles. \n\nThe development of advanced variants like triplet networks, which compare an anchor input with both similar and dissimilar inputs, further enhances differentiation learning (Serrano et al., 2023). These advancements are driving richer environmental understanding and improved obstacle detection for AVs. Fig. 25 provides a visual representation of the SNNs model. \n\n![18_image_0.png](18_image_0.png)"}
{"doc352": "![18_image_1.png](18_image_1.png)\n\nautonomous vehicles, a meticulous data preprocessing sequence is essential to refine the raw inputs for enhanced perception and decisionmaking capabilities. This sequence commences with the data cleaning stage, a critical process aimed at rectifying cluttered and noisy data through noise reduction techniques such as Gaussian and median filtering, effectively minimizing random noise. Statistical methods further aid in outlier detection and removal, thus preparing the dataset for subsequent stages (Qi et al., 2020). \n\nCalibration procedures are then undertaken to reconcile the data from various sensors to a uniform physical frame of reference, crucial for mitigating discrepancies and ensuring data integrity. The data fusion phase encompasses temporal and spatial alignment, synchronizing data streams to a common timeframe and transforming disparate data to a unified coordinate system. Techniques like Kalman or particle filtering are then employed to synthesize the cleaned data, enhancing the overall situational awareness through a composite environmental representation (Chen et al). For example, the spatial precision of LiDAR data is enriched with the colour depth from cameras, culminating in a richer data mosaic. The subsequent feature engineering stage involves the extraction of relevant features imperative for tasks such as obstacle detection. This is accomplished through edge detection, texture analysis, and other such techniques. Dimensionality reduction methods like "}
{"doc353": "## 20\n\nPrincipal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) refine the feature set, retaining only those of utmost relevance, thereby optimizing computational efficiency and model performance (El-Ghamry et al., 2023; Diaz-Chito et al., 2016). Data augmentation techniques, including image flipping and rotation, supplement the dataset with varied perspectives, supporting the model's ability to generalize from the training data. Data formatting, the final step in the preprocessing pipeline, ensures that the dataset is aptly structured for the application of deep learning models. This encompasses normalization practices such as Min-Max scaling or Z-score normalization, which standardize feature scales, and data batching, which segments the data into optimal portions for the learning process (Abdennour et al., 2021). 5.2. *Sensor fusion technique and data combination for obstacle detection* Sensor fusion, an integral and complex component of AV development, plays a vital role in enhancing system robustness and dependability. The inception of multi-sensor data fusion is attributed to the Joint Directors of Laboratories (JDL) framework, which describes it as a complex, multi-level process encompassing the automated detection, association, correlation, estimation, and integration of data from multiple sources (White, 1991). Fig. 26 provides a cohesive environmental perception by integrating data from various sensors, such as cameras, RADARs, LiDAR, and ultrasonic devices. This harmonization is essential for creating a multidimensional understanding of the surroundings. The main advantage of sensor fusion is its ability to validate data from multiple sources, minimizing errors when, for example, a camera misinterprets distances in low visibility, while RADAR and LiDAR provide accurate measurements. \n\nThe efficacy of sensor fusion is further demonstrated in diverse weather conditions. In fog, where visibility is low, and signal diffraction is significant, combining data from LiDAR, RADAR, and thermal cameras through advanced filtering and adaptive algorithms is critical for maintaining safety. Rainy conditions, which introduce reflection and scattering challenges, are countered by the use of LiDAR, RADAR, and weather sensors that employ adaptive methods for error correction, enhancing decision-making processes. Snow and wind present their unique obstacles, with snow causing occlusions and altering road textures, and wind affecting sensor noise and vibration. These are managed through multi-sensor calibration, dynamic thresholding, noise filtering, and robust estimation techniques to ensure stability and accurate vehicle control. Table 19 discusses the sensor fusion techniques used under various weather conditions. "}
{"doc354": "Sensor fusion techniques can be organized according to the origin of data, with multimodal fusion being a primary category. This technique combines data from various sensors to harness their collective strengths, significantly enhancing system capabilities beyond what any single sensor could achieve. This approach is critical for ensuring that the integration of data from diverse modalities addresses the limitations inherent in individual sensors. By prioritizing consistency in data alignment from various modalities, complementarity by diminishing uncertainties, and compatibility of algorithmic approaches, data structures, and specific tasks involved when integrating data from diverse modalities, multimodal fusion aims to produce outputs that are coherent, comprehensive, and highly reliable. Through such strategic data integration, systems become more accurate, robust, and adaptable, capable of delivering superior performance across a wide range of applications. \n\nHistorically, sensor fusion relied on traditional methods such as Kalman filters and Bayesian networks, effective yet limited in adaptability, which has been detailed in Table 20 (Chen et al); Ounoughi and Yahia, 2023). However, with the advent of deep learning, a paradigm shift occurred, leading to more detailed obstacle understanding and improved adaptability in changing environments. Unlike traditional methods that follow set algorithms, deep learning-enabled systems learn from data, adapt to new scenarios, and improve over time. This adaptability makes them especially valuable in scenarios where the environment is constantly changing, like on busy roads with unpredictable elements. Sensor fusion strategies span from Early Fusion, integrating raw data at the start, to Late Fusion, combining processed data at the decision level, and Hybrid Fusion, which merges both strategies, as discussed in section 4.6. The comparison of sensor fusion strategies has been mentioned in Fig. 27. \n\n## 5.3. Deep Learning Based Sensor Fusion Technique For Obstacle Detection"}
{"doc355": "As AVs continue to advance, the fusion of sensory data becomes increasingly complex and vital for accurate environmental perception and decision-making. Deep learning has emerged as a transformative force in this space, providing sophisticated methods to synthesize and interpret the diverse streams of data captured by an AV's array of sensors. These methods enable vehicles to transcend the limitations of individual sensors, offering a composite and detailed understanding of the surroundings that is crucial for safe navigation. For instance, CNNs excel in interpreting visual data from cameras, while RNNs and LSTMs process sequential data from RADAR and LiDAR, making sense of temporal sequences and spatial contexts (Shin and Su, 2020). Fusion strategies are chosen based on the requirement, with some models employing early fusion to integrate raw data at the start of the processing pipeline, others using late fusion to combine insights after individual processing, and still others utilizing a hybrid approach to benefit from both strategies. In the context of AVs, Z. Huang et al.'s research presents a deep neural network model that performs early fusion by taking visual and depth data to provide a detailed semantic segmentation for scene understanding, alongside controlling vehicle actions like steering and speed. \n\nThe model's success in simulated urban environments demonstrates its potential, achieving a significant success rate in static navigation tasks and outperforming existing benchmarks (Huang et al., 2022). Arnav Vaibhav Malawade's work introduces \"HydraFusion\", an innovative context-aware sensor fusion technique that selectively integrates sensor data, considering the driving context to enhance the robustness of AV perception systems. This method optimizes the use of computational resources on energy-constrained AV platforms, demonstrating its practical applicability on an industry-standard hardware platform and showcasing improved performance in real-world conditions (Malawade et al., 2022). Fig. 27 illustrates a comparison of results obtained from individual sensors followed by those obtained through HydraFusion. \n\nTable 21 provides a succinct overview of deep learning fusion techniques, their key features, and applications in the realm of AV \ntechnology. "}
{"doc356": "The transformative impact of sensor fusion on AV functions is outlined in Table 22. It presents the positive effects and potential drawbacks of sensor fusion across various AV functions, such as object detection, collision avoidance, adaptive speed control, navigation, mapping, human-machine interaction, traffic sign recognition, lane keeping, and vehicle-to-vehicle (V2V) & vehicle-to-infrastructure (V2I) communication. Each function involves different sensor combinations, highlighting the complexity and multifaceted nature of sensor fusion within the AV \nlandscape. \n\nContinuing the discourse on deep learning in AVs, the performance of sensor fusion techniques is critically appraised using specific evaluation metrics. These metrics are indispensable for assessing the accuracy and reliability of obstacle detection systems, which are central to the safety and functionality of AVs. Table 23 delineates these key evaluation metrics, starting with the Intersection over Union (IoU), which quantifies the accuracy of the obstacle localization by measuring the overlap between predicted and actual bounding boxes. precision and recall are fundamental metrics that respectively measure the correctness of positive predictions and the system's capacity to detect all actual obstacles. \n\nThe Mean Average Precision (mAP) provides a comprehensive performance indicator by averaging the precision across all categories of obstacles, offering an overall effectiveness score of the detection system. "}
{"doc357": "Data Cleaning Dataset cleaning and refinement Data Clean-up: Filtering noise improves data accuracy Confirm detections and remove false Standardise Data: facilitates smooth inclusion Sync sensor data for consistency Create a combined dataset for analysis Decision Making & Output l l l l l l l l l l l l l l positives l l l l l l l l l l l l\n\n| Table 19  Sensor fusion techniques in different weather conditions.  Weather Condition Challenging Factors   | Required Sensors                | Fusion Techniques        | Impact on AV Performance           |                                    |\n|--------------------------------------------------------------------------------------------------------------|---------------------------------|--------------------------|------------------------------------|------------------------------------|\n| Fog (Manjunatha et al., 2023)                                                                                | Reduced visibility, Diffraction | LIDAR, RADAR, Thermal    | Enhanced filtering, Adaptive       | Maintain safety and accuracy       |\n| of signals                                                                                                   | Camera                          | algorithms               |                                    |                                    |\n| Snow/Ice (de Araujo et al., 2023)                                                                            | Occlusion, Reflection, Altered  | LIDAR, RADAR, Thermal    | Multisensor calibration, Dynamic   | Ensure proper navigation and       |\n| road texture                                                                                                 | Camera                          | thresholding             | control                            |                                    |\n| Rain (Hasanujjaman et al., 2023)                                                                             | Reflection, Absorption,         | LIDAR, RADAR, Weather    | Weather-adaptive methods, Error    | Minimize false detections and      |\n| Scattering                                                                                                   | sensors                         | correction               | optimize response                  |                                    |\n| Sand/Dust Storm (Hasanujjaman                                                                                | Reduced visibility, Abrasion    | LIDAR, RADAR, Protective | Vision enhancement, Particle       | Maintain operability and safeguard |\n| et al., 2023)                                                                                                | measures                        | filtering                | equipment                          |                                    |\n| Wind (Zhang et al., 2023a)                                                                                   | Sensor noise, Vibration         | Anemometers, LIDAR,      | Noise filtering, Robust estimation | Stabilize control and enhance      |\n| RADAR                                                                                                        | handling                        |                          |                                    |                                    |\n\n| Overview of traditional sensor fusion approaches in AV (Fayyad et al., 2020).  Method Description Strengths   | Limitations                      | Typical Use                      | Fusion Level                       |                         |           |\n|---------------------------------------------------------------------------------------------------------------|----------------------------------|----------------------------------|------------------------------------|-------------------------|-----------|\n| Statistical                                                                                                   | Apply statistical models to      | Unknown correlation handling;    | Restricted to linear models;       | Estimation Processes    | Low       |\n| Techniques                                                                                                    | structure sensory data           | Tolerance                        | Computationally intense            |                         |           |\n| Probabilistic                                                                                                 | Utilize probability for sensory  | Manages uncertainty; Handles     | Needs prior system model           | Estimation/             | Low to    |\n| Strategies                                                                                                    | information                      | nonlinear systems                | knowledge                          | Classification          | Medium    |\n| Knowledge-based                                                                                               | Emulate human-like               | Addresses Uncertainty; Manages   | Relies on specific expertise and   | Classification/Decision | Medium to |\n| Models                                                                                                        | intelligence mechanisms          | nonlinear systems                | knowledge extraction               | Making                  | High      |\n| Evidence                                                                                                      | Implement Dempster's             | Assesses uncertainty; Identifies | High computational needs; Assumes  | Decision Making         | High      |\n| Reasoning                                                                                                     | combination mechanism            | conflicts                        | evidence                           |                         |           |\n| Interval Analysis                                                                                             | Divides the operating space into | Guarantees integrity; Complex    | Discretizes space; Computationally | Estimation Processes    | Low       |\n| Theory                                                                                                        | intervals                        | nonlinear system handling        | complex                            |                         |           |"}
{"doc358": "![21_image_0.png](21_image_0.png)\n\nThese metrics collectively form the basis for a rigorous evaluation framework for AV obstacle detection capabilities. \n\nTo train and validate these sophisticated detection models, a collection of diverse datasets is employed. PASCAL VOC 2007/2012 and Microsoft COCO are pivotal datasets for multi-class object recognition, providing a variety of scenarios to refine models for particular obstacle types and complexities encountered in the real world. Specialized datasets like KITTI and the Waymo Open Dataset offer extensive sensor data and realistic driving conditions that are integral to developing robust and adaptable obstacle detection models. ModelNet and SceneFlow contribute to the training process by focusing on 3D object recognition and depth perception, aiding models in predicting threedimensional object attributes and spatial relationships. Table 24 presents a comparison of these datasets, highlighting their unique characteristics and contributions to model training. This diverse array of datasets ensures that obstacle detection models are well-rounded and capable of performing reliably across a spectrum of real-world conditions and scenarios, ultimately contributing to the advancement of autonomous vehicle technologies. These datasets, combined with the deep learning techniques outlined earlier, form a comprehensive ecosystem for the development and evaluation of cutting-edge sensor fusion systems in AVs. "}
{"doc359": "## 6. **Challenges And Future Directions**\n\nFuture research trends in multi-sensor data processing for obstacle detection in AVs are expected to be diverse and multidisciplinary. To tackle these issues comprehensively, Table 25 explores the challenges \n\n| Table 21  Deep learning approaches for sensor fusion in AV.  Approach/  Primary Purpose  Components or   | Applications or                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                          |                                                                                                  |\n|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n| Technique                                                                                                | or Mechanism                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Key Features                                                                             | Benefits                                                                                         |\n| FusionNet (  Subramani  et al., 2021)                                                                    | also trustworthy and verifiable, paving the way for their widespread  adoption and enhanced performance in diverse conditions.  Emphasizing machine learning, future directions involve developing  automated calibration and synchronization of various sensors, employing techniques like unsupervised and reinforcement learning to mitigate  variance in sensor readings and temporal misalignments. This  advancement would enhance the accuracy and reliability of environment perception. To combat the influence of environmental changes,  research is likely to focus on deep learning models that are resilient to  variations in lighting and weather, leveraging transfer learning, domain  adaptation, and data augmentation to maintain consistent AV performance. This approach will aim to provide robustness against electronic  interference and the dynamism of driving scenarios. The issue of sensor  noise and outliers, which can lead to false detections and impact safety,  is another area for innovation. The integration of advanced statistical  models and artificial intelligence for outlier detection promises to refine  data interpretation, thereby reducing the occurrence of false positives  and negatives. Processing the high-dimensional data generated by AV  sensors in a timely manner remains a critical requirement. Future  research is likely to invest in edge computing, hardware optimization,  and efficient deep learning architectures to process massive data streams                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                          |                                                                                                  |\n| Handles diverse  sensors like RGB,  LiDAR; Hierarchical  feature extraction &  data integration          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                          |                                                                                                  |\n| Multi-modal  Neural  Networks (  Schneider  et al., 2017)                                                | Sensor Data                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Convolutional                                                                            |                                                                                                  |\n| Fusion                                                                                                   | Layers, Fusion  Layers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Processes multiple  data types  concurrently;  Captures peculiarities  of each data type |                                                                                                  |\n| Sensor Fusion  Transformer (  Chitta et al.,  2022)                                                      | Multi-sensor  Data  Management                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Separate Initial  Layers, Fusion  Layers                                                 | Correlates data from  different sensors;  Handles sequential  data with positional  significance |\n| Transfer  Learning (Li  et al., 2020)                                                                    | Inter-sensor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Self-attention,                                                                          |                                                                                                  |\n| Relationships                                                                                            | Positional  Encodings  Depends on                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Benefits scenarios                                                                       |                                                                                                  |\n| source model                                                                                             | with limited labelled  data; Speeds up  training & potentially  improves  performance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |                                                                                          |                                                                                                  |\n| GANs  (Generative  Adversarial  Networks) (Li  et al., 2023b)                                            | Domain  Knowledge  Transfer  Synthetic Sensor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Generator,                                                                               | Augments training                                                                                |\n| Data Generation                                                                                          | Discriminator                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | datasets; Ensures  high-quality  synthetic samples                                       |                                                                                                  |\n| VAEs  (Variational  AutoEncoders) (Li  et al., 2023b)                                                                                                          | Table 23  Key Evaluation Metrics in Obstacle Detection using sensor fused data.  Evaluation Metrics Description  Intersection over Union  A quantification of the overlap between the actual and  (IoU)  predicted bounding boxes for obstacles, ranging from  0 to 1.  Predictions Categorizes detections into True Positives (TP), False  Negatives (FN), and False Positives (FP), with IoU  calculated for each bounding box.  Precision Reflects how often the detector's predictions about  obstacles were correct, also known as the positive  predictive value.  Recall Represents the system's ability to accurately detect the  obstacles that are verified as ground truth.  Precision x Recall Curve A graphical representation that contrasts recall against  precision, seeking a point as close to (1.0, 1.0) as  possible, representing both high recall and precision for  obstacle detection.  Average Precision (AP) Provides an aggregated measure of precision across 11  uniformly spaced recall points for obstacles, computed  through interpolation of the precision values above a  specific recall threshold.  Mean Average Precision  Averages the AP across all categories of obstacles  (mAP)  present within a dataset.  Average Orientation  Assesses the ability of obstacle detection systems in  Similarity (AOS)  pinpointing obstacles and estimating their 3D  orientation.  Mean IoU (mIoU) Derives an average IoU for each type of obstacle within  a category, defaulting to 1 if no overlap is found  between the predictions and ground truth coordinates. |                                                                                          |                                                                                                  |\n| Produces compact  representations;  Generates new  samples & detects  anomalies                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                          |                                                                                                  |\n| Attention  Mechanisms (  Paigwar et al.,  2019)                                                          | Data  Representation  & Generation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Compression &  Generation  Mechanisms                                                    |                                                                                                  |\n| Dynamic Input                                                                                            | Varies with                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Emphasizes on more                                                                       |                                                                                                  |\n| Weighting                                                                                                | architecture                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | pertinent sensors;  Adjusts based on  reliability or  relevance of sensors               |                                                                                                  |\n| Autoencoders (  Ohashi et al.,  2021)                                                                    | Data  Dimensionality  Reduction                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Bottleneck                                                                               | Reduces noise and                                                                                |\n| Architecture                                                                                             | redundancy; Retains  crucial features for  obstacle detection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                          |                                                                                                  |\n| and potential research directions in multi-sensor data processing for  AVs.  Key areas include the development of advanced sensor fusion algorithms leveraging machine learning to integrate data from various sensors more effectively, innovation in sensor technologies to enhance  detection capabilities, utilization of synthetic and augmented datasets  for robust model training, and the exploration of collaborative sensing  techniques for shared situational awareness. Additionally, focusing on  edge computing for real-time data processing and advancing model  explainability will ensure these systems are not only more efficient but                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                          |                                                                                                  |"}
{"doc360": "| Table 22  Impact of sensor fusion on key autonomous vehicle functions.  AV Function Primary Sensors Involved   | Fusion Techniques          | Positive Impact            | Potential Drawbacks               |                                  |\n|----------------------------------------------------------------------------------------------------------------|----------------------------|----------------------------|-----------------------------------|----------------------------------|\n| Object Detection & Collision Avoidance (                                                                       | LIDAR, RADAR, Cameras      | Multisensor Integration    | Improved detection accuracy;      | Complexity; Cost                 |\n| Kotur et al., 2021)                                                                                            | Real-time response         |                            |                                   |                                  |\n| Adaptive Speed Control (Liu et al., 2023)                                                                      | RADAR, GPS, Cameras        | Predictive Algorithms      | Smooth speed adjustments; Fuel    | Computation overhead;            |\n| efficiency                                                                                                     | Calibration needs          |                            |                                   |                                  |\n| Navigation & Mapping (Yan et al., 2023)                                                                        | GPS, LIDAR, Inertial Units | Map Matching; SLAM         | Precise localization; Robust path | Need for frequent updates; Map   |\n| planning                                                                                                       | accuracy                   |                            |                                   |                                  |\n| Human-Machine Interaction (Ghorbel                                                                             | Cameras, Microphones       | Multimodal Fusion          | Intuitive interaction; Enhanced   | Privacy concerns; Integration    |\n| et al., 2019)                                                                                                  | safety alerts              | challenges                 |                                   |                                  |\n| Traffic Sign Recognition (Mu et al., 2015)                                                                     | Cameras, LIDAR, Optical    | Image Recognition; Machine | Accurate recognition and          | Dependence on clear visuals;     |\n| Sensors                                                                                                        | Learning                   | compliance                 | Maintenance                       |                                  |\n| Lane Keeping (Biparva et al., 2022)                                                                            | Cameras, LIDAR, RADAR      | Tracking Algorithms; PID   | Enhanced stability and control in | Sensitivity to lane markings;    |\n| Control                                                                                                        | lane                       | Complexity                 |                                   |                                  |\n| V2V & V2I Communication (Khan et al.,                                                                          | Various sensors, DSRC,     | Protocol Integration;      | Improved coordination and traffic | Security risks; Interoperability |\n| 2022)                                                                                                          | Cellular networks          | Security measures          | efficiency                        | issues                           |\n\n23\n\n| Table 24  Comparison of diverse datasets for autonomous vehicle object detection.  Dataset Characteristics Contribution to Model  Training  PASCAL VOC  Comprises 20 categories Suitable for multi-class object  2007/2012  recognition, helps in finetuning models for specific  obstacle categories  Microsoft COCO Over 330K fully segmented  images from complex  everyday scenes  Rich dataset that offers realworld complexity, beneficial  for training models to handle  diverse scenarios  ImageNet Contains 14,197,122 images  organized into 21,841  subclasses  Extensive image collection for  generalized training, useful for  pre-training models in largescale visual recognition  KITTI Autonomous driving dataset  with 2D and 3D bounding  boxes of objects in urban  driving scenarios  Specialized for autonomous  driving; training on this  dataset imparts realistic urban  obstacle detection skills  SceneFlow Synthetic dataset with stereo  Provides controlled  image pairs  environments and stereo data,  allowing models to learn depth  perception and 3D  understanding  ModelNet Clean collection of 3D  Computer-Aided Designs  (CAD) models of objects  Suitable for 3D object  recognition and analysis,  assists models in  understanding and predicting  3D shapes and orientations  OutdoorScene 200 images primarily  designed to test detections of  highly occluded and  truncated objects  Offers challenges related to  occlusion and truncation,  honing the model's ability to  detect partially visible  obstacles  Sydney Urban  Collected by a Velodyne HDL64E LiDAR in Sydney  Provides LiDAR data, crucial  Objects  for spatial awareness and  object detection in AV  Waymo Open  High-resolution sensor data  Dataset  collected by Waymo selfdriving cars in diverse  conditions  Comprehensive real-world  driving data, enhances the  model's robustness and  adaptability to various driving  conditions   |\n|---|"}
{"doc361": "rapidly, reducing latency and enabling real-time applications critical to autonomous navigation. Finally, improving model transparency and reliability remains a key concern, with the black-box nature of deep learning models posing significant challenges to validation and trust. Efforts in Explainable AI (XAI) and formal verification techniques will be crucial in enhancing model interpretability and ensuring the safety of AV systems. Overall, the future of obstacle detection in AVs lies in a more integrated approach, where the synergy between various sensor data and machine learning technologies lead to more sophisticated, reliable, and transparent driving systems. This will involve the creation of comprehensive datasets and the development of advanced algorithms that can navigate the complexities of real-world driving environments. \n\n## 7. **Conclusion**\n\nThe combination of deep learning and multi-sensor fusion in AVs has significantly improved their ability to detect obstacles. This advancement has been crucial in making AVs safer and more reliable. However, several challenges still need to be addressed for these systems to function optimally in all conditions. One of the main issues is the ability of AVs to perform accurately in different environmental settings, such as low light or bad weather, which can affect sensor performance. Developing deep learning models that can adapt to these changes is essential for ensuring the reliability of AVs in various scenarios. Another challenge is dealing with sensor noise, which can lead to incorrect readings and affect the vehicle's decision-making process. Advanced algorithms that can filter out this noise and accurately interpret sensor data are crucial for the efficient operation of AVs. Moreover, the decision-making process of AVs needs to be transparent and understandable. As AVs are designed to make complex decisions, it is important that we can understand and trust how these decisions are made. This is where techniques like XAI \ncome into play, helping to make the AI's decision process clearer and more interpretable for humans. In summary, while deep learning and sensor fusion have brought significant improvements to AV technology, further advancements are needed to enhance their adaptability, noise handling, and decision-making transparency. Overcoming these challenges will be key to fully realizing the potential of AVs in various fields, including transportation and robotics. "}
{"doc362": "| Table 25  Detailed examination of challenges and future research directions in multi-sensor data processing.  Current Challenge Specific Problems Example Impact on AV  Potential Future   | Specific Proposed Techniques                                                               | Anticipated Outcome                                             |                                                                      |                                                                                |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|-----------------------------------------------------------------|----------------------------------------------------------------------|--------------------------------------------------------------------------------|\n| Performance                                                                                                                                                                                | Directions                                                                                 |                                                                 |                                                                      |                                                                                |\n| Sensor Calibration and  Synchronization (Yeong  et al., 2021)                                                                                                                              | Improved data accuracy,  Reliable environment  perception                                  |                                                                 |                                                                      |                                                                                |\n| Environmental Changes (                                                                                                                                                                    | Light variations, Weather                                                                  |                                                                 |                                                                      |                                                                                |\n| Zhao et al., 2023)                                                                                                                                                                         | conditions, Electronic  interference  Variance in sensor  readings, Temporal  misalignment | Incorrect obstacle detection,  Unreliable environment  mapping  | Machine learning for                                                 | Unsupervised learning                                                          |\n| automated calibration                                                                                                                                                                      | algorithms, Reinforcement  learning                                                        | Improved model  resilience, Consistent  performance             |                                                                      |                                                                                |\n| Sensor Noise and Outliers (  Sinha and Papadakis,  2013)                                                                                                                                   | Reduced sensor data  reliability, Inconsistent  model performance                          | Deep learning models  resilient to  environmental changes       | Transfer learning, Domain  adaptation, Data  augmentation techniques | Accurate data  interpretation, Reduced  false detections                       |\n| High-Dimensional Data  Processing (Lu et al.,  2021)                                                                                                                                       | Irregular data patterns,                                                                   | False positive/negative                                         |                                                                      |                                                                                |\n| False data spikes                                                                                                                                                                          | obstacle detection, Reduced  safety and efficiency                                         | Noise reduction and                                             | Advanced statistical                                                 |                                                                                |\n| outlier detection                                                                                                                                                                          | methods, AI-based outlier  detection                                                       | Improved processing  speed, Enable real-time  applications      |                                                                      |                                                                                |\n| Model Transparency and  Reliability (Pang et al.,  2023)                                                                                                                                   | Massive data streams,  Resource-intensive  processing                                      | Slower processing times,  Reduced real-time operation  capacity | Efficient data processing  algorithms and  structures                | Edge computing, Hardware  acceleration, Efficient deep  learning architectures |\n| Black-box nature of deep  learning models,  Difficulties in validation                                                                                                                     | Reduced trust in model  outputs, Impediments to  safety-critical decisionmaking                                                                                            | Model interpretability                                          | Explainable AI (XAI)                                                 |                                                                                |\n| and validation                                                                                                                                                                             | methods, Formal verification  techniques                                                   | Enhanced model  transparency, Improved  safety and trust        |                                                                      |                                                                                |\n\n## Data Availability\n\nNo data was used for the research described in the article. "}
{"doc363": "Azzalini, D., Bonali, L., Amigoni, F., 2021. A minimally supervised approach based on variational autoencoders for anomaly detection in autonomous robots. IEEE Rob. Autom. Lett. 6 (2), 2985\u20132992. https://doi.org/10.1109/LRA.2021.3062597. \n\nBabak, S.J., Hussain, S.A., Karakas, B., Cetin, S., 2017. Control of autonomous ground vehicles: a brief technical review. In: IOP Conference Series: Materials Science and Engineering, vol. 224. IOP Publishing, 012029. No. 1. \n\nBae, S., Saxena, D., Nakhaei, A., Choi, C., Fujimura, K., Moura, S., 2020. Cooperationaware lane change maneuver in dense traffic based on model predictive control with recurrent neural network. In: 2020 American Control Conference (ACC), Denver, CO, \nUSA, pp. 1209\u20131216. https://doi.org/10.23919/ACC45564.2020.9147837. "}
{"doc364": "Broedermann, T., Sakaridis, C., Dai, D. and Van Gool, L., HRFuser: A multi-resolution sensor fusion architecture for 2D object detection, 2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC), Bilbao, Spain, 2023, pp. 4159-4166, doi: 10.1109/ITSC57777.2023.10422432. \n\nT. Chen, Y. Cai, L. Chen and X. Xu, Sideslip angle fusion estimation method of three-Axis autonomous vehicle based on composite model and adaptive cubature kalman filter, in IEEE Transactions on Transportation Electrification, doi: 10.1109/ TTE.2023.3263592. \n\nChitta, K., Prakash, A., Jaeger, B., Yu, Z., Renz, K., Geiger, A., 2022. Transfuser: Imitation with transformer-based sensor fusion for autonomous driving. IEEE Transactions on Pattern Analysis and Machine Intelligence 45 (11), 12878\u201312895. https://doi.org/ \n10.1109/TPAMI.2022.3200245. "}
{"doc365": "Liu, W., Hua, M., Deng, Z., Meng, Z., Huang, Y., Hu, C., Song, S., Gao, L., Liu, C., \nShuai, B., Khajepour, A., 2023. A systematic survey of control techniques and applications in connected and automated vehicles. IEEE Internet Things J. vol. 10, no. 24, pp. 21892-21916, doi: 10.1109/JIOT.2023.3307002. \n\nLu, Y., Ma, H., Smart, E., Yu, H., 2021. Real-time performance-focused localization techniques for autonomous vehicle: a review. IEEE Trans. Intell. Transport. Syst. 23 \n(7), 6082\u20136100. \n\nLuo, Y., Shen, H., Cao, X., et al., 2022. Conversion of Siamese networks to spiking neural networks for energy-efficient object tracking. Neural Comput & Applic 34, 9967\u20139982. https://doi.org/10.1007/s00521-022-06984-1. "}
{"doc366": "Qi, X., Fu, W., An, P., Wu, B., Ma, J., 2020. Point cloud preprocessing on 3D LiDAR data for unmanned surface vehicle in marine environment. In: 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), \nvol. 1. IEEE, pp. 983\u2013990. \n\nQian, Y., Feng, S., Hu, W., Wang, W., 2022. Obstacle avoidance planning of autonomous vehicles using deep reinforcement learning. Adv. Mech. Eng. 14 (12), \n16878132221139661. \n\nRafique, A.A., Gochoo, M., Jalal, A., et al., 2023. Maximum entropy scaled super pixels segmentation for multi-object detection and scene recognition via deep belief network. Multimed Tools Appl 82, 13401\u201313430. https://doi.org/10.1007/s11042022-13717-y. "}
{"doc367": "Sanil, N., Rakesh, V., Mallapur, R., Ahmed, M.R., 2020. Deep learning techniques for obstacle detection and avoidance in driverless cars. In: 2020 International Conference on Artificial Intelligence and Signal Processing (AISP). IEEE, pp. 1\u20134. \n\nSarda, A., Dixit, S., Bhan, A., 2021. Object detection for autonomous driving using YOLO \nalgorithm. In: 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM), London, United Kingdom, pp. 447\u2013451. https://doi.org/ \n10.1109/ICIEM51511.2021.9445365. \n\nSchneider, L., Jasch, M., Frohlich, \u00a8 B., Weber, T., Franke, U., Pollefeys, M., R\u00a8atsch, M., \n2017. Multimodal neural networks: RGB-D for semantic segmentation and object detection. In: Image Analysis: 20th Scandinavian Conference, SCIA 2017, Troms\u00f8, Norway, June 12\u201314, 2017, Proceedings, Part I 20. Springer International Publishing, pp. 98\u2013109. "}
{"doc368": "Xia, X., Hashemi, E., Xiong, L., Khajepour, A., Xu, N., 2021. Autonomous vehicles sideslip angle estimation: single antenna GNSS/IMU fusion with observability analysis. IEEE \nInternet Things J. 8 (19), 14845\u201314859. https://doi.org/10.1109/ \nJIOT.2021.3072354, 1 Oct.1. \n\nXie, G., Yang, L.T., Yang, Y., Luo, H., Li, R., Alazab, M., 2021. Threat analysis for automotive can networks: a gan model-based intrusion detection technique. IEEE \nTrans. Intell. Transport. Syst. 22 (7), 4467\u20134477. https://doi.org/10.1109/ \nTITS.2021.3055351. \n\nXu, X., Zhao, J., Li, Y., Gao, H., Wang, X., 2021. BANet: a balanced atrous net improved from SSD for autonomous driving in smart transportation. IEEE Sensor. J. 21 (22), \n25018\u201325026. https://doi.org/10.1109/JSEN.2020.3034356, 15 Nov.15. "}
{"doc369": "Zhao, Changyu, 2023. Hirotaka Uchitomi, Taiki Ogata, Xianwen Ming, Yoshihiro Miyake, Reducing the device complexity for 3D human pose estimation: a deep learning approach using monocular camera and IMUs,. Eng. Appl. Artif. Intell. 124, 106639. https://doi.org/10.1016/j.engappai.2023.106639. ISSN 0952-1976. \n\nZhao, Z.-Q., Zheng, P., Xu, S.-T., Wu, X., 2019. Object detection with deep learning: a review, in IEEE Transactions on neural networks and learning systems, vol. 30, no 11, 3212\u20133232. https://doi.org/10.1109/TNNLS.2018.2876865. \n\nZhao, X., Fang, Y., Min, H., Wu, X., Wang, W., Teixeira, R., 2023. Potential sources of sensor data anomalies for autonomous vehicles: an overview from road vehicle safety perspective. Expert Syst. Appl. 121358. "}
{"doc370": "![0_image_0.png](0_image_0.png)\n\n# Fundamental Research\n\njournal homepage: http://www.keaipublishing.com/en/journals/fundamental-research/\nReview Review and challenge: High definition map technology for intelligent connected vehicle Mengmeng Yanga,1, Kun Jianga, Benny Wijayaa,1, Tuopu Wena, Jinyu Miaoa, Jin Huanga, Cao Zhonga, Wei Zhang b, Huixian Chenc, Diange Yanga,\u2217\na School of Vehicle and Mobility, Tsinghua University, Beijing 100084, China b Ministry of Natural Resources, Beijing 100812, China c Map Supervision Center, Ministry of Natural Resources, Beijing 100830, *China* a r t i c l e i n f o Article *history:*\nReceived 3 April 2023 Received in revised form 9 January 2024 Accepted 9 January 2024 Available online xxx"}
{"doc371": "| Keywords: High definition (HD) map Highly automated driving (HAD) map Digital map Intelligent connected vehicle (ICVs) Autonomous driving   |\n|---------------------------------------------------------------------------------------------------------------------------------------------|\n\n## 1. Introduction\n\nAs economies and societies evolve, maps have become an indispensable part of people's daily lives. People can effortlessly travel by following the navigation information to any destination planned by their map app on their smartphones. For ICVs, the map plays an even more critical role in localization, navigation, and many other core functions\n[1]. Furthermore, different levels of autonomy require a different level of the map, as outlined in Table. 1. According to the definition of autonomy levels by SAE [2], for Level 1(L1)-Level 2(L2), where drivers still retains primary control of the vehicles while can function effectively with an Advanced Driver-Assistance System (ADAS) map offering sub-meter accuracy. These navigational maps are enough to assist drivers in performing the driving task correctly. However, as vehicles advance towards higher levels of automation, the need for more precise and accurate maps becomes imperative. For Level 4(L4) and Level 5(L5) autonomy, where the vehicle assumes most or all driving functions, a highly automated driving (HAD) map is paramount. These maps will provide detailed and critical information about the driving environment, enabling automated driving systems to react better than human drivers."}
{"doc372": "\u2217 Corresponding author. 1 These authors contributed equally to this work.\n\nAn accurate and up-to-date High Definition (HD) Map is critical for an intelligent vehicle to drive safely and effectively. Although research in this area is growing, there is still a lack of clarity in defining HD maps for intelligent connected vehicles (ICVs). This gap in knowledge is particularly challenging for new researchers, who often struggle to find suitable HD map datasets due to a lack of comprehensive reviews on current HD map products, as far as the authors' knowledge. Thus, this article aims to bridge this gap by providing a thorough analysis of the core ideas of HD map technology. Initially, this paper presents the brief history of HD map. Following this, it describes the taxonomy and ontology of HD maps, complete with the HD map contents and existing standards. An insight into the mapping process is also given by discussing the algorithms used for creating and updating HD maps. This manuscript also lists current HD map products and the open-sourced dataset available for interested researchers in this space. As part of this study, the authors also describe common applications of HAD maps in ICVs. Finally, the article highlight the key research challenges and potential future directions in this field. Addressing these challenges is vital for the advancement and integration of HD maps for ICVs.\n\nHAD map contains plenty of road information, such as lanes, traffic lights, crosswalks, and more, offering essential prior knowledge for various core functions in automated driving. These include perception, positioning, decision-making, and control [1]. The primary application of the HAD map is facilitating high-precision vehicle localization."}
{"doc373": "Accurate localization and positioning are essential prerequisites for the safety and reliability of autonomous driving, enabling vehicles to make correct decisions and control themselves according to their perceived surroundings. The most commonly used method is the Global Navigation Satellite System (GNSS). However, GNSS often falls short in precision, which is critical to autonomous driving [3]. The localization performance further deteriorates when the vehicles go through areas with frequent signal loss, such as tunnels, or where elevation varies, like overpasses. Traditional high-precision localization methods, like Inertial Measurement Unit (IMU) or light detection and ranging (LiDAR)\nsensors, are costly and not feasible for mass production due to budget constraints. Recent advancements in HAD mapping technology have enabled decimeter-level vehicle localization using low-cost sensors, such as cameras. It can be enhanced with the contextual information provided by HAD map [4].\n\nhttps://doi.org/10.1016/j.fmre.2024.01.006 2667-3258/\u00a9 2024 The Authors. Publishing Services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC\nBY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\n\n## A B S T R A C T"}
{"doc374": " \n\nJID: FMRE [m5GeSdc;July 1, 2024;10:0]\n\n| Automated driving level classification of SAE [2]. Level Title Description                           | Map                                                                                   | Precision                                                                                                                        | Necessity         |                  |                                          |\n|------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|-------------------|------------------|------------------------------------------|\n| Driver scenario 1 (DA)                                                                               | Driving assistance                                                                    | The vehicle features a single automated system (e.g., it monitors speed through cruise control                                   | ADAS map          | Sub-meter level  | Optional                                 |\n| 2 (PA)                                                                                               | Partial driving                                                                       | The vehicle can perform steering                                                                                                 |                   |                  |                                          |\n| automation                                                                                           | and acceleration, the human still monitors all tasks and can take control at any time | ADAS map                                                                                                                         | Sub-meter level   | Optional         |                                          |\n| Automated driving system ('system') scenario 3 (CA) Conditional driving The vehicle can perform most | ADAS map + HD map                                                                     | Sub-meter level,                                                                                                                 | Optional          |                  |                                          |\n| automation                                                                                           | driving tasks, but human override                                                     | Centimeter level                                                                                                                 |                   |                  |                                          |\n| is still required                                                                                    |                                                                                       |                                                                                                                                  |                   |                  |                                          |\n| 4 (HA)                                                                                               | High driving automation                                                               | The vehicle performs all driving tasks under specific circumstances, geofencing is required, a human override is still an option | ADAS map + HD map | Sub-meter level, | Compulsory                               |\n| Centimeter level                                                                                     |                                                                                       |                                                                                                                                  |                   |                  |                                          |\n| 5 (FA)                                                                                               | Full driving automation                                                               | The vehicle performs all driving tasks under all conditions, zero human attention or interaction is required                     | HD map            | Centimeter level | Compulsory (Required real-time updating) |"}
{"doc375": "The fundamental approach is to match the geometric features present in both the camera images and the map, which aids in inferring the vehicle position and orientation relative to the map. The key features for this process typically involve lane markings, traffic signs [5], or other semantic-level features [6]. To optimize memory usage, a compressed semantic HAD map could support high-precision localization while being resource-efficient [7]. The extensive information on lanes, traffic lights, crosswalks, and more stored in the HAD map acts as an additional sensor for environment perception. For example, it simplifies traffic light recognition by providing the light's location, type, and the road's slope, allowing for easy extraction of the region of interest (ROI) [8], and selection of an appropriate classifier [9]. 3D object detection also benefited from a HAD map through a bird's eye-view to enhance the understanding of surroundings [10]. Besides, the sensing range of the vehicle could be extended beyond the line of sight and field of view by fusing the vehicles' environmental information in the map, which could greatly improve perception capability [11]. HAD map is particularly useful in scenarios like dynamic visual occlusion, which may otherwise cause even cooperative perception to fail.\n\nAs they become more standardized, HAD maps can serve as a shared, real-time updated data structure among autonomous vehicles, effectively creating a crowdsourced solution. This comprehensive map data provides a reliable baseline for other onboard sensors. For example, a study [12] shows a multi-radar online self-calibration method using the precise locations of street lamps and traffic signs from the HAD map.\n\nHAD maps are also instrumental in motion planning and decisionmaking. Initially, path planning utilized digital maps in platforms like Google and Baidu maps. However, HAD maps, with detailed information on road conditions, static objects, and traffic rules, offer more constraints for local motion planning and decision-making. They allow direct extraction of intersection geometries and real-time traffic situations for motion planning and control [13]. This was exemplified in the 2018 Intelligent Vehicles Future Challenge, where the 'Pioneer' team from Xi'an Jiangtong University, leveraging HD maps, won the championship\n[14]. The team used the OpenStreetMap structure to build the map and generated a path set based on vehicle location, target points, lane states, and traffic rules from the HAD map. Overall, HAD maps play a vital role in localization, perception, navigation, motion planning, decisionmaking, and, ultimately, the safety of autonomous driving."}
{"doc376": "In September 2020, Baidu Apollo unveiled its Robotaxi, during a live broadcast at Beijing Shougang Industrial Park. This event marks the beginning of a new milestone in vehicle autonomy research. Similarly, Mobileye released an edited video depicting urban autonomous driving tests, which can be seen in Fig. 1. In one instance, a huge truck stopped in front of the vehicle and hindered it from perceiving frontal situations. Initially, the vehicle hesitated, unable to determine if the truck had stopped due to a red traffic light or other reasons. However, with the assistance of the HAD map, it was identified that the truck remained stationary even after the light turned green. Consequently. the vehicle successfully changed lanes to continue its path, without driver intervention.\n\nOther notable companies like TomTom, Waymo,and Momenta have also dedicated efforts to develop HAD map. They have demonstrated remarkable achievements by integrating HAD maps into autonomous driving tasks.\n\nWhile many research works have focused on addressing specific facets of autonomous driving with the HAD map as a potential solution, there is a notable gap in the literature concerning the comprehensive definition, historical development, classification, modeling, mapping processes, updates, and application of the HAD map. Consequently, this paper aims to comprehensively define the high-definition map and explore its updates and applications for autonomous driving. Furthermore, it will touch upon the ongoing challenges regarding the develop-\nFig. 2. The organizational structure of this survey HAD map."}
{"doc377": "Section 5 briefly analyzes HAD map mapping, updates, products, and open-source map datasets. Section 6 explores the application of the HAD map, which consists of localization, cooperative perception, and intelligent decision-making. The prospective future development and challenges associated with the HAD map are written in Section 7. Section 7 draws conclusions based on current research.\n\n## 2. Digital Map History\n\nInitially, digital maps were used similarly to paper maps but were more portable [16]. Early digital maps offered a \"virtual image\" of roadways typically delineated by the landscape enclosing the surrounding area, which was essentially the same functionality as paper maps. Unlike most paper maps, digital maps are machine-readable. Digital maps allow quickly synchronizing changes from map data servers, representing the changing reality in real-time. The late 1900s enlarged the role of the digital map as digital maps increased along with the growth of Global Navigation Satellite Systems (GNSS). The old \"virtual views\" no longer make up the entire Navigation Digital Map. The Mazda Eunos Cosmo was the first automobile with an integrated Global Positioning System (GPS) and digital maps in 1990 [17]. Then, navigation digital maps were widely employed on automobiles to establish the vehicle's location, carry out map matching, compute routes, and provide drivers with directions. Their updating capability allows the inclusion of new roads and locations, enhancing their utility."}
{"doc378": "JID: FMRE [m5GeSdc;July 1, 2024;10:0]\nbasic warning and cruising features alongside the development of vehicle intelligence. This period also marked the introduction of ADAS maps, designed to support ADAS and autonomous driving [18,19]. ADAS maps enhance digital maps with more accurate road geometry, like road curvature and road slope, and richer road attributes, such as lane width, number of lanes, and speed limits, along with traffic signs and traffic lights, are all added by ADAS maps to the existing digital maps. Thus, ADAS maps extend beyond navigation, providing dynamic traffic data to bolster ADAS functionality and covering SAE's L1 and L2 levels of driving automation. The ADASIS Forum has established guidelines for ADAS Horizon and standardized map data interfaces like ADASISv1 and v2, with an accuracy of approximately 50 cm.\n\nThe concept of \"high-definition map\" idea was conceived in 2010 at a Mercedes-Benz research planning session. In 2013, a fully autonomous Mercedes Benz S-Class S 500 completed a 103 km journey on urban and country roads using high-resolution maps [20]. Designed to capture all relevant environmental variables for driving, which sensors alone might not accurately detect, HD maps introduced novel features for vehicle perception and localization.\n\nThese maps, offering 3D representations, integrate closely with localization functions and support the planning and control modules. Beyond mere navigation aids, they are pivotal for high-level automated driving (SAE L3 and above), hence the term High Automated Driving (HAD) Map. HAD Maps encompass a broader range of data, including dynamic information like real-time traffic and sensor data and detailed static road-level data. Their comprehensive static information surpasses that of standard maps. Functioning as virtual sensors, HAD Maps enhance vehicle safety without complicating the hardware system. Standards associated with HAD Maps include the Tsinghua Seven layers HD\nmap model [21], OpenDRIVE, and Local Dynamic Map (LDM) [22]. LDM\nprovides a framework for hierarchically storing dynamic and static elements, while the Tsinghua model offers an in-depth representation of the environment for highly automated driving. HAD Maps achieve an impressive accuracy of 10 20 cm."}
{"doc379": "Despite these maps evolving gradually, there are still certain discrepancies between digital maps, ADAS maps, and high-definition maps. The following table illustrates how high-definition, conventional, and ADAS\nmaps differ from one another in terms of map users, functionalities, accuracy, frequency of updates, and content. The specifics are displayed in Table 2.\n\n## 3. What Is A High-Definition Map ?\n\nIn this section, we aim to clarify the definition and the components of a high-definition map. Additionally, we present different classifications of map representation, enhancing the readers' comprehension of map data. Here, we also provide all of the standards that have been commonly referenced in the literature. Finally, we summarize all of this information in the last subsection."}
{"doc380": "## 3.1. The Definition Of Hd Map\n\nHAD maps offers precise and reliable information about the driving environment for vehicles. In addition to serving as a navigational tool, HAD Map can function as an effective \"sensor\". After a vehicle has been localized on the map [19], it offers precise information about both the immediate and extended surrounding area. Furthermore, it is a component of the digital infrastructure that supports not just automated driving also several other applications, including smart cities, safety, and urban planning and management [23].\n\nAs the role of machines in driving expands, digital maps evolve beyond mere navigation tools. Traditional GPS solutions fail to provide the accurate and dynamic data required for autonomous vehicles."}
{"doc381": "Autonomous driving software requires self-updating mapping systems specifically designed for these vehicles, enhancing their perception of the environment. Utilizing HAD mapping technology, an autonomous\n\n| Table 2 The features of digital map, ADAS map and HAD map. Feature Navigation Digital Map                                               | ADAS map                                                                                                   | HAD Map                                                                             |                                                                                   |\n|-----------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------|\n| User                                                                                                                                    | Drivers                                                                                                    | Intelligent vehicle, ADAS system                                                    | Intelligent vehicle, autonomous driving system                                    |\n| Function                                                                                                                                | Navigation and search                                                                                      | ACC, LDW, LKA, and FCW.                                                             | Environmental perception, high-precision positioning, and path planning decision. |\n| Object Types                                                                                                                            | static objects                                                                                             | and dynamic objects                                                                 | Static and dynamic objects                                                        |\n| Route Planning                                                                                                                          | Global path planning                                                                                       | Local path planning/global path planning                                            | Local path planning                                                               |\n| Resolution                                                                                                                              | 5-20 meters                                                                                                | Meters and sub-meters                                                               | 0.1-0.2 meters                                                                    |\n| Updating                                                                                                                                | Permanent static data                                                                                      |                                                                                     |                                                                                   |\n| Frequency                                                                                                                               | (update frequency: about 3 months), semi-permanent static data (update frequency: about 1 hour)            | Permanent static data (frequency approximately 1 month), semi-permanent static data |                                                                                   |\n| (frequency approximately 1 hour), semi-dynamic data (frequency approximately 1 minute), dynamic data (frequency approximately 1 second) |                                                                                                            |                                                                                     |                                                                                   |\n| Semantic                                                                                                                                | Road names                                                                                                 | Road names and map element information                                              |                                                                                   |\n| Information Road Names                                                                                                                  | Important                                                                                                  | Less Important                                                                      | Less Important                                                                    |\n| Location                                                                                                                                | GPS                                                                                                        | High dimensional data matching                                                      |                                                                                   |\n| Content                                                                                                                                 | Road-level data, such as road                                                                              | High-precision road-level data: road                                                | Detailed and high-precision road-level                                            |\n| shape, slope, direction                                                                                                                 | shape, slope, curvature, paving, and                                                                       | data, including lane models, components,                                            |                                                                                   |\n| direction.                                                                                                                              | attributes, and targets. Multiple information layers: sensing layer, positioning layer, and dynamic layer. |                                                                                     |                                                                                   |\n| ACC: Adaptive Cruise Control, LDW: Lane Departure Warning, LKA: Lane Keep Assistance, FCW: Forward Collision Warning                    |                                                                                                            |                                                                                     |                                                                                   |\n\nvehicle can localize itself with high precision, accurately mapping its position relative to itssurroundings. HAD maps assimilate and analyze data from multiple sources in real-time, including vehicle sensors, LiDAR, onboard cameras, satellite imaging, and GPS. This integration differs significantly from conventional maps designed for general navigation. The amalgamation of this data provides a comprehensive, up-to-date understanding of road gradients, boundaries, traffic signals, lane positions, anticipated curves, and safety conditions. As such, high-definition maps redefine the standards for in-car navigation systems in autonomous vehicles [24,25], offering an exceptionally accurate depiction of the route.\" Definition 1. High-Definition Map (HD map) is an accurate and detailed expression of the road traffic scene. Compared with the traditional navigation electronic map, the content of the expression is more abundant. HD map belonging to the lane level has higher accuracy, reaching the centimeter-level accuracy requirements. The map data must be updated at a high frequency to ensure the authenticity of the map data to provide map matching to assist the environmental perception and path planning tasks."}
{"doc382": "Definition 2. The Highly Automated Driving Map (HAD map) constitutes a real-time, dynamic, multi-layered data characterized by centimeter-level precision. As a cornerstone in the realm of automated driving, the HAD map underpins critical functionalities such as positioning, planning, decision-making, and control, thereby ensuring safety and reliability. It encompasses a detailed representation of both static road features and dynamic traffic elements, including roads, lane lines, curbs, and traffic signs. Beyond capturing these map elements' geometric and topological relationships, the HAD map also integrates multidimensional information, such as confidence levels. Moreover, the representation of HAD maps extends beyond point cloud and vector maps, encompassing semantic maps, grid maps, and various other formats.\n\nDefinition 3. Automated driving high-precision map is type of data characterized by accurate positional information and an extensive array of road elements information. This map integrates 2D and 3D representations, vector and raster formats, as well as point cloud and semantic map [26]. It provides essential prior knowledge for intelligent driving and understanding of real roads, similar to the human brain's perception of actual road conditions. Additionally, this map also predicts complex road scenarios for the intelligent vehicle and mitigating potential driving risks, which is the core foundation for realizing automated driving.\n\nAs a crucial component in developing autonomous driving technology, the automated driving map plays a pivotal role in high-precision positioning, intelligent navigation, control, and other aspects directly influencing to the safety, stability, and comfort of autonomous driving."}
{"doc383": "## 3.2.1. Static Elements\n\nThe static elements in the HAD map can be divided into basic road features and supplementary static elements, as the basic features of the structural road environment, road, junction, and lane are essential in global path planning and local driving decisions. The local environment also has supplementary static elements, such as traffic signs, bridges, railway crossings, platforms, and road lamps [24]. These elements can be divided into three categories according to their relationship with the road network: on-road elements, accessories, and off-road elements. Onroad elements include tunnels, bridges, and railway crossings, which are part of the road network and can be described as properties of roads or junctions. Road accessories are the functional elements related to traffic rules. Traffic lights, signs, and road marks can represent traffic rules in the lane property. Crosswalk is also an accessory highly related to the driving process [21]. According to geographic data files (GDF) standards [27], some road accessories are still not included, namely environment facilities, road lamps, guideposts, road cameras, and guard rails. The last type of supplementary elements, off-road elements, includes parking lots, and bus platforms. These functional elements can give some indications to the driving process.\n\n## 3.2.2. Dynamic Elements"}
{"doc384": "![4_image_1.png](4_image_1.png)\n\nJID: FMRE [m5GeSdc;July 1, 2024;10:0]\nFig. 3. Example of local OGMs generated from the fusion between **camera** and LiDAR data between intelligent connected vehicle: (a) ego vehicle (b) vehicle 1. The figures are obtained from Zheng et al. [29] work.\n\ncyclists. It is important to note that stationary dynamic obstacles are also classified as dynamic obstacles, as treating them as static could pose risks if they unexpectedly move. Since vehicles, pedestrians, and cyclists are the most common traffic participants and have quite different dynamic characteristics and behaviour modes, they are represented separately with specific properties. Due to the highly dynamic properties of these physical entities, they should be updated at a high frequency through V2X [24]."}
{"doc385": "Dynamic information, on the other hand, encompasses traffic light data, traffic conditions, weather, and temporary traffic regulations. Traffic light details and status, including flow and density, are typical elements in commercial electronic maps. Weather information plays a significant role in perception, decision-making, and vehicle control. Accurately quantifying weather effects can aid in adjusting control algorithms for enhanced safety. Temporary traffic rules, such as speed limits, restricted vehicle access (like bus lanes during certain hours), and accident reports are also dynamic elements. These rules often vary based on road weather conditions and can be viewed as time-dependent properties, similar to the regulations indicated by traffic signs [21].\n\n## 3.3. Classification Of Different Had Maps\n\nDerived from a variety of map elements, high-definition maps can"}
{"doc386": "## Be Represented In Different Forms, Such As:\n\n3.3.1. Raster map (Occupancy grid *Map)*\nRaster map is also known as the occupancy grid map (OGM). It was first proposed by Moravec and Elfes [28,30,31]. The surrounding environment is modelled by dividing the space into uniform cell grids (either 2D or 3D), which store corresponding information as shown in Fig. 3\n[32]. Han et al. [33] proposed a 2.5D version that adds the height data on the grid cell rather than converting it into a 3D grid map.\n\nThe type of information stored can either be occupancy probability [34,35], reflection intensity [36], probability distribution [37], or distance information [30]. The size of the cell grids determined the resolution and required storage space of the map. This type of map can be used to determine the movements of pedestrians [38], vehicle position\n[39], and vehicle navigation [40]."}
{"doc387": "## 3.3.2. Point Cloud Map\n\nThe rapid development of light detection and ranging (LiDAR) technology lowered the barriers to point cloud maps. Therefore, many HD\nmap providers have employed point cloud maps, such as HERE, TomTom, and Waymo. [31]. Point cloud maps offer discrete and dense samplings of the environment, capturing accurate 3D coordinates of points for a high-quality representation of the world which can be seen in Fig. 4\n[41]. In Simultaneous Localization and Mapping (SLAM), the map includes only landmarks or even a sparse 3D point cloud, called a 3D\nsparse map[16]. The advantage of point cloud maps is that they densely\n\n![4_image_0.png](4_image_0.png)"}
{"doc388": "![4_image_2.png](4_image_2.png)\n\nmodel the entire environment and preserve rich environmental information [42]. Their disadvantage is that the storage space required will grow exponentially as the mapped area expands, which inconveniences maps' storage, transmission, and application [31]. There have been a lot of use cases for localization [43] and navigation [44] since the data provided by LiDAR is considered state-of-the-art in terms of ranging precision and accuracy.\n\n3.3.3. Geometric feature map Geometric feature maps represent the elements in an abstract, vectorized form. The elements are stored as points, lines, surfaces, and other basic geometric entities as illustrated in Fig. 5. Thus the map provides the information needed for positioning while saving storage space [30]."}
{"doc389": "Topological maps do not focus on the accuracy and structural details of the map, which is a more compact form of expression, which can be seen in Fig. 6. However, when dealing with complex structures, it is necessary to implement appropriate graph segmentation [26]. These maps are particularly useful in street-level navigation and path-planning tasks. Besides, it can be integrated with semantic information to enhance vehicle perception and localization robustness in complex and dynamic environments. Readers interested in the information regarding topological mapping through vision-based methods can refer to [47].\n\n## 3.3.5. Intensity Map\n\nThe intensity value is a metric indicating the pulse strength generated by a laser radar at a specific point. This value is determined by the reflectivity of the object scanned by the LiDAR pulse, which in turn is dependent on the wavelength used. Consequently, the intensity of the"}
{"doc390": "Among ,,, represents the intensity value of the grid cell (,); ,,\nis the \u210e weight value of cell (,); , is the gray value of cell (,).\n\nThe intensity map is a two-dimensional representation created through raster processing and projection calculation. This map is derived directly based on the intensity values obtained from raw LiDAR data. B\u00e2rsan et al. [50] proposes a real-time localization at 15 Hz by using a LiDAR intensity map and achieves centimeter-level accuracy.\n\n3.3.6. Semantic map The semantic map layer plays a crucial role in providing a higher level of understanding of the environment compared to traditional maps. The semantic map contains information about the meaning and function of objects and features in the environment, allowing autonomous vehicles to understand their surroundings better and make more informed decisions [56,57]. The depiction of this map can be seen in Fig. 8. The construction of a semantic map follows some basic principles:\n1. All data must be consistent with the geometric layer information of the vehicle."}
{"doc391": "The complexity of the driving environment requires that the elements of the HAD map be organized in a standardized data structure for comprehensive understanding [26]. A standard format and model not only provide convenient access to necessary data for users but also ensure uniformity across different platforms. Numerous standard institutes and companies are developing their unique map standards. This section will introduce some of the most influential standards in the industry and examine their approaches to organizing environmental elements. Notable standards in the autonomous driving sector include OpenDRIVE, NDS, LDM, ADASIS, lanelet, and Tsinghua HAD map are the most influential HAD map standards in the autonomous driving industry [26,60].\n\nAmong them, OpenDRIVE [61\u201363] and NDS [64] predominantly concentrate on the static map model, providing a thorough understanding of the static structural road environment. Conversely, LDM [65,66] focuses on dynamic elements. Lanelet [67,68] presents an efficient map representation for autonomous driving. ADASIS focuses on data transmission and its application in ADAS [69]. In this chapter, we will introduce the typical map standards and models.\n\n## 3.4.1. Opendrive"}
{"doc392": "OpenDRIVE [61\u201363] is an open-source map format created by the enterprise alliance engaged in simulation development. It encompasses road networks and topologies while supporting the 3D geometric information representation for autonomous driving. OpenDRIVE map is organized as a hierarchical repository in XML format, which is more suitable for automated driving simulation. This format is often adopted for static information expression and centralized storage. It is realised according to a strict hierarchical inheritance relationship. With road links and junctions as basic units, with additional elements like lanes and traffic signs being methodically integrated into hierarchical layers. The most significant feature of the OpenDRIVE map is its distinct and clear structure as shown in Fig. 10.\n\n1. Coordinate system: Latitude and longitude are transformed to a ground plane with the north-east-sky ground coordinate system. The road geometry is calculated from the ground coordinate. The elements along the road, such as lanes and traffic signs, are represented in the  \u2212  coordinate. The  axis is set along the road center line, while the  axis is set vertically to the road center line. See Fig. 11.\n\n2. Road network: A road in the OpenDRIVE network comprises several key components:\n(a) Reference **line:** This is typically the road's center line. The reference line can be a straight line, a clothoid, or a circular arc. Additional road attributes like elevation and traffic signs are specified along the reference line."}
{"doc393": "(b) Lanes and lane **properties:** Each road may contain one or more lanes. The basic format of a lane includes its basic properties (like connection relationship, lane type, length, and speed limit), which are stored as strings.\n\n(c) 3D geometry **information:** This section includes sectional lines with four basic geometry types: straight line, clothoid, circle arc, and polynomial. Essential parameters for each geometry type and start-end points are detailed.\n\n(d) Elevation Profile and Section **Shape:** A cubic curve represents the elevation profile and illustrates the height-longitudinal distance (height-) relationship. Based on the longitudinal coordinate (), the section shape is depicted through the height-width\n(height-) relationship."}
{"doc394": "![6_image_2.png](6_image_2.png)\n\n(e) Lane boundary **information:** This covers the colour, type (solid or broken), material, and width of lane boundaries.\n\n(f) Additional **Information:** OpenDRIVE maps also support elements beyond the road network, such as stations, railways, and parking lots. This information and road and junction data form the complete XML file.\n3.4.2. NDS *format* In the NDS map [64], the whole earth's surface is divided into tiles by quadtree. The higher the level in the quadtree, the smaller the tiles. Each tile is given an ID number, as shown in Fig. 12. Different types of information are stored in different building blocks. The information in each tile is stored in the building blocks. Considering the high complexity of the NDS format, here we will only introduce some basic information provided by the NDS format."}
{"doc395": "2. Lane **Representation:** In the context of ADAS and autonomous driving applications, the lanes in NDS maps are defined by their basic properties, connection relationships, and geometric characteristics.\n\nKey attributes include lane type and speed limits. Lanes are grouped based on their direction and road association, forming the foundation of a lane-level network. The geometric design of lanes is articulated using splines, augmented with elevation profiles and section shapes akin to those in the OpenDRIVE format. The NDS map format also supports lane boundary types, such as lane markers, road edges, and railings.\n\n3. Other **information:** The NDS map has detailed, high-precision data and includes information typical of traditional maps. Leveraging a comprehensive tile system, the NDS map supports various types of information, including map display, traffic data, terrain features, object names, and more. This makes the NDS map more mature than OpenDRIVE and improves its complexity, making it less simple than an XML OpenDRIVE file."}
{"doc396": "3.4.3. ADASIS [69] and LDM *[65,66]*\nADASIS is a map standard developed for ADAS applications, and it focuses on the data transmission between the cloud and the clients. The cloud provides ADAS Horizon (AH) for client subscriptions, containing information pertinent to autonomous driving map standards, including the road, junction, lanes, and reference lines. When users input the destination in real applications, the global path planner will simultaneously sort the map element information [69]. In addition, ADASIS supports the fusion of perception results in the map platform as shown in Fig. 13.\n\nIn contrast, LDM focuses on the dynamic elements in the driving environment. It is designed for the Intelligent Transportation System (ITS)\nrather than only the static geographical environment. LDM contains four layers: highly dynamic, transient dynamic, transient static, and permanently static data, with dynamic information being updated by V2X.\n\nAs shown in Fig. 14, LDM contains static information from OpenDRIVE\nand NDS, as well as dynamic elements. The traffic details, such as traffic lights and flow, is allocated to the third layer, while the highly dynamic elements, predominantly dynamic obstacles on the road, are slotted in the fourth layer."}
{"doc397": "![7_image_1.png](7_image_1.png)\n\n## 3.4.4. Lanelet\n\nIn the field of automated driving, LaneLet [67,68] serves as an effective expression of high-precision maps. It specify the area where automated driving is possible with LaneLets that are connected to one another. It is capable of fully expressing both the lane topology and the lane geometry. It can also incorporate people's driving behaviours and traffic laws simultaneously. A physical, relational, and topological layer can be found in Lanelet2 [68]. Each Lanelet is bordered by left and right bounds, each composed of a sequence of points, enabling precise replication of various lane shapes. The output map of the lanelet2 software typically adopts the OSM format. This technology was notably employed during the MERCEDES BENZ S 500 INTELLIGENT DRIVE's autonomous trip over the Bertha Benz Memorial Route in the summer of 2013 [20]."}
{"doc398": "The map example for a highway road and the resulting map structure, as well as for an intersection and the resulting routing graph for normal vehicles, are shown in Fig. 15. The red in the graph indicates conflicting lanelets.\n\n## 3.4.5. Tsinghua Had Map\n\nGenerally, the basic idea of the above map standards is to find a way to better sort the information in the road environment. In contrast, the Tsinghua HAD map standard focuses on the application in autonomous driving, providing information according to the requirements of perception, positioning, and decision-making [21]. Tsinghua HAD map contains seven layers, considering the road-level and lanelevel network, high-precision static information, dynamic obstacles, and partial decision-making assistant information (See Fig. 16)."}
{"doc399": "6. Dynamic object container **layer:** This layer is designed for obstacle perception and local dynamic trajectory planning. With the help of V2X, the roadside infrastructure, and the connected vehicles can upload the obstacle information to the cloud, achieving the real-time update of the dynamic objects container layer. Autonomous vehicles can get this information from the map to get a non-occlusion environment perception, thus better supporting local dynamic trajectory planning.\n\n7. Intelligent decision support **layer:** The layer can support driving decisions by providing some prior decision knowledge. In fact, the driving decisions are closely related to the local geographical features. The characteristics of driving decisions are analyzed according to every specific location. Then, these are stored in the intelligent decision support layer as prior knowledge. This data can be acquired by leveraging crowdsourced data from taxis, for example, inside a city. The vehicle can download the local driving knowledge for the most appropriate driving decision policy. This layer is a significant characteristic of the Tsinghua HAD map.\n\n## 3.5. Summary"}
{"doc400": "High-definition maps are diverse, each featuring multiple layers tailored to the information they store and their specific application scenarios. These maps can be classified into various types, including raster, point cloud, geometric feature, topological, intensity,semantic, and density maps. This section also encapsulates the standardization process of current HD maps across these classifications. As illustrated in Table 3, OpenDRIVE and NDS are geared towards static environments, whereas LDM and Tsinghua maps encompass both static and dynamic elements.\n\nOpenDRIVE is known for its simplicity, open-source nature, and ease of use, making it popular in research settings. In contrast, NDS aims for comprehensive coverage, providing detailed static information that includes both conventional map data (e.g., GDF map standard) and additional HD details essential for autonomous driving. The LDM standard, designed for ITS, addresses static and dynamic elements. It enables updating macroscopic traffic information and microscopic dynamic obstacles via V2X communication in ITS. The Tsinghua map model, distinct from LDM, prioritizes integration with technical modules in autonomous driving, offering advanced features for positioning and decision-making.\n\nUnlike these standards, ADASIS is more concerned with data transmission than an extensive driving environment description. It provides users with information along the globally planned path, making the \"path\" its sole layer or building block, with all relevant data treated as path properties. Collectively, these five standards each have their unique focal points, characteristics, and advantages."}
{"doc401": "HAD maps are widely used to enhance autonomous vehicle technologies, and the accuracy and quality of HAD maps are directly related to the reliability, safety, and efficiency of autonomous driving. At present, the accuracy of the HAD map is centimeter-lever, and the update should be done frequently to ensure the precision and quality of the HAD map.\n\nHAD map mapping can be divided into four steps: data acquisition, HD\nmap generation, quality control, and release and maintenance [71]. The details are as follows:\n1. Data **acquisition:** This task involves using multiple Mobile Mapping Systems (MMS) to gather high-precision, multi-source road data. These MMS can be seen in Fig. 17. Updating these maps promptly with each change is crucial to ensure autonomous vehicle safety.\n\nCurrently, the prevalent method employs MMS equipped with cameras, LiDAR, GPS/IMU, and other sensors [72]. The raw data of MMS\nis collected from cameras, LiDAR, GPS, IMU, wheel speed sensors, and other onboard sensors for HD map generation afterward [73]."}
{"doc402": "While this approach offers high accuracy, it is costly, and updates may only occur monthly at times. Although this method ensures high accuracy, it is expensive and may lead to monthly update cycles at best. To address the need for real-time updates, there is a growing trend towards crowdsourcing data from vehicles like smart cars, public buses, and taxis, all equipped with various sensors [74].\n\nThis approach significantly enriches the data sources and increases the frequency of updates. However, it presents challenges related to the variable quality of crowdsourced data, which can be affected by differences in sensor capabilities, timing of data collection, and the perspectives from which the data is acquired.\n\n2. HD Map **Generation:** This stage can utilize MMS or SLAM (Simultaneous Localization and Mapping) technology [31,75]. MMS estimates the vehicle's pose directly through GPS and IMU [76\u201378],"}
{"doc403": "| The characteristics of different map standards. Standard Layers Contained elements   | Characteristics                              |                                                                       |                                                                                        |\n|--------------------------------------------------------------------------------------|----------------------------------------------|-----------------------------------------------------------------------|----------------------------------------------------------------------------------------|\n| OpenDRIVE                                                                            | 5                                            | Road network, junction, lane, traffic sign, traffic rule, station     | HD static road information, XML hierarchical format, open and free                     |\n| NDS                                                                                  | 18                                           | Complete understanding of static elements                             | Abundant static HD information, quadtree storage, both HAD and traditional information |\n| ADASIS                                                                               | 1                                            | Road network, junction, lane, traffic sign, and traffic rule.         | ADAS application, communication consideration                                          |\n| LDM                                                                                  | 4                                            | Permanent static, transient static, transient dynamic, highly dynamic | Both static and dynamic information, designed for ITS and V2X                          |\n| Tsinghua                                                                             | 7                                            | Road network, detailed static elements, static positioning features,  | Designed for autonomous driving application, decision-making                           |\n| dynamic elements, decision-making knowledge                                          | support, additional features for positioning |                                                                       |                                                                                        |\n\nwhile SLAM combines data from odometers, GPS, IMU, and wheel speed sensors for a more confident pose estimation and reduces error accumulation through loop closure [79\u201381]. After acquiring poses, an HD map can be pieced together using map elements extracted from the point clouds and images collected. The three-dimensional geometric and topological information of map elements extracted based on LiDAR [82,83] and image data [84\u201391], include lanes, traffic signs, traffic lights, and poles. Finally, the map elements are transformed into the coordinate system and saved in the corresponding map layers [72,92].\n\n3. Quality **Control:** This phase involves applying predefined evaluation metrics and standards to verify the map's accuracy. Some map elements, automatically extracted by algorithms, require manual verification [93]."}
{"doc404": "4. Release and **Maintenance:** After meeting accuracy requirements, the HD map is released. In this stage, map elements are compiled and issued according to set standards. HD maps undergo updates to reflect environmental changes and issues identified in use [71].\n\n## 4.2. The Had Map Products\n\nIn the sector of automotive driving, various research institutions and leading companies have proposed map products, including Apollo HD\nmap, AMAP HD map, NavInfo HD map, HERE HD Live Map, Waymo HD map, and Mobileye HD map. These products of HD maps have been improved continuously, enriching their content and enhancing data accuracy to reach a level of precision within centimeters."}
{"doc405": "4.2.1. Commercialized HAD map Given the value provided by HAD map towards autonomous driving, more and more companies are now working on commercializing the HAD map data (See Table 4). Various companies are working on this aspect, such as:\n1. Apollo HD map **(Baidu)** [94]: The production of Apollo HD\nmaps includes four links: data collection, data processing, element identification, and manual verification. Data elements of the Apollo HD map include road elements, intersection elements, traffic signal elements, logical relationship elements, and other road object elements. The data format is mainly inherited from the OPENDRIVE format.\n\n2. AMAP HD map [104]: AMAP, formerly AutoNavi, has amassed high-precision autopilot map data over more than 320,000 kilometers. The two LiDARs and four cameras on AMAP's specialized mapping vehicle for HAD-level autonomous driving maps primarily gather road data with an accuracy of up to 10 cm. To offer a complete \"autonomous driving map + high-precision positioning solution,\" AMAP collaborated with the provider of precise location services, Qianxun Location. The lateral and longitudinal errors are within 7 cm under normal road conditions and 6 cm and 5 cm under high-speed/urban loop conditions, according to the two parties' present lane-level positioning solutions [95].\n\n3. NavInfo HD map [96]: NavInfo initiated its foray into the realm of autonomous driving maps with technical research and exploration starting in 2013. The company further solidified its commitment to this field in 2015 by establishing the Smart Map Division, marking the official commencement of product development and commercialization efforts for autonomous driving maps, specifically targeting Level 3 and higher autonomous driving systems. NavInfo has now achieved comprehensive proficiency in the entire product capability suite for autonomous driving maps. This suite encompasses a range of processes from data collection, automated mapping, and crowdsourcing updates to rapid iteration, demonstrating NavInfo's significant progress and expertise in this domain."}
{"doc406": "4. TomTom HD map [105]: TomTom N.V., a Dutch multinational company specializing in developing and producing consumer gadgets and location-based services. With precision down to a few centimeters, it provides TomTom HD map, a very accurate representation of the road with various features, including lane models, traffic signs, road furniture, and lane geometry. To guarantee that the automated driving system has access to the most recent road information, TomTom developed the TomTom AutoStream delivery service, which effectively distributes the most recent and pertinent HD map data.\n\n5. HERE HD Live Map [106]: HERE was formerly known as NAVTEQ, an American mapping company. HERE's autonomous driving map is an extension of the traditional navigation map.\n\nThe accuracy of the map must be at least sub-meter level, and the information will be more abundant. Basic road information, features, and dynamic information layers are composed of different layers, which can be customized according to the needs of the OEM. In May 2018, HERE, NavInfo (China), Increment P /Pioneer\n(Japan), and SK Telecom (South Korea) announced establishing the OneMap alliance to develop global map standards. Starting in 2020, we will provide uniform standard high-precision map products and services to the industry to support the implementation of global OEM autonomous driving solutions."}
{"doc407": "6. Dynamic Map and Cooperation **Area** [99]: Dynamic Map and Cooperation Area is a high-precision three-dimensional location information platform that DMP (Dynamic Map Platform Co., Ltd.)\noffers. It contains both static information (High-Accuracy 3D Information) and dynamic information, such as road construction plans, accident information, and traffic light information. They can achieve centimeter-class precision for their geometric map data.\n\n7. **Waymo** HD map [107]: Waymo's high-precision maps are developed from Google Maps and have a strong data and technical background. Currently, the high-precision maps it produces are only used for its own autonomous driving, not as a commercial product. The method of collecting maps is LiDAR, plus an integrated navigation and positioning system. They also have a large surveying and mapping fleet to create high-precision maps together by means of map fusion.\n\n8. **Mobileye** [108]: Although Mobileye does not directly produce high-precision maps, its camera technology significantly contributes to this domain. Each Mobileye camera is capable of capturing detailed road conditions ahead. For instance, these cam-"}
{"doc408": "| The comparison of various HAD Map. HD map Accuracy                                | Updating method                                 | Coverage                                                |                                                         |\n|-----------------------------------------------------------------------------------|-------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|\n| Apollo HD map [94]                                                                | Centimeters                                     | Professional mapping vehicles and crowdsourced vehicles | China                                                   |\n| AMAP HD map [95]                                                                  | < 10\ud835\udc50\ud835\udc5a                                        | Professional mapping vehicles and crowdsourced vehicles | China                                                   |\n| NavInfo HD map [96]                                                               | -                                               | Crowdsourced data, UGC, OEMs                            | China                                                   |\n| HERE HD map [97]                                                                  | < 20\ud835\udc50\ud835\udc5a                                        | Crowdsourced data and satellite imagery                 | North America and Western Europe                        |\n| TomTom HD map [98]                                                                | 15-20 cm                                        | Professional equipped vehicles and crowdsource          | U.S., Europe and East Asia                              |\n| Dynamic map and cooperation                                                       | Centimeters                                     | Professional mapping vehicles and crowdsourced vehicles | Japan and U.S.                                          |\n| area [99] Waymo HD map [100]                                                      | 10 cm, low efficiency,                          | Crowdsourced vehicles                                   | U.S.                                                    |\n| long cycle and high cost                                                          |                                                 |                                                         |                                                         |\n| Mobileye HD map [101]                                                             | Centimeters                                     | Professional mapping vehicles                           | U.S.                                                    |\n| Uber HD map [102]                                                                 | -                                               | Professional mapping vehicles                           | U.S.                                                    |\n| Apple map [103]                                                                   | -                                               | Professional mapping vehicles                           | U.S.                                                    |\n| Table 5 Comparative between different HD map datasets. Dataset Lyft Level 5 [109] | NAVER LABS HD map Dataset [110]                 | Argoverse[111]                                          |                                                         |\n| Sensors                                                                           | 7 cameras and 3 laser scanners                  | 10 cameras and 2 laser scanners                         | 2 laser scanners, 7 cameras, and 2 front stereo cameras |\n| Annotation                                                                        | 55000+ 3D manual annotation                     | contain about 130k images as well as 6DoF               | HD map with geometric shape and semantic                |\n| camera poses for training and validation                                          | information                                     |                                                         |                                                         |\n| Map information                                                                   | Surface map for safe driving, and               | 3D Road Layout, LiDAR Feature Data, and Visual          | Geometric lane vector map, grid map of the              |\n| semantic map of the underlying                                                    | Feature Data                                    | drivable area, and grid map with actual height          |                                                         |\n| high-definition space                                                             |                                                 |                                                         |                                                         |\n| Map content                                                                       | More than 4000 lane sections, 197               | 3D location information, including lanes, road          | (1) Two HD maps with lane centerline, traffic           |\n| crosswalks, 60 stop signs, 54 parking                                             | signs, crosswalks, intersections, and overspeed | direction, and ground height (2) An API for             |                                                         |\n| areas, 8X speed bumps, 11X speed bumps                                            | stops                                           | connecting map data with sensor information             |                                                         |\n| Data size                                                                         | 350+Scenes at 60-90 Minutes Long, 30K           | -                                                       | 3D tracking annotation with 113 scenes 290KM            |\n| LiDAR Point Clouds, 1.3M 3D Annotations                                           |                                                 |                                                         |                                                         |\n\neras can accurately identify lane markings or the position of speed limit signs. They process each captured image into data, subsequently packaging it into packets for uploading. This data is then overlaid in real time onto the base map for enhanced accuracy.\n\nThe collaborative efforts between Mobileye and automotive manufacturers like Volkswagen, Nissan, and GM are leading to more vehicles being equipped with Mobileye cameras. The combination of image, intelligence, and network connection can achieve a high precision of 10cm."}
{"doc409": "## 4.2.2. Opensourced Had Map\n\nSeveral companies have made significant contributions by opensourcing their High-Definition (HD) map datasets to foster the advancement of autonomous driving technology. These datasets are instrumental in the development and refinement of autonomous vehicle technologies. Among these notable contributions are the NAVER LABS HD map Dataset [110], the Lyft LEVEL 5 OPEN DATA Perception Dataset [109],\nand the Argoverse Dataset by Argo.ai [111], each offering unique features and data types (See Table 5):\n1. NAVER LABS HD map **Dataset:** This dataset consists of three data layers. These layers can be explained as:\n(a) 3D Road *Layout:* This layer comprises a detailed representation of the road's surface, including the types and positions of visual elements such as lanes, road markings, crosswalks, and speed bumps.\n\n(b) LiDAR Feature *Data:* It includes 3D LiDAR point clouds of the static road environment, meticulously captured by MMS vehicles and enriched with semantic annotations for each data point."}
{"doc410": "Given the quality of the HAD map's information, numerous important use case applications exist. The most common are localization, cooperative perception, and intelligent decision support. Below, the explanation of each application is elaborated.\n\nFig. 18. Three stages of mapping based on crowdsourced data, which consisted of (a) smoothed trajectories, (b) aligned trajectories, and (c) **learning**. This result is extracted from Liebner et al. [116] works.\n\nA requirement for autonomous vehicle navigation, decision-making, and control is high-precision and reliable self-vehicle localization [125\u2013\n127]. Theoretically centimeter-level localization findings are theoretically possible using high-precision localization techniques, such as GNSS\nbased on differential RTK (D-RTK). The GNSS signal may be blocked by nearby structures and trees in practical applications, such as urban settings, leading to a significant localization divergence. When GNSS positioning is unsuccessful, the dead reckoning (DR) technology based on an IMU can offer correction, but a cumulative inaccuracy will invariably result from long-term GNSS signal loss. Moreover, the cost of the D-RTK and IMU systems prevents them from being used commercially."}
{"doc411": "Map-based localization has been quite popular as an alternative strategy since it may be used with other localization techniques [128,129].\n\nAfter its initial release, HD maps have become incredibly common in the fields of intelligent vehicles, to list just a few [128,130]. Road elements on HD maps are more precisely detailed than conventional navigation maps [21]. Several map-building companies have accumulated HD map datasets on a significant scale using several standards, such as NDS [64] and LDM [65]. The common method for creating HD maps is to use MMS [73,75] that are outfitted with high-precision sensors, such as LiDAR, RTK, and IMU, with centimeter-level accuracy. The generated map, which includes localization information, can help autonomous vehicles plan their positions and trajectories. A dense point cloud feature and a sparse vector landmark feature are two ways that HD map's localization feature can be broken down; these two types of features are referred to as point cloud HD map and vector HD map, respectively.\n\nto updating the HAD map database: the centralized update method and the crowd-sourced method [112,113]. 4.3.1. Centralized *update* The centralized method is often considered the state-of-the-art method since this method utilizes a dedicated fleet of mapping vehicles equipped with a highly accurate GPS sensor, 360-degree camera, and LiDAR sensors [73,75]. Due to the high cost of the vehicle, the number of these specialized vehicles is limited. Thus, the update frequency provided by this method is not sufficient[112,113]. For example, Google updates the map database using a street view vehicle fleet. In 2012, there were only 250 vehicles actively roaming around on streets and freeways worldwide. Another mapping company named HERE used a vehicle fleet of a little above 200 cars to do mapping by the end of 2015. These examples show that even giant companies cannot satisfy a timely map update. Therefore, the future outlook of the autonomous vehicle presented back in 2016 stated that the crowdsourcing method of the map-building framework by large fleets of autonomous vehicles equipped with onboard sensors would be the future [114,115]."}
{"doc412": "4.3.2. Crowdsourced *Update* While centralized mapping methods are often favored for their quality, crowdsourced approaches are increasingly recognized for their ability to incorporate the most current information into existing maps, a key aspect of map updates. For example, research [9] performs an update by lane line merging through hierarchical clustering. Study [116] introduced a scoring system grounded in consistency, spatial fit, and coverage, refining new data integration into existing HAD maps using graph calculations (See Fig. 18). A similar graph-based method was used in [117], assuming the presence of a monocular camera and basic GPS in vehicles, to achieve cross-correlation between landmarks and centimeter-level accuracy using 1000 passing vehicle data. Research [118] focused on the semantic alignment of lane features from visual odometry, enhancing the reconstruction process through edge refinement (See Fig. 19).\n\nPioneering work by Aijazi et al. [119] established the pipeline where map update is not a given situation but a situation that needs to be first detected and then updated. In [12], they approach the problem by first predicting whether the change has happened through a boosted particle filter. They assess the change based on the road-edge geometry in the visual landmark layer. Pannen et al. [120] considered a broader range of road sections with crowdsourced lane feature data, prioritizing areas with the highest update probability. Jo et al. [121] introduced SLAMCU, a SLAM approach that includes change detection. Heo et al. [122] proposed a novel cross-domain deep learning framework to align map data with real-time semantic layer detections. Zhang et al. [123] envisioned crowdsourced data comprising advanced sensors and 5.1.1. Point cloud feature-based *localization* GNSS systems cannot meet the demanding requirements for autonomous vehicles' self-localization in several environments. LiDARbased localization offers a promising solution and can be divided into SLAM (simultaneous localization and mapping) and map-based techniques. SLAM methods have two main categories: feature-based\n[131] and scan-based [132]. Typically, localization based on SLAM suffers from an error accumulation problem [133]. In contrast, many researchers focus on vehicle localization in urban areas using LiDAR and priori known maps due to the significance of localization accuracy for autonomous driving in complex urban scenarios.\n\nThe original point cloud scanned by a LiDAR sensor, which preserves the point cloud's raw geometric data, forms the basis of the point cloud HD map. State-of-the-art map-based localization methods use point cloud HD maps to estimate vehicle pose accurately. The vehicle has a LiDAR sensor, and the LiDAR scans match the point cloud map. Yoneda et al. [134] use the Iterative Closest Point (ICP) method to match the real-time LiDAR scan with the point cloud map. Kato et al."}
{"doc413": "JID: FMRE [m5GeSdc;July 1, 2024;10:0]\nFig. 19. The pipeline and result for crowdsourced 3D edge map **reconstruction**. The figure is obtained from Herb et al. [118] works.\n\n| The comparison between centralized and crowdsourced approaches. Content Centralized   | Crowdsourced                                                        |                                                                               |\n|---------------------------------------------------------------------------------------|---------------------------------------------------------------------|-------------------------------------------------------------------------------|\n| Equipment                                                                             | Professional mobile mapping systems, Limited quantity               | Ordinary vehicles equipped with low-cost sensors, abundant crowdsourcing data |\n| Data                                                                                  | Laser point cloud, high-resolution camera, and other high-precision | Track, photo, video, and other low-cost sensing data                          |\n| data obtained by MMS                                                                  |                                                                     |                                                                               |\n| Precision                                                                             | high-precision centimeter level                                     | Low precision up to sub-meter or meter                                        |\n| Period                                                                                | Updated quarterly/monthly                                           | Update by month/week/day                                                      |\n| Cost                                                                                  | High                                                                | Low                                                                           |\n| Worker                                                                                | Surveying and mapping staff with professional training              | Volunteers, public and other non-professional surveying and mapping personnel |\n| Characteristic                                                                        | High-precision, low efficiency, long cycle, and high cost           | Limited precision, high efficiency, real-time update and low-cost             |\n| Suitable scenarios                                                                    | Reconstruction of large-scale new roads                             | Update of a few map changes with random distribution                          |\n\ncan be utilized in the map-matching process. Ding et al. [137] makes the LiDAR intensity-based map matching algorithm better by combining intensity and altitude cues in a way that adapts to different road conditions. This makes sure that localization is accurate even when the conditions are bad. Based on it, [137] adaptively fuses the map-matching result with a tightly coupled LiDAR inertial odometry to obtain a more accurate pose estimation. Bauer et al. [138] The localization performance has been demonstrated to achieve 10 cm or less localization error by benefiting from the dense geometric feature of the point cloud. 5.1.2. Vector landmark feature-based *localization* Compared to the point cloud HD map, the lightweight vector HD\nmap is more adaptable and simple to use. In contrast to the original point cloud HD map [128], the vectorized HD map format is far more lightweight and consists of static vectorized semantic features like lane lines, poles, and traffic signs. For mass-produced vehicles, matching the vector HD map with the affordable camera is an engineering and business-friendly option [126]. Researchers have worked hard to align the camera and the vector HD map. The fundamental idea behind it is to find semantic HD map landmarks in the image. The vehicle position may be made as efficient as possible by lining up the 3D landmarks in the vector HD map corresponding to the recognized landmarks in the image. Pink [139] employs aerial pictures to extract lane markings and their locations to create a lane-level map. They then use a straightforward ICP method to compare the lane marking feature in the image with the pre-built map. In addition, several different methods are employed, including direct point comparison [140,141]. Later work improved the map-matching localization by adding more sensors, like GNSS and IMU,\nto an Extended Kalman Filter (EKF) architecture. Tao et al. suggested integrating lost GPS, dead reckoning, and map-matching information from visual lane markings using the EKF fusion framework [142]. The video camera system uses lane markers to determine the vehicle's lateral distance and heading angle. They demonstrated the viability and potential of a vision-based map-matching approach for localization applications utilizing pre-built lane-level maps."}
{"doc414": "## 5.2. Cooperative Perception Based On Had Map\n\nHAD map is supplementary in improving the perception's performance and accuracy, especially in cooperative perception, which has been widely applied in autonomous vehicle areas. This subsection analyzes the role the high-precision map plays in improving perception.\n\n5.2.1. Expand the perception *range* Cooperative perception information needs temporal and partial alignment [143]. HAD map can act as a container that stores the multisource asynchronous sensing information from cooperative perception and distributes it to each vehicle, thus making over-the-horizon perception possible. Kim et al. [144] showed the demo of see-through visualization as a subfunction of over-the-horizon perception. Xiao et al. proposed a unified multi-target positioning framework that could handle the situation of occlusion perception and perception out of range [11]."}
{"doc415": "Priori mapping methods have been widely adopted by state-of-theart vehicles, such as Google, Uber, and Navya Arma vehicles [146]. HAD\nmaps provide centimeter-accurate priori map information to AVs and continually update map information based on collected sensor data [1].\n\nHere are some applications based on a priori map. Obstacle detection is done by observing differences between the priori map and the current sensor data [146]. Yang et al. exploited priori knowledge from HAD\nmap for 3D object detection [10]. Xiao et al. created a small semantic map model and a method for choosing landmarks ahead of time that can make alignment easier with onboard measurement [129]. Ghallabi double-checked the detected road sign to be valid if a correspondent road sign exists in the HAD map [147]. Many practices implement maps to store perception information. Rauch et al. modeled Car2X-based perception as a virtual sensor to integrate into a high-level sensor data architecture [148,149]. Kim et al. built a multivehicle system and explored cooperative perception, where sensing information was dealt with as a 2-D map, and cooperative perception was handled by map merging [150]. Xiao et al. extended the concept of HAD map to a map container, a theoretical model that solves the problem of cooperative perception.\n\nIt makes the driving environment space using data from various onboard sensors and the HAD map. It then estimates the vehicle's state using multi-source asynchronous redundant data and adds the HAD map's non-sensorized data on top of that. Moreover, complete estimating the state quantity in the driving environment space [11]. From the review above, the HAD map is a stable base and a powerful supplement to the cooperative perception of ICVs."}
{"doc416": "Navigation is an important part of autonomous driving decisionmaking and is also called mission planning [26,36,151,152]. In early autonomous driving, navigation information only used static information the route network definition file (RNDF), waypoints, and road topology for navigation. Subsequently, with the introduction and widespread use\n\n![13_image_1.png](13_image_1.png)\n\nof lane-level maps, road-level navigation algorithms are gradually applied to lane-level navigation [153]. Many methods often establish a special map topology based on the lane-level map for road search. At the same time, different types of costs are also considered when creating the topology map. After that, as the map contains more and more dynamic traffic information based on the distance, the navigation algorithm also considers traffic congestion, fuel consumption, and other data accordingly."}
{"doc417": "## 5.3.2. Planning\n\nWith the development of autonomous driving technology, adding semantic information in the map has further assisted the trajectory planning algorithm[154]. For example, some methods use point clouds to establish a potential field and perform trajectory planning based on the potential field, and some methods use information in a feature map to construct a cost function for trajectory planning. In recent years, with the development of learning-based planning algorithms, more and more planning methods rely on specific knowledge to make decisions [155]. Although this \"knowledge\" is not stored in the map for the time being, this information is related to geographic features, such as information related to cognitive state, state transition probability, and reward function. Using this information in trajectory planning also helps trajectory planning algorithms, as shown by Diaz-Diaz et al. [156] in Fig. 21.\n\n## 6. Futures And Challenges"}
{"doc418": "This section emphasizes the difficulties that will need to be overcome in the development of high-quality map technology. Here, we emphasize the significance of real-time dynamic updates, a unified map model, strong localization, map data confidence, V2X technology, and the security of map data. Furthermore, we complete this section with a future outlook on the HAD map industry as a whole.\n\n## 6.1. Challenges\n\n6.1.1. Real-time dynamic update of HAD map The real-time dynamic updating of automated driving maps is still challenging, especially for the crowd-sourced map update, which is mainly based on low-cost sensors. How to achieve high-precision maps based on visual data with limited accuracy? Due to the limited mapping accuracy of visual data and the lack of effective scale information, how to ensure the high accuracy and reliability of map element reconstruction based on visual data remains to be solved and broken through. Meanwhile, it is hard to combine data from multiple vehicles and sources that are accurate because the visual data collected by different vehicle ends is different in terms of angle, space-time scale, and other factors. The data from the different vehicle ends is also not always accurate because of things like positioning and matching errors, false detections, and missed detections. This makes it hard to combine data from"}
{"doc419": "Though HAD maps have been widely considered a key technology for autonomous driving, the key challenge for HAD maps is determining the levels of geometric, semantic, and real-time information to add to the standard map. Commercial use of HD maps also differs from research use depending on the application, and characteristics such as redundancy, compatibility, modularity, and interoperability are all major considerations that factor into the model and the data size of the map.\n\nA unified and universal multi-layer map model for automated driving maps is lacking. Currently, the existing automated driving map models are not unified in design, expression, interface, and other aspects. It is necessary to closely combine the actual needs of automated driving, especially in the face of complex road traffic scenarios in China, to establish a unified auto-mated driving map model that supports all elements, flexible expansion, and real-time updates.\n\n6.1.3. Robust localization based on HAD map and other *sensors* Although there are some localization algorithms at present, robust positioning still has some challenges in the face of complex traffic scenarios, especially low-cost, high-precision localization at the vehicle end. In the case of loss of GNSS signals at the vehicle end, achieving stable, reliable, and low-cost high-precision positioning in various complex traffic scenarios is a big challenge. Additionally, changes in lighting, weather, and other environmental factors can affect the performance of sensors like LiDAR and cameras. HAD maps may also not accurately reflect environmental changes, such as construction or road damage."}
{"doc420": "Compounding with the first challenge, the accuracy of the HAD map is critical to achieving accurate localization in ever-changing dynamic environments as illustrated in Fig. 22.\n\n## 6.1.4. The Confidence Level Of Map Data\n\nMaps have been helpful in assisting in navigational tasks and localization, perception, planning, and decision. These important tasks can ensure safety in several driving scenarios. However, the reliability of the map data proposed has its limitations. For example, even though the research direction trends towards the crowdsourcing method of a map update, there remains the challenge of putting a system in place to guarantee the map data is accurate and precise in every scenario. To address this challenge, a framework to quantify the reliability factor of the map data according to the time of the update or the number of updates that have happened in a given area can be a potential solution."}
{"doc421": "In the meantime, many articles always assume map data is a reliable information source. However, there are still many uncertainties in the construction process that have not been considered. 6.1.5. The combination of V2X *technology* Through the perspective of a single vehicle, the HAD map represents a vast amount of information that must be downloaded and processed before being used to supplement sensor fusion failure scenarios. However, with the addition of vehicle-to-everything (V2X) applications, HAD\nmaps can be considered a cloud solution where the amount of data can be optimized. The map itself can be broken down into static elements that act as ground truth and dynamic real-time elements that could be shared amongst vehicle nodes, thus lowering both the pre-processing and transmission requirements. Real-time traffic information could be transferred from vehicular nodes to the roadside unit (RSU) infrastructure, effectively building and updating the HAD map through a fleet of autonomous vehicles. The transmission of the real-time portion of the HAD map has been considered from the power and communication efficiency perspective. Though present-day HD maps have been built with top-end professional mapping vehicles, as sensor technology and quality have progressed and the barrier cost has been lowered, the potential for autonomous vehicles to create their high-definition maps has also been explored with promising results in accuracy.\n\n## 6.1.6. The Policy And Security Of Had Map\n\nAccurate 3D map information is related to national defense security. Therefore, strict laws and regulations have been implemented for the HAD map industry. In autonomous driving, HAD maps contain highly detailed and accurate geographical information, making them even more important to national security than traditional navigation electronic maps. For the security of HAD maps, in the process of uploading and publishing HAD maps, it is very important to ensure the security of geographic information by introducing bias and encrypting the data processing module. It is difficult to ensure the timeliness of map data updates and the security of real-time transmission of updated data from many sources by using the traditional offline processing mode of navigation electronic map data plus bias encryption. The policy about data security on the HAD map in China is designed to ensure national security. There is a lack of standards and specifications related to key technologies involved in high-precision maps, which requires the cooperation of government, industries, universities, and research units in the industry. At the same time, laws and regulations must be further promoted to support the development of automated driving, high-precision map-related technology, and industry progress reasonably."}
{"doc422": "## 6.2. Future Outlook\n\nThe future outlook for HAD map technology in the autonomous driving space is poised for significant growth and transformation. As selfdriving cars become increasingly common on the road, the industry is shifting towards a paradigm where strong perception technology takes precedence over traditional positioning technologies. Here is the author's take on the future outlook for HD map technology in this evolving landscape:\n1. Rise in Autonomous Vehicle **Deployment**: With each passing year, we can expect a substantial increase in the deployment of autonomous vehicles on the road. As more self-driving cars navigate our streets, the demand for accurate and up-to-date HD maps will grow exponentially. These maps will be a critical foundation for safe and efficient autonomous driving.\n\n2. Enhanced Perception **Technology**: One of the most significant trends in the industry is the emphasis on advanced perception technology. Autonomous vehicles will increasingly rely on a combination of sensors, cameras, LiDAR, and radar to navigate their surroundings. HD maps will complement these sensors by providing highprecision reference data, allowing vehicles to validate their perceptions and make informed decisions."}
{"doc423": "3. Positioning Technology **Approach**: Traditional positioning technology, such as GPS, is inherently limited in terms of accuracy, especially in downtown, urban canyons, or challenging weather conditions. Autonomous vehicles will rely less on global positioning systems and more on real-time sensor fusion and perception to determine their exact location. HD maps will assist in localization by matching sensor data with known map features with high precision and accuracy.\n\n4. Dynamic Map **Updating**: The future of HD maps will involve dynamic updating in real-time or near-real-time. Maps will no longer be static but will evolve continuously to reflect changing road conditions, construction, accidents, and other dynamic factors. This realtime map data will be essential for route planning, obstacle avoidance, and decision-making in autonomous vehicles.\n\n5. Collaborative **Mapping**: To keep maps accurate and updated, there will be greater collaboration between automakers, tech companies, municipalities, and even individual vehicles. Crowdsourced data and vehicle-to-infrastructure communication will play a significant role in maintaining the integrity of HD maps. This collaboration will result in more comprehensive and reliable mapping datasets."}
{"doc424": "6. Safety and **Regulation**: As autonomous vehicles become more common, safety regulations and standards will evolve accordingly. HD\nmaps will play a crucial role in ensuring the safety of self-driving cars, as they can provide a high level of redundancy and validation for the vehicle's perception systems. Regulatory bodies will work closely with the industry to establish map accuracy, updating, and security guidelines.\n\n## 7. Conclusion\n\nHAD map is a necessary database for automotive driving and has become the focus of countries at home and abroad. HAD map plays an important role in automated driving perception, positioning, control, decision-making, planning, and other aspects. However, achieving real-time dynamic updates of high-precision maps is difficult, seriously affecting the safety and reliability of automotive driving. Although the crowdsourcing of high-precision map updates still faces many challenges, the increased effort from governments, industry, universities, and research centers on this domain shows a positive outlook on the future of low-cost HD map building and maintenance. The rapid development and application of automated driving will also affect the advancement of HAD map technology in terms of its technology, policy, laws, and regulations."}
{"doc425": "[55] J. Wan, W. Luo, B. Wu, et al., Residual regression with semantic prior for crowd counting, in: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2019, pp. 4031\u20134040, doi:10.1109/CVPR.2019.00416.\n\n[56] D. Paz, H. Zhang, Q. Li, et al., Probabilistic semantic mapping for urban autonomous driving applications, in: IEEE International Conference on Intelligent Robots and Systems, 2020, pp. 2059\u20132064, doi:10.1109/IROS45743.2020.9341738.\n\n[57] H. Wang, C. Xue, Y. Zhou, et al., Visual semantic localization based on HD\nmap for autonomous vehicles in urban scenarios, in: Proceedings - IEEE International Conference on Robotics and Automation ICRA, 2021, pp. 11255\u201311261, doi:10.1109/ICRA48506.2021.9561459."}
{"doc426": "[84] M. Rezaei, M. Amiri, P. Mohajeri, et al., A new algorithm for lane detection and tracking on pulsed field gel electrophoresis images, Chemom. Intell. Lab. Syst. 157\n(2016) 1\u20136, doi:10.1016/j.chemolab.2016.05.018.\n\n[85] S.-C. Yi, Y.-C. Chen, C.-H. Chang, A lane detection approach based on intelligent vision, Comput. Electr. Eng. 42 (2015) 23\u201329, doi:10.1016/j.compeleceng.2015.01.002.\n\n[86] Y. Tian, J. Gelernter, X. Wang, et al., Lane marking detection via deep convolutional neural network, Neurocomputing 280 (2018) 46\u201355, doi:10.1016/j.neucom.2017.09.098. Applications of Neural Modeling in the new era for data and IT\n[87] S.L. Phung, M.C. Le, A. Bouzerdoum, Pedestrian lane detection in unstructured scenes for assistive navigation, Comput. Vis. Image Understanding 149 (2016) 186\u2013\n196, doi:10.1016/j.cviu.2016.01.011."}
{"doc427": "[88] H. Du, Z. Xu, Y. Ding, The fast lane detection of road using RANSAC algorithm, in:\nJ. Abawajy, K.-K. R. Choo, R. Islam (Eds.), International Conference on Applications and Techniques in Cyber Security and Intelligence, 2018, pp. 1\u20137.\n\n[89] Y.Y. Ye, X.L. Hao, H.J. Chen, Lane detection method based on lane structural analysis and CNNs, IET Intell. Transp. Syst. 12 (6) (2018) 513\u2013520, doi:10.1049/iet-its.2017.0143.\n\n[90] C.H. Quach, V.L. Tran, D.H. Nguyen, et al., Real-time lane marker detection using template matching with RGB-D camera, in: Proceedings of International Conference on Recent Advances in Signal Processing, Telecommunications & Computing\n(SigTelCom), 2018, pp. 152\u2013157, doi:10.1109/SIGTELCOM.2018.8325781."}
{"doc428": "[125] T. Wen, Z. Xiao, K. Jiang, et al., High precision target positioning method for RSU in cooperative perception, in: Proceedings of IEEE International Workshop on Multimedia Signal Processing (MMSP), 2019, pp. 1\u20136, doi:10.1109/MMSP.2019.8901755.\n\n[126] T. Wen, Z. Xiao, B. Wijaya, et al., High precision vehicle localization based on tightly-coupled visual odometry and vector HD map, in: Proceedings of IEEE Intelligent Vehicles Symposium (IV), 2020, pp. 672\u2013679, doi:10.1109/IV47402.2020.9304659.\n\n[127] K. Jiang, X. Zhang, B. Qin, et al., Feature-based loop closure detection and optimization for LiDAR mapping, in: Proceedings of International Forum on Connected Automated Vehicle Highway System through the China Highway & Transportation Society, 2020, doi:10.4271/2020-01-5225."}
{"doc429": "[156] A. Diaz-Diaz, M. Ocana, A. Llamazares et al. HD maps: exploiting OpenDRIVE potential for path planning and map monitoring, IEEE Intelligent Vehicles Symposium\n(IV), Proceedings(2022) 1211\u20131217. 10.1109/IV51971.2022.9827297\n[157] S. Zheng, J. Wang, High definition map-based vehicle localization for highly automated driving: Geometric analysis, in: Proceedings of International Conference on Localization and GNSS (ICL-GNSS), 2018, pp. 1\u20138, doi:10.1109/ICL-GNSS.2017.8376252.\n\nMengmeng **Yang** received the PhD degree in Photogrammetry and Remote Sensing from Wuhan University, Wuhan,China in 2018. She is currently an assistant research professor at Tsinghua University, Beijing, China. Her research interests include autonomous vehicles, high precision digital map, and sensor fusion.\n\nKun **Jiang** received the BS degree in mechanical and automation engineering from Shanghai Jiao Tong University, Shanghai, China in 2011. Then he received the Master degree in mechatronics system and the PhD degree in information and systems technologies from University of Technology of Compiegne (UTC), Compiegne, France, in 2013 and 2016, respectively. He is currently an assistant research professor at Tsinghua University, Beijing, China. His research interests include autonomous vehicles, high precision digital map, and sensor fusion."}
{"doc430": "and Mobility of Tsinghua University, Beijing, China. His research interests include computer vision, high definition map, and high precision localization for autonomous driving.\n\nJinyu **Miao** received the BS degree in Automation from Beihang University, Beijing, China in 2019. Then he received the MSc degree in Control Science and Engineering from Beihang University, Beijing, China in 2022. He is currently pursuing the PhD degree at the School of Vehicle and Mobility in Tsinghua University, Beijing, China. His research interests include highprecision localization and mapping for autonomous driving.\n\nJin **Huang** received his PhD and BE degrees from the College of Mechanical and Vehicle Engineering, Hunan University, China, in 2012 and 2006. He is also a joint PhD in the George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA, during 2009\u20132011."}
{"doc431": "He started his career at School of Software, Tsinghua University, Beijing, China, since 2013. He is now serve as an Associate Professor at School of Vehicle and Mobility, Tsinghua University. His research interests include artificial intelligence in Intelligent Transportation Systems, dynamics control, fuzzy engineering, etc.\n\nDiange **Yang** received his PhD in Automotive Engineering from Tsinghua University in 2001. He is now a Professor at the school of vehicle and mobility at Tsinghua University. He currently serves as the director of the Tsinghua University Development & Planning Division. His research interests include autonomous driving, environment perception, and HD map. He has more than 180 technical publications and 100 patents.\n\nHe received the National Technology Invention Award and Science and Technology Progress Award in 2010, 2013, 2018, and the Special Prize for Progress in Science and Technology of China Automobile Industry in 2019."}
{"doc432": "| Autonomous vehicles Autonomous mobility Public perception Road transportation Traffic safety   |\n|------------------------------------------------------------------------------------------------|\n\nAs the advancement of driverless technology, together with information and communication technology moved at a fast pace, autonomous vehicles have attracted great attention from both industries and academic sectors during the past decades. It is evident that this emerging technology has great potential to improve the pedestrian safety on roads, mitigate traffic congestion, increase fuel efficiency, and reduce greenhouse gas emissions.\n\nHowever, there is limited systematic research into the applications and public perceptions of autonomous vehicles in road transportation. The purpose of this systematic literature review is to synthesise and analyse existing research on the applications, implications, and public perceptions of autonomous vehicles in road transportation system. It is found that autonomous vehicles are the future of road transportation and that the negative perception of humans is rapidly changing towards autonomous vehicles. Moreover, to fully deploy autonomous vehicles in a road transportation system, the existing road transportation infrastructure needs significant improvement. This systematic literature review contributes to the comprehensive knowledge of autonomous vehicles and will assist transportation researchers and urban planners to understand the fundamental and conceptual framework of autonomous vehicle technologies in road transportation systems."}
{"doc433": "## 1. Introduction\n\nRoad transport system is significant in the transportation of goods and people from one place to another via the road network. The transportation of goods and people relies on the distance, weight, volume, and type of cargo, as well as the local road infrastructure. The demand for travel within an area is met by the availability of transportation services, collectively referred to as transportation systems. Analysing the relationship between road capacity and traffic volume is crucial in transportation studies. However, there have been significant issues with road transportation systems, such as traffic gridlock, road accidents, and inadequate road infrastructure, especially in a connected and automated driving environment (Alex et al., 2023; Barberi et al., 2022; Pappalardo et al., 2022).\n\nThe movement of people from one place to another is the core framework of the transportation planning and decisionmaking of urban planners in metropolitan cities. These cities primarily focus on walking, cycling (Zhang et al., 2023), and public transportation, which are starting to depend on electric vehicles and other intelligent shared mobility. These intelligent shared mobilities assists in accelerating the conversion of fuel-driven vehicles to electric vehicles and minimizes global warming and air quality failures. Urban areas have created and developed mechanisms to encourage people to use electric vehicles and not fuel-driven cars and single-passenger public taxis to achieve this aim. This is to convince people that sustainable transportation will continue in the future. Recently, metropolitan cities have invested financially in road infrastructure and intelligent transportation systems, which are necessary to assist connected multimodal transportation systems. This comprises of shared autonomous electric vehicles to replace less effective bus lines (Alonso Raposo et al., 2019). In addition, previous research carried out by transportation and logistics researchers on autonomous vehicles stated that the aim is to minimize the dangers of vehicular collision (Glaser et al., 2010), and Gelbal et al. (2020) suggested a new approach to the prevention of collision with reference to low-speed autonomous shuttles comprising of pedestrians in a real-life traffic situation in comparison to other approaches. Their objective was to focus on the immediate environment and safety of their driving environment, such as steering or braking, without any human intervention."}
{"doc434": "The importance of introducing autonomous mobilities into the transportation of goods and services cannot be underemphasized (Gonzalez-gonz  alez et al., 2019  ; Stead and Vaddadi, 2019; Ukaegbu et al., 2021b). In recent years, researchers such as Severino et al. (2021), Stead and Vaddadi\n(2019) and Mattas et al. (2021) have argued that the demand for autonomous mobilities will play a significant role in mobility in urban areas and its effects on the transportation of goods and services coupled with the risks associated with this disruptive technology on road transportation. There may be a reduction in the production of carbon and travel time spent in the vehicle, which allows the driver to engage in some other things rather than driving all day. However, it is not impossible to reduce traffic congestion and vehicular accidents, which are majorly caused by excessive drinking of alcohol, drivers not adhering to traffic rules, and tiredness\n(Olayode et al., 2022a). The primary objectives of autonomous vehicles are illustrated in Fig. 1.\n\nAccording to the previous studies (Fagnant and Kockelman, 2015; Kockelman et al., 2016; Litman, 2017; Olayode et al., 2020a, 2020b), autonomous vehicles are supposed to reduce accidents on the road and make travelling times shorter, accident-free, reduced excessive road maintenance (Bosch et al., 2018 \u20ac ), ergonomically comfortable, and more viable (Anderson et al., 2014; Brown et al., 2014; Fagnant and Kockelman, 2014; Wadud et al., 2016) and reduce the costs associated with travelling. Autonomous vehicles can lead to a gradual reduction of the overall number of vehicles on the road depending on the real-life traffic scenario (Bosch et al., 2018 \u20ac ; Chen et al., 2016; Zachariah et al., 2014; Zhang et al., 2015) and significant urban road capability (Brownell, 2013; Fernandes and Nunes, 2010; Friedrich, 2015). Using autonomous technologies to\n\n![1_image_0.png](1_image_0.png)"}
{"doc435": "transport goods will revolutionize the logistics and supply chain industry and change the status of urban transportation to a more robust, intelligent, and innovative system. Drastically reducing the overall expenses of travel may likely lead to a significant increase in additional travel demand (Gucwa, 2014; Hills, 1996) and usher in a new wave of suburban urbanization and urban development (Glaeser and Kahn, 2004).\n\n## 1.1. Research Gaps And Contributions\n\nMany transportation researchers have published academic literature describing the technological advancement of autonomous vehicles and their application in road transportation (Denaro et al., 2014). However, there is a limitation in the literature review which outlines the negative disruption of autonomous vehicle technologies and the application of autonomous technologies such as autonomous vehicles in transporting goods and services. Another significant observation is that despite recent research carried out by Bansal and Kockelman (2017) and Litman (2017), in which they stated that in the next 20 years, autonomous vehicles would have been widely implemented in road transportation systems worldwide (i.e., level 4 or 5 of autonomous vehicles). However, to our best knowledge, there is no research in the academic literature that critically scrutinizes the historical concepts, applications, and technologies of autonomous vehicles."}
{"doc436": "The changes experienced by road transportation over the last two years remain unprecedented. The outbreak of COVID19 and its variants have led to a renewed interest in autonomous vehicles and the application of autonomous technologies in the transportation of people, goods, and services. This paper aims to torchlight the importance of introducing autonomous technologies in the movement of goods and services, including their advantages and disadvantages. This literature review will provide a significant opportunity to advance our understanding of autonomous vehicles and make an important contribution to the field of connected and autonomous vehicles. Also, this literature review will explain the mode of autonomous vehicles comprehensively and systematically. The research gaps are summarized as follows.\n\n Public perception and acceptance of autonomous vehicles.\n\nWhile several studies have explored public attitudes towards autonomous vehicles, more research is needed to understand how the public views this technology, what factors influence their perception, and how to enhance public acceptability."}
{"doc437": " Drawing upon previous related studies, this research gives a comprehensive overview of the history and definition of autonomous vehicles, not excluding the public perceptions of different countries on using autonomous vehicles in their road transportation networks.\nThe overall structure of this literature review takes the form of eight sections. Section one gives a brief introduction comprising of the aim and contributions of this research.\n\nSection two gives an overview of the recent history of autonomous vehicles, and the third section is concerned with the methodologies used for this literature review. The fourth section presents autonomous vehicle technologies, including their advantages, disadvantages, and limitations. The fifth section of this research discusses the human public perceptions of autonomous vehicle technologies. The sixth section presents the theoretical dimensions of autonomous mobilities in the transportation of goods and services, including autonomous mobility-as-a-service (MaaS). The seventh section explains in detail the impacts of autonomous vehicles in road transportation systems regarding safety, traffic congestion and travel behaviour. Finally, the conclusion summarizes the implications of the findings and future research on autonomous vehicles.\n\n## 2. A Short History Of Autonomous Vehicles"}
{"doc438": "Autonomous vehicles were firstly envisioned in the early 19th century (Pendleton et al., 2017). The US, Germany, France, and Japan had R&D programmes from 1964 through the early 2000s to develop autonomous bus and truck platoons, intelligent vehicle systems, and video-based vehicle driving scene processors (Shladover, 2018). Automotive makers like Volvo have used autonomous driving technology since 2006 and introduced a fully autonomous test car (SAE levels 1 and 2) onto the road transportation network in 2017 (Shladover, 2018). In 2009, Google and other technology companies developed an autonomous vehicle within the SAE levels 1 and 2. By late 2020, WAYMO, a subsidiary of Alphabet Inc., had debuted its commercial AV prototypes, which had driven over 3 million miles in four US states. Since 2014, TESLA, another tech behemoth, has built electric vehicles with driverless capacity of operating 90% of the running time without human intervention (Shladover, 2018).\n\nCompletely self-driving vehicles, such as an NHTSA-level 4 autonomous vehicle (Aldana, 2013), ensured a rudimentary advance in car mobility. According to the National Highway Traffic Safety Administration (NHTSA) (2016), autonomous vehicles are expected to reduce road accidents and make travel times shorter and accident-free, less expensive\n(Boesch et al., 2016), more comfortable, and more viable\n(Kockelman et al., 2016), and substantially reduce the costs associated with travel. Children, the disabled, and the elderly will find travelling easier with AV (Anderson et al.,\n2014; Chong et al., 2013; Chun and Lee, 2015; Kockelman et al., 2016). Depending on the real-life traffic condition, autonomous cars can steadily reduce the number of vehicles on the road (Bosch et al., 2018 \u20ac ) and substantial urban road capability (Brownell, 2013; Tientrakool et al., 2011). Human errors on the road will be reduced by autonomous vehicles, and this is projected to result in considerable improvements in human and vehicular safety, vehicular mobility, and road transportation sustainability (Olayode et al., 2020a).\n\nNowadays, road transportation is experiencing a worrisome issue regarding the implementation of an autonomous vehicles in road transportation; issues such as traffic safety and road visibility issues are emerging. These issues must be addressed before AVs become a reality (Easa et al., 2020)."}
{"doc439": "Assume that all of the futuristic predictions regarding selfdriving cars come true. In that case, it will alter worldwide road transportation networks and transform urban transportation into a more robust, intelligent, and inventive system. Reduced travel expenses are likely to increase additional demand for travel (Gucwa, 2014), as well as a new wave of suburban urbanisation and urban development (Glaeser and Kahn, 2004).\n\nMoreover, there have been some significant issues with autonomous vehicles. These issues, for example, are the autonomous vehicle's reaction time to environmental changes and low public confidence are their key issues.\n\nAutonomous vehicles are often questioned, such as \"How soon will autonomous vehicles be part of our daily lives?\", \"Is it reliable?\", \"Will it decrease traffic and road accidents?\""}
{"doc440": "## 2.1. Different Levels Of Sae Automation\n\nAccording to the conceptual framework of an autonomous vehicle, we have four levels of taxonomy in automated vehicles; these levels were developed in 2013 by NHTSA (Wadud et al., 2016). In 2014, a level of taxonomy in automation, as shown in Fig. 2, was developed by the Society of Automotive Engineers International (SAE). It was later upgraded in 2016\n(Coppola and Morisio, 2016; Milakis et al., 2017; SAE, 2016a, b; Snyder, 2016). Later in 2016, NHTSA adopted SAE's levels of taxonomy and automation (NHTSA, 2016).\n\nIn conceptual theory, an automated vehicle system can be called an \"autonomous\" system if the automated system inside the vehicle can do the dynamic vehicle driving functionalities in a driving environment. Regarding the Federal Automated Vehicles Policy of the United States Department of Transportation, a vehicle is considered autonomous if it possesses levels 3e5 automated systems (Dot, 2016). The caveat about these autonomy levels is that they are not adequately maintained, and researchers have grouped all these levels of autonomy as autonomous (Shladover, 2018)."}
{"doc441": "![3_image_0.png](3_image_0.png)\n\nDriving a vehicle on the road requires essential functions such as localization, perception, planning, control, and management (Coppola and Morisio, 2016). Acquiring information about the immediate driving environment of an AV is significant to localization and perception. The availability of all these functions in a vehicle is what makes a vehicle autonomous. Suppose any autonomous vehicles have to communicate with various types of infrastructures to acquire information about their driving environment or negotiate their driving manoeuvres. In that case, it is referred to as a connected autonomous vehicle (CAV) (Shladover, 2018); however, when any human-driven vehicle, either manual or automated, has to communicate with different types of infrastructures to possess information, it is known as a connected vehicle (CV)\n(Coppola and Morisio, 2016; Hendrickson et al., 2014).\n\nTherefore, CV technology is complementary or synergistic to implementing autonomous vehicles to a certain degree\n(Shladover, 2018), even though connectivity is not a mandatory characteristic of an autonomous vehicle\n(Hendrickson et al., 2014)."}
{"doc442": "## 3.2. Source Of Literature Reviews\n\nThe search was only conducted on peer-reviewed manuscripts. The search was conducted from January 2021 to August 2021, and we only focused on articles published in the last ten years (2011e2021). Different types of searches were carried out by combining multiple keywords. The keywords applied were grouped into two significant categories. The first parentheses used in the first group were associated with the title of the journal and conference articles, and the second group was applied to the abstract of this research. The resultant search keywords were first verified by going through the abstract and reading the full text to verify their scope against the research objectives.\n\nThis research used three academic databases (i.e., Scopus, EBSCO and Web of Science) to search articles related to\n\"autonomous vehicles\" or \"automated vehicle technology\" or \"driverless vehicle\" or \"self-driving vehicle\" or \"autonomous driving\". These journal articles were then filtered by a criterion dependent on the inclusion and exclusion of relevant journal and conference articles to the aim and objectives of the research. According to the research by Mallett et al. (2012),\nthe inclusion and exclusion criteria applied for screening of data gathered are applied to achieve the aim and filter the data collected so that the valuable data will not be mixed with useless ones. The inclusion and exclusion techniques principles were created and applied to filter journal articles, select common features, and choose the most relevant articles that were gathered. A typical example is a journal article that is 15 years old and cannot be used to compare to the one published two years ago. A clearly defined inclusion and exclusion criteria will assist in sorting data gathered\n(journal and conference articles) on a homogenous level."}
{"doc443": "Table 1 shows the inclusion and exclusion criteria applied in this research.\n\nIt is important to note that these criteria are applied in sorting journal or conference articles according to their level of relevance to the research; this is important to ensure that the journal or conference articles used are appropriate for the research. An overall of 623 research articles were gathered using the keywords when searching academic databases such as Web of Science, Scopus, and EBSCO. The research narrowed its search to only English-language journals and conference articles because English is a universal language that is easy to speak and understand and is well-known in the academic community. Another significant criterion adhered to during this research is that the research only focuses on peerreviewed journal or conference articles to achieve a high level of credible research contribution. The table below summarizes the process of identifying the articles that are not excluded from the research.\n\n## 3.3. Sample And Sampling Techniques"}
{"doc444": "The up-to-date search carried out on these academic databases was investigated by applying the search keyword of\n\"autonomous vehicles\" or \"automated vehicle technology\" or\n\"driverless vehicle\" or \"self-driving vehicle\" or \"autonomous driving\" to identify related research that aimed at Autonomous Vehicle capacities and abilities. These up-todate searches came out with 623 research papers, which were reduced to 453 and 362 articles after deleting non-peerreviewed and duplicated articles (this is shown in Table 2). It was further reduced to 158 after deleting non-English research articles. Fig. 4 illustrates the breakdown of how the articles used for this research were analysed considering the three academic databases used: Web of Science, Scopus, and EBSCO. Fig. 4 shows the PRISMA flowchart that was developed for the literature review. Fig. 5 shows the analysis of the search keywords in Fig. 5, \"AV\" is autonomous vehicles, \"AVT\" is automated vehicle technology, \"DV\" is driverless vehicle, \"AD\" is autonomous driving, \"SDV\" is selfdriving vehicle.\n\n## 4. Autonomous Vehicle Technology\n\nIn the last few years, autonomous vehicle technology has been making headway in road transportation systems, especially in the shape of advanced driver assistance systems\n(ADAS), which can be found in research and public transportation vehicles. Autonomous vehicle technologies aim to reduce or increase vehicular crashes, enhance the mobility of people with disabilities, reduce greenhouse gas emissions, and encourage transportation infrastructure applications more effectively (Fagnant and Kockelman, 2015). One of the primary reasons why there is an acceleration of advancement of autonomous vehicle technologies is avoidable human-dependent errors such as human fatigue"}
{"doc445": "| Table 1 e The inclusion and exclusion criterion. No. Inclusion criterion   | Exclusion criterion                       |                                                  |\n|----------------------------------------------------------------------------|-------------------------------------------|--------------------------------------------------|\n| 1                                                                          | High peer-reviewed articles               | Articles that are not peer-reviewed              |\n| 2                                                                          | Original articles                         | Duplicate articles                               |\n| 3                                                                          | Articles written in the English language  | Articles not written in the English language     |\n| 4                                                                          | Possessing one or more search keywords in | Articles do not have any search keyword in their |\n| the abstract or keywords of the article.                                   | abstract or titles.                       |                                                  |\n\n| Table 2 e Compilation of the selection and inclusion of articles used in this research. Academic Search keyword Selected Deleting non-peerreviewed article After deleting duplicated                              | After deleting      |         |                     |     |    |\n|------------------------------|---------------------|---------|---------------------|-----|----|\n| database                     | article             | article | non-English article |     |    |\n| Scopus                       | Autonomous vehicles | 58      | 36                  | 26  | 13 |\n| Automated vehicle technology | 47                  | 32      | 27                  | 15  |    |\n| Driverless vehicle           | 50                  | 40      | 32                  | 15  |    |\n| Autonomous driving           | 73                  | 63      | 47                  | 10  |    |\n| Self-driving vehicle         | 62                  | 41      | 39                  | 13  |    |\n| Web of Science               | Autonomous vehicles | 68      | 57                  | 42  | 16 |\n| Automated vehicle technology | 52                  | 39      | 29                  | 14  |    |\n| Driverless vehicle           | 34                  | 24      | 19                  | 10  |    |\n| Autonomous driving           | 56                  | 39      | 30                  | 10  |    |\n| Self-driving vehicle         | 33                  | 22      | 18                  | 12  |    |\n| EBSCO                        | Autonomous vehicles | 22      | 19                  | 15  | 12 |\n| Automated vehicle technology | 13                  | 10      | 8                   | 4   |    |\n| Driverless vehicle           | 19                  | 10      | 9                   | 4   |    |\n| Autonomous driving           | 26                  | 16      | 16                  | 5   |    |\n| Self-driving vehicle         | 10                  | 5       | 5                   | 5   |    |\n| Total                        | 623                 | 453     | 362                 | 158 |    |\n\n![6_image_0.png](6_image_0.png)"}
{"doc446": "and distractions when driving. All these human errors have been known to be the primary cause of 93% of road accidents from a statistical survey from NHTSA (Fagnant and Kockelman, 2015). The processes involved in the navigation of autonomous vehicles are shown in Fig. 6.\n\nCurrently, a primary issue is the occurrence of a brand new, unsafe act of driving by drivers who do not want to adhere to or understand the guidelines and ethical obligations when it comes to using AV-related technologies (Kyriakidis et al., 2019; Lowry et al., 2015). Additionally, it is of paramount importance for self-driving features and vehicles to significantly enhance the driving safety of vehicles and pedestrians, improving the mobility and effectiveness of AV\ntechnologies. Pedestrians and drivers must have a rudimentary understanding of the abilities of the AV\ntechnology (Kyriakidis et al., 2015, 2019). This comprises important features like technological limitations and technology usage, not excluding the suitable occurrences to apply or depend on the AV technology.\n\nIt is important to note that the navigation framework of an autonomous vehicle can be categorized into five primary components (Fig. 6). According to Cheng (2011), these five components are perception, localization and mapping, path planning, decision making, and vehicle control. Perception applies sensors to regularly scan and supervise the driving environment, which is almost similar to the vision of a human being (Maurer et al., 2016). Other components such as localization and mapping algorithms can be used to evaluate the global and local environment of the ego-vehicle and map the environment by using the sensor data and perception outputs (Maurer et al., 2016). AVs' primary components such as path planning can be used to evaluate"}
{"doc447": "![8_image_0.png](8_image_0.png)\n\nunpredictable weather conditions (Maurer et al., 2016). In addition to this, the module associated with the vehicle control will then evaluate the suitable vehicle command, such as the vehicular acceleration, the angle of the steering wheel, and the torque. The evaluation is done to adhere to the appropriate decision-making regarding changing lanes or manoeuvring (Gruyer et al., 2016). It is imperative to understand that the navigation process of an AV involves an elevated frequency level of a recursive process. This elevated frequency enables AVs to supervise and control movable objects efficiently and possess high speed, for example, pedestrians, motorbikes, and vehicles (Julier and Durrant-whyte, 2003).\n\nIt is a common occurrence that vehicles usually possess their drive-by-wire functionality. This statement means that various distinct driving mechanisms, including but not limited to steering, can be supervised and controlled by a joystick or sophisticated computer software. This offers an interface between the hardware and software. The sensors fitted in the vehicles are interconnected to a group of computing systems connected to share data. The computing systems comprise the output connected to the steering wheel's motors, brake, and throttle. This computing system drives the vehicle."}
{"doc448": "Autonomous vehicles' intelligence allows them to autonomously navigate a traffic flow at a freeway or a road intersection can be found in the vehicle's software. This intelligence software functions as a tool for mapping the sensory percept of the sensors' sensors to the actuators' activation. However, the mapping is complicated, considering that many sensors create so much data information applied in complex manoeuvres navigation. Therefore, a gradual and hierarchical method is adopted, at which point having a proper clarity of the function ability of sensor percept occurs in various ways applied to create a world map. Another use of a sensor in autonomous vehicles is in the determination of the location of the vehicle. The autonomous vehicle's motion arrangement depends on a map representation of the world and the vehicle's GPS. Motion planning occurs in various distinct stages of hierarchies. The trajectory of the autonomous vehicle created by motion planning is imperative to the control algorithms. The vehicle can be controlled and send necessary signals to the actuation units.\n\nAutonomous driving is therefore in continuous evolution and development. Although current automotive innovation has reached astonishing levels of automation, an even greater acceleration is expected in the coming years. The ultimate goal, which many car manufacturers are aiming for, is to reach level 5, ensuring that the driver is always safe and comfortable to drive.The automotive industry is working on optimising technologies to be implemented in autonomous vehicles and improve road transport, logistics and personal vehicles. Sensors are certainly critical components of autonomous vehicles. They can detect objects in the path of the vehicle and act as eyes, providing data from which autonomous decisions can be made. Cameras play a key role in image classification and interpretation (texture) and are currently the most valuable and widely used sensor type. They are the main sensors used by advanced driver assistance systems\n(ADAS) for frontal vision and recognition of traffic signals. The data acquired by the sensors convey information of crucial importance for vehicle decision-making. Several of the sensors used in today's autonomous vehicles incorporate advanced functionalities that enable them to handle all possible driving scenarios in all environmental conditions.\n\nHigh dynamic range (HDR) is a critical and critically important specification of camera sensors. This parameter defines the sensor's ability to record information in different lighting conditions within a scene (where obviously there will be lighter and darker parts) without over- or under-saturation."}
{"doc449": "The use of sensors with higher and higher resolutions is another important technological trend in the field of autonomous vehicles. Autonomous vehicles must not only be able to see further, but also detect objects of any size. This makes it possible to increase the number of pixels per degree on the object and gives greater efficiency to the automatic driving algorithms, which are then able to perform object detection and classification tasks (Royo and Ballesta-garcia, 2019).\n\nFor autonomous vehicles of level 3 and above, the dependence on hardware and software for decision-making is very high, not to mention that the vehicles themselves are more exposed to the danger of cyber attacks and fraudulent access\n(hacking). This has led to the development of numerous protection and security features. Another technology used in autonomous vehicles is LiDAR, although the cost is high. LiDAR's ability to create a 3D point cloud sets it apart from other sensing technologies. The objective is not only to detect an object on the road, but also to make a classification, provide feedback to the decision-making system and modify the vehicle's route when necessary. The reflectivity of an object also plays a crucial role. While current LiDARs are able to remotely detect objects with high reflectivity, further improvements are needed to enable these devices to detect objects with low reflectivity over long distances (Royo and Ballesta-garcia, 2019).\n\nRadar is another popular type of sensor that is of critical importance for the future of self-driving vehicles. The advantages of radar are evident during night-time driving and in all weather conditions. Millimetre-wave radars are a particular class of radars that use electromagnetic waves with short wavelengths and are rapidly gaining popularity in autonomous driving applications. By acquiring the reflected signal, a radar is able to determine the range, speed and angle of objects. A further advantage is that more integrated and compact designs can be achieved without the need for large, visible antennas (Bilik et al., 2019)."}
{"doc450": "Autonomous vehicles are undoubtedly one of the most eagerly anticipated innovations that will radically change the lifestyles of millions of people around the world. As this technology becomes more accessible to the general public, the overall effects-whether positive or negative-will have a significant impact. In particular, traditional and new car manufacturers are pursuing several actions aimed at developing both personally owned production vehicles and robo-taxis.\n\nDespite advances in technology and interest from the public and businesses, the autonomous vehicle industry is still facing many challenges, foremost of which is safety.\n\nAlthough with some progress on safety, the regulation that could enforce safety requirements is largely absent, and it is still unclear how local authorities will administer the laws and regulations governing the use of autonomous vehicles. Some states have enacted legislation for autonomous vehicles."}
{"doc451": "Another challenge with the technology is trying to understand the area in which AVs can be most useful. One industry sector that is crying out for autonomous vehicles is the truck sector, which suffers from a widespread shortage of drivers. An autonomous vehicle on the motorway is much easier than driving an autonomous vehicle in the city. Autonomous vehicles are not at the stage where car manufacturers thought they would be by now. However, some vehicles are operating commercially with safety drivers inside. While some are focussing on trucks on highways because it's easier than driving in cities and doesn't contain many intersections, others are limiting the scope of their version of autonomous vehicle technology by geography, location or weather conditions.\n\nIn general, autonomous vehicle technology is still firmly in the experimental phase. It is possible to divide the mission of an autonomous driving system into four main steps: The first step is detection and perception, using a software system on top of an array of sensors including cameras, radar, lidar and ultrasonic sensors. The sensors observe the world around the vehicle to detect its surroundings. The next step is to make sense of all the different objects surrounding the vehicle (e.g., object recognition, pedestrians, cyclists, other vehicles and roadside objects). After prediction, the next step is to plan a route for a vehicle to drive through that environment. The final step is control. This is where the system sends signals to the steering, brakes and accelerator to get the car or truck where it needs to go. One of the thorniest problems for autonomous vehicle technology is the prediction phase. While it might be easy for the autonomous vehicle to figure out what other vehicles might do, pedestrians are relatively unpredictable and can easily change their minds at any time.\n\n## 4.1. Advantages Of Autonomous Vehicle Technology"}
{"doc452": "In the past decade, autonomous vehicles have been proposed to be operated both as non-commercial and as public vehicles in the not-too-distant future (Collingwood, 2017; Heinrichs, 2016; Wadud, 2017). One of the merits and flexibility of autonomous private vehicles compared to conventional private vehicles is that they can simultaneously be used among all family members, depending on the size of the family. Non-private autonomous vehicles can be used as commercial taxis, transit buses, or freight services. Public autonomous taxis can offer services as a combination of traditional car-sharing and taxi services, known as shared autonomous vehicles (SAV) or driverless public taxis (Fagnant and Kockelman, 2014; Krueger et al., 2016). Public perception prevails that driverless public taxi is likely to improve public transportation systems. It can likely replace or reduce the usage of private vehicle ownerships because SAVs are expected to be cheap and aid opportunities for multitasking when driving (Krueger et al., 2016; Malokin et al., 2015; Milakis et al., 2017). Despite the cooperation traditional taxi drivers have when they use conventional vehicles, they still want to profit maximization and shorter travel time (Boesch et al., 2016).\n\nSome transportation companies, such as Uber and Lyft, have been trying to create a model that is no different from SAVs in their daily operations. However, although its process is autonomous in this model, human drivers oversee its driving routing, relocation, driving operation times, and other immediate driving environment decision-making features. Despite that, 100% central control system of SAV can tackle the limitations of non-autonomous taxi services. Therefore, SAV can create more system-optimal and ensure a comprehensive profit-maximizing transportation network with a higher service level and lower cost of travel time when compared to conventional public taxi services and transportation companies (Fagnant et al., 2015). SAV can expedite dynamic ridesharing (DRS) by applying a comprehensive information communication technology. Therefore, SAV\ncould provide driving services with or without DRS (Krueger et al., 2016). The limitations or problems associated with conventional ridesharing services can be addressed or tackled via the application of DRS (Krueger et al., 2016) or driverless public taxis (Martinez and Viegas, 2017). The theoretical framework of mobility-as-a-service (MaaS) can also be accommodated with the application of SAV and DRS.\n\nPublic transportation operations such as taxi, bus, and freight services can benefit from the use of automation by reducing driver's cost of expenses (Wadud, 2017)."}
{"doc453": "The application of driverless private vehicles of taxis will reduce the demand for parking spaces in malls and offices, making these spaces available for other economic activities or for constructing and expanding more roads or road lanes. This may lead to an increase in urban migration (Bagloee et al., 2016; Levine et al., 2017). However, reliability in the mode of travelling, comfortability, and travel time reduction may likely lead to long commuting distances, contributing to metropolitan cities' expansion and influencing real-estate prices city's outskirts (Heinrichs, 2016; Rubin, 2016; Snyder, 2016). With the assistance of autonomous and cooperative technology, the introduction of platooning characteristics in freight and public bus transportation services will significantly increase the capacities of roads in public transportation. These are a few well-known examples of autonomous vehicles regarding their diversity in application.\n\nAs discussed in the paragraphs above, AVs' modern technological improvement and advantages are all connected (Heinrichs, 2016).\n\n## 4.2. Limitations Of Autonomous Vehicle Technology"}
{"doc454": "In the last few years, the world has experienced a lot of revolutionary changes when it comes to road transportation systems and the integration of artificial intelligence into the foundational framework of road transportation systems\n(Olayode et al., 2021b, 2021c; Ukaegbu et al., 2021a). Some of the revolutionary changes are also because of the rapid technological innovations in engineering, science, and technology, for example, the wide human usage of laptops and AI portable devices. The introduction of autonomous vehicle technologies into the road transportation system has been regarded as one of the significant breakthroughs in the last few years. It also may propose a significant threat in the future years to come. However, it is important to understand the limitations associated with the introduction of autonomous vehicle technologies in road transportation systems; understanding the limitation will pave the way for developing feasible solutions to tackle these limitations\n(Howard and Dai, 2014). Table 3 presents the tabular information's on the limitations of autonomous driving technologies.\n\n4.2.1. Technological efficiency The first significant challenge that must be tackled to introduce self-driving vehicles to reality is creating suitable autonomous driving technology. However, despite the tremendous technological advancements that have been made in terms of autonomous driving technology, most AVs manufacturers are still struggling with safety issues when it comes to the immediate driving environment. Artificial intelligence algorithms which are applied for identifying the immediate driving environment of a vehicle are not strong enough when it comes to efficiency and effectiveness in operating in unstable urban driving environments, and also these technologies struggle in unstable weather conditions such as hurricanes, typhoons, and heavy snowfalls (Bezerra and Gomes, 2015). Additionally, autonomous vehicles require high resolution and are well detailed for navigation compared to the present being used (Levinson et al., 2011a).\n\nFinally, when it comes to communications between autonomous vehicles, there must be no breakdown in communication because such breakdowns can lead to unpredictable disastrous consequences (Gerla et al., 2014)."}
{"doc455": "4.2.2. Protection of data and privacy Data privacy and protection remain one of the most severe threats to the functionality of autonomous vehicles. Personal information is significant for the software servers of autonomous vehicles (Glancy, 2012). This personal information may comprise sensitive information on the owner or driver of the vehicle, such as phone number, address, location, and gender. Although it is not clear who will want to use this information for their benefit, it has been discovered that online hackers have hacked this information over the years. Exorbitant ransoms are being asked from individuals whose information is hacked. This is one of the primary reasons people are skeptical about uploading their biodata online, even if the car-making company assured them zero security breaches.\n\n4.2.3. Cyber security Another significant issue regarding AVs similar to the above limitation is the ease at which hackers can hack with ease any software. And the increase in vulnerability of these software's to outside hackers. At present, it is possible that someone that hacks your car can have access to your biodata, and they can use this information to take over the control of your car even without you knowing it. These can lead to terrorist attacks in some exceptional circumstances (Fagnant and Kockelman, 2015). In conclusion, autonomous vehicles must be verified Table 3 e Summary of limitations of autonomous driving technology.\n\nLimitation of autonomous driving technology Related study"}
{"doc456": "(2014)\n\nto be 100% protected from hackers and outside interferences before they are introduced into the road transportation system.\n\n4.2.4. Legislation-liability surrounding AVs In the last few years, transportation researchers have discovered that the problem of legislation and liabilities is becoming a significant roadblock for the integration of AVs into road transportation notable among these roadblocks is that each nation in the world have their required age of when you are supposed to start driving a car, for example, the age you can start driving a vehicle is 18 years old in South Africa while in Australia it is 16 years old, and this all depends on the person passing their driving license examination. Another major roadblock is the liability problem in case there are road accidents involving AVs, liabilities which are usually judged according to the driving code of that country. These roadblocks are usually caused because AVs are still regarded as an innovative transportation system, so there is no legislation or requirements for them to be integrated into urban transportation. Also, there is the problem of who should take responsibility if an accident happens because an autonomous vehicle is a driverless vehicle, nobody is driving the vehicle. All these roadblocks concerning legislation and liabilities need to be removed before autonomous vehicles can smooth integration into the transportation market (Hevelke and NidaRu\u00a8melin, 2015)."}
{"doc457": "## 5. Public Perceptions Of Autonomous Vehicles\n\nExisting studies have examined the features related to human interests in autonomous vehicles, people's attitudes towards autonomous vehicles technology, and the level of willingness to buy, drive, and adopt autonomous technologies. Many researchers have indicated that adults and grown-up males are the two demographics that have more open and positive perceptions concerning autonomous vehicle technology\n(Anania et al., 2018; Hulse et al., 2018; Lee et al., 2017; Nielsen and Haustein, 2018). Specifically, young adults and men have been investigated to be more agreeable to the conception that autonomous vehicles will enhance driver and motorists' safety (Nielsen and Haustein, 2018), have non-existent concerns about the safety of autonomous vehicles in the immediate driving environment (Kyriakidis et al., 2015; Schoettle and Sivak, 2014), and are willing to apply the technology (Smith and Anderson, 2017; Payre et al., 2014). Considering these demographics, they have been related to dangerous motorists' behaviour (Turner and Mcclure, 2003)\nand dangerous behaviour of pedestrians (Holland and Hill, 2007; Rosenbloom, 2009). All these behaviours are related to the elevated possibility of collision, resulting in the worst road safety consequences. Due to these behavioural occurrences, Hulse et al. (2018) stated that the positive attitudes of male adults towards autonomous vehicles may likely lead to more elevated manifestations of the benefits of road safety.\n\nAdditionally, research has shown that young adults, especially men and university educated adults and residents of metropolitan cities, have positive perceptions of autonomous vehicles, including the willingness to apply this technology (Schoettle and Sivak, 2014; Smith and Anderson, 2017)\nand increased attitudes towards the safety of AVs (Nielsen and Haustein, 2018; Schoettle and Sivak, 2014). Research carried out by Sanbonmatsu et al. (2018) discovered that the increased knowledge of the operations of AVs is related to the agreement that they would be unsafe because of technological limitations and insufficient familiarity with the operations of AVs; however, self-reported perceived technological-know-how of autonomous vehicles had a negative correlation with these beliefs. However, several researchers have investigated and indicated the significant attitudinal characteristics that explain these attitudes (Choi and Ji, 2015; Nees, 2016; Tussyadiah et al., 2017). A research investigated in Denmark stated three classes of respondents depending on reported attitudes: enthusiasts, skeptics, and an indifferent group in between with higher car stress."}
{"doc458": "Enthusiasts were primarily likely to have a college degree, try new innovative technologies in the adoption curve, reside in Copenhagen, and probably be young males. The likely merits of autonomous vehicles, such as driving safety, indicated the biggest gap between skeptics and enthusiast respondents; in contrast, 56.8% of enthusiasts indicated a belief that driverless vehicles would ensure road safety, only about 7.4% of skeptics and 20.7% of indifferent individuals are of the opinion about the same (Nielsen and Haustein, 2018).\n\n## 5.1. Global Comparisons On Human Perceptions Of Autonomous Vehicles\n\nInvestigations carried out by multiple nations have shown that people's perceptions about autonomous vehicles and the socio-demographics that predict autonomous vehicles operations are widely different among countries. Haboucha et al."}
{"doc459": "(2017) discovered that people's gender played an important role in predicting perceptions of autonomous vehicles in Israel, indicating that adult males are more interested when compared to their female counterparts. Still, the opposite is the case in the United States of America because there is no significant difference in perceptions of gender to AVs. The authors concluded that their research implications, especially regarding human perceptions of AVs, are because of the cultural differences between Israel and the USA.\n\nAnania et al. (2018) carried out research on the perceptions of Indian society on AVs. They discovered that Indian women are more willing to use autonomous vehicles than their Indian men. However, the opposite is the case in the United States of America. The men embrace the idea of AVs more than the women. Research using a methodological approach involving participants from developed countries such as Germany, China, Japan, and the United States discovered a major disparity in attitudes towards autonomous driving in these four developed countries\n(Sommer, 2013). In the research, about 45% and 62% of participants in Japan and the United States consider autonomous driving as dangerous to pedestrians and motorists. About 74% of participants in China believe that autonomous technology is reliable, and only 38% in Japan believe that autonomous vehicles will be part of our daily lives in the future. An investigation on the public perception of pedestrians on AVs was conducted in 2014 in the United States, United Kingdom, and Australia in which they concluded that there is a significant difference in attitudes participants used in the research; for example, participants from the United States have positive mindsets when it comes to using AVs, but they are also concerned about the safety of riding in it as compared with participants from other developed countries (Schoettle and Sivak, 2014).\n\nTable 4 shows the various types of related research of human perceptions regarding AVs."}
{"doc460": "The pie chart shown in Fig. 7 shows the number of factors or key determinants identified (Table 4) as human perceptions regarding AVs. From Fig. 7, the size of each slice represents the level of human perceptions or concerns regarding AVs, and it is constructed based on the frequency of each perception among the various studies. From the plot, a combination of other factors such as gender, cost of AV technology, trust, legal labilities, safety, and control as well as consequences regarding the use of AV technology had the highest (12.93%)\nvariables of human perception (see column chart). This is an indication of the level or majority of concerns spanning from these factors. Loss of vehicle control (10.34%), liability\n(10.34%) and equipment failure (10.34%) followed as factors that determine public or human opinions towards AV technologies.\n\n## 6. Application Of Autonomous Mobilities In The Transportation Of People And Goods 6.1. Autonomous Shuttles\n\nThe autonomous shuttles comprise no driver seats, steering wheel, or accelerating or brake pad pedals. They are programmed to adhere to an already existing route while associating with other vehicles and pedestrians in their immediate driving environment. The autonomous shuttles themselves are fully equipped with sensors and computing capacities, and they assist the autonomous shuttles in perceiving their environment and correcting themselves when facing any driving emergencies. This is to ensure the safety of the passengers. The organization and management of mobility services within urban areas and satisfying the expectations of pedestrians is gradually becoming a complex and challenging task. The inability of conventional transportation systems models to tackle this task has been compounded by the proliferation of alternative options such as social and grassroots frameworks to achieve a flexible mode of transportation, for example, carpooling and ride-sharing services."}
{"doc461": "Some of these objectives have been achieved, especially with the successful introduction of Uber and Lyft in public road transportation network. However, these solutions are not enough. It is only focused on specific mobility groups and not all the mobility ecosystems, which are primarily dependent on traditional public and private transportation systems. However, recent research studies carried out by mobilities researchers only evaluate queuing-related problems with autonomous cars in smart urban areas (Cui et al.,\n2018). There is a need for a new approach in managing the transportation of people and goods and services required in sustainable smart urban cities. Researchers have stated that the introduction of driving autonomously in city driving environments is still a challenge (Rasouli and Tsotsos, 2019), and there is little or no research finding solutions or discussing these problems. Research done on smart transportation has created dynamics models used for the connected automated vehicles (CAV) -dependent traffic control system (Zhang et al., 2018) and application of V2X channels of communications (Kuutti et al., 2018). In recent years, the concepts of the mobility-as-a-service ecosystem have been experiencing severe challenges in providing effective services due to short distances (Peled et al., 2019).\n\nThe reason why a new mobility model was introduced was that there is a need for the introduction and operation of a new mobility model to use autonomous shuttles as a primary provider of services that are innovative and efficient, which is also known as autonomous shuttle as a service (ASaaS). ASaaS\noffers support for an efficient shared, non-rigid, and contextualized delivery of goods and services in the area known as last-mile mobility. According to Bucchiarone et al. (2020) there is an expectation that mobility services providers will provide different types of ASaaS products in a modular and extensible way. The merits of these are that it will assist in designing mobility architectures that will be flexible in adaptation to delivery of services to different types of customers such as citizens, tourists, and aged people and not excluding market advertising and last-mile delivery of goods and services. The autonomous shuttle as a service model is of benefits to the following users.\n\n Municipalities: this is useful to municipalities and communities via cost reduction, traffic congestion, reduction in greenhouse gas emissions, and gradual decrease in energy consumption."}
{"doc462": " The city service providers: These providers can be government-owned or privately-owned companies. They offer them a more customer base coupled with the service flexibility needed to run day-to-day activities more costeffectively.\n\nThe collectivity assists the emergence and diffusion of creative, intelligent mobility solutions that are aiding in reducing traffic jams in urban areas and promoting the right to autonomous mobility in rural and disadvantaged areas. The primary aim of the ASaaS model is to create an information technology template that will support the definition and implementation of a portfolio of city mobility services that are i) are tailored-made to satisfy the travellers needs and choices to and that, at the same time, ii) exploit synergistically and collectively the pre-existing mobility services. The similarity is that these mobility services make use of technology behind the autonomous shuttle hardware and software that can be configured to be used in any environment (i.e., shopping malls, hospitals, private companies, stadiums, university surroundings, etc.) and for different types of aims such as management of events, delivery of goods and services and security management.\n\n| e1060 1050J. Traffic Transp. Eng. (Engl. Ed.) 2023; 10 (6): 1037                                 |                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n|--------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Table 4 e Different researches of human perceptions on autonomous vehicles. Research Methodology | Location of study                                                                                                                                                                                                                                                       | Conclusion                                                                                                                                                                                                            |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Schoettle and Sivak (2014)                                                                       | Questionnaires                                                                                                                                                                                                                                                          | United States of America (USA), United                                                                                                                                                                                | The findings of this study show that females are more                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n| Kingdom (UK), and Australia                                                                      | inclined to be concerned about the use of AVT than males. In addition, most of the participants would like to have AVT installed in their vehicles, but they are not willing to accrue such technology's cost. They believe it is too expensive to install or maintain. |                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Howard and Dai (2014)                                                                            | Questionnaires                                                                                                                                                                                                                                                          | California, United States of America                                                                                                                                                                                  | The implication of this research shows that many people are willing to use AVT due to its multi-tasking abilities and efficient parking techniques. However, people are worried about the expensive cost of AVs. Another important finding is that men are less worried about AVs \"self-driving\" aspects but more concerned about the liability.                                                                                                                                                                               |\n| Choi and Ji (2015)                                                                               | Questionnaires                                                                                                                                                                                                                                                          | Unknown                                                                                                                                                                                                               | The major determinants in using AVs are trust and its perceived applications.                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Kyriakidis et al. (2015)                                                                         | 63 research questions internet-based                                                                                                                                                                                                                                    | 5000 responses from questionnaires from 109                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| questionnaires                                                                                   | countries (developed and developing countries)                                                                                                                                                                                                                          | The result of this research shows that most participants prefer manual driving. The respondents are more concerned with legal liabilities, AV software malware attacks, and driving safety regarding AV technologies. |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Bansal et al. (2016)                                                                             | Simulation-depended fleet evolution                                                                                                                                                                                                                                     | Unknown                                                                                                                                                                                                               | The result of the study shows the eight-level of application                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| conceptual framework                                                                             | stages of AV technologies in the USA from 2015 to 2045                                                                                                                                                                                                                  |                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Krueger et al. (2016)                                                                            | Questionnaire                                                                                                                                                                                                                                                           | Unknown                                                                                                                                                                                                               | The results show that AV's application and acceptance are based on service features such as travel time, cost of travel, and waiting time.                                                                                                                                                                                                                                                                                                                                                                                     |\n| Daziano et al. (2017)                                                                            | Application of vehicle-purchase discrete choice                                                                                                                                                                                                                         | Country-wide group of 1260 people                                                                                                                                                                                     | Their findings show that the average family is only willing to part away with $3500 for partially autonomous vehicles and about $4900 for fully autonomous vehicles.                                                                                                                                                                                                                                                                                                                                                           |\n| Menon (2017)                                                                                     | Questionnaire                                                                                                                                                                                                                                                           | Unknown                                                                                                                                                                                                               | This study shows that the consequences of relinquishing the control of vehicles are different compared with single and multi-vehicle-family households.                                                                                                                                                                                                                                                                                                                                                                        |\n| Lee et al. (2017)                                                                                | Questionnaire                                                                                                                                                                                                                                                           | Country-wide samples of about 1800 adults in the United States of America                                                                                                                                             | The study's implication shows that \"age\" is an important factor when using AVT. Most adults tend to favour the usage of AVT compared to people above that age.                                                                                                                                                                                                                                                                                                                                                                 |\n| Bansal and Kockelman (2017)                                                                      | Questionnaire                                                                                                                                                                                                                                                           | About 1100 people took part in these questionnaires, and they are all from the State of Texas in the United States of America.                                                                                        | This research highlights that those experienced drivers and people of age are not worried about applying autonomous technologies in their immediate driving environment. Another significant observation from this research is that the results of this study will assist in predicting long-term adoption of autonomous vehicles technologies and assist urban and transportation engineers in having clarity on understanding the features of regions with elevated or low levels of adoption connected autonomous vehicles. |\n| Bansal and Kockelman (2018)                                                                      | Questionnaire                                                                                                                                                                                                                                                           | The questionnaire was internet-based, and 347 residents in Austin, TX, participated in the research.                                                                                                                  | Their study shows that participants are more worried about the system failure of AVs or any other type of vehicular safety.                                                                                                                                                                                                                                                                                                                                                                                                    |"}
{"doc463": "![14_image_0.png](14_image_0.png)\n\nDifferent models use sophisticated theoretical and empirical models for autonomous shuttle services tailored to university surroundings (Kim et al., 2017; Peled et al., 2019). These models are tested and trusted, and environmentally friendly. By referring to Bucchiarone et al. (2020), the ASaaS platform is uniformly organized in three primary layers (Fig. 8), and its objectives are: providing services for mobility operators (both public and privately owned) to design, customize and maintain mobility packages that do service integration using available autonomous shuttles. The Enablers offer a group of services such as multimodal travel planner and analytics using mobility and applied results from Bucchiarone et al.\n\n(2012, 2013) for enabling a dynamic and a group of more dynamic and collective management of mobility elucidation such as a group of adaptation facilities. The Services layer exposes the functionalities applied by the enablers platforms as services, which can be used to create a frontend application (front-end layer) for travellers. They may be individuals or groups and mobility operators. The model explained in this section creates emerging innovative opportunities for new business models and actors. The implications of these opportunities showcased that peer-topeer form of transportation is a significant sector of Europe's socio-economy (Kim et al., 2015a) taking into consideration the revenues (as of 2015, Europe's revenue is at 1.66 billion)\nand there is an expectancy that this sector will continue to become a crucial sector in the next decade with over 33 billion Euro of revenues projected (Burns, 2013). Mobility-asa-service is an important example of an emerging market that wants to find solution to the transportation needs of users by buying services at reduced costs than those spent on private transportation. This market will apply fixed price rates and roaming opportunities already been widely applied by telecommunication industries in the concepts of mobility-as-a-service."}
{"doc464": "![15_image_0.png](15_image_0.png)\n\nThe movement of people, goods, and services is crucial for transportation planning and smart cities' decision-making.\n\nDue to efficient shared mobility and interconnectivity, intelligent cities focus on walking, cycling, and public transportation. This is to fast-track the evolution of zero gas emission vehicles (electric vehicles), promote climate change and breathing efficacy. To make this a reality, developed cities are introducing technological measures to reduce the usage of cars, single-passenger taxis, and other oversized public transport vehicles. This was done to encourage people to practice sustainable mobility behaviour (Alonso Raposo et al., 2019). In recent years, developed countries have shifted their focus by investing heavily in infrastructural and technological innovations that are important in supporting a connected, multimodal transportation network comprising autonomous electric vehicles (AVs). These vehicles will function as a replacement for ineffective bus lines(Alonso Raposo et al., 2019). Also, transportation researchers on autonomous vehicles have been able to identify a practicable manoeuvre to minimize the threat of a collision, and Gelbal et al. (2020) proffered an innovative method for low-velocity autonomous shuttles to avoid colliding with pedestrians in a real-time situation."}
{"doc465": "Usually, autonomous vehicles have the necessary capability to travel from one place to another without human control. They can also sense their driving environment and implement safety mechanisms such as steering or braking without human interference. There are many merits and demerits that autonomous mobility will have on people and stakeholders in the logistics industry (Gonzalez-gonz  alez et al., 2019; Stead and Vaddadi, 2019). One of the merits of autonomous mobility in the logistics and supply chain industry is introducing the TIAGo Base, an autonomous technology introduced in the logistics industry to assist with logistics and stock control in the warehouse. This TIAGo Base (Fig. 9) is also called \"autonomous mobile robots (AMR)\", which can transport goods from one position to another with a maximum mass of 100 kg.\n\nThere are also stockbots, which is another autonomous technology in the transportation of goods. They can automatically do inventories in warehouses and manufacturing plants. They interact well with their immediate environment by using sophisticated vision technologies to control stocks in the warehouse safely. Problems associated with urban logistics in the movement of goods and services have become a pertinent topic for transportation planning. In the last decade, urban planners and logistics experts have tried to investigate the problems related to transporting goods within the urban environment by investigating some local authorities, transportation industries, supply chain companies, and pedestrians (Taniguchi et al., 2004). Investigating these problems is essential in developing solutions that will minimize traffic congestion in developed cities and lead to logistics and supply chain companies' delivery process efficiency.\n\n![16_image_0.png](16_image_0.png)"}
{"doc466": "However, several researchers have concluded investigations on transportation and delivery of goods and services, including retail deliveries and courier companies. There is still a need for more research in this area. Urban transportation of goods and services comprises waste transportation, equipment, and construction materials (Russo and Comi, 2011). Taniguchi et al. (2001) explained that city logistics plays a vital role in improving transportation logistics by using state-of-the-art information systems in urban areas. The upsurge in the complexity of interorganizational frameworks and a corresponding reduction of sophisticated logistics infrastructural technologies needed to accelerate the efficiency and effectiveness of pre-existing logistics processes have negatively affected the transportation of goods and services. The elevated levels of mobility in urban areas have influenced logistics methodologies' development and control in a dynamic environment (Bemeleit et al., 2008).\n\nDespite different research studies carried out in the field of models associated with urban logistics (Brownell, 2013; de Carvalho, 2004; Robuste et al., 2002  ; Wisetjindawat et al.,\n2007; Vleugel and Janic, 2004), urban logistics is not as essential in urban planning compared to the transportation of goods by road. This is because of cost optimization and efficacy in the supply chain (Nemoto et al., 2004). The increase in demand for mobility has challenged researchers across the various academic fields to design and create more effective traffic and transportation systems. These include control equipment's information systems and techniques to optimize pre-existing transportation networks. Bazzan and Klugl (2005) stated that it is of fundamental importance that models that incorporate interdisciplinary strategies are developed.\n\nTaniguchi et al. (2004) explained that the problem ofmobility could be solved from three perspectives: autonomous mobility, sustainability, and feasibility. They also presents some characteristics related to the challenges urban transportation of goods is experiencing. Some existing systems can adequately develop a futuristic vision of how urban goods and services are supposed to work. A major historical event in history was when the fourth industrial revolution was ushered into transportation and how it has changed the handling of manufacturing and logistical processes. Autonomous and machines have replaced manual production processes and transportation of goods. From the beginning of the 18th century, innovative and disruptive technologies have revolutionized the world economy and steered it to automate information, production, and logistics. In recent years, global digitization, electric vehicles, connectivity, accessibility, and autonomous vehicles are game-changing ingenuities affecting how contemporary business models and operational flows are being utilized (Gao et al., 2016). Decades ago, autonomous vehicles sounded like a dream. However, recent changes in the transportation industries have been suggested. Otherwise, it looks more realistic as more innovative technologies have been developed."}
{"doc467": "The autonomous vehicle in the future will change the way we use or see transportation, but it will also change the way we transport goods and services. Autonomous mobility will have a significant role to play in the global operation of logistics and supply chains. Autonomous mobility will have a robust impact on the breakdown of expenses of logistics industries. This can be in lowering stress levels of drivers of heavy vehicles, assistance in overcoming the challenges of long-distance travelling, and creating an innovative way to transport goods and services worldwide. However, actualizing autonomous mobility in the transportation of goods is experiencing difficulties. These difficulties can be research and development expenses, ethical issues, legal guidelines, and road transportation public unions.\n\nGrahle et al. (2020) stated that autonomous mobility would play a significant role in urban transportation. The effects of this disruptive innovation (autonomous mobility) can lead to the reduction of carbon production and travel times reduction. Furthermore, autonomous mobility can also lead to the likelihood of traffic reduction, traffic congestion, and car accidents that are primarily caused by errors in the driver's decision-making process, tiredness, drunkenness, or indiscriminate usage of drugs (Morando et al., 2018; Olayode et al., 2022; Severino et al., 2021). Nevertheless, although the security levels granted by such an intelligent system are forecasted to improve over the years, numerous experimental tests have already been carried out on nonrural road networks (Fagnant and Kockelman, 2015). The next decade's market penetration of autonomous mobility technologies cannot be assured (Kockelman et al., 2016). Notwithstanding, many transportation researchers are still undertaking studies on the introduction of autonomous mobility technologies to transport goods and services, including their interaction with the immediate driving environment.\n\n## 7. The Impacts Of Autonomous Vehicles On Road Transportation 7.1. Safety"}
{"doc468": "The implementation of autonomous vehicles in developed countries has drastically reduced road accidents. More than 40% of fatal car crashes usually involve drinking alcohol, overdosing on marijuana, or fatigue. A self-driving vehicle will not be affected because it relies on little or no human interference in its navigation. It is rare for an autonomous vehicle to malfunction to the extent of causing an accident on the road. According to National Highway Traffic Safety Administration (2008), Almost 90% of car crashes on the road are caused by an error from a vehicle's driver. The potential benefits of using an autonomous vehicle are comprehensive, both economically and environmentally, for any country. More than 30 to 40 thousand people die every year from death related to vehicles' collisions on the road in the United States of America (National Highway Traffic Safety Administration, 2012), with 2.2 million people getting injured due to these crashes (National Highway Traffic Safety Administration, 2013). At the same time, there are many positive impacts of using autonomous vehicles on the road, some negative impacts, such as the autonomous vehicles' inability to recognize objects or a person by the roadside quickly. Researchers have already predicted that AVs will overcome this problem in the future and recognize the object and persons on the road.\n\n## 7.2. Traffic Congestion\n\nApart from making roads accident-free, transportation researchers have also come up with ways by which autonomous can safely reduce traffic congestion on highways and road intersections by developing an external sensor that can easily sense the lead car decision-making involving braking and acceleration. Such developments will reduce brake wear, reduce travel times, and save fuel cost/energy consumptions."}
{"doc469": "Adaptive cruise control has already been introduced into autonomous vehicle systems that assist autonomous vehicles in decision-making, such as route choices and platoon coordination. There is a need for a 95% introduction of autonomous vehicles into the road transportation network, if the use of autonomous intersections is going to be implemented in the foreseeable future (Dresner and Stone, 2008). Another significant impact of autonomous vehicles in reducing traffic congestion is the advantage of vehicles travelling close together which lead to a significant upsurge in road capacity on existing road lanes (Olayode et al., 2020b, 2021a, 2021c; Tientrakool et al., 2011).\n\n## 7.3. Travel Behaviour\n\nAutonomous vehicles will change the travel behaviour of people, especially in the following areas."}
{"doc470": " The car ride-sharing programs will expand, leading to fewer vehicles on the road, reducing traffic congestion.\nThese can be achieved by vehicle-miles travelled (VMT)\nand vehicular-oriented development. Unless demand management is carefully implemented, all these travel behaviour can be implemented (Gupta et al., 2006). According to recent studies, it has been shown that there is an increment in the miles of vehicles travelled because of autonomous vehicles.\n\nThereby leading to a reduction in parking expenses of vehicles and an increase in market shares of autonomous vehicles (Auld et al., 2017; Kim et al., 2015b). Research into non-public autonomous vehicles (de Almeida Correia and van Arem, 2016; Kroger et al., 2019 \u20ac ) reported a broad mode shift when there is an increase in the reduction of value of time and parking or operating costs of autonomous vehicles. According to the effect of autonomous vehicles on a vehicle, hours travelled research studies (Childress et al., 2015; Kim et al., 2015b) from the research studies. It shows that vehicle hours travelled increases concerning private autonomous vehicles. It is an assumption that leads to a reduction in parking expenses.\n\n## 8. Discussions"}
{"doc471": "This study presents an unprecedented systematic literature review on the significance of autonomous technologies in the transportation of humans, goods, and services by torch lighting research articles via using search keywords such as autonomous vehicles, self-driving vehicles, and automated vehicle technology using the Web of Science, Scopus, and EBSCO as the academic databases. This research also investigates the socio-demographic genders in various countries (using developing and developed countries as a yardstick)\nto discover which gender in these countries' perceptions on autonomous technologies in terms of positivity towards AVs travel safety. Our review validates and extends previous research carried out by different transportation researchers that young adult males are more liberal and progressive regarding the risk associated with automated driving.\n\nThis research discovers from the existing literature review that young adult males between the ages of 18 and 35 are a primary demographic that reports elevated levels of positive perceptions of the safety of automated vehicle technology. It is important to note that young adult males are more connected to dangerous driving and aggressive road behaviour\n(Holland and Hill, 2007; Rosenbloom, 2009; Turner and Mcclure, 2003), their widely acknowledged non-negativity aimed at autonomous vehicle safety and early application of autonomous vehicle technology could likely result in an enormous rapid actualization of road transportation safety advantages (Hulse et al., 2018).\n\nOur research also validates and extends literature review on the history and comprehensive definitions of different levels of autonomous vehicles, especially when it comes to the theoretical, conceptual framework of autonomous vehicles, not excluding their functionalities and technologies. Furthermore, another significant contribution of this systematic review is that many developed countries have started to invest more and more in autonomous technologies over the last few years. The COVID-19 pandemic and global warming have accelerated this kind of technology investment in autonomous technologies. This is because developed countries are now pledging to phase out fuel-driven vehicles in the next decade and focus more on hybrid and electric vehicles, which possess a core framework of automated vehicle technology."}
{"doc472": "The most striking observation from this review is African countries' lack of innovation and creativity regarding automated vehicle technology. Only South Africa has tried to introduce the fourth industrial revolution in all aspects of its road transportation by encouraging more importation and driving hybrid electric vehicles on its roads. No African country has come close to fully allowing automated vehicle technology in its immediate driving environment.\n\nContrary to expectations about when autonomous vehicles will be fully accessible in various road transportation systems, it is somewhat surprising that most developed countries, especially in the USA, China, and some European countries\n(Finland, Germany, and the Netherlands), are miles behind when it comes to introducing all the SAE automation levels in their road transportation system. Another significant finding of this research is that the methodology applied in this research validates previous related literature review that discovers that metropolitan and University-graduate people have greater progressive public perceptions of the safety of autonomous vehicles. These people are more likely to be early users of autonomous vehicles in any developing or developed country due to their non-negativity progressive cognizance of AVs. These phenomena will likely elevate their intentions of buying and using AVs in their future day-to-day activities\n(Payre et al., 2014).\n\nWe have noticed a pattern, and the pattern is that almost 90% of the reviewed articles all concluded that has been argued and debated over the last few years that \"autonomous vehicles is the future\". With the outbreak of COVID-19 and the mandatory implementation of social distancing in most countries, this conclusion looks at a possible reality. However, we have discovered that while the USA, UK, China, and some artificial intelligence developed European countries might be getting closer to fully implementing AVT in their transportation system. The majority of African countries are still decades away from even achieving level 4 of SAE automation levels (Level 4: the vehicle has the capacity of carrying out all driving functionalities supervised by some specific driving conditions. There is an alternative to either control or relinquish the control of the vehicles) talk less of implementing full automation in their road transportation system."}
{"doc473": "## 8.1. Conclusion And Future Work\n\nThis study investigated the most recent academic articles related to the significance, impacts, public perceptions and applications of autonomous vehicles in road transportation and we also shine a light on the application of autonomous mobility in the transport of goods and services using academic websites such as Web of Science, Scopus, and EBSCO. The search was conducted through a PRISMA driven methodology using specific keywords. In addition, we also discussed application scenarios of autonomous shuttles aiming at lastmile delivery of goods. Autonomous vehicles (AVs) could revolutionise public transportation. Yet, public perception and acceptance, safety implications, socio-economic repercussions, infrastructural requirements, legal and regulatory concerns, integration with public transportation systems, environmental impacts, and human aspects all affect AV integration into public transit. A thorough literature review was done to determine the importance, impacts, public views, and applications of AVs in road transportation.\n\nThis study found that AV incorporation into public transportation depends on public perception and acceptability."}
{"doc474": "Nonetheless, more research on their public transportation integration hazards and limitations is needed. In particular, AVs' interactions with pedestrians and cyclists must be understood to ensure their safe and successful operation in all conditions.\n\n AVs have complex socioeconomic effects. AVs could produce jobs in data analysis and software development, according to some research, but they could also diminish transportation jobs. So, additional research is needed to understand AVs' socio-economic effects and how to mitigate them.\n\n AV incorporation into public transit depends on infrastructure. To accommodate a large-scale AV deployment, traffic management systems, roads, highways, and charging and refuelling infrastructure must be upgraded."}
{"doc475": "AV infrastructure requirements and how to make these adjustments cost-effectively and sustainably need more investigation.\n\n AV legal and regulatory issues are complicated. New AVspecific regulations are needed. Understanding how AVs can be integrated into public transportation systems will require new technologies to manage and coordinate AVs with other modes. AV environmental consequences must be properly studied, including the development of new powering technologies and legislation to encourage their use. To safely deploy AVs, human aspects, especially drivers, must be studied.\n\nThis study has shown that the pace of advanced technological innovations in the transport of human goods is moving at lightning speed. The notion of transporting goods autonomously was once a dream and is now becoming a reality. This study found that, in general, transport researchers have proposed ideas and practical solutions on how to transport goods autonomously. Among the proposed solutions is the introduction of autonomous vehicles into the road transport system. This article has highlighted some of the benefits and current challenges of autonomous mobility in freight transport in the supply chain sector. The evidence from this study suggests that there is still a need for further research on the importance and how we can fully develop an autonomous system that can efficiently transport goods from one place to another. This research study has raised many questions that need further investigation. Additional research is needed to determine the effectiveness of using autonomous technologies in transporting goods and services from one place to another. The world of transport is evolving every day; there are still some grey areas in the development of autonomous technologies for the transport of goods, not to mention the need for further experimentation and feasibility studies on autonomous technologies in the logistics and supply chain sectors. Finally, future researchers should focus on using more keywords, to broaden their search on research related to autonomous vehicles, the world of autonomous vehicles are fast evolving, transportation researchers need to keep up with the trends and evolvement."}
{"doc476": "at the Faculty of Engineering and Architecture, Kore University of Enna, Italy. She serves as a member of different editorial board such as The Open Transportation Journal, Safety and IET Intelligent Transport Systems. She is also a reviewer for several international transportation journals and conferences. Her research interests include transport supply/ demand, road safety, road vulnerable users, road traffic microsimulation. Frimpong Justice Alex is a PhD candidate at the School of Automotive Engineering, Wuhan University of Technology, China. He doubles as an assistant lecturer at the Faculty of Engineering, Kumasi Technical University, Ghana. Specifically, his research interests include vehicle systems dynamics, driving simulations (drunk driving, road intersections/traffic safety), automotive and mechanical engineering, sustainability, and global health. He has reviewed several manuscripts for vehicle dynamics journals."}
{"doc477": "![0_image_1.png](0_image_1.png)\n\nBirmingham B15 2TT, UK; e.ferranti@bham.ac.uk 2 School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham B15 2TT, UK; d.dissanayake@bham.ac.uk\n* Correspondence: hxm298@bham.ac.uk Abstract: Autonomous vehicles (AVs) aim to improve safety and comfort of road users while contributing to the reduction of traffic congestion, air pollution, fuel consumption, and enabling mobility and accessibility of disabled and older people. As AV technology is rapidly advancing, there is an urgent need to explore how those new mobility services will impact urban transport systems, including the users, the infrastructure, and the design of future urban areas. This paper applies a systematic review to assess the role of AVs in urban areas. It reviews 41 articles published between 2003 and 2023, and uses inductive and deductive coding approaches to identify seven themes and thirty sub-themes within the literature. The seven include: benefits, attitudes, and behaviours and user perception, climate adaptation, climate mitigation, legislation and regulations, sustainability, and infrastructure. Studies related to benefits accounted for 25% of the sample, followed by behaviours and user perception (24%) and sustainability (22%). The least amount of research has been undertaken on the role of AVs to support climate adaptation. Geographically, almost half (\\#22) of the papers originate within Europe, followed by America (\\#10) and Asia (\\#7). There is only limited research originating from the Global South. This systematic review sets the scene for considering how AVs in public transport can be implemented in urban areas by establishing the current state of knowledge on user attitudes, perceptions, and behaviour, the benefits of AVs, the infrastructure and legislation and regulations required for AVs, and the role AVs have in climate mitigation, adaptation, and sustainability. Keywords: autonomous vehicles; urban areas; sustainability; legislation and regulations; systematic review; NVivo\n\n## 1. Introduction"}
{"doc478": "Autonomous vehicles (AVs) are perceived as the future of transportation in our cities [1]. The intelligent mobility sector is developing within the framework of AV technology, which is expected to have a global market share of \u00a3900 billion by 2025 [2]. Currently, approximately 1.3 million people are killed in traffic accidents annually [3]. Human error accounts for more than 90% of traffic accidents; the decision makers believe that AV is a promising travel alternative that could help reduce road deaths and injuries [4]. Researchers predict AVs will enhance road safety standards and management [5]. Consideration of security aspects becomes paramount when preparing the integration of AV technology in urban environments. Recent studies using unique data sets, including detailed AV accident data, have begun to reveal the specific conditions and manoeuvres that caused accidents, informing the development of targeted safety management strategies and actions to reduce those risks [6]. In this trajectory toward a safer and more intelligent transportation ecosystem, the inclusion of diverse AV modes, encompassing private cars and buses, assumes paramount importance. These distinct AV modes promise to not only enhance Citation: Makahleh, H.Y.; Ferranti, E.J.S.; Dissanayake, D. Assessing the Role of Autonomous Vehicles in Urban Areas: A Systematic Review of Literature. *Future Transp.* **2024**, 4, 321\u2013348. https://doi.org/10.3390/\nfuturetransp4020017 Academic Editor: Laura Eboli\n\n```\nReceived: 12 January 2024\nRevised: 25 March 2024\nAccepted: 1 April 2024\nPublished: 7 April 2024\n\nCopyright: \u00a9 2024 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/)."}
{"doc479": "AVs are becoming increasingly able to sense surrounding environments without the need for human interactions. The implementation of AVs has potential benefits to urban areas, including increasing climate resilience by providing more reliable and safer transport alternatives, reduced carbon emissions via switching to battery charging or improved driving efficiency, and reducing the need for a city centre and thereby allowing for additional space for green infrastructure to facilitate sustainable living. Moreover, the incorporation of Avs into public transport systems has the potential to minimize spatial requirements in urban areas. This opens up avenues for expansive green initiatives, not only aimed at promoting sustainable living but also addressing the urgent need for environmentally sensitive urban development.\n\nAdditionally, the utilization of Avs as a mode of shared mobility assumes a crucial role in alleviating traffic congestion across the city. These reductions directly contribute to easing traffic gridlocks, facilitating the creation of a car-free environment that fosters a transition towards more pedestrian-friendly spaces. It is estimated that the deployment of Avs in urban areas will result in a substantial 35% reduction in greenhouse gas emissions, representing a significant stride towards a more visionary urban future [7,8].\n\nTo properly address the implications of urban mobility's shift toward more pedestrianfriendly environments, we must investigate the continuing transition from a human-centred to an autonomous-centred driver paradigm. This phase includes a diverse mix of semi-AV,\nfully AV, and non-AV, and displays a diverse set of barriers and opportunities. The coexistence of several AV technologies on the same roads needs a thorough understanding of the security, safety, and operational difficulties that occur, as well as the design of effective methods to alleviate these barriers."}
{"doc480": "The ability to distinguish between densely populated metropolitan areas and nonurban areas, such as suburbs, peripheries, intercity routes, and roadways, has a substantial impact on a number of sectors. AV infrastructure requirements in urban and non-urban environments might greatly vary, to start [9]. In urban areas, handling dense traffic and pedestrian interactions may need complex signalling systems, dedicated lanes, and extensive mapping. On the other hand, in non-urban settings, highway safety features and long-distance efficiency may take precedence. Furthermore, the primary uses of AVs in urban areas are last-mile issues, traffic reduction, and the enhancement of public transit [10,11]. To improve sub-urban connection and long-distance transport, AVs can also be used in non-urban areas. The adoption of AVs in urban regions may have various social and economic consequences, as opposed to non-urban situations. For instance, it might affect urban public transportation systems and lessen isolation in isolated communities. Furthermore, alternative strategies may be required to be used by legislative frameworks that approve the use of AVs [12\u201314]. In metropolitan areas, laws concerning zero-emission zones and the integration of AVs into public transport may be necessary, whereas high-speed travel safety requirements may have greater significance in non-urban areas.\n\nAccording to the Society of Automotive Engineers (SAE) [15], there are six levels of driving automation ranging from 0 (fully manual) to 5 (fully automated). Level 1 has the lowest level of automation, limited to providing warnings, and Level 2 has partial driving automation that can control both acceleration/deceleration and steering. Levels 3 and 4 have substantial driving automation capabilities compared to lower levels. However, the fundamental difference between Levels 3 and 4 is that level 4 automation can intervene in case of a system failure. Level 5 means fully automated AVs (level 5 driving automation); they are not currently commercially available, and testing has only taken place in controlled environments [16]. Fully commercial AVs are not available in the market and in urban spaces. There has been no testing as to how Level 5 vehicles could undergo widespread adoption onto road networks. This applies to both AVs integrated into public transport systems and those used as private cars.\n\nThe current state scenario of fully automated Avs is marked by significant advancements and persistent challenges. Leading companies include Waymo, Cruise, Tesla, and Baidu. Waymo is the first to introduce a completely autonomous taxi service in Phoenix, Arizona, demonstrating the commercial use of Level 5 autonomy [17]. A significant advancement for commercial AV services, Cruise has also gained approval for autonomous rides in San Francisco [5]. Regulatory barriers, safety concerns, and technological difficulties prevent the AV market from being widely adopted despite these developments. With rising investments from major automakers and tech companies, the market is anticipated to increase at a compound annual growth rate (CAGR) of 13.3% between 2021 and 2030 [18]. Light Detection and Ranging (LiDAR), radar, cameras, and artificial intelligence algorithms are some of the critical technologies that enable autonomous vehicles to navigate. Luminar and Waymo, for example, prioritise LiDAR sensors for improved vehicle vision, whereas Tesla focuses on AI and data to develop autonomous driving capabilities [19]. Additional companies involved in AV technology include Cruise, Aurora, Argo AI, Zoox, and Wayve."}
{"doc481": "As AV technology is rapidly advancing, there is a growing need to explore how an increased usage of AVs can impact our urban areas to put necessary plans and processes in place before having AVs appear in our transportation systems. To date, most research conducted on AVs has considered the development and adaptation of the technology itself with some primary focus on private vehicles. There is little research investigating the attitudes of road users towards AVs, and how the wide uptake of AVs can impact the utilization and design of urban areas. Therefore, a systematic review is carried out in this study to investigate the role of AVs in urban areas by considering:\n- RQ1: What are the attitudes and behaviours of road users towards AVs?\n\n- RQ2: How would the infrastructure be changed to enable AVs in urban areas? - RQ3: How and in what way will the regulations and legislations around AVs evolve with a focus on urban areas?\n\n- RQ4: What are the implications of AVs for urban areas in terms of achieving sustainable living, climate mitigation, and adaptation targets?"}
{"doc482": "The outcomes of this review will inform us about the key roles that Avs in public transport play in the sustainability design of urban regions, and user attitudes, perceptions, and behaviour. Moreover, this research will advance our understanding of how urban design should change for accommodating AVs in urban areas. This systematic review will provide some useful information to policy makers to consider how to organise cities and urban areas to accommodate new mobility services.\n\n## 2. Materials And Methods\n\nA systematic review of the literature is performed using the databases of Scopus and Web of Science to search answers for the research questions raised in the introduction. The systematic review uses a qualitative text mining software, NVivo 12, to analyse, organise, and uncover insights [20]."}
{"doc483": "There are several different approaches to undertaking a systematic literature review.\n\nIn order to decide the most appropriate approach for this systematic review, we undertook a critical review on previous studies that undertook systematic reviews in several related academic disciplines (Table 1). All studies utilized the PRISMA approach (see Supplementary Materials), i.e., the Preferred Reporting Items for Systematic Review and Meta-Analyses. This method ensures transparency and complete reporting of research.\n\nAs such, this paper applies a methodology consistent with other authors [21]. The scope includes peer-reviewed conference papers. Furthermore, the search was exclusive to documents produced from 2003 to 2023 and documents published in the English language only."}
{"doc484": "To narrow the search area, this method uses a four-step clustering algorithm (i.e., Scope, Target Group, Subject Domain, and Methods). To simplify, this process of narrowing down involves excluding somewhat unrelated studies. It is done by using the OR operator within the keywords of each category and the AND operator within each group [22]. This helps\n\n| Table 1. Article selection process from literature.   |                                                                                        |                                                                                                 |                                                                                                                       |                                               |\n|-------------------------------------------------------|----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|\n| Author(s)                                             | Year                                                                                   | General Theme                                                                                   | Approach                                                                                                              | Database                                      |\n| (1)                                                   | Initial search using keywords                                                          |                                                                                                 |                                                                                                                       |                                               |\n| (2)                                                   | Removal of duplicates                                                                  |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Screening on basis of title and keywords                                               |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Screening on basis of abstract                                                         |                                                                                                 |                                                                                                                       |                                               |\n| (5)                                                   | Screening based on indicators                                                          |                                                                                                 |                                                                                                                       |                                               |\n| (6)                                                   | Studies included                                                                       |                                                                                                 |                                                                                                                       |                                               |\n| Alsaeed et al. [21]                                   | 2022                                                                                   | Water Resources Management                                                                      | Scopus, Engineering Village                                                                                           |                                               |\n| (1)                                                   | Initial search using keywords                                                          |                                                                                                 |                                                                                                                       |                                               |\n| (2)                                                   | Removal of duplicates                                                                  |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Screening on basis of title                                                            |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Screening on basis of abstract                                                         |                                                                                                 |                                                                                                                       |                                               |\n| (5)                                                   | Studies included                                                                       |                                                                                                 |                                                                                                                       |                                               |\n| Topal et al. [22]                                     | 2020                                                                                   | Urban Sustainability                                                                            | Scopus, Web of Science                                                                                                |                                               |\n| (1)                                                   | Initial search using main keywords                                                     |                                                                                                 |                                                                                                                       |                                               |\n| (2)                                                   | Search was conducted for journal articles published between January 2008 and July 2019 |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Initial thematic search was conducted                                                  |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Critically evaluate and document the findings                                          | Science Direct, Scopus, Web of Science, Wiley Online Library, Directory of Open Access Journals |                                                                                                                       |                                               |\n| Gamification in                                       |                                                                                        |                                                                                                 |                                                                                                                       |                                               |\n| Kankanamge et al. [23]                                | 2020                                                                                   | disaster emergency planning                                                                     | (1)                                                                                                                   | Identification based on keywords              |\n| (2)                                                   | Screening based title/abstract                                                         |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Full text screening and assessed for eligibility                                       |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Full text articles included                                                            |                                                                                                 |                                                                                                                       |                                               |\n| Artificial Intelligence                               |                                                                                        |                                                                                                 |                                                                                                                       |                                               |\n| Yigitcanlar et al. [24]                               | 2020                                                                                   | in Building Smart cities                                                                        | Scopus, Science Direct, Web of Science Ovid MEDLINE ALL, Web of Science Core Collection, PubMed, PsycINFO, REHABDATA. |                                               |\n| (1)                                                   | Identification based on keywords                                                       |                                                                                                 |                                                                                                                       |                                               |\n| (2)                                                   | Title/Abstract screening                                                               |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Full text Review Screening                                                             |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Full-text articles Included                                                            |                                                                                                 |                                                                                                                       |                                               |\n| Automated vehicles                                    |                                                                                        |                                                                                                 |                                                                                                                       |                                               |\n| Dicianno et al. [25]                                  | 2021                                                                                   | and people with disabilities                                                                    | (1)                                                                                                                   | Collected studies from previous peer-reviewed |\n| (2)                                                   | surveys                                                                                |                                                                                                 |                                                                                                                       |                                               |\n| (3)                                                   | Explored additional studies using keywords                                             |                                                                                                 |                                                                                                                       |                                               |\n| (4)                                                   | Explored additional studies                                                            |                                                                                                 |                                                                                                                       |                                               |\n| (5)                                                   | Grouped datasets                                                                       |                                                                                                 |                                                                                                                       |                                               |\n| Masello et al. [26]                                   | 2021                                                                                   | Traditional to                                                                                  |                                                                                                                       |                                               |\n| Autonomous vehicles                                   | N/A                                                                                    |                                                                                                 |                                                                                                                       |                                               |\n| 2.1. Keywords Selection                               |                                                                                        |                                                                                                 |                                                                                                                       |                                               |\n\nrefine the search to find more relevant information. Hence, this review was developed based on the intersection area of all four clusters."}
{"doc485": "Selecting keywords for a systematic review entails careful consideration to ensure comprehensive coverage of relevant literature. The selection in this paper was on the basis of relevance to research questions, inclusiveness, variability (including synonyms),\nand consultation among the researchers. For the scope cluster, the terms \"Autonomous Vehicles\" AND \"Urban Areas\" were used to define the largest scope with what the search should start. In addition to that, synonyms such as \"Self-Driving Cars\", \"Intelligent Vehicles\", \"Driverless Cars\", \"Urban Spaces\", \"Urban Environments\", and \"Downtown Areas\" were considered.\n\nThe target group of this review was primarily concerned with the subsets of urban areas. The main terms for the target group cluster were: \"sustainability\", \"climate mitiga-\nSelecting keywords for a systematic review entails careful consideration to ensure comprehensive coverage of relevant literature. The selection in this paper was on the basis of relevance to research questions, inclusiveness, variability (including synonyms), and consultation among the researchers. For the scope cluster, the terms \"Autonomous Vehicles\" AND \"Urban Areas\" were used to define the largest scope with what the search should start. In addition to that, synonyms such as \"Self-Driving Cars\", \"Intelligent Vehicles\", \"Driverless Cars\", \"Urban Spaces\", \"Urban Environments\", and \"Downtown Areas\" were considered.\n\nThe target group of this review was primarily concerned with the subsets of urban areas. The main terms for the target group cluster were: \"sustainability\", \"climate mitigation\", \"climate adaptation\", \"legislation\", \"attitudes and perception, and user behaviours\", \"user benefits\", \"legislations and regulations\", \"Infrastructure\"."}
{"doc486": "The subject domain of this review was concerned with the subsets of the target group. \n\nThe main terms for the subject domain were: \"Awareness and education\", \"Consumer behaviour and the environment\", \"Social norms and values\", \"Attitude-behaviour change interventions\", \"Economic benefits\", \"Social benefits\", \"Environmental benefits\", \"Adaptation and decision making\", \"Resilience to climate change impacts\", \"Risk management\", \n\"Resources management\", Low-carbon transportation\", \"Renewable energy sources\", \"Mitigation measures\", \"Industrial decarbonization\", \"Enforcement and compliance\", \n\"National polices\", \"Safety and comfort standards\", \"Environmental regulations\", \"Sustainable development\", \"Circular economy\", \"Corporate social responsibility\", \"Accessibility, equity and social justice\", \"Trust and credibility, \"User preferences and needs\", \n\"Expectations and satisfaction\", \"Vehicle-to-Infrastructure (V2I)\", \"Roadway design\", \"Charging stations\".\n\nThe fourth group, the methods of data collection or handling based on the collective approach of data, was assigned. The terms included in this cluster were \"questionnaire\",\n\"survey\", \"interview\", \"participants\", \"modelling\", and \"intervention\"."}
{"doc487": "The subject domain of this review was concerned with the subsets of the target group.\n\nThe main terms for the subject domain were: \"Awareness and education\", \"Consumer behaviour and the environment\", \"Social norms and values\", \"Attitude-behaviour change interventions\", \"Economic benefits\", \"Social benefits\", \"Environmental benefits\", \"Adaptation and decision making\", \"Resilience to climate change impacts\", \"Risk management\",\n\"Resources management\", Low-carbon transportation\", \"Renewable energy sources\", \"Mitigation measures\", \"Industrial decarbonization\", \"Enforcement and compliance\", \"National polices\", \"Safety and comfort standards\", \"Environmental regulations\", \"Sustainable development\", \"Circular economy\", \"Corporate social responsibility\", \"Accessibility, equity and social justice\", \"Trust and credibility, \"User preferences and needs\", \"Expectations and satisfaction\", \"Vehicle-to-Infrastructure (V2I)\", \"Roadway design\", \"Charging stations\".\n\nThe fourth group, the methods of data collection or handling based on the collective approach of data, was assigned. The terms included in this cluster were \"questionnaire\",\n\"survey\", \"interview\", \"participants\", \"modelling\", and \"intervention\"."}
{"doc488": "## 2.2. Database Search\n\n2.2. Database Search The search through Scopus and Web of Science databases was performed, and generated 409 and 209, respectively. Articles were merged and duplicates were removed, reducing the number to 442 articles. Among these articles, 112 were conference papers, while the rest were peer-reviewed articles.\n\nEstablishing and adhering to specific inclusion and exclusion criteria is imperative for maintaining the rigour, transparency, and focus of a systematic review. These criteria act as a set of predefined rules that guide the selection of studies for analysis. The inclusion and exclusion criteria concentrate on relevance and precision, minimization of bias, consistency, and reproducibility, and addressing the research questions. Under these criteria, any articles unrelated to the main scope (i.e., both autonomous vehicles and urban areas), whether directly or indirectly, were excluded straight away. The primary focus of this review was on urban areas; hence, articles related to rural areas were removed. Similarly, articles that were not concerned with autonomous vehicles were also excluded. Furthermore, if the criterion was met, an additional verification was necessary to ensure that the studies under consideration had explicitly mentioned a framework or index either in their title or keywords. For the first screening stage, both conditions are applied to the 442 articles, hence reducing the number of articles by 270."}
{"doc489": "In the second screening stage, abstracts were examined with regards to the target group and subject domain (i.e., sustainability, climate mitigation, and climate adaptation). In this stage, the focus was on the target group and subject domain, specifically sustainability, The search through Scopus and Web of Science databases was performed, and generated 409 and 209, respectively. Articles were merged and duplicates were removed, reducing the number to 442 articles. Among these articles, 112 were conference papers, while the rest were peer-reviewed articles.\n\nEstablishing and adhering to specific inclusion and exclusion criteria is imperative for maintaining the rigour, transparency, and focus of a systematic review. These criteria act as a set of predefined rules that guide the selection of studies for analysis. The inclusion and exclusion criteria concentrate on relevance and precision, minimization of bias, consistency, and reproducibility, and addressing the research questions. Under these criteria, any articles unrelated to the main scope (i.e., both autonomous vehicles and urban areas), whether directly or indirectly, were excluded straight away. The primary focus of this review was on urban areas; hence, articles related to rural areas were removed. Similarly, articles that were not concerned with autonomous vehicles were also excluded. Furthermore, if the criterion was met, an additional verification was necessary to ensure that the studies under consideration had explicitly mentioned a framework or index either in their title or keywords. For the first screening stage, both conditions are applied to the 442 articles, hence reducing the number of articles by 270.\n\nIn the second screening stage, abstracts were examined with regards to the target group and subject domain (i.e., sustainability, climate mitigation, and climate adaptation). "}
{"doc490": "In this stage, the focus was on the target group and subject domain, specifically sustainability, climate mitigation, and climate adaptation. By narrowing down the selection based on these criteria, the aim was to ensure that the studies under consideration were directly aligned with the core themes of the systematic review. This step is crucial to maintain relevance and address the specific research objectives. This stage excluded 106 articles, reducing the total number of articles to 66.\n\nIn the third screening stage, full-text articles were also investigated based on the target group and subject domain (i.e., sustainability, climate mitigation, and climate adaptation). This stage involved the examination of full-text articles which allowed for a more detailed evaluation of the articles in terms of their relevance to the target group and subject domain. This thorough examination aimed at maintaining a high standard of quality in the selected studies, ensuring that only those with substantive contributions to sustainability, climate mitigation, and climate adaptation were retained. This round was the last one and reduced the total number of included articles by 25. Subsequently, 41 studies were selected to be included in this analysis. Although the final number of included articles, 41, may appear relatively small, the emphasis was on quality over quantity.\n\nThe systematic review was concerned with selecting studies that meet rigorous criteria that enhance the reliability and validity of findings. Emphasizing a smaller, more focused sample is a standard strategy in systematic reviews, ensuring methodological rigour and a comprehensive examination of the literature. All the identification and screening stages are summarized and better demonstrated in Figure 2."}
{"doc491": "In the third screening stage, full-text articles were also investigated based on the target group and subject domain (i.e., sustainability, climate mitigation, and climate adaptation).\n\nThis stage involved the examination of full-text articles which allowed for a more detailed evaluation of the articles in terms of their relevance to the target group and subject domain.\n\nThis thorough examination aimed at maintaining a high standard of quality in the selected studies, ensuring that only those with substantive contributions to sustainability, climate mitigation, and climate adaptation were retained. This round was the last one and reduced the total number of included articles by 25. Subsequently, 41 studies were selected to be included in this analysis. Although the final number of included articles, 41, may appear relatively small, the emphasis was on quality over quantity."}
{"doc492": "The systematic review was concerned with selecting studies that meet rigorous criteria that enhance the reliability and validity of findings. Emphasizing a smaller, more focused sample is a standard strategy in systematic reviews, ensuring methodological rigour and a comprehensive examination of the literature. All the identification and screening stages are summarized and better demonstrated in Figure 2.\n\nFigure 2 illustrates the process used for the identification of relevant studies, displaying how various databases were systematically searched and filtered to compile the research material. This graphical representation serves as a clear visual aid, detailing the methodology behind the selection of studies, including the criteria for inclusion and exclusion, ensuring transparency and replicability in the research process.\n\n2.3. Utilizing NVivo for In-Depth Coding and Analysis in Systematic Review In this study, the researchers used NVivo software to code the articles. This approach was informed by the established literature emphasizing the benefits of using NVivo for systematic research [27]. Although inclusion and exclusion criteria shape the initial selection of studies, coding approaches contribute to the subsequent analysis. Collectively, these components create a comprehensive and structured framework for conducting a systematic review. The researchers in this study employed both inductive coding, where themes and patterns emerge directly from the data, and deductive coding, which involves using existing theories or concepts to analyse the data. Themes were systematically constructed based on inductive and deductive approaches. The inductive approach is primarily guided by the data itself and remains unaffected by any preconceived frameworks or the researcher's initial assumptions. The analysis is primarily driven by the data, aiming to reduce bias, and allowing it to shape the conclusions. In contrast, in the deductive approach, the researchers may provide a less detailed description of the overall data. This is because they are influenced by their own theories and interests, leading them to focus more on certain aspects of the data for a more thorough analysis. The codes were then grouped into themes, which played a crucial role in developing the conceptual framework for AVs in urban areas."}
{"doc493": "A geographical coverage map was drawn to present the distribution of the 41 articles across the globe (Figure 3). Articles were found in 31 countries and across 4 continents, which are as follows: 22 from Europe (Spain, Germany, Greece, Portugal, Switzerland, France, UK,\nBelgium, Hungary, Italy, Greece, Croatia, Netherlands, Austria, Sweden, Norway, Finland, Ireland), 10 from America (USA, Chili, Canada), 7 from Asia (UAE, KSA, Taiwan, China, Malaysia, Indonesia, Japan), 1 from Africa (Egypt), and 1 from Oceania (Australia).\n\nFuture Transp. **2024**, 4, FOR PEER REVIEW 8 Figure 3. Geographical coverage of research across the globe (this study).\n\nA cross-tabulation analysis was carried out considering the seven main themes with particular attention to regions specified as follows: America, Europe, and Asia, with case studies published in journals and conferences."}
{"doc494": "Figure 4 illustrates the distribution of each category based on different regions. As illustrated in Figure 4, benefits are some of the most prominent considered factors of the papers written in America, Europe, and Asia. The Europe region has considered all seven factors. Both Europe and America regions considered factors such as benefits and legislation and regulations and sustainability almost equally. However, Asia pays less attention to climate mitigation and adaptation compared to America and Europe. One could argue A cross-tabulation analysis was carried out considering the seven main themes with particular attention to regions specified as follows: America, Europe, and Asia, with case studies published in journals and conferences.\n\nFigure 4 illustrates the distribution of each category based on different regions. As illustrated in Figure 4, benefits are some of the most prominent considered factors of the papers written in America, Europe, and Asia. The Europe region has considered all seven factors. Both Europe and America regions considered factors such as benefits and legislation and regulations and sustainability almost equally. However, Asia pays less attention to climate mitigation and adaptation compared to America and Europe. One could argue that the lower use of cars in comparison to developed countries might contribute to this situation [28]. To clarify, they might not fully recognize the changing climate, therefore resulting in a lack of proactive adaptation and mitigation measures. In addition, the Asia region did not consider infrastructure as a factor of investigation.\n\n![7_image_0.png](7_image_0.png)"}
{"doc495": "A cross-tabulation analysis was carried out considering the seven main themes with particular attention to regions specified as follows: America, Europe, and Asia, with case studies published in journals and conferences.\n\nFigure 4 illustrates the distribution of each category based on different regions. As illustrated in Figure 4, benefits are some of the most prominent considered factors of the papers written in America, Europe, and Asia. The Europe region has considered all seven factors. Both Europe and America regions considered factors such as benefits and legislation and regulations and sustainability almost equally. However, Asia pays less attention to climate mitigation and adaptation compared to America and Europe. One could argue that the lower use of cars in comparison to developed countries might contribute to this situation [28]. To clarify, they might not fully recognize the changing climate, therefore resulting in a lack of proactive adaptation and mitigation measures. In addition, the Asia region did not consider infrastructure as a factor of investigation.\n\nthat the lower use of cars in comparison to developed countries might contribute to this situation [28]. To clarify, they might not fully recognize the changing climate, therefore resulting in a lack of proactive adaptation and mitigation measures. In addition, the Asia region did not consider infrastructure as a factor of investigation."}
{"doc496": "## 3. Results\n\n3.1. Themes and Sub-Themes in the Systematic Literature Review Upon conducting the systematic review, 41 articles were identified and selected in this review. Seven different themes and thirty-two sub-themes were obtained using a hybrid model which considered inductive and deductive approaches (selection process detailed in the above methodology). This methodology enables a comprehensive investigation of the present status of knowledge regarding AVs, including both newly discovered insights and those informed by pre-existing theoretical frameworks. The seven themes include: benefits, user attitudes, perception and behaviour, climate mitigation, legislation and regulations, sustainability, and infrastructure (Table 2). The sub-themes are shown in Figure 5. By highlighting particular aspects of each theme, these sub-themes provide the overall themes with more depth. This detailed approach guarantees a thorough examination that is attuned to the complex aspects of the selected themes. This section describes and discusses the current state of knowledge as related to these themes and sub-themes.\n\nTable 2. Main categories and themes."}
{"doc497": "| Table 2. Main categories and themes.   |                                                                                                                                                                                |\n|----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Main Themes                            | Description                                                                                                                                                                    |\n| Benefits                               | This extends to include economic, social, and environment benefits This includes awareness and education, consumer behaviour and the environment, social norms                 |\n| User Attitudes, Perceptions,           | and values, attitude\u2013behaviour change interventions, trust and credibility, user preferences and                                                                               |\n| and Behaviour                          | needs, and expectations and satisfaction                                                                                                                                       |\n| Climate Adaptation                     | Adaptation and decision making, resilience to climate change impacts, risk management, and resources management                                                                |\n| Climate Mitigation                     | Factors such as low carbon/green transportation, renewable energy sources, mitigation measures, and industrial decarbonization                                                 |\n| Legislation and Regulations            | Enforcement and compliance, national polices, safety and comfort standards, and environmental regulations                                                                      |\n| Sustainability                         | Sustainable development, circular economy, corporate social responsibility, accessibility, and equity and social justice                                                       |\n| Infrastructure                         | Vehicle-to-Infrastructure (V2I), roadway design, expectations and satisfaction, accessibility, equity, and social justice, charging stations, and safety and comfort standards |\n\n![8_image_1.png](8_image_1.png)\n\nUpon conducting the systematic review, 41 articles were identified and selected in this review. Seven different themes and thirty-two sub-themes were obtained using a hybrid model which considered inductive and deductive approaches (selection process detailed in the above methodology). This methodology enables a comprehensive investigation of the present status of knowledge regarding AVs, including both newly discovered insights and those informed by pre-existing theoretical frameworks. The seven themes include: benefits, user attitudes, perception and behaviour, climate mitigation, legislation and regulations, sustainability, and infrastructure (Table 2). The sub-themes are shown in Figure 5. By highlighting particular aspects of each theme, these sub-themes provide the overall themes with more depth. This detailed approach guarantees a thorough examination that is attuned to the complex aspects of the selected themes. This section describes "}
{"doc498": "![8_image_0.png](8_image_0.png)\n\n3.2. Benefits The benefits theme was created with three sub-themes: economic, social, and environmental. These sub-themes were given a wide scope to accommodate the benefits of AVs in urban areas. From a social and economic perspective, according to studies [29\u201331], AVs in public transportation have improved traffic flow and reduced congestion. By decreasing transportation times and related expenses, these developments improve the economic efficiency of urban areas.\n\nAdditionally, an increased access to AVs improves the welfare of workers, travel distances, and city size [31]. The implementation of AV in urban areas could have positive impacts on public transportation. This is in terms of lower risk of traffic incidents and higher traffic efficiency compared to other modes [32]."}
{"doc499": "Moreover, AV fleets have positive environmental impacts on land use. Urban parking spaces may be reduced to as much as 90% when AVs are implemented in ridesharing mode [32]. These include increased efficiency in traffic management and routing, the possibility of platooning to cut fuel consumption, optimized vehicle utilization through ride-sharing services, and the promotion of shared transportation. It is critical to recognize that the environmental impact of AVs is determined not only by the energy source or combustible used (such as electric or non-polluting cars, green hydrogen), but also by mode of transportation (public versus private).\n\nAn assessment of AVs in urban areas demonstrated positive effects on network capacity and traffic stability. These effects are achieved as the AV penetration rate (% of AVs in roads) increases above (10\u201320%) [33]. Similarly, some studies indicate a substantial increase in accessibility and encouragement of urban sprawl from AVs [34\u201337]. This confirms the earlier findings [38,39].\n\nAV shuttles improve current transit services by making cost-efficient benefits [32]."}
{"doc500": "3.3. User Attitudes, Perceptions, and Behaviour The user attitudes, perceptions, and behaviour theme was created with seven subthemes: awareness and education, consumer behaviour and the environment, social norms and values, attitude\u2013behaviour change interventions, trust and credibility, user preferences and needs, and expectations and satisfaction. The emerging sub-themes have been considered in diverse ways in previous studies. To elaborate, several earlier studies have used these sub-themes in their investigations. In terms of consumer behaviour and the environment, passengers tend to be more interested in arriving at the desired location at a lower price than in AV technology [50]. From an attitude\u2013behaviour change perspective, Avs in both private and public transportation improve people willingness to travel further [31].\n\nHence, homes and workers could be moved in the long term.\n\nThe introduction of Avs in the transportation systems could result in considerable changes of travel behaviour, mode choice, and car ownership [48]. To cause an attitude\u2013\nbehaviour change intervention, governments may impose incentives or restrictions on private and public transportation [51]. Additionally, the planning principles for mobility services based on AVs such as less flexible travel motivations could have a direct effect on passengers [52]."}
{"doc501": "The implementation of AVs into the transportation system could promote the use of public transportation (i.e., bus, trains, and trams) [53], causing a behaviour shift among the populace. The improvement of public transportation large-scale restricted traffic areas and pedestrian areas induces a significant modal shift towards better environmentally friendly alternatives [54]. Furthermore, the value of trip time for AVs will potentially decrease significantly, as individuals will be more productive in AVs [55].\n\nOn the contrary, in terms of social norms and values, AVs create a social dilemma [56].\n\nAlthough most individuals think that everyone would benefit from utilitarian AVs (those that reduce the number of fatalities on the road), these same people have a personal motive to travel in AVs that protect them at all costs. Moreover, the projected distribution of accessibility impacts could encourage public transportation to be superfluous [34]."}
{"doc502": "AVs show immense potential for future mobility development, not only in large cities and urban areas, but also in suburban and rural locations [50]. There are special issues in these places due to limited availability and access to public transportation. AVs are seen as a potential answer to these difficulties by delivering on-demand transportation services that can serve a variety of interest groups, transcending the restrictions of traditional bus lines with set bus stops to enable the effective implementation and adoption of autonomous vehicles in rural areas, it is critical to understand the local residents' needs and expectations.\n\nFactors like availability, accessibility, and cost have a significant impact on how users perceive autonomous mobility services. Whether they are thinking about using private or public transportation, people carefully analyse these factors, which shapes their views and choices [50]. Moreover, respondents saw fewer crashes as the primary benefit of AVs, showing a positive view of safety improvements [57,58]. Their main issue, however, is device failure, emphasizing the importance of dependability and faith in technology. In terms of willingness to pay (WTP), the average WTP for adding complete (Level 4)\nautomation to their vehicles ($7253) is much greater than the WTP for adding partial\n(Level 3) automation ($3300) [59]. This indicates that that responders may be more willing to accept fully autonomous capabilities. Another factor to consider is the influence of demographics and travel characteristics. This is with respect to how income, gender, technological familiarity, urban residency, and crash experience influence respondents' interest and WTP for AV technologies [57]. Similarly, this influences the adoption of shared AVs. This is according to rates of adoption of shared AVs under various pricing scenarios, considering the influence of peers' adoption decisions [57]; it not only affects this, but also home-location decisions. This means analysing how the availability and prevalence of AVs and SAVs influence people's decisions about where to live [57].\n\nAnother researcher focuses on addressing the problem of jointly detecting pedestrians and recognizing 32 pedestrian attributes from a single image [52]. These characteristics include visual appearance, behaviour, and road crossing predictions, which are major safety concerns. AVs can enable safe interactions with pedestrians in urban contexts by making decisions that take into consideration the presence and characteristics of pedestrians [52]."}
{"doc503": "Correlations between users' sociodemographic traits, mobility preferences, and predicted aspects or features of mobility services offered by AVs are discovered through surveys and studies [59]. A framework for organizing mobility services based on AVs is provided by insights by considering customer preferences and expectations. The acceptance and usability of AVs in urban environments are eventually improved by this user-centric approach, which assists in designing services that are in line with passengers' wants and preferences [59,60].\n\n## 3.4. Climate Adaptation\n\nClimate adaptation involves implementing strategies to modify systems, processes, and behaviours in response to climate change effects [61]. Within this theme, four sub-themes were identified: adaptation and decision making, resilience to climate change impacts, risk management, and resources management. In terms of resilience to climate change impacts, AVs might bring health risks like air pollution, noise, and less physical activity all things that connect to climate concerns [32]. Nonetheless, given the right rules and regulations, these self-driving vehicles could actually make our streets safer, reducing the chances of accidents [32]. From a resilience to climate change impacts perspective, a study examined the effects of AVs on pollutant in a medium-sized Portuguese urban region using numerical modelling [62]. Results indicate a small rise in emissions with 30% of AVs penetration (% of AVs in in the road network), but a significant 30% reduction when these AVs are electric; hence, this promotes a future of greener and healthier communities. For the same reason, adaptation and decision-making efforts can benefit from promoting healthy AV use patterns, particularly by incorporating entirely electric vehicles in ride-sharing and ride-splitting systems. To ensure positive adaptation and health outcomes, establishing appropriate rules and regulatory frameworks before widespread AV deployment is crucial [32,62]."}
{"doc504": "When AVs operate exclusively on electric power sourced from renewables, participate in ridesharing initiatives, and seamlessly integrate with public and active transportation modes, they offer substantial potential for public health benefits. These characteristics collectively promote physical activity, enhance urban environmental conditions by improving air quality and reducing noise, and contribute to a healthier urban design by freeing up more public space [32]. This holistic approach reflects a shift toward sustainable and health-conscious urban mobility solutions.\n\nOther researchers looked at the effects of AVs on the environment, especially how they affected urban air quality, with a focus on Nitrogen Oxides (NOx) emissions in a medium-sized urban region [40,41,62]. These studies find that the electric autonomous option results in significant reductions in NOx emissions by comparing three scenarios, including a baseline representing current traffic conditions, an autonomous scenario with a 30% AV market penetration, and an electric autonomous scenario with 30% batteryelectric AVs. This highlights the potential for AV technology to aid in climate adaptation by reducing emissions by improving urban air quality and has a direct impact on cities' resilience and sustainability [32]. This connection stems from the knowledge that better air quality reduces environmental impact and promotes long-term resilience, which are characteristics of sustainable activities. Sustainable urban development is taking steps to limit negative environmental effects. Cities may build more resilient and sustainable environments for their citizens by cutting emissions and improving air quality. Clean air initiatives support larger environmental responsibility objectives and improve a city's capacity to adapt to changing conditions.\n\nOn the other hand, serious risks can arise when AVs are adopted for personal use, depend on fossil fuels, lead to more kilometres driven, increased traffic congestion and occupation of public spaces. All these factors contribute to increased inactivity, deterioration of the urban environment (air quality and noise), and reduction of public space available for social interaction and physical activity [32]."}
{"doc505": "## 3.6. Legislation And Regulations\n\nThe legislation and regulations theme was produced with 4 sub-themes: enforcement and compliance, national polices, safety and comfort standards, and environmental regulations. Due to the lack of legislation, autonomous vehicle deployment and operation require some form of regulation [55,64,65]. The inherent need for AV technology to address privacy and security concerns emphasizes the imperative to resolve potential issues in these areas [64].\n\nThe absence of an AV regulatory framework contributes to technological ambiguities and hazards that require resolution [64]. The real-world implications extend to urban planning, impacting parking optimization, land rents, and mass transit, with potential regulatory consequences [31,32]. The adoption of proper policies and regulatory frameworks emerges as essential for AV implementation [32]. The usage of public spaces more frequently, a greater reliance on fossil fuels, and increasing traffic congestion are some potential dangers connected to the deployment of AVs. These dangers stress on how urgently strict laws and regulations are essential. Reducing these risks and making sure that AVs will improve urban mobility and environmental sustainability can be attained by regulating the use of renewable energy, managing traffic, and encouraging the use of shared vehicles. This demonstrates how good governance may transform opportunities to increase the efficiency and environmental friendliness of transportation networks from barriers to AV adoption. This involves comprehensive laws considering relevant deployment factors, including environmental effects and public health [51]."}
{"doc506": "The safety of AVs for use in congested metropolitan streets is acknowledged, underscoring the requirement for restrictions to ensure their safety and dependability before integration into regular city traffic [66]. Shared-use AVs present opportunities to lower taxi costs and enhance economic effectiveness in public transportation [66]. Governmental measures to support and encourage shared-use AVs and diverse public transportation options are deemed feasible. The potential for individually owned AVs to travel unattended may require regulation, particularly in areas where this could contribute to traffic congestion.\n\nConsidering the diverse landscape of AV possibilities, city officials crafting transportation policy must weigh these options [66]. This highlights the significance of factoring in the effects of AVs when developing transportation laws, potentially resulting in the adoption of specific legislation and standards [44,59,66]. Regulatory measures become imperative for influencing demand across various transportation modes, encompassing AVs, private vehicles, and public transportation [36]. The design of transportation systems, be it private or shared AVs, necessitates legislation governing their operation and integration with existing modes [36]. Urban infrastructure must adapt or undergo a complete redesign to support AVs, emphasizing the need for regulatory measures to guide this transformation [36,37,67\u201370].\n\nIn essence, navigating the regulatory landscape for AVs involves a comprehensive approach that considers safety, urban planning, and the integration of diverse transportation modes, underscoring the pivotal role of legislation and regulations in shaping the future of transportation."}
{"doc507": "Other sustainability aspects include enhancing public transportation and restricting individual vehicle use and urban sprawl [42,46,55]. By enabling a broad dissemination of shared vehicles that might support the mass rapid transit network, the introduction of AVs is considered as a chance to increase the allure of public transportation. By improving public transportation, this attempts to persuade more people to utilize sustainable means of transportation instead of private vehicles, so lowering traffic congestion and emissions [43,44,67,68,72]. To urge sustainability, there is a need to plan the transition towards incorporating autonomous electric vehicles into the urban system [45]. Moreover, implementing travel demand management methods, in conjunction with automobile use limitations and car-free zones, is considered as a way to control transportation demand and reduce reliance on individual cars. This strategy tries to reduce urban sprawl, which is the outward expansion of metropolitan areas that can result in longer distances between various parts of the city and a greater reliance on private automobiles. This encourages a more compact and sustainable urban development pattern by reducing urban sprawl.\n\nThe introduction of autonomous vehicles and other new mobility technologies could have both direct and indirect consequences on urban mobility and structure, which raises concerns about sustainability [36]. Although it is evident that AVs would improve safety and traffic flow immediately, it is important to think about the larger implications, some of which may have unforeseen effects. One such worry is the possibility of rising demand and congestion, which might affect not just traffic dynamics but also the design and layout of urban areas and possibly encourage urban sprawl [36]. Extensive travel times and a greater reliance on private automobiles between different city districts can result from urban sprawl, which is characterized by the outward spread of metropolitan centres. The sustainability aspect comes into focus as urban sprawl is recognized as a phenomenon with long-term adverse effects on the environment, society, and the economy [36,73].\n\n## 3.8. Infrastructure"}
{"doc508": "The infrastructure theme was created with six sub-themes: Vehicle-to-Infrastructure\n(V2I), roadway design, expectations and satisfaction, accessibility, equity, and social justice, charging stations, and safety and comfort standards. These sub themes have been obtained with consideration to previous studies [44,70,73]. The development of AVs and road safety are coupled to infrastructure. The connectedness of vehicles to other vehicles (V2V) and to everything (V2X), including other vehicles (V2I), enables real-time communication between vehicles and their surroundings. The rapid information sharing made possible by the rollout of 5G, and other high-speed data transfer technologies will assist AVs and enhance road user safety in general, including pedestrian safety, by offering users with timely access to critical information. These infrastructure investments are necessary for the widespread deployment of AVs as well as the safer and more efficient operation of the transportation ecosystem [44]. There are several factors to consider when implementing AVs into the transportation network which are charging infrastructure, dedicated lanes, safety measures, and exposure to electromagnetic radiation [44]. An efficient charging infrastructure is necessary for electric AVs to operate well in urban areas. This infrastructure gives AV\nusers choice by including both wireless and plug-in charging alternatives [44]. Vehicles can charge via plug-in charging, which is dependent on physical connectors at charging stations. Wireless charging, on the other hand, makes charging more convenient by doing away with the necessity for direct contact with charging stations.\n\nTo ensure a smooth and safe flow of AV traffic, the integration of AVs into urban environments may also call for the construction of dedicated lanes [44]. These lanes improve general traffic safety in addition to the effectiveness of AV operations.\n\nRoad safety standards must be followed, and strict safety measures must be implemented in order to ensure the safety of AVs [44]. Evaluating potential risks, such as exposure to electromagnetic radiation, becomes essential when comparing various infrastructure solutions, in addition to standard safety concerns [44]. This emphasizes the significance of a thorough assessment and management of any possible health or safety risks connected to electromagnetic radiation emissions from unmanned aerial vehicles."}
{"doc509": "For the successful integration of AVs into urban contexts, it is essential to create a supportive infrastructure. Outside of the charging features, specific lanes and stringent safety protocols are essential for achieving a seamless integration that improves urban mobility's efficiency and safety [44].\n\nOther major factors to consider are intelligent transportation systems (ITS), road infrastructure upgrades, parking infrastructure, communication infrastructure, and urban planning and development [49,73]. Developing and implementing ITS that enable AVs to interact with one another as well as with infrastructure features such as traffic lights, road sensors, and other vehicles can enhance overall traffic flow and safety [70]. To support their navigation and operations properly, AVs may require specific road infrastructure enhancements such as improved road markings, signage, and dedicated lanes. AVs navigate and make choices using a variety of sensors and communication technologies [70]. Creating a dependable data and communication infrastructure is critical to ensuring continuous connectivity and information exchange. AVs have the potential to influence urban structure and development [70]. As a result, urban planning rules and guidelines must be revised to accommodate AVs, including adjustments to road networks, land use patterns, and zoning regulations.\n\nTable 3 provides a detailed overview of the study characteristics, offering a comprehensive summary of the key themes addressed in each article. This table serves as a valuable resource for readers to quickly grasp the scope and focus of the research conducted across numerous studies included in this analysis. Additionally, it highlights the diversity of topics explored within the literature, aiding in the identification of trends and gaps in current research on the subject matter."}
{"doc510": "Future Transp. **2024**, 4, FOR PEER REVIEW 16 16. Social 17. Environmental 18. Low carbon/green transportation 19. Renewable energy sources 20. Mitigation measures 21. Industrial decarbonization Figure 6. Themes and sub-themes hierarchy chart obtained from NVivo; hierarchy charts are coloured by hierarchy and sized by coding references.\n\n| Table 3. Study characteristics.   | Theme      |             |          |                              |         |         |                             |                |                |\n|-----------------------------------|------------|-------------|----------|------------------------------|---------|---------|-----------------------------|----------------|----------------|\n| Author(s)                         | Year       | Country     | Benefits | User Attitudes, Perceptions, | Climate | Climate | Legislation and Regulations | Sustainability | Infrastructure |\n| and Behaviour                     | Adaptation | Mitigation  |          |                              |         |         |                             |                |                |\n| Zambrano-Martinez et al. [29]     | 2019       | Sapin       | \u221a        |                              |         |         |                             |                |                |\n| Huang et al. [30]                 | 2021       | Taiwan      | \u221a        |                              |         |         |                             |                |                |\n| Radwan et al. [31]                | 2022       | Egypt       | \u221a        | \u221a                            | \u221a       |         |                             |                |                |\n| Rojas-Rueda et al. [32]           | 2020       | USA         | \u221a        | \u221a                            | \u221a       | \u221a       |                             |                |                |\n| Tympakianaki et al. [33]          | 2022       | UK          | \u221a        |                              |         |         |                             |                |                |\n| Meyer et al. [34]                 | 2017       | Switzerland | \u221a        | \u221a                            |         |         |                             |                |                |\n| Camps-Arag\u00f3 et al. [35]           | 2022       | Belgium     | \u221a        | \u221a                            |         |         |                             |                |                |\n| Medina-Tapia and Robust\u00e9 [36]     | 2018       | Chile       | \u221a        | \u221a                            | \u221a       |         |                             |                |                |\n| Eppenberger and Richter [37]      | 2021       | Switzerland | \u221a        | \u221a                            | \u221a       |         |                             |                |                |\n| Rafael et al. [40]                | 2022       | Portugal    | \u221a        | \u221a                            | \u221a       |         |                             |                |                |\n| Glazener and Khreis [41]          | 2019       | USA         | \u221a        | \u221a                            |         |         |                             |                |                |\n| Sanders and Karpinski [42]        | 2022       | USA         | \u221a        | \u221a                            | \u221a       |         |                             |                |                |\n| Fournier et al. [43]              | 2017       | Germany     | \u221a        | \u221a                            |         |         |                             |                |                |\n| Anastasiadou et al. [44]          | 2021       | Greece      | \u221a        | \u221a                            | \u221a       | \u221a       |                             |                |                |\n| Kova\u02c7ci\u00b4c et al. [45]             | 2022       | Croatia     | \u221a        |                              |         |         |                             |                |                |\n| Sya'bana and Sanjaya [46]         | 2020       | Indonesia   | \u221a        | \u221a                            |         |         |                             |                |                |\n| Suganuma [47]                     | 2020       | Japan       | \u221a        |                              |         |         |                             |                |                |\n| Pechinger et al. [48]             | 2021       | Germany     | \u221a        | \u221a                            |         |         |                             |                |                |\n| May et al. [49]                   | 2020       | UK          | \u221a        |                              |         |         |                             |                |                |\n| Hinderer et al. [50]              | 2018       | Germany     | \u221a        |                              |         |         |                             |                |                |\n| Lanzer et al. [51]                | 2020       | China       | \u221a        | \u221a                            |         |         |                             |                |                |\n\n| Table 3. Cont.                 | Theme      |                                  |          |                              |         |         |                             |                |                |\n|--------------------------------|------------|----------------------------------|----------|------------------------------|---------|---------|-----------------------------|----------------|----------------|\n| Author(s)                      | Year       | Country                          | Benefits | User Attitudes, Perceptions, | Climate | Climate | Legislation and Regulations | Sustainability | Infrastructure |\n| and Behaviour                  | Adaptation | Mitigation                       |          |                              |         |         |                             |                |                |\n| Mordan et al. [52]             | 2022       | France                           | \u221a        |                              |         |         |                             |                |                |\n| Zhao and Malikopoulos [53]     | 2020       | USA                              | \u221a        |                              |         |         |                             |                |                |\n| Coppola and Silvestri [54]     | 2019       | Italy                            | \u221a        | \u221a                            |         |         |                             |                |                |\n| Garrow et al. [55]             | 2021       | USA                              | \u221a        | \u221a                            |         |         |                             |                |                |\n| BONNEFON et al. [56]           | 2016       | France                           | \u221a        | \u221a                            |         |         |                             |                |                |\n| Bansal et al. [57]             | 2016       | USA                              | \u221a        |                              |         |         |                             |                |                |\n| Deb et al. [58]                | 2017       | USA                              | \u221a        |                              |         |         |                             |                |                |\n| F\u00f6ldes and Csisz\u00e1r [59]        | 2018       | Hungary                          | \u221a        | \u221a                            |         |         |                             |                |                |\n| Adnan et al. [60]              | 2018       | Malaysia, KSA                    | \u221a        |                              |         |         |                             |                |                |\n| Rafael et al. [62]             | 2020       | Portugal                         | \u221a        | \u221a                            |         |         |                             |                |                |\n| Hasan et al. [64]              | 2020       | Australia, UAE                   | \u221a        | \u221a                            |         |         |                             |                |                |\n| Cugurullo et al. [65]          | 2021       | Ireland                          | \u221a        | \u221a                            |         |         |                             |                |                |\n| Metz [66]                      | 2018       | UK                               | \u221a        |                              |         |         |                             |                |                |\n| Nogu\u00e9s et al. [67]             | 2020       | Spain                            | \u221a        | \u221a                            |         |         |                             |                |                |\n| \u221a                              | \u221a          |                                  |          |                              |         |         |                             |                |                |\n| Richter et al. [68]            | 2022       | Austria, Sweden, Norway, Finland |          |                              |         |         |                             |                |                |\n| Staricco et al. [69]           | 2019       | Italy                            | \u221a        |                              |         |         |                             |                |                |\n| Cottam [70]                    | 2018       | USA                              | \u221a        |                              |         |         |                             |                |                |\n| Bani Younes and Boukerche [71] | 2022       | Canada                           | \u221a        |                              |         |         |                             |                |                |\n| Pauwels et al. [72]            | 2022       | Netherlands                      | \u221a        | \u221a                            |         |         |                             |                |                |\n| Leg\u00eane et al. [73]             | 2020       | Netherlands                      | \u221a        | \u221a                            |         |         |                             |                |                |"}
{"doc511": "This emphasis highlights the importance of information on the potential advantages that AVs can offer.\n\n\"User Attitudes, Perceptions, and Behaviour\" appears as another prominent theme, considered in 15 articles. This indicates a growing interest in comprehending how users engage with and reply to AVs, presenting valuable insights into the human elements of AVs in urban areas.\n\nThe themes of \"Legislation and Regulations\" and \"Sustainability\" are carefully aligned, with 15 and 16 articles respectively exploring these components. This suggests a concerted attempt to examine the legal frameworks and sustainable practices associated with the implementation of AVs. The delicate corporation legal frameworks and sustainable practices is clearly a key focus of the scholarly discourse."}
{"doc512": "Although \"Climate Mitigation\" is explored in five articles, \"Climate Adaptation\" and\n\"Infrastructure\" emerge with a more limited presence, considered in two articles each.\n\nThese themes, despite the fact that they are much less pervasive, indicate a recognition of the environmental and infrastructural dimensions related to AVs. As the field progresses and AVs continue to emerge, those themes can also permit further exploration to address potential gaps in understanding.\n\nOverall, the thematic distribution within the systematic assessment highlights a balanced approach, with a strong emphasis on benefits, user perceptions, and the regulatory and sustainable components of AVs. This comprehensive approach lays the foundation for a refined understanding of AVs from various perspectives."}
{"doc513": "Furthermore, the methods of data collection and analysis of the 41 reviewed articles are shown in Table 4. This table reflects the comprehensive approach followed in this review. For the data collection methods, a substantial number of the studies used empirical evidence, with 12 articles employing traffic data to draw insights. 18 articles were conducted through a critical examination of previous studies, illustrating the need to build on existing knowledge. Surveys along with other approaches contributed to 9 articles. This provided a valuable resource to understand user attitudes, perceptions, and behaviour.\n\nAdditionally, the singular study that combined surveys with interviews offered a more detailed exploration.\n\n| Table 4. Methods of DC and DA in reviewed articles.   | Method   |                                |                 |\n|-------------------------------------------------------|----------|--------------------------------|-----------------|\n| Author(s)                                             | Year     | DC                             | DA              |\n| Zambrano-Martinez et al. [29]                         | 2019     | Traffic data                   | SC (SM)/SA      |\n| Huang et al. [30]                                     | 2021     | Traffic data                   | SC (SM)/SA (RA) |\n| Radwan et al. [31]                                    | 2022     | Previous studies               | LitRev/FA       |\n| Rojas-Rueda et al. [32]                               | 2020     | Previous studies               | LitRev/FA       |\n| Tympakianaki et al. [33]                              | 2022     | Traffic data                   | SC (SM)/SA/FA   |\n| Meyer et al. [34]                                     | 2017     | Traffic data                   | SC (SM)         |\n| Camps-Arag\u00f3 et al. [35]                               | 2022     | Surveys/Interviews             | SA (DSA)        |\n| Medina-Tapia and Robust\u00e9 [36]                         | 2018     | Previous studies               | AM (CAM)        |\n| Eppenberger and Richter [37]                          | 2021     | Traffic and accessibility data | SC (SM)/SA (RA) |\n| Rafael et al. [40]                                    | 2022     | Traffic data                   | SC (SM)         |\n| Glazener and Khreis [41]                              | 2019     | Previous studies               | LitRev/FA       |\n| Sanders and Karpinski [42]                            | 2022     | Previous studies               | LitRev/FA       |\n| Fournier et al. [43]                                  | 2017     | Traffic data                   | AM (SM)         |\n| Anastasiadou et al. [44]                              | 2021     | Previous Studies               | CA (MCA)        |\n| Kova\u02c7ci\u00b4c et al. [45]                                 | 2022     | Previous studies               | LitRev/FA       |\n| Sya'bana and Sanjaya [46]                             | 2020     | Previous studies               | LitRev/FA       |\n| Suganuma [47]                                         | 2020     | Previous studies               | LitRev          |\n| Pechinger et al. [48]                                 | 2021     | Traffic data                   | SC (SM)         |\n| May et al. [49]                                       | 2020     | Previous Studies/Traffic data  | SC (SM)/CA      |\n| Hinderer et al. [50]                                  | 2018     | Surveys                        | SA (SHT)        |\n| Lanzer et al. [51]                                    | 2020     | Surveys                        | CA/FA           |\n| Mordan et al. [52]                                    | 2022     | Traffic data                   | SC (SM)/SA      |\n| Zhao and Malikopoulos [53]                            | 2020     | Previous studies               | LitRev          |\n| Coppola and Silvestri [54]                            | 2019     | Previous studies               | SC (SM)         |\n| Garrow et al. [55]                                    | 2021     | Previous studies               | LitRev/FA       |\n| BONNEFON et al. [56]                                  | 2016     | Surveys                        | SA/CA           |\n| Bansal et al. [57]                                    | 2016     | Surveys                        | SA (OPM)        |\n| Deb et al. [58]                                       | 2017     | Surveys                        | SA (PCA)        |\n| F\u00f6ldes and Csisz\u00e1r [59]                               | 2018     | Surveys                        | SA (CAN)/FA     |\n| Adnan et al. [60]                                     | 2018     | Previous studies               | LitRev/FA       |\n| Rafael et al. [62]                                    | 2020     | Traffic data                   | SC (SM)         |\n| Hasan et al. [64]                                     | 2020     | Previous studies               | LitRev          |"}
{"doc514": "| Method                                                                                                                                                                                                                                                                                                                                 |      |                         |              |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|-------------------------|--------------|\n| Author(s)                                                                                                                                                                                                                                                                                                                              | Year | DC                      | DA           |\n| Cugurullo et al. [65]                                                                                                                                                                                                                                                                                                                  | 2021 | Previous studies        | FA/ SA (PCA) |\n| Metz [66]                                                                                                                                                                                                                                                                                                                              | 2018 | Previous studies        | LitRev/FA    |\n| Nogu\u00e9s et al. [67]                                                                                                                                                                                                                                                                                                                     | 2020 | Surveys                 | CA (CLA)     |\n| Richter et al. [68]                                                                                                                                                                                                                                                                                                                    | 2022 | Traffic data            | SC (SM)/FA   |\n| Staricco et al. [69]                                                                                                                                                                                                                                                                                                                   | 2019 | Focus groups/Interviews | SA (PCA)     |\n| Cottam [70]                                                                                                                                                                                                                                                                                                                            | 2018 | Previous studies        | LitRev/FA    |\n| Bani Younes and Boukerche [71]                                                                                                                                                                                                                                                                                                         | 2022 | Previous studies        | FA/SA        |\n| Pauwels et al. [72]                                                                                                                                                                                                                                                                                                                    | 2022 | Traffic data            | SC (SM)      |\n| Leg\u00eane et al. [73]                                                                                                                                                                                                                                                                                                                     | 2020 | Traffic data            | SC (SM)      |\n| Abbreviations: DC: Data Collection, DA: Data Analysis, SM: Simulation, LitRev: Literature Review, RA: Regression Analysis, SHT: Statistical Hypothesis Testing, FA: Framework Analysis, OPM: Ordered Probit Model, SC: Scenario Comparison, CA: Comparative Analysis, PCA: Principal Component Analysis, CAM: Continuous Approximation |      |                         |              |\n\nTable 4. *Cont.*\nIn terms of data analysis, the articles illustrated a diverse methodological approach.\n\n![19_image_0.png](19_image_0.png)"}
{"doc515": "Scenario comparison along with statistical approaches were used in four articles, providing statistical rigour coupled with hypothetical exploration. The literature review method was employed in three studies. Moreover, the framework analysis along with literature review approach was prevalent in 11 studies. Followed by comparative analysis (five studies), analytical methods (two studies), and several combinations of framework analysis, scenario comparison and statistical approaches. Furthermore, Venn diagrams highlighting the frequent and common methods for both data collection and analysis were created as presented in Figures 8 and 9.\n\nFuture Transp. **2024**, 4, FOR PEER REVIEW 21\n\nFigure 8. Data collection (Venn Diagram)."}
{"doc516": "![20_image_0.png](20_image_0.png)\n\n## 5. Discussion Of The Approach And Limitations 5. Discussion Of The Approach And Limitations\n\nIn this study, a comprehensive review of the existing literature through a systematic review, utilizing both inductive and deductive coding approaches was conducted. The inclusion and exclusion criteria carefully shaped the initial selection of studies, forming a robust framework for analysis. This structured methodology allowed for a methodical examination of AVs in urban areas, investigating diverse aspects such as benefits, user attitudes, perceptions and behaviour, sustainability, and climate impact. The primary aim was to offer valuable insights for policymakers and provide guidance for the future development of transport systems and urban design."}
{"doc517": "Although the findings contribute significantly to informing policymakers on key considerations regarding AVs in urban areas, it is crucial to acknowledge certain limitations.\n\nFirstly, a notable geographic bias appeared, with a significant portion of identified articles originating from Europe and North America. This imbalance not only reflects disparities in resources and infrastructure but also influences the scope and focus of scientific inquiries, potentially overlooking or underrepresenting the challenges and opportunities present in other regions, particularly in the global south. This concentration may pose challenges in generalizing findings to regions with distinct urban transport systems and socio-economic contexts, warranting careful consideration. The implications of this geographical bias may result in AV technologies and urban integration strategies that are not suited to the unique needs, infrastructure, and regulatory landscapes of regions outside of Europe and North America. Overlooking the Global South in AV research neglects the distinct challenges and opportunities presented by these areas, including higher congestion levels, different road user behaviours, and varying infrastructure quality. Addressing these disparities is crucial to ensuring that AV technologies can effectively address the diverse transport needs of urban populations worldwide. The articles highlight a significant research gap in understanding the diverse impacts of autonomous vehicles across different geographic regions, including the Global South. This emphasizes the limitation related to geographic bias mentioned earlier. To better generalize findings, it would be appropriate to go into more detail on how future research should strive to incorporate a greater variety of urban contexts [74\u201376].\n\nThe limitation associated with small sample sizes for regions like Asia primarily affects the representativeness and generalizability of the findings. Small sample sizes may not adequately capture the diversity and complexity of urban environments, cultural attitudes In this study, a comprehensive review of the existing literature through a systematic review, utilizing both inductive and deductive coding approaches was conducted. The inclusion and exclusion criteria carefully shaped the initial selection of studies, forming a robust framework for analysis. This structured methodology allowed for a methodical examination of AVs in urban areas, investigating diverse aspects such as benefits, user attitudes, perceptions and behaviour, sustainability, and climate impact. The primary aim was to offer valuable insights for policymakers and provide guidance for the future development of transport systems and urban design. Although the findings contribute significantly to informing policymakers on key considerations regarding AVs in urban areas, it is crucial to acknowledge certain limitations. "}
{"doc518": "Firstly, a notable geographic bias appeared, with a significant portion of identified articles originating from Europe and North America. This imbalance not only reflects disparities in resources and infrastructure but also influences the scope and focus of scientific inquiries, potentially overlooking or underrepresenting the challenges and opportunities present in other regions, particularly in the global south. This concentration may pose towards technology, regulatory landscapes, and infrastructural variations present across such a vast and heterogeneous region. This can lead to conclusions that are not fully applicable across different Asian contexts, potentially skewing perceptions of the benefits, challenges, and societal readiness for AVs.\n\nOne of the limitations of this systematic review stems from the decision to narrowly define the inclusion and exclusion criteria for the selection of studies, which focused specifically on the role of AVs in urban areas. Although this approach enabled a detailed and focused analysis of the intersection between AVs and urban sustainability, it also necessitated the exclusion of broader research themes related to AVs and sustainability at large. Consequently, several relevant studies that could potentially offer additional insights into the sustainability implications of AVs, were not included within the scope of our review.\n\nThe lack of sufficient data and experimental results creates a significant constraint in drawing definitive conclusions about the role of AVs in urban environments. Although existing studies provide valuable insights and hypotheses, they are often based on limited datasets and experimental environments. As a result, the conclusions drawn from these studies may be subject to interpretation and revision as more comprehensive data becomes available."}
{"doc519": "It is crucial to acknowledge the uncertainty surrounding the future development of AV technology and its integration into urban contexts. Our systematic review attempts to navigate this uncertainty by critically evaluating existing literature and identifying key areas where further research is needed. By acknowledging the speculative nature of the topic, we aim to provide a nuanced understanding of the challenges and opportunities associated with the evolving field of autonomous transport.\n\nWorks based on AVs \"traffic data\" are limited and we do not have a wide study about AVs in Urban spaces, so, many conclusions and results are based on limited data and hypothetical conclusions. The prospective of AVs to reduce traffic congestion and challenge the necessity of traditional public transportation infrastructure in future urban planning adds depth to the limitations around understanding the impacts of AVs on urban transport systems. This could be stated when discussing potential oversights in current AV research methodologies [76].\n\nThe dynamic nature of the field suggests that the identified themes and sub-themes may evolve as new research emerges, emphasizing the need for ongoing scrutiny and adaptation. Finally, the review focused exclusively on articles published in English, recognizing the language bias inherent in such a choice. Although English is prevalent in academic discourse, it is essential to acknowledge the potential existence of relevant research in other languages. The reflection on these limitations enhances the transparency of the approach and encourages future research to adopt more inclusive strategies."}
{"doc520": "## 6. Conclusions, Recommendations, And Forward Look\n\nAs AV technology is rapidly advancing, there is an urgent need to explore how those new mobility services will impact on urban transport systems, including the users, the infrastructure, and the design of future urban areas. This paper applies a systematic review to establish the current state of knowledge with regards to the role of AV in urban areas. It conducted a systematic review based on the studies found on literature that were produced from 2003 to 2023 using the PRISMA approach. Results of the systematic review show seven different themes and thirty sub-themes, with articles originating in thirty-one different countries, predominantly in the Global North. Studies related to benefits accounted for 25%\nof the sample, followed by behaviours and user perception (24%) and sustainability (22%).\n\nLeast research has been undertaken on the role of AVs to support climate adaptation."}
{"doc521": "This systematic review sets the scene for considering how AVs can be implemented in urban areas, with a specific emphasis on their potential impacts on public transport. AVs in both private and public transport have the potential to improve road safety and increase access for older people or those living with disabilities. Nevertheless, it is crucial that AVs are introduced in an environmentally considerate way, so that they bring benefits in terms of climate mitigation, adaptation, and sustainability. The findings from two studies suggest that the integration of AVs and electric vehicles could significantly contribute to emission reductions and air quality improvements. This aligns with the focus on the impact of AVs on sustainability and climate adaptation, providing empirical data to support the optimistic viewpoint on AVs contributing to climate goals [74,75]. The continuous development of AVs and their implementation within the public transport system will be game changing.\n\nThis is in terms of improving accessibility, efficiency, and promoting healthier communities.\n\nInsights suggest a significant shift in how urban spaces could be designed, moving away from centralized transport hubs to more distributed systems facilitated by AVs. This could inform a dynamic perspective on urban planning and infrastructure development, encouraging adaptable and AV-friendly cities [76]. Future work will consider the policy and infrastructure changes that are required to implement Level 5 AVs as a public mobility choice within urban areas within the UK."}
{"doc522": "Table 5 outlines recommendations for the integration of AVs into urban contexts.\n\nThese recommendations emphasize the importance of environmental standards, public transportation integration, infrastructure development, and inclusive frameworks to ensure sustainable and equitable adoption of AV technology worldwide.\n\n| Table 5. Recommendations for Sustainable Integration of AVs in Urban Contexts.   |                                                |                                                                         |\n|----------------------------------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------|\n| Recommendation                                                                   | Expected Outcome/Regulation                    | Rationale/Comment                                                       |\n| AVs as Green Vehicles                                                            | Regulations requiring AVs to meet strict       | To ensure AVs contribute to climate mitigation                          |\n| environmental standards.                                                         | and sustainability goals.                      |                                                                         |\n| AVs in Shared and Public                                                         | Policies promoting AV integration into public  | Improves accessibility, reduces congestion, and                         |\n| Transportation (Priority)                                                        | transport systems.                             | supports sustainable urban mobility.                                    |\n| AVs for Long and Medium                                                          | Development of AV corridors for mass           | Enhances efficiency and accessibility in                                |\n| Distances (Mass Transportation)                                                  | transit routes.                                | inter-city and suburban travel. Aims to reduce parking issues, optimize |\n| AVs for Local Traffic and Very                                                   | Local policies supporting AV use for           | charging infrastructure, and improve local                              |\n| Short Distances                                                                  | last-mile connectivity.                        | mobility.                                                               |\n| Guidelines ensuring AV technology meets                                          |                                                |                                                                         |\n| Inclusive Frameworks for                                                         | Addresses geographic bias and ensures          |                                                                         |\n| the unique needs of different urban areas,                                       |                                                |                                                                         |\n| Diverse Regions                                                                  | equitable AV benefits worldwide.               |                                                                         |\n| including the Global South.                                                      |                                                |                                                                         |\n| Cross-regional Studies and                                                       | Collaborative research initiatives focusing on | Promotes understanding of regional challenges                           |\n| International Cooperation                                                        | AV deployment in varied urban contexts.        | and opportunities in AV implementation.                                 |\n| Investment in Supporting                                                         | Funding and development of infrastructure      | Ensures AV integration contributes effectively                          |\n| Infrastructure                                                                   | that facilitates AV adoption.                  | to urban sustainability and accessibility.                              |\n| Empirical Studies and                                                            | Encouragement of research that provides        | Aids in making evidence-based decisions on                              |\n| Real-world Adoption Focus                                                        | robust data on AV impacts in urban settings.   | AV policy and infrastructure development.                               |"}
{"doc523": "Based on the findings of this study, several actionable policy recommendations emerge for consideration. Policymakers should develop inclusive frameworks that consider the unique needs and conditions of diverse regions, especially those outside of Europe and North America. This includes facilitating the deployment and adoption in various urban contexts with particular attention to the Global South. Research institutions and governments should promote and adopt cross-regional studies to better grasp the geographical bias in AV research. This entails collaborating on studies that address the challenges and prospects of implementing AVs in the Global South. Investments in infrastructure that support the adoption of AVs and the broader sustainability goals should be prioritized. This is to effectively contribute to urban sustainability goals. Policymakers and governments should encourage international cooperation to establish regulations and standards that facilitate AV deployment across different urban and legal settings.\n\nTo ensure a more comprehensive understanding of AVs in urban areas, future research should prioritize inclusivity by focusing on diverse geographic regions, particularly those in the Global South. This can be attained through collaborative international research initiatives, localized pilot studies, and demonstrations tailored to varied urban environments.\n\nEngaging with cross-disciplinary stakeholders and allocating resources specifically for AV research in underrepresented regions are also fundamental steps. By broadening the geographic scope of AV research, insights can be developed that address local needs and contribute to more equitable and effective outcomes in AV deployment worldwide."}
{"doc524": "Future work should focus on how AVs integrate with existing transport systems and services. This entails examining into ways to smoothly include AVs in public transit systems. It is also essential for researchers to explore how AVs impact various transport methods like ridesharing, biking, walking, and how they shape urban mobility patterns and modal shifts.\n\nAdditionally, investigating the role of Mobility as a Service platforms in proposing different travel options and improving urban transport accessibility is necessary. Additionally, understanding the social and economic impacts of AVs on urban communities is important.\n\nResearch should assess how AV adoption influences urban land use patterns, property values, and real estate development. Furthermore, studying the labour market impacts of AVs, including job displacement and the emergence of new employment opportunities in AV technology development and maintenance, is essential. Exploring equity considerations such as access to AV mobility services for marginalized communities and addressing transport disparities in urban areas is necessary for ensuring inclusive and sustainable urban development."}
{"doc525": "Given the speculative nature of the topic, there is a clear need for future research to focus on empirical studies and real-world adoption of AVs in urban contexts. By prioritizing research efforts to produce robust data and experimental results, the potential impacts and challenges of AV integration can be better understood through evidence-based findings.\n\nDrawing from the themes and sub-themes identified in this study, the following are potential research questions to guide future work:\n- RQ1: How might systematic reviews broaden their inclusion criteria to incorporate broader research themes related to AVs and sustainability?\n\n- RQ2: How will AVs perform in different urban environments, particularly in the Global South, given that congestion, traffic behaviour and infrastructure quality drastically differ from those in Europe and North America?"}
{"doc526": "Transp. Res. Part A Policy Pract. **2015**, 77, 167\u2013181. [CrossRef]\n6. Chen, Y.; Zou, Y.; Kong, X.; Wu, L. Investigating the impact of influential factors on crash types for autonomous vehicles at intersections. *J. Intell. Transp. Syst.* **2023**, 1\u201315. [CrossRef]\n7. Stead, D.; Vaddadi, B. Automated vehicles and how they may affect urban form: A review of recent scenario studies. *Cities* **2019**,\n94, 125\u2013133. [CrossRef]\n8. Massar, M.; Reza, I.; Rahman, S.M.; Abdullah, S.M.H.; Jamal, A.; Al-Ismail, F.S. Impacts of Autonomous Vehicles on Greenhouse Gas Emissions\u2014Positive or Negative? *Int. J. Environ. Res. Public Health* **2021**, 18, 5567. [CrossRef] [PubMed]\n9. Tengilimoglu, T.; Carsten, O.; Wadud, Z. Infrastructure requirements for the safe operation of automated vehicles: Opinions from experts and stakeholders. *Transp. Policy* **2023**, 133, 209\u2013222. [CrossRef]\n10. Othman, K. Exploring the implications of autonomous vehicles: A comprehensive review. *Innov. Infrastruct. Solut.* **2022**, 7, 165.\n\n[CrossRef]\n11. Schippl, J.; Truffer, B.; Fleischer, T. Potential impacts of institutional dynamics on the development of automated vehicles: Towards sustainable mobility? *Transp. Res. Interdiscip. Perspect.* **2022**, 14, 100587. [CrossRef]\n12. Schepis, D.; Purchase, S.; Olaru, D.; Smith, B.; Ellis, N. How governments influence autonomous vehicle (AV) innovation. *Transp.*\nRes. Part A Policy Pract. **2023**, 178, 103874. [CrossRef]\n13. Eastman, B.; Collins, S.; Jones, R.; Martin, J.J.; Blumenthal, M.S.; Stanley, K.D. A Comparative Look at Various Countries' Legal Regimes Governing Automated Vehicles. *JL Mobil.* **2023**, *2023*, 2. Available online: https://repository.law.umich.edu/jlm/vol202 3/iss1/2 (accessed on 5 August 2023).\n\n14. Parekh, D.; Poddar, N.; Rajpurkar, A.; Chahal, M.; Kumar, N.; Joshi, G.P.; Cho, W. A Review on Autonomous Vehicles: Progress, Methods and Challenges. *Electronics* **2022**, 11, 2162. [CrossRef]\n15. SAE Levels of Driving Automation\u2122 Refined for Clarity and International Audience. May 2021. Available online: https:\n//www.sae.org/blog/sae-j3016-update (accessed on 5 August 2023)."}
{"doc527": "19. Tesla, Inc. AI. Tesla. Available online: https://www.tesla.com/AI (accessed on 15 March 2024).\n\n20. McNiff, K. What is Qualitative Research? November 2016. Available online: https://lumivero.com/resources/what-isqualitative-research/ (accessed on 5 August 2023).\n\n21. Alsaeed, B.S.; Hunt, D.V.L.; Sharifi, S. Sustainable Water Resources Management Assessment Frameworks (SWRM-AF) for Arid and Semi-Arid Regions: A Systematic Review. *Sustainability* **2022**, 14, 15293. [CrossRef]\n22. Topal, H.F.; Hunt, D.V.; Rogers, C.D. Urban Sustainability and Smartness Understanding (USSU)\u2014Identifying Influencing Factors:\nA Systematic Review. *Sustainability* **2020**, 12, 4682. [CrossRef]\n23. Kankanamge, N.; Yigitcanlar, T.; Goonetilleke, A.; Kamruzzaman, M. How can gamification be incorporated into disaster emergency planning? A systematic review of the literature. *Int. J. Disaster Resil. Built Environ.* **2020**, 11, 481\u2013506. [CrossRef]\n24. Yigitcanlar, T.; Desouza, K.C.; Butler, L.; Roozkhosh, F. Contributions and Risks of Artificial Intelligence (AI) in Building Smarter Cities: Insights from a Systematic Review of the Literature. *Energies* **2020**, 13, 1473. [CrossRef]\n25. Dicianno, B.E.; Sivakanthan, S.; Sundaram, S.A.; Satpute, S.; Kulich, H.; Powers, E.; Deepak, N.; Russell, R.; Cooper, R.; Cooper, R.A. Systematic review: Automated vehicles and services for people with disabilities. *Neurosci. Lett.* **2021**, 761, 136103. [CrossRef]\n[PubMed]\n26. Masello, L.; Sheehan, B.; Murphy, F.; Castignani, G.; McDonnell, K.; Ryan, C. From Traditional to Autonomous Vehicles: A\nSystematic Review of Data Availability. *Transp. Res. Rec. J. Transp. Res. Board* **2022**, *2676*, 161\u2013193. [CrossRef]\n27. Houghton, C.; Murphy, K.; Meehan, B.; Thomas, J.; Brooker, D.; Casey, D. From screening to synthesis: Using nvivo to enhance transparency in qualitative evidence synthesis. *J. Clin. Nurs.* **2017**, 26, 579\u2013881. [CrossRef] [PubMed]\n28. Shoham, D.A.; Dugas, L.R.; Bovet, P.; Forrester, T.E.; Lambert, E.V.; Plange-Rhule, J.; Schoeller, D.A.; Brage, S.; Ekelund, U.;\nDurazo-Arvizu, R.A.; et al. Association of car ownership and physical activity across the spectrum of human development:\nModeling the Epidemiologic Transition Study (METS). *BMC Public Health* **2015**, 15, 173. [CrossRef]\n29. Zambrano-Martinez, J.L.; Calafate, C.T.; Soler, D.; Lemus-Z\u00fa\u00f1iga, L.G.; Cano, J.C.; Manzoni, P.; Gayraud, T. A Centralized Route-Management Solution for Autonomous Vehicles in Urban Areas. *Electronics* **2019**, 8, 722. [CrossRef]\n30. Huang, C.J.; Hu, K.W.; Ho, H.Y.; Xie, B.Z.; Feng, C.C.; Chuang, H.W. A Distributed Urban Traffic Congestion Prevention Mechanism for Mixed Flow of Human-Driven and Autonomous Electric Vehicles. *Int. J. Comput. Intell. Syst.* **2021**, 14, 1714\u20131727."}
{"doc528": "[CrossRef]\n31. Hosney Radwan, A.; Ghaney Morsi, A.A. Autonomous vehicles and changing the future of cities: Technical and urban perspectives. *J. Urban Regen. Renew.* **2022**, 16, 85\u2013108.\n\n32. Rojas Rueda, D.; Nieuwenhuijsen, M.J.; Khreis, H.; Frumkin, H. Autonomous Vehicles and Public Health. Annu. Rev. Public Health **2020**, 41, 329\u2013345. [CrossRef] [PubMed]\n33. Tympakianaki, A.; Nogues, L.; Casas, J.; Brackstone, M.; Oikonomou, M.G.; Vlahogianni, E.I.; Djukic, T.; Yannis, G. Autonomous Vehicles in Urban Networks: A Simulation-Based Assessment. *Transp. Res. Rec. J. Transp. Res. Board* **2022**, *2676*, 540\u2013552.\n\n[CrossRef]\n34. Meyer, J.; Becker, H.; B\u00f6sch, P.M.; Axhausen, K.W. Autonomous vehicles: The next jump in accessibilities? *Res. Transp. Econ.* **2017**,\n62, 80\u201391. [CrossRef]\n35. Camps-Arag\u00f3, P.; Temmerman, L.; Vanobberghen, W.; Delaere, S. Encouraging the Sustainable Adoption of Autonomous Vehicles for Public Transport in Belgium: Citizen Acceptance, Business Models, and Policy Aspects. *Sustainability* **2022**, 14, 921. [CrossRef]\n36. Medina-Tapia, M.; Robust\u00e9, F. Exploring paradigm shift impacts in urban mobility: Autonomous Vehicles and Smart Cities."}
{"doc529": "Transp. Res. Procedia **2018**, 38, 203\u2013210. [CrossRef]\n37. Eppenberger, N.; Richter, M.A. The opportunity of shared autonomous vehicles to improve spatial equity in accessibility and socio-economic developments in European urban areas. *Eur. Transp. Res. Rev.* **2021**, 13, 32. [CrossRef]\n38. Kim, K. The Travel Impact of Metro Atlanta through Activity-Based Modeling. In Proceedings of the 15th TRB National Transportation Planning Applications Conference, Atlantic City, NJ, USA, 17\u201321 May 2015.\n\n39. Childress, S.; Nichols, B.; Charlton, B.; Coe, S. Using an activity-based model to explore. In *Transportation Research Board 2015*;\nTransportation Research Board, National Academy of Sciences: Washington, DC, USA, 2014.\n\n40. Rafael, S.; Fernandes, P.; Lopes, D.; Rebelo, M.; Bandeira, J.; Macedo, E.; Rodrigues, M.; Coelho, M.C.; Borrego, C.; Miranda, A.I."}
{"doc530": "How can the built environment affect the impact of autonomous vehicles' operational behaviour on air quality? *J. Environ. Manag.* 2022, 315, 115154. [CrossRef]\n41. Glazener, A.; Khreis, H. Transforming Our Cities: Best Practices towards Clean Air and Active Transportation. *Curr. Environ.*\nHealth Rep. **2019**, 6, 22\u201337. [CrossRef]\n42. Sanders, T.; Karpinski, E. Implications for Interactions between Micromobility and Autonomous Vehicles. SAE Int. J. Connect.\n\nAutom. Veh. **2022**, 6, 185\u2013197. [CrossRef]\n43. Fournier, G.; Pfeiffer, C.; Baumann, M.; W\u00f6rner, R. Individual mobility by shared autonomous electric vehicle fleets: Cost and CO2 comparison with internal combustion engine vehicles in Berlin, Germany. In Proceedings of the 2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC), Madeira, Portugal, 27\u201329 June 2017.\n\n44. Anastasiadou, K.; Gavanas, N.; Pitsiava-Latinopoulou, M.; Bekiaris, E. Infrastructure Planning for Autonomous Electric Vehicles, Integrating Safety and Sustainability Aspects: A Multi-Criteria Analysis Approach. *Energies* **2021**, 14, 5269. [CrossRef]\n45. Kova\u02c7ci\u00b4c, M.; Mutavd\u017eija, M.; Buntak, K. New Paradigm of Sustainable Urban Mobility: Electric and Autonomous Vehicles\u2014A\nReview and Bibliometric Analysis. *Sustainability* **2022**, 14, 9525. [CrossRef]\n46. Sya'bana, Y.M.K.; Sanjaya, K.H. The Study of Shared-Autonomous Vehicle Design Concept for Urban Public Transportation in Indonesia. In Proceedings of the 2020 International Conference on Sustainable Energy Engineering and Application (ICSEEA),\nTangerang, Indonesia, 18\u201320 November 2020."}
{"doc531": "47. Suganuma, N. Towards fully automated driving in urban areas. In Proceedings of the 2020 International Conference on Artificial Life and Robotics (ICAROB2020), Oita, Japan, 13\u201316 January 2020.\n\n48. Pechinger, M.; Schr\u00f6er, G.; Bogenberger, K.; Markgraf, C. Cyclist Safety in Urban Automated Driving-Sub-Microscopic HIL\nSimulation. In Proceedings of the 2021 IEEE International Intelligent Transportation Systems Conference (ITSC), Indianapolis, IN, USA, 19\u201322 September 2021.\n\n49. May, A.D.; Shepherd, S.; Pfaffenbichler, P.; Emberger, G. The potential impacts of automated cars on urban transport: An exploratory analysis. *Transp. Policy* **2020**, 98, 127\u2013138. [CrossRef]\n50. Hinderer, H.; Stegm\u00fcller, J.; Schmidt, J.; Sommer, J.; Lucke, J. Acceptance of Autonomous Vehicles in Suburban Public Transport."}
{"doc532": "Syst. **2022**, 23, 11823\u201311835. [CrossRef]\n53. Zhao, L.; Malikopoulos, A.A. Enhanced Mobility with Connectivity and Automation: A Review of Shared Autonomous Vehicle Systems. *IEEE Intell. Transp. Syst. Mag.* **2021**, 13, 87\u2013102. [CrossRef]\n54. Coppola, P.; Silvestri, F. Future mobility and land use scenarios: Impact assessment with an urban case study. *Transp. Res. Procedia* 2019, 41, 53\u201363. [CrossRef]\n55. Garrow, L.A.; German, B.J.; Leonard, C.E. Urban air mobility: A comprehensive review and comparative analysis with autonomous and electric ground transportation for informing future research. *Transp. Res. Part C Emerg. Technol.* **2021**, 132, 103377.\n\n[CrossRef]\n56. Bonnefon, J.-F.; Shariff, A.; Rahwan, I. The social dilemma of autonomous vehicles. *Science* **2016**, 352, 1573\u20131576. [CrossRef]\n57. Bansal, P.; Kockelman, K.M.; Singh, A. Assessing public opinions of and interest in new vehicle technologies: An Austin perspective. *Transp. Res. Part C Emerg. Technol.* **2016**, 67, 1\u201314. [CrossRef]\n58. Deb, S.; Strawderman, L.; Carruth, D.W.; DuBien, J.; Smith, B.; Garrison, T.M. Development and validation of a questionnaire to assess pedestrian receptivity toward fully autonomous vehicles. *Transp. Res. Part C Emerg. Technol.* **2017**, 77, 178\u2013195. [CrossRef]\n59. F\u00f6ldes, D.; Csisz\u00e1r, C. Framework for planning the mobility service based on autonomous vehicles. In Proceedings of the 2018 Smart City Symposium Prague (SCSP), Prague, Czech Republic, 24\u201325 May 2018.\n\n60. Adnan, N.; Nordin, S.M.; bin Bahruddin, M.A.; Ali, M. How trust can drive forward the user acceptance to the technology?"}
{"doc533": "In-vehicle technology for autonomous vehicle. *Transp. Res. Part A Policy Pract.* **2018**, 118, 819\u2013836. [CrossRef]\n61. United Nations. Climate Adaptation. 2023. Available online: https://www.un.org/en/climatechange/climate-adaptation\n(accessed on 5 January 2024).\n\n62. Rafael, S.; Correia, L.P.; Lopes, D.; Bandeira, J.; Coelho, M.C.; Andrade, M.; Borrego, C.; Miranda, A.I. Autonomous vehicles opportunities for cities air quality. *Sci. Total Environ.* **2020**, 712, 136546. [CrossRef] [PubMed]\n63. United Nations. Mitigation. 2023. Available online: https://www.unep.org/topics/climate-action/mitigation (accessed on 5 August 2023).\n\n64. Hasan, U.; Whyte, A.; Al Jassmi, H. A Review of the Transformation of Road Transport Systems: Are We Ready for the Next Step in Artificially Intelligent Sustainable Transport? *Appl. Syst. Innov.* **2020**, 3, 1. [CrossRef]\n65. Cugurullo, F.; Acheampong, R.A.; Gueriau, M.; Dusparic, I. The transition to autonomous cars, the redesign of cities and the future of urban sustainability. *Urban Geogr.* **2021**, 42, 833\u2013859. [CrossRef]\n66. Metz, D. Developing Policy for Urban Autonomous Vehicles: Impact on Congestion. *Urban Sci.* **2018**, 2, 33. [CrossRef]\n67. Nogu\u00e9s, S.; Gonz\u00e1lez-Gonz\u00e1lez, E.; Cordera, R. New urban planning challenges under emerging autonomous mobility: Evaluating backcasting scenarios and policies through an expert survey. *Land Use Policy* **2020**, 95, 104652. [CrossRef]\n68. Richter, M.A.; Hagenmaier, M.; Bandte, O.; Parida, V.; Wincent, J. Smart cities, urban mobility and autonomous vehicles: How different cities needs different sustainable investment strategies. *Technol. Forecast. Soc. Change* **2022**, 184, 121857. [CrossRef]\n69. Staricco, L.; Rappazzo, V.; Scudellari, J.; Vitale Brovarone, E. Toward Policies to Manage the Impacts of Autonomous Vehicles on the City: A Visioning Exercise. *Sustainability* **2019**, 11, 5222. [CrossRef]\n70. Cottam, B.J. Transportation Planning for Connected Autonomous Vehicles: How It All Fits Together. *Transp. Res. Rec. J. Transp.*\nRes. Board **2018**, *2672*, 12\u201319. [CrossRef]\n71. Younes, M.B.; Boukerche, A. Towards a Sustainable Highway Road-Based Driving Protocol for Connected and Self-Driving Vehicles. *IEEE Trans. Sustain. Comput.* **2022**, 7, 235\u2013247. [CrossRef]\n72. Pauwels, A.; Pourmohammad-Zia, N.; Schulte, F. Safety and Sustainable Development of Automated Driving in Mixed-Traffic Urban Areas\u2014Considering Vulnerable Road Users and Network Efficiency. *Sustainability* **2022**, 14, 13486. [CrossRef]\n73. Leg\u00eane, M.F.; Auping, W.L.; Correia, G.H.D.A.; van Arem, B. Spatial impact of automated driving in urban areas. *J. Simul.* **2022**,\n16, 295\u2013307. [CrossRef]\n74. Le Hong, Z.; Zimmerman, N. Air quality and greenhouse gas implications of autonomous vehicles in Vancouver Canada. Transp."}
{"doc534": "Res. Part D **2021**, 90, 102676. [CrossRef]\n75. Ercan, T.; Onat, N.C.; Keya, N.; Tatari, O.; Eluru, N.; Kucukvar, M. Autonomous electric vehicles can reduce carbon emissions and air pollution in cities. *Transp. Res. Part D Transp. Environ.* **2022**, 112, 103472. [CrossRef]\n\n76. Wiseman, Y. Driverless cars will make union stations obsolete. *Open Transp. J.* **2019**, 13, 109\u2013115. Available online: https://\nopentransportationjournal.com/contents/volumes/V13/TOTJ-13-109/TOTJ-13-109.pdf (accessed on 6 January 2024). [CrossRef]\n77. Page, M.J.; McKenzie, J.E.; Bossuyt, P.M.; Boutron, I.; Hoffmann, T.C.; Mulrow, C.D.; Shamseer, L.; Tetzlaff, J.M.; Akl, E.A.;\nBrennan, S.E.; et al. The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ **2021**, 372, n71.\n\n[CrossRef]\nDisclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."}
{"doc535": "## Abstract\n\n| Article history: Received 5 August 2022 Revised 1 February 2023 Accepted 26 March 2023 Available online 22 June 2023   |\n|------------------------------------------------------------------------------------------------------------------------|\n\nKeywords:\nAutonomous driving Decision-making Motion planning Deep reinforcement learning Model predictive control Decision-making and motion planning are extremely important in autonomous driving to ensure safe driving in a real-world environment. This study proposes an online evolutionary decision-making and motion planning framework for autonomous driving based on a hybrid data- and model-driven method. First, a data-driven decision-making module based on deep reinforcement learning (DRL) is developed to pursue a rational driving performance as much as possible. Then, model predictive control (MPC) is employed to execute both longitudinal and lateral motion planning tasks. Multiple constraints are defined according to the vehicle's physical limit to meet the driving task requirements. Finally, two principles of safety and rationality for the self-evolution of autonomous driving are proposed. A motion envelope is established and embedded into a rational exploration and exploitation scheme, which filters out unreasonable experiences by masking unsafe actions so as to collect high-quality training data for the DRL agent. Experiments with a high-fidelity vehicle model and MATLAB/Simulink co-simulation environment are conducted, and the results show that the proposed online-evolution framework is able to generate safer, more rational, and more efficient driving action in a real-world environment."}
{"doc536": " 2023 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company. This is an open access article under the CC BY-NC-ND license\n(http://creativecommons.org/licenses/by-nc-nd/4.0/).\n\n## 1. Introduction\n\nAutonomous vehicles are a product of the deep integration of the automotive industry with new-generation information technologies such as artificial intelligence (AI) and high-performance computing, and they represent one of the most important directions of global automotive development. Decision-making and motion planning are the core of autonomous driving, as they directly determine how an autonomous vehicle moves and reacts to its dynamic environment. The decision-making module receives environment and vehicle information, and outputs the desired driving behavior to the motion planning module. The latter further outputs the desired trajectory to the trajectory tracker or directly outputs the desired commands to the vehicle actuators. Thus, these two modules form the ''brain\" of an autonomous vehicle, and their performance directly affects the ability of the vehicle to deal with a dynamic and open traffic environment."}
{"doc537": "The decision-making methods used in autonomous driving include rule-, optimization-, utility-function-, and AI-based methods. Rule-based methods are simple, but their applicable scenarios are limited. Nilsson et al. [1] investigate rules to determine the appropriate lane-changing time by choosing a safe trajectory through longitudinal planning. Another typical method based on a hierarchical state machine is also widely used [2]. Noh [3] proposes a robust method using risk metrics and Bayesian networks, with a distributed reasoning structure to ensure safety.\n\nOptimization-based methods can achieve optimality, but it is difficult to use them to handle model-free problems. Nilsson and Sj\u00f6berg [4] employ a hybrid logic system to develop an integrated decision-making method based on model predictive control (MPC), and predicting the movement of surrounding vehicles is further considered in Refs. [5,6]. Karlsson et al. [7] first use MPC to generate candidate trajectories, and then determines the optimal decision through optimization. Nilsson et al. [8] consider the average travel time, remaining time, and traffic rules to form a utility function to generate the target lane. Cui et al. [9] consider the gap and speed satisfaction from the preceding vehicle to calculate a utility value. Comfort, efficiency, safety, and human-like lane selection probability are also considered to design a utility function in Ref. [10]. Utility-function methods have simple structures, but the selection of evaluation indicators is complicated.\n\nFor motion planning, two main frameworks are popularly used in the literature. In the first framework, the trajectory is planned first, and then trajectory tracking is executed. Common trajectory planning methods include the polynomial method [11], the spline method [12], and the clothoid method [13]. Widely used trajectory tracking methods include proportional\u2013integral\u2013derivative (PID) control [14,15], sliding mode control (SMC) [16,17], and MPC\n[18,19]. Most of these methods ignore the coupling between trajectory planning and tracking control, which can easily cause conflicts. For example, in a fast-changing environment, the planned trajectory may not be trackable. In the other framework, the trajectory planning stage is skipped by means of optimization methods, and steering and longitudinal-control commands are directly outputted to vehicle actuators. This framework can obtain optimality under certain conditions and considers the coupling between trajectory planning and tracking control. As a result, it has been widely studied, especially in regard to MPC-related methods [20\u2013 24]. MPC can be used to deal with the optimal control problem with multiple constraints and can naturally imitate a driver's predictive behavior."}
{"doc538": "In addition, with the recent development of AI methods, learning-based autonomous driving techniques have been widely studied [25] and are usually based on imitation learning (IL) [26] and reinforcement learning (RL) [27] methods. Liu et al. [28] use a Gaussian kernel support vector machine (SVM) to make lanechanging decisions, while Wang et al. [29] utilize long short-term memory (LSTM) to make human-like decisions. End-to-end learning is another popular technique that maps sensing information to the vehicle control commands. Xiao et al. [30] present a multimodal conditional IL (CIL) method for end-to-end autonomous driving. Menner et al. [31] propose that the parameterized motion planning objective be learned via inverse learning. Regarding RL\nmethods, Peng et al. [32] employ a dueling double deep Qnetwork (DQN) approach to design the steering controller. Lin et al. [33] further utilize a deep deterministic policy gradient\n(DDPG) algorithm for continuous adaptive cruise control. In addition, He et al. [34] present a constrained robust actor-critic (AC)\nmethod for lane changing under traffic uncertainties. Although AI-based methods are good at learning, they are highly dependent on data, and cannot easily ensure safety for safety-critical systems.\n\nSimilar studies can also be found in Refs. [35\u201339] and others.\n\nAutonomous vehicles are a typical safety-critical system, so the aforementioned methods still present challenges, especially in an open driving environment. First, from the perspective of system development, rule- and model-based methods are mostly used to develop decision-making and planning algorithms, or AI-based methods are employed to train feasible policies offline in the developing stage. These algorithms or policies are then deployed in autonomous vehicles, making it difficult to endow vehicles with online learning and continuous evolution in the operating stage with the driver and passengers in the loop. However, such a capability is extremely necessary in order for autonomous vehicles to be able to deal with an unknown, dynamic and open traffic environment in a continuable, growable, and reliable manner."}
{"doc539": "Second, the ''black-box\" nature of deep learning and the random trial-and-error mechanism of deep RL (DRL) seriously affect safety and trustworthiness when exploring and exploiting policy online in the operating stage. Therefore, it is another important challenge to realize the safe and rational evolution of autonomous driving. Finally, most existing studies ignore the mutual coupling between decision-making and motion planning, and design the two layers separately to achieve individual objectives in a sequential manner. These studies usually develop the decision-making layer without considering the planning capability boundary constrained by vehicle kinematics and dynamics. This will result in decisions that are too aggressive to be well executed by the planning layer or too conservative to waste the planning layer's capability; thus, such methods cannot achieve optimal performance of the whole decision-making and planning system. The present study addresses these problems, and its main contributions are as follows:\n(1) A novel online-evolution framework of decision-making and planning for autonomous driving in the operating stage is proposed by developing a hybrid data- and model-driven method based on DRL and MPC. This framework takes advantage of the high self-adaptation and self-learning capabilities of data-driven methods, as well as the interpretability and ability to handle hard constraints of model-driven methods.\n\n(2) Two principles for safety and rationality in the online evolution of autonomous driving are proposed. Based on the above framework, a safe-driving envelope is established, and a rational exploration and exploitation scheme is designed that filters out random and unsafe experiences by masking unsafe actions in order to obtain high-quality training data and realize the safe and rational self-evolution of autonomous driving.\n\n(3) Mutual coupling between the decision-making layer and the planning layer is considered in order to pursue the optimal performance of the whole system. Based on a safe online-learning mechanism, the continuous evolution of the system within the capability boundary of the planning layer is realized, along with the maximum utilization of the capabilities of the planning layer."}
{"doc540": "The remainder of this paper is organized as follows: Section 2 introduces the whole proposed framework. The data-driven evolutionary decision-making module is then presented in Section 3 with the DQN problem formulation and parameter design. A\nmodel-driven motion planning method using MPC is elaborated in Section 4. Section 5 develops the safe and rational exploration and exploitation mechanism based on a predictive safe driving envelope model and a rational exploration and exploitation scheme. Finally, Section 6 demonstrates a case study, and Section 7 presents conclusions and identifies future work.\n\n## 2. Proposed Framework\n\nAutonomous vehicles require not only high adaptability and learning ability in an open traffic environment but also strict safety and strong rationality. Data-driven methods are difficult to interpret and cannot ensure strict safety, although they are good at learning. In comparison, model-driven methods lack selfadaptation and self-learning, but they are interpretable and can handle various constraints. Therefore, this study proposes a framework by designing a hybrid data- and model-driven method to deal with decision-making and motion planning as a whole. Decisionmaking is more relevant to vehicle adaptation and learning capabilities, while motion planning is directly related to vehicle safety."}
{"doc541": "scenarios. MPC has an inherent advantage in dealing with predictive optimization problems with hard constraints and well reflects the predictive driving behavior of human drivers. Therefore, in this study, we chose the DQN approach in DRL for learning discrete decision policies, while using MPC for safe motion planning. It should be noted that the planning layer in this study receives the decision commands and directly outputs the desired steering and acceleration commands to the vehicle actuators. The overall structure proposed in this study is shown in Fig. 1.\n\nThis framework consists of an environment module, a datadriven evolutionary decision module, a model-driven motion planning module, and a safe and rational policy exploration and exploitation module. First, the environment module outputs the motion states of the ego vehicle and the surrounding vehicles to the three modules. Then, in the decision module, the DQN agent learns iteratively by continuously interacting with the environment through trial-and-error. At each time step, the DQN agent outputs the decision command to the motion planning module and receives a filtered signal on the current bad decision from\n\n## "}
{"doc542": "the safe and rational policy exploration and exploitation module. Next, the MPC-based motion planning module decouples the desired driving behavior into longitudinal and lateral motions after receiving the decision commands. Accordingly, longitudinal and lateral planning are respectively performed. Finally, in the safe and rational policy exploration and exploitation module, a safe driving envelope is constructed to constrain the MPC planning problem. The rational exploration and exploitation scheme based on trial-and-error is further designed to perform safety checking and rational motion correction control of the desired decision commands in real time. In this way, the current unreasonable desired decisions are masked and fed back to the DQN decision agent. Meanwhile, the corresponding obtained acceleration and steering commands are outputted to the environment to control the ego vehicle.\n\n## 3. Data-Driven Evolutionary Decision-Making\n\nThis section introduces the DQN-based evolutionary decision module, including decision problem formulation and parameter design."}
{"doc543": "3.1. DQN-based decision-making problem formulation The decision-making of autonomous driving can be considered to be a sequential optimal decision-making process, which can be described by a Markov decision process (MDP). Based on the MDP,\nthe RL agent can guide the autonomous vehicle to interact and learn with the environment by defining the reward function, constructing the optimization objective, and using the trial-and-error learning mechanism, finally obtaining the optimal decisionmaking policy. An MDP is defined as a tuple M \u00bc hS; A; T; R; ci, where S is the state space; A is the action space; T \u00bc pat st st\u00fe1\n: st; st\u00fe1 2 S; at 2 A\nn o is the state transition probability from state st to st+1 with action at (where pat st st\u00fe1 is the state transition probability and at is the chosen action); R \u00bc rat st st\u00fe1 is the instant reward of the above state transition and r is the reward value; and c is the discount factor. The corresponding decision-making policy is defined as p\u00f0atjst\u00de \u00bc pat st , denoting the probability of choosing at at st. The state value function Vp\u00f0st\u00de is the expected accumulated reward obtained by executing p starting from st, which is defined as follows:\n\n$V_{\\pi}(\\mathbf{s}_{t})=\\mathbf{E}_{\\pi}\\left[\\mathbf{s}_{t-0}^{\\pi}\\mathbf{r}_{\\mathbf{s}_{t+k}\\mathbf{s}_{t+k+1}}^{\\mathbf{a}_{t+k}}\\left|\\mathbf{s}_{t}\\right|\\right]$\nh i \u00f01\u00de\nwhere Ep is the calculation of expectation, k is the state transition index, and t is the current time step.\n\nThe state-action value function Qp\u00f0st; at\u00de is defined as follows:"}
{"doc544": "## 3.2. Dqn Parameter Design\n\n3.2.1. State and action space configuration The action space in autonomous driving must accurately and completely describe the driving behavior during a specific driving task. On the one hand, the selection of the state space must consider the most important environment elements that induce driving behavior; on the other hand, it is necessary to ignore less important environment elements as much as possible to reduce their interference on driving behavior, which can simultaneously reduce the dimension of the state space to save computation resources. In this study, we design an algorithm for the driving task of an ego vehicle traveling in three-lane traffic flow. The driving behaviors in this task include lane keeping, left lane changing, and right lane changing, which can be regarded as behaviors that pursue different target lanes. Therefore, the identifiers (IDs) of all the possible target lanes are directly selected to construct the action space. The perception attention of a human driver directly affects the generation of that person's driving behavior and is the most important factor inducing different driving behaviors. In general, the most basic perception attention range of a human driver can be described by the position and motion information of the ego vehicle and its nearest surrounding vehicles; thus, this information is selected to construct the state space. It should be noted that this state space construction method can be extended to other driving tasks, as well as to a wider range of human-like perception.\n\nThe state space S and the action space A are depicted in Fig. 2, and are defined as follows:"}
{"doc545": "3.2.2. Reward function design The reward function is the driving force that guides the learning direction of the RL agent. In autonomous driving, the primary criterion for the design of the reward function is to reflect the global goal of the driving task, which in our case is to make the ego vehicle pursue the highest possible traffic efficiency under the premise of the road speed limit. Therefore, this study considers the speed reward. It should be noted that this paper does not need to consider reward dimensions such as safety (i.e., collision avoidance)\nand comfort using traditional reward design methods; rather, it transfers these global goals to the model-driven planning layer and the safe and rational exploration and exploitation mechanism, to be introduced later. This mechanism is based on trial-and-error of the desired decision, where the success of trial-and-error means that the planning layer can immediately implement the safe planning to execute the desired decision command, and failed trials mean that the desired decision cannot be executed immediately in a safe way and will be masked and corrected back to safe controls. In this way, the mechanism can directly and stably ensure the most basic driving needs such as safety and comfort.\n\nTherefore, the reward function of the autonomous driving RL\nagent is defined as follows:\n\n$$\\mathbf{r}_{\\mathrm{s_{r}s_{r+1}}}^{\\mathrm{n_{r}}}=w_{v}\\bigg{(}\\frac{v_{x}-v_{\\mathrm{max}}}{v_{\\mathrm{max}}}\\bigg{)}^{2}\\tag{10}$$  where $v_{\\mathrm{max}}$ is the road speed limit and $w_{v}$ is the weighting coefficient.  "}
{"doc546": "4.1.1. Vehicle kinematics and dynamics modeling In different driving tasks and even different driving behaviors, human drivers have different preferences for longitudinal and lateral motions. When solving the longitudinal and the lateral motion control problems of the ego vehicle through the same optimization problem with the same optimization objective, it is often difficult to reasonably allocate the priority of longitudinal and lateral optimal control, which results in unstable vehicle motion control.\n\nTherefore, this study decouples the longitudinal and lateral motion of the vehicle and uses MPC to control the vehicle.\n\nThe longitudinal differential kinematics model of the ego vehicle is defined as follows:"}
{"doc547": "X_ \u00bc vX\n$$\\mid v_{X}=a_{X},$$\n(\n$$(11)$$\nwhere X, vX, and aX denote the longitudinal position, the longitudinal velocity, and the longitudinal acceleration of the ego vehicle in global coordinates, respectively.\n\nTo consider the lateral dynamics of the ego vehicle more accurately and to improve the lateral motion stability, a linear tire model is employed. This model assumes a linear relationship between the tire force and the slip angle over a certain range of tire slip angle and assumes a small front wheel steering angle. Based on this assumption, a linear MPC prediction model can be constructed, which can then be solved by means of standard quadratic programming, avoiding the high computation burden brought by nonlinear MPC calculations. This assumption can also be used for normal stable driving conditions. The lateral dynamics model of the ego vehicle is shown in Fig. 3.\n\n8\n>>>>>><\n$$\\left\\{\\begin{array}{l}\\dot{\\psi}=\\frac{(F_{\\psi\\xi}+F_{\\psi\\pi})}{m}-\\frac{\\dot{X}+\\psi\\sin\\psi}{\\cos\\psi}\\,r_{e}\\\\ \\dot{\\psi}=r_{e}\\\\ \\dot{r}_{e}=\\frac{(F_{\\psi\\xi}+F_{\\psi\\pi})}{l_{e}}\\\\ \\dot{Y}=\\frac{\\dot{X}+\\psi\\sin\\psi}{\\cos\\psi}\\,\\sin\\psi+\\psi\\cos\\psi\\end{array}\\right.\\tag{12}$$"}
{"doc548": ">>>>>>:\nwhere v is the lateral velocity in vehicle coordinates; re is the yaw rate; w represents the yaw angle in global coordinates; m and Iz denote the mass and the moment of inertia, respectively; lf and lr are the distances from the vehicle's center of gravity to the front and the rear axles, respectively; Fyf and Fyr are the lateral forces of the front and the rear tires, respectively; and v_ , w_ , r_e; and _Y\ndenote the differential calculations. The linear tire forces can be calculated as follows:\n\n$$\\left[\\begin{array}{l}F_{\\rm yf}=C_{\\rm zf}\\left(\\delta-\\frac{(v+\\mu_{\\rm r})\\cos\\psi}{X+v\\sin\\psi}\\right)\\\\ \\\\ F_{\\rm yr}=C_{\\rm zf}\\left(-\\frac{(v-\\mu_{\\rm r})\\cos\\psi}{X+v\\sin\\psi}\\right)\\end{array}\\right.\\tag{13}$$\n8\n><\n>:\nwhere Caf and Car are the cornering stiffnesses of the front and rear tires, respectively; and d is the front wheel steering angle. It should be noted that the kinematics and dynamics models of the ego vehicle in this study can be directly transferred to the Frenet coordinate system through coordinate transformation.\n\n4.1.2. Driving behavior interpretation"}
{"doc549": "![4_image_0.png](4_image_0.png)\n\nWhen using MPC to plan the motions of the desired driving behavior, another important issue is how to model the behavior as an optimization objective with constraints that MPC can understand. Since the desired longitudinal and lateral positions of the ego vehicle reflect the most important characteristics of the lane-keeping and lane-changing behaviors, we select the longitudinal and lateral positions as state variables and carry out motion planning in the MPC prediction horizon to track the desired position signals that reflect the desired decision-making commands in real time.\n\nIn the prediction horizon, the state, output, and control vectors of the longitudinal and lateral motions are defined as follows:"}
{"doc550": "$$(14)$$\n$$\\left\\{\\begin{array}{l}\\chi_{\\rm lon}=\\left[X,\\,\\upsilon_{X}\\right]^{\\rm T},y_{\\rm lon}=X,u_{\\rm lon}=a_{X}\\\\ \\chi_{\\rm lat}=\\left[\\,\\upsilon\\quad\\psi\\quad\\Gamma_{\\rm e}\\quad Y\\right]^{\\rm T},y_{\\rm lat}=Y,u_{\\rm lat}=\\delta\\end{array}\\right.\\tag{1}$$\nwhere xlon, ylon, and ulon are the longitudinal model variables; and\nxlat, ylat, and ulat belong to the lateral model. The time-discrete prediction model with a longitudinal time step tp;lon and a lateral step\ntp;lat is defined as follows:\n$$\\left\\{\\begin{array}{l}X_{\\text{lon},k_{\\text{lon}}+1}=A_{\\text{lon}}X_{\\text{lon},k_{\\text{lon}}}+B_{\\text{lon}}u_{\\text{lon},k_{\\text{lon}}}+C_{\\text{lon}}\\\\ Y_{\\text{lon},k_{\\text{lon}}+1}=C_{\\text{c,lon}}X_{\\text{lon},k_{\\text{lon}}+1},k_{\\text{lon}}=0,1,...,N_{\\text{p,lon}}-1\\\\ X_{\\text{lat},k_{\\text{lat}}+1}=A_{\\text{lat}}X_{\\text{lat},k_{\\text{lat}}}+B_{\\text{lat}}u_{\\text{lat},k_{\\text{lat}}}+C_{\\text{lat}}\\\\ Y_{\\text{lat},k_{\\text{lat}}+1}=C_{\\text{c,lat}}X_{\\text{lat},k_{\\text{lat}}+1},k_{\\text{lat}}=0,1,...,N_{\\text{p,lat}}-1\\end{array}\\right.$$\n$$(15)$$\n\nwhere klon and klat are time indexes in longitudinal and lateral predictions, respectively; Alon, Blon, Clon, Cc;lon, Alat, Blat, Clat; and Cc;lat are system matrixes; Np;lon and Np;lat are the longitudinal and lateral prediction horizons, and\n\n$$\\mathbf{A}_{\\text{lon}}=\\begin{bmatrix}1&\\mathbf{f}_{\\text{p,lon}}\\\\ 0&1\\end{bmatrix},\\mathbf{B}_{\\text{lon}}=\\begin{bmatrix}0\\\\ \\mathbf{f}_{\\text{p,lon}}\\end{bmatrix},\\mathbf{C}_{\\text{lon}}=\\begin{bmatrix}0\\\\ 0\\end{bmatrix},\\mathbf{C}_{\\text{c,lon}}=[1,0]\\tag{16}$$  The matrixes $\\mathbf{A}_{\\text{lat}}$, $\\mathbf{B}_{\\text{lat}}$, $\\mathbf{C}_{\\text{lat}}$, and $\\mathbf{C}_{\\text{c,lat}}$ can be calculated by lin \nThe matrixes Alat, Blat, Clat, and Cc;lat can be calculated by linearizing the lateral nonlinear dynamics model of the ego vehicle\n[22]."}
{"doc551": "The desired longitudinal and lateral positions of different driving behaviors are shown in Fig. 4. The lane width Wlane is 4 m in this study. The desired longitudinal position is determined based on a safe distance from all the front vehicles. The desired lateral position comes from the decision-making command, which is also the lateral position of the centerline of the target lane. In the prediction horizon, the desired longitudinal and lateral positions can be defined as follows:\n\n$$(17)$$\n$\\left\\{\\begin{array}{l}X_{\\text{ref},k_{\\text{lan}}+1}=X_{\\text{ref},t}\\\\ Y_{\\text{ref},k_{\\text{lan}}+1}=Y_{\\text{ref},t}\\end{array}\\right.$  where $X_{\\text{ref},t}$ and $X_{\\text{ref},t}$ are the desired positions at $t$.  \n4.2. MPC-based motion planning problem formulation 4.2.1. Optimization problem statement The objective function of MPC-based motion planning in this study is defined as follows:\n\nstudy is defined as follows:  $$\\begin{split}J_{t}(x_{t},u_{t-t_{p}})&=\\sum\\nolimits_{i=1}^{N_{p}}\\left|y_{t+i\\eta_{p}|t}-y_{\\text{ref},t+i\\eta_{p}|t}\\right|^{2}_{\\boldsymbol{Q}}+\\sum\\nolimits_{j=0}^{N_{c}-1}\\left\\|u_{t+j\\eta_{p}|t}\\right\\|^{2}_{\\boldsymbol{R}_{u}}\\\\ &\\quad+\\sum\\nolimits_{j=0}^{N_{c}-1}\\left\\|\\Delta u_{t+j\\eta_{p}|t}\\right\\|^{2}_{\\boldsymbol{R}_{d_{u}}}\\end{split}\\tag{18}$$"}
{"doc552": "where tp is the prediction time step; Np is the prediction horizon; Nc\nis the control horizon; Q is the weighting matrix to pursue the\ndesired driving decision command; and Ru and Rdu are the weighting matrixes to minimize the control and its jerk, respectively,\nwhich are related to driving comfort. On this basis, the constrained\nMPC optimization problem is formulated as follows:\nmin\n$\\Delta u_{t}$  s.t. $X_{t+it_{p}|t,\\min}\\leq X_{t+it_{p}|t}\\leq X_{t+it_{p}|t,\\max}$  $y_{t+it_{p}|t,\\min}\\leq y_{t+it_{p}|t}\\leq y_{t+it_{p}|t,\\max}$  $u_{t+it_{p}|t,\\min}\\leq u_{t+it_{p}|t}\\leq u_{t+it_{p}|t,\\max}$  $\\Delta u_{t+it_{p}|t,\\min}\\leq\\Delta u_{t+it_{p}|t}\\leq\\Delta u_{t+it_{p}|t,\\max}$\nJt xt; uttp ;DUt\n \f\n$$(19)$$\nwhere DUt is the control vector and\n\n$$\\Delta\\mathbf{U}_{\\mathrm{f}}=\\left[\\ \\Delta u_{\\mathrm{f}|\\mathrm{f}},\\quad\\Delta u_{\\mathrm{f}+\\mathrm{f}_{\\mathrm{p}}|\\mathrm{f}},\\ldots,\\quad\\Delta u_{\\mathrm{f}+\\mathrm{f}_{\\mathrm{p}}|\\mathrm{f}}\\ \\right]^{\\mathrm{T}}\\tag{1}$$  $$\\Delta u_{\\mathrm{f}+\\mathrm{f}_{\\mathrm{p}}|\\mathrm{f}}=u_{\\mathrm{f}+\\mathrm{f}_{\\mathrm{p}}|\\mathrm{f}}-u_{\\mathrm{f}+(j-1)\\mathrm{f}_{\\mathrm{p}}|\\mathrm{f}}$$\n8\n<\n:\n$$(20)$$\n\nThe above problem is then applied to the longitudinal and the lateral motion planning, respectively, of the ego vehicle."}
{"doc553": "4.2.2. Constraints setting Autonomous driving must satisfy physical constraints related to the physical performance of the vehicle and task constraints related to driving tasks, so as to achieve safe, comfortable, and stable driving. The physical constraints include the accelerationrelated constraints, constraints related to the front wheel steering angle, and the sideslip angle constraints of the tire model. Substituting aX, d, af , and ar into Eqs. (19) and (20), the upper and lower bounds are defined as follows:\n\naX;t\u00feitp;lonjt;min  aX;t\u00feitp;lonjt  aX;t\u00feitp;lonjt;max DaX;t\u00feitp;lonjt;min  DaX;t\u00feitp;lonjt  DaX;t\u00feitp;lonjt;max dmin  dt\u00fejtp;latjt  dmax Ddmin  Ddt\u00fejtp;latjt  Ddmax af;min  af;t\u00feitp;latjt  af;max ar;min  ar;t\u00feitp;latjt  ar;max\n$$(16)$$\n8\n>>>>>>>>><\n>>>>>>>>>:\n$$(21)$$\nwhere tp;lon and tp;lat are longitudinal and lateral prediction time steps, respectively.\n\nIt is notable that the above jerk constraints on the acceleration and the front wheel angle can also be regarded as comfort and stability constraints, from the perspective of driving tasks. The other comfort constraint is the lateral acceleration constraint, which is defined as follows:\nay;t \u00fe itp;latjty;maxy;min \u00f022\u00de\nIn addition to the above constraints, traffic rules are considered."}
{"doc554": "Thus, the road speed limit constraint is defined as follows:\nvX;t \u00fe itp;lonjtX;t\u00feitp;lonjt;maxX;t\u00feitp;lonjt;min \u00f023\u00de\nThe aim is to imitate the comfortable acceleration and deceleration behavior of human drivers. Thus, in the process of acceleration, the changing rate of the acceleration gradually decreases with the increase in acceleration, while in the process of deceleration, the changing rate of the acceleration gradually decreases with the decrease in acceleration. This avoids the discomfort caused by continuously stepping on the accelerating or braking pedal. Therefore, the acceleration jerk constraint is defined as follows:\n\n$$\\left\\{\\begin{array}{l}\\Delta a_{X,t+\\hat{u}_{\\rm p,lim}|t,\\min}=W_{1}\\left(a_{X,t+\\hat{u}_{\\rm p,lim}|t,\\min}-a_{X}\\right)\\\\ \\Delta a_{X,t+\\hat{u}_{\\rm p,lim}|t,\\max}=W_{2}\\left(a_{X,t+\\hat{u}_{\\rm p,lim}|t,\\max}-a_{X}\\right)\\end{array}\\right.$$\n$$(24)$$\n\nIn addition, the longitudinal and lateral safety constraints of driving behavior determine the safety of the entire decisionmaking and planning system; they are also the safety basis for online trial-and-error by the RL agent. This part will be introduced in the next section."}
{"doc555": "Safety is the primary principle. To ensure the strict safety of the autonomous vehicle during its evolution, this study proposes the introduction of longitudinal and lateral safety requirements of driving behavior into the MPC problem in the form of hard constraints. These safety constraints are modeled as a predictive safe-driving envelope, as shown in Fig. 5, where the blue areas represent the safe spaces for the ego vehicle in different lanes, and the longitudinal envelope boundary is determined according to the shorter one of the safe spaces in different lanes.\n\nTherefore, the longitudinal and lateral position constraints in the MPC prediction horizon are defined as follows:\n\n$X_{t+it_{p,\\rm{len}}}|t,\\rm{min}\\leq X_{t+it_{p,\\rm{len}}}|t\\leq X_{t+it_{p,\\rm{len}}}|t,\\rm{max}$  $Y_{\\rm{min}}\\leq Y_{t+it_{p,\\rm{len}}}|t\\leq Y_{\\rm{max}}$\nYmin  Yt\u00feitp;latjt  Ymax (\u00f025\u00de"}
{"doc556": "executed immediately in a safe way. The working principle is shown in Fig. 6.\n\nIt is only when the longitudinal motion planning of the desired decision has a feasible solution that the optimized longitudinal acceleration is executable; then, the corresponding desired lane centerline can be pursued through lateral motion planning. Otherwise, the longitudinal motion planning of the original decision\n(e.g., lane keeping) will be conducted and executed, and the lateral motion planning will lead the ego vehicle to track the original lane centerline. More specifically, the rational exploration and exploitation module is designed based on the criterion of longitudinal driving planning priority. This is intended to mimic the driving habits of humans. Usually, human drivers will prioritize the estimation of the longitudinal safety of the vehicle motion. If the decision made does not affect the longitudinal safety, then the decision can be used as one of the candidate decisions; if the decision affects the longitudinal safety, then the decision will not be executed. For example, when the vehicle is in the lane-keeping state, if it wants to change to the left lane, it can first use the MPC to carry out the longitudinal planning of the left lane changing behavior. If the longitudinal planning can obtain a reasonable optimal acceleration at the MPC algorithm level, this indicates that the optimal acceleration is safe and can be implemented; thus, the left lane change decision can be implemented. The optimal acceleration can be determined by whether the MPC has an optimal solution that satisfies the constraints. Furthermore, an acceleration limit interval related to comfort can be also introduced to evaluate qualities of MPC solutions. For example, if the deceleration obtained by the optimization is less than a certain threshold or the acceleration is greater than a certain threshold, then the ultimate optimal acceleration will not exist.\n\nThe proposed mechanism well describes a safe and rational online trial-and-error mechanism for the learning and evolution process of human drivers in the real world. For example, when driving, novice drivers usually constantly use trial-and-error driving behaviors and interact with surrounding vehicles so as to increase their driving experience and improve their driving ability."}
{"doc557": "In this trial-and-error process, human drivers always attempt to drive their vehicle normally and stably to ensure safety, instead of driving by means of random unsafe exploration, as a traditional RL agent usually does. It should be noted that the ''trial-and-error\" in traditional RL refers to the agent utilizing randomization methods to enhance its exploration of unknown states or actions when making decisions, so as to increase the possibility of policy improvement. However, the goal of the trial-and-error mechanism of the MPC planning layer in this study is to imitate the process Fig. 5. The predictive safe-driving envelope. human drivers use to improve their driving skills.\n\n## 6. Case Study\n\nIn this section, the proposed method is verified by using a highfidelity dynamics model, including a performance verification of the proposed framework and an analysis of the effects of key parameters."}
{"doc558": "## 6.1. Simulation Setup\n\nThe Sim-to-Real problem is one of the challenges that restrict the extensive application of RL in real-world autonomous driving. This problem stems from the unreality of environment perception and vehicle dynamics in a simulation and training environment.\n\nSince the environment states are the relative positions and velocities of the surrounding vehicles rather than image information, this study uses a high-fidelity dynamics model and constructs a training environment using MATLAB/Simulink in order to truly reflect the dynamics of an autonomous vehicle in the real world as much as possible. This simulation scheme is capable of simulating the continuous learning and evolution process of autonomous driving in the real world."}
{"doc559": "In the RL algorithm, the replay buffer size is 100 000, the batch size is 32, the target network updating interval is 100, and the neural network is a fully connected network with a size of 16  50  50  1. Other simulation parameters are listed in Table 1.\n\n## 6.2. Results And Analysis\n\nHere, we first verify the effectiveness of the algorithm in stable and unstable traffic flow in case 1, including the evolution performance and safety performance. Next, in cases 2 and 3, we discuss the effects of the driving style of the planning layer and the traffic flow density on the performance of the algorithm."}
{"doc560": "6.2.1. Case 1: Different average speeds of traffic flow This case compares the effectiveness of the proposed framework for different average speeds of traffic flow. The results are provided in Fig. 7, where Figs. 7(a) and (b) show the results in stable traffic flow with an average speed of 20 (case 1-A) and 40 kmh1 (case 1-B), respectively. The blue, orange, and yellow curves represent the average reward or speed within the past 1, Table 1 Simulation parameters.\n\n| Simulation parameters. I: identity matrix; g: gravitational acceleration.   |\n|-----------------------------------------------------------------------------|\n\n30, and 60 min, respectively. Fig. 7(c) further shows the results for the ego vehicle in an unstable traffic flow. The velocities of all the traffic vehicles are randomly assigned between 20 and 50 kmh1. The accelerations of the traffic vehicles are constrained to be within 4 to 2 ms 2, and are updated as follows:"}
{"doc561": "## Atv \u00bc \u00d0vtv;F 2  Vtv2\u00de 2\u00d0xtv;F  Xtv  Dtv;S\u00fe \u00d026\u00de\n\nwhere Xtv and vtv are the longitudinal position and the longitudinal velocity of the traffic vehicle, respectively; Xtv;f and vtv;f denote the longitudinal position and velocity of the vehicle in front of the traffic vehicle; and dtv;s refers to the safe distance. This setting is to simulate interactive driving behavior between vehicles in real traffic.\n\nBecause this paper focuses on the driving task in three-lane traffic flow, and its goal is to maximize the traffic efficiency as much as possible, the average speed is selected as the evaluation index. The impact of decision-making instructions on traffic efficiency is often in the long-term domain, reflecting the effect during a future period, and it is difficult to describe the quality of a certain decision using the instantaneous speed increase or decrease. Therefore, in this paper, we choose to evaluate and analyze the changes in the average speed within 1, 30, and 60 min, so as to reflect the degree of evolution of the decision-making layer. As can be seen from Figs. 7(a) and (b), with an increase in the training time, the average speed of the ego vehicle gradually increases and finally converges to a level about 10 kmh1 above the designated traffic flow speed (20 and 40 kmh1). This means that, after online training, the ego vehicle has already learned how to obtain acceleration space through lane changing, so as to pursue a faster average speed. These results show the learning and evolution of the ego vehicle in its driving efficiency."}
{"doc562": "In this study, the acceleration capacity of the ego vehicle is determined by longitudinal motion planning based on MPC, and the maximum speed that can be achieved is determined by the average speed and density of the traffic flow. The higher the average speed of the traffic flow is and the lower the density is, the higher the equivalent longitudinal acceleration space of the ego vehicle will be, allowing the vehicle to achieve a higher average speed. Therefore, in this case, a stable traffic flow and fixed MPC parameters theoretically determine a maximum upper bound of the average speed in this environment. The goal of the DQN\ndecision-making is to encourage the ego vehicle to continuously evolve to approach this maximum average speed, in theory. Therefore, in the simulation results, the MPC parameters, traffic flow characteristics, and DQN parameters jointly determine the level to which the ego vehicle can evolve, which in this case is to a level where the average speed exceeds the traffic flow speed by about 10 kmh1. As a further validation of the proposed framework in unstable traffic flow (case 1-C), Fig. 7(c) shows that, in the initial stage of training, the average reward curves of different time scales show a downward trend, because the agent prefers to explore to obtain more diverse experiences. With an increase in the training time, the average reward gradually increases and finally tends to stabilize. It is worth noting that the upper bound of the reward is determined by the average speed and density of the traffic flow, to a certain extent, and the trend of the reward curve is also greatly affected by the traffic flow.\n\nFor example, if a human driver encounters a traffic jam in a real traffic environment, regardless of how the driver drives, the speed will not be too high. During the training, the positions and velocities of traffic vehicles are random and time-varying, so the training environment is uncertain, resulting in oscillation of the reward curve. However, in general, with an increase in the training time, the agent shows an obvious upward trend in reward and achieves an obvious evolution. Consistent with the reward curve, the\n\n![8_image_0.png](8_image_0.png)"}
{"doc563": "average longitudinal velocity of the ego vehicle decreases first and then increases. Since the velocities of all the traffic vehicles are less than 50 kmh1, it can be seen that the average velocity of the ego vehicle reaches about 57 kmh1 in the later stage of training, which indicates that the ego vehicle has evolved to achieve a higher velocity through lane-changing behaviors in unstable traffic flow. This also reflects the online-evolution process of the ego vehicle.\n\nTo illustrate the safety performance, Fig. 8 presents the longitudinal distance from the ego vehicle to the front and rear traffic vehicles in the same lane, and the lateral position of the ego vehicle in the whole training process in case 1-A. Fig. 9 shows the longitudinal and lateral acceleration in the whole training process. It can be seen from Fig. 8 that, during the whole training process, the distance from the front traffic vehicle is always above 0 and the distance from the rear traffic vehicle is always below 0. This means that the ego vehicle does not collide with the traffic vehicles. Moreover, Fig. 8 shows that the ego vehicle never exceeds its lane boundaries (from 6 to 6 m). The distribution of vehicle's lateral positions changes with time, reflecting the trial-and-error behavior of multiple desired decisions. The above results all benefit from the safe driving envelope and the safe exploration and exploitation mechanism, which utilize MPC hard constraints to ensure safety.\n\nIn addition, it can be seen from Fig. 9 that the longitudinal acceleration is constrained from 0.4g to 0.2g (where g is gravitational acceleration), and the lateral acceleration is always within 0.4g\n(mainly from 0.02g to 0.02g, which achieves reasonable comfort and stable longitudinal and lateral motion control."}
{"doc564": "which is an exploration mode of ''knowing mistakes and correcting mistakes,\" is therefore needed. This mode simulates the learning process of human drivers. For example, when novice drivers learn lane-changing behavior, if they find that the lane-changing instructions they want to execute will lead to a collision, they will immediately give up on lane changing and return to lane keeping.\n\nSecond, every driving experience collected in the training includes not only decision-making results but also planning results. The planning layer in this study uses MPC to naturally imitate the predicted driving behavior of human drivers. For example, in longitudinal motion planning, different following distances and their bounds reflect the following styles of conservative or aggressive drivers. This rational motion planning is the embodiment of the anthropomorphic nature of exploring and exploitation.\n\n6.2.2. Case 2: Different planning layer styles This case compares the effects of different MPC parameters of the planning layer on the proposed framework, which imitate conservative and aggressive human driving styles. The results are shown in Fig. 10. In case 2-A (shown in Fig. 10(a)), which imitates a conservative style, the longitudinal maximum position and the desired distance from the front vehicle in the MPC prediction horizon are 10 and 25 m, respectively. In case 2-B (shown in Fig. 10(b)),\nwhich represents an aggressive style, these parameters are 5 and 15 m, respectively. The average speed of the traffic flow is 40 kmh1 in both cases 2-A and B."}
{"doc565": "Figs. 10(a) and (b) respectively correspond to the online training results of the ego vehicle based on a conservative and an aggressive MPC planning layer. In both cases, the ego vehicle can gradually\n\n![10_image_0.png](10_image_0.png)\n\nevolve to exceed the average speed of the traffic flow by about 10 kmh1. However, the MPC planning layer in case 2-A has a larger longitudinal maximum position and a further desired position from the front vehicle than that in case 2-B, so its acceleration space is shorter. This causes a relatively conservative planning performance, causing the average speed of the ego vehicle with a more aggressive planning layer in case 2-B to converge faster, and the final speed is slightly higher than that in case 2-A. Therefore, a more aggressive planning level results in a higher maximum average speed being achieved by the whole decision-making and motion planning system. This is consistent with the driving performance of human drivers: The more aggressive drivers are, the higher their utilization of the traffic flow free space is, and the more they can pursue a higher average speed by changing lanes frequently."}
{"doc566": "6.2.3. Case 3: Different traffic flow densities This case compares the effects of traffic flow density on the proposed framework. The results are shown in Fig. 11. The longitudinal distance between the traffic vehicles in the same lane are 80 and 120 m in cases 3-A and B (shown in Figs. 11(a) and (b)), respectively. The average speed of the traffic flow is 40 kmh1 in both cases.\n\nAs shown in Fig. 11, the final average speed of the ego vehicle in case 3-A reaches 50 kmh1, while the final average speed in case 3-B is 55 kmh1. This finding shows that, at the same speed, sparse traffic flow allows the ego vehicle to evolve so that it can reach a higher average speed. This is because sparse traffic flow results in a greater distance between traffic vehicles, which provides a larger longitudinal acceleration space in which the ego vehicle can extend its acceleration time during lane keeping. It also increases the space for implementing lane-changing exploration. As a result, the probability of successful lane changing is increased, which permits the ego vehicle to extend the equivalent longitudinal space for acceleration through continuous lane-changing behavior. Taken together, these factors lead to an increase in the average speed of the ego vehicle.\n\n## 7. Conclusions"}
{"doc567": "This study deals with the online learning and evolution problem of decision-making and motion planning for autonomous driving in the operating stage by developing a hybrid data- and modeldriven framework. This framework takes advantage of DRL's high self-learning capabilities and MPC's ability to deal with safety constraints and MPC's interpretability to develop a decision-making module and motion planner. The two principles of safety and rationality in the online evolution of autonomous driving in the operating stage are further proposed, and a corresponding safe and rational exploration and exploitation mechanism is designed.\n\nThis mechanism is able to filter out random and unsafe experiences by masking unsafe actions so as to obtain high-quality training data with safe and human-like features. Moreover, based on the proposed framework, continuous evolution of the decisionmaking layer within the capability boundary of the planning layer is realized, along with the maximum utilization of the capabilities of the planning layer. Finally, safe and rational self-evolution of autonomous driving is realized. The results show that the proposed framework achieves the safe and rational online evolution of autonomous driving to pursue higher traffic efficiency. More specifically, it is found that \u2460 the maximum speed that can be achieved is determined by the average speed and density of the 118\n\n![11_image_0.png](11_image_0.png)"}
{"doc568": "traffic flow, as well as the planning layer style; \u2461 the more aggressive the planning style is, the higher the utilization of the traffic flow free space will be, and the more possible it is to pursue a higher average speed by changing lanes frequently; and \u2462 sparse traffic flow allows the ego vehicle to evolve to provide more accelerating space, so that it can reach a higher average speed.\n\nIn our future work, we will focus on enabling the agent to learn the MPC parameters together with the proposed framework to improve the decision-making and motion planning flexibility; we will also investigate more driving tasks under this framework and conduct real vehicle experiments.\n\n## Acknowledgments"}
{"doc569": "[5] Du Y, Wang Y, Chan CY. Autonomous lane-change controller via mixed logical dynamical. In: Proceedings of 17th International IEEE Conference on Intelligent Transportation Systems (ITSC); 2014 Oct 8\u201311; Qingdao, China. New York City: IEEE; 2014. p. 1154\u20139.\n\n[6] Zhou Z, Yang Z, Zhang Y, Huang Y, Chen H, Yu Z. A comprehensive study of speed prediction in transportation system: from vehicle to traffic. iScience 2022;25(3):103909.\n\n[7] Karlsson J, Murgovski N, Sj\u00f6berg J. Optimal trajectory planning and decision making in lane change maneuvers near a highway exit. In: Proceedings of 18th European Control Conference (ECC); 2019 Jun 25\u201328; Naples, Italy. New York City: IEEE; 2019. p. 3254\u201360."}
{"doc570": "[16] Sabiha AD, Kamel MA, Said E, Hussein WM. ROS-based trajectory tracking control for autonomous tracked vehicle using optimized backstepping and sliding mode control. Robot Auton Syst 2022;152:104058.\n\n[17] El Atwi H, Daher N. A composite model predictive and super twisting sliding mode controller for stable and robust trajectory tracking of autonomous ground vehicles. In: Proceedings of IEEE 3rd International Multidisciplinary Conference on Engineering Technology (IMCET); 2021 Dec 8\u201310. Beirut, Lebanon. New York City: IEEE; 2022. p. 107\u201312.\n\n[18] Ji J, Khajepour A, Melek WW, Huang Y. Path planning and tracking for vehicle collision avoidance based on model predictive control with multiconstraints. IEEE Trans Vehicular Technol 2016;66(2):952\u201364."}
{"doc571": "[25] Zhou Q, Zhao D, Shuai B, Li Y, Williams H, Xu H. Knowledge implementation and transfer with an adaptive learning network for real-time power management of the plug-in hybrid vehicle. IEEE Trans Neural Netw Learn Syst 2021;32(12):5298\u2013308.\n\n[26] Wang Y, Zhang D, Wang J, Chen Z, Li Y, Wang Y, et al. Imitation learning of hierarchical driving model: from continuous intention to continuous trajectory. IEEE Robot Autom Lett 2021;6(2):2477\u201384.\n\n[27] Hoel CJ, Wolff K, Laine L. Automated speed and lane change decision making using deep reinforcement learning. In: Proceedings of 21st International Conference on Intelligent Transportation Systems (ITSC); 2018 Nov 4\u20137; Maui, HI, USA. New York City: IEEE; 2018. p. 2148\u201355."}
{"doc572": "[34] He X, Yang H, Hu Z, Lv C. Robust lane change decision making for autonomous vehicles: an observation adversarial reinforcement learning approach. IEEE Trans Intell Vehicles 2023;8(1):184\u201393.\n\n[35] Li G, Li S, Li S, Qin Y, Cao D, Qu X, et al. Deep reinforcement learning enabled decision-making for autonomous driving at intersections. Automotive Innovation 2020;3(4):374\u201385.\n\n[36] Liu Z, Hu J, Song T, Huang Z. A methodology based on deep reinforcement learning to autonomous driving with double Q-Learning. In: Proceedings of 7th International Conference on Computer and Communications (ICCC); 2021 Dec 10\u201313; Chengdu, China. New York City: IEEE; 2022. p. 1266\u201371."}
{"doc573": "Autonomous driving is a rapidly developing technology that is also a source of debate. People believe that autonomous vehicles will provide a better future by increasing road safety, lowering infrastructure expenses, and improving mobility for children, the old, and the disabled. On the other hand, many individuals are concerned about incidences of automotive hacking, the likelihood of fatal crashes, and the loss of driving-related professions. Autonomous driving is, without a question, a complex and problematic technology for many people. To better comprehend how safe self-driving cars are, it's necessary to first understand how they function, as well as what kind of sensors autonomous vehicles use to determine where they should travel and recognize things on the road in order to avoid automobile accidents. Data collected by the sensors exhibit heterogeneous and multimodal characteristics, which are further fused to frame effective decision rules. Thus sensors play a major role in decision making activity of Autonomous Vehicles (AVs). In order to acquire more information related to the sensors, this paper analyses and summarizes different types of AV sensors based on their mandatory attributes. This analysis helps the readers to understand the contribution of the sensors towards decision-making in AVs and also summarizes the data types collected by different sensors. The summarized inferences will be an eye-opener to most of the budding researchers and students in the field of AVs to select the appropriate sensor based on their needs for their research. The study also gives brief information regarding the specifications of different categories of sensors manufactured by leading vendors in the market. Autonomous driving is a rapidly developing technology that is also a source of debate. People believe that autonomous vehicles will provide a better future by increasing road safety, lowering infrastructure expenses, and improving mobility for children, the old, and the disabled. On the other hand, many individuals are concerned about incidences of automotive hacking, the likelihood of fatal crashes, and the loss of driving-related professions. Autonomous driving is, without a question, a complex and problematic technology for many people. To better comprehend how safe self-driving cars are, it's necessary to first understand how they function, as well as what kind of sensors autonomous vehicles use to determine where they should travel and recognize things on the road in order to avoid automobile accidents. Data collected by the sensors exhibit heterogeneous and multimodal characteristics, which are further fused to frame effective decision rules. Thus sensors play a major role in decision making activity of Autonomous Vehicles (AVs). In order to acquire more information related to the sensors, this paper analyses and summarizes different types of AV sensors based on their mandatory attributes. This analysis helps the readers to understand the contribution of the sensors towards decision-making in AVs and also summarizes the data types collected by different sensors. The summarized inferences will be an eye-opener to most of the budding researchers and students in the field of AVs to select the appropriate sensor based on their needs for their research. The study also gives brief information regarding the specifications of different categories of sensors manufactured by leading vendors in the market. \u00a9 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the Conference Program Chairs.\n\n\u00a9 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the Conference Program Chairs\n\u00a9 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the Conference Program Chairs.\n\nKeywords: *Autonomous Vehicles (AVs), Autonomous Driving (AD), sensors, LiDAR, RADAR, Intelligent Transportation System (ITS*\n* Corresponding author. Tel.: +971543781405; fax:+0-000-000-0000 ."}
{"doc574": "At no point is a human passenger required to assume control of the car, nor is a human passenger required to be present in the car at all. Self-driving cars are progressively gaining market penetration. While there were about 31 million machines with some level of automation in operation around the world in 2019, that number is predicted to rise to 54 million by 2024 [1]. As a result, the worldwide autonomous vehicle market is expected to expand. Although the market dropped by roughly 3% in 2020 because to the economic slowdown induced by the Covid-19 epidemic, the market is expected to rise by about 60% between 2020 and 2023 [2]. Rapid advancements in electronics, information, and communications technology (leading to downsizing and improved computer, sensor, and networking performance) have spawned various autonomous vehicle (AV) technologies. In real-world scenarios, most autonomous driving (AD) systems face similar obstacles and limits, such as safe driving and navigating in inclement weather, and safe interactions with pedestrians and other vehicles. Harsh weather conditions, such as glare, snow, mist, rain, haze, and fog, can have a substantial impact on the perception and navigation performance of perception-based sensors. In addition, AD issues in inclement weather are encountered in other limited AD contexts like agriculture and logistics. \n\nBecause of the unpredictable situations and behaviors of other cars, these difficulties become more complex for onroad AVs. Placing a yield sign in an intersection, for example, can alter the behavior of approaching vehicles. As a result, in order to limit collision hazards, AVs must have a thorough prediction module that can identify all position future motions. Despite the fact that AD systems face many of the same issues in real-world circumstances, they differ dramatically in a number of ways. As a result, in AVs, a complete prediction module is essential for identifying all future position motions and reducing collision hazard. While AV systems differ differently from one another, they are always sophisticated systems with several subcomponents. The architecture of an Autonomous Driving (AD) system is described from two perspectives: technical, which includes the hardware and software components of the AD system, and functional, which explains the processing blocks necessary within the AV, from data gathering through vehicle control. From a technological standpoint, the two fundamental layers are hardware and software, with each layer containing multiple subcomponents that represent distinct parts of the entire system [3]. The paper is organized in the following hierarchy. Section two, discusses the background information related to multimodal fusion and decision making in AVs. Section three, briefs the overview of different sensors based on their characteristics. Section four, concludes the survey.\n\n## 2. **Background And Related Work**"}
{"doc575": "Sensors are devices that convert sensed events or changes in the environment into a numerical measurement that may then be processed. Sensors are divided into two categories based on their operational principle. Internal state sensors, also known as proprioceptive sensors, record the dynamical state of a dynamic system and detect internal data such as force, angular rate, wheel load, battery voltage, and so on. Inertial measurement units (IMU), encoders, inertial sensors (gyroscopes and magnetometers), and location sensors (Global Navigation Satellite System (GNSS) \nreceivers) are examples of proprioceptive sensors. Exteroceptive sensors, or external state sensors, on the other hand, perceive and gather information from the system's environment, such as distance measurements or light intensity. Exteroceptive sensors include cameras, radio detection and range (Radar), light detection and range (LiDAR), and ultrasonic sensors. Additionally, sensors might be either passive or dynamic in nature. Autonomous sensors are crucial in automated driving because they allow automobiles to monitor their surroundings, recognize approaching impediments, and plan their routes securely [4]. They will eventually allow the automation system to take full control of the car when combined with automotive software and computers, saving drivers a substantial amount of time by performing chores in a much more efficient and safe manner. [5] [6]. Passive sensors, such as vision cameras, receive energy from their environment and provide outputs. Active sensors, such as LiDAR and radar sensors, emit energy into the environment and detect the environmental \"response\" to that energy to provide outputs. Sensors are vital in AVs for perception of the environment and vehicle localization for path planning and decision making, which are necessary before managing the vehicle's movements. To sense its surroundings, AV relies on numerous vision cameras, radar sensors, LiDAR sensors, and ultrasonic sensors. Other sensors, such as the Global Navigation Satellite System (GNSS), the Inertial Measurement Unit (IMU), and vehicle odometry sensors, are also utilized to determine the vehicle's relative and absolute positions. \n\n![2_image_0.png](2_image_0.png)\n\nThe sensors are split into three categories based on the wireless technology's transmission range: short-range, mediumrange, and long-range. The architecture design and execution of an AV is covered in [7], and several multi-sensor fusion solutions are discussed in [8]. [9], discusses recent breakthroughs and advancements in the perception and sensor technology for AVs. Multiple-target and multiple-source are coupled in [10] to construct an on-board sensor framework. [11]. [12], discusses resource allocation techniques for DSRC and C-V2X. Both of these technologies, however, are only appropriate for medium- and long-range communication and do not support low-latency applications. Figure 1, depicts the positioning of sensors for environment perception in common AV systems, as well as their coverage and uses and Figure 2, explains the processing of vehicular data collected from the sensors by the four main functional modules of the AV system."}
{"doc576": "## 3. **Overview About The Sensors**\n\nThis section summarizes the overall overview about different types of AV sensors based on their different properties. This section examines the benefits and drawbacks of the three basic sensors for environment perception in AV applications: cameras, LiDARs, and radars. 3.1 *Cameras* Cameras are one of the most widely used technologies for observing the environment. A camera produces crisp images of the surrounding by detecting lights emitted from the surroundings on a photosensitive surface (image plane) using a camera lens (placed in front of the sensor) [13-18]. Cameras are generally affordable, and when used in conjunction with appropriate software, they can identify both moving and stationary impediments within their field of vision, as well as produce high-resolution photographs of the surroundings. Table 1, illustrates the specifications of various stereo cameras.\n\n3.2 *LiDAR*\nLiDAR, or light detection and ranging, was first developed in the 1960s and has since been widely employed in the mapping of aeronautical and aerospace terrain. The first commercial LiDAR's with 2000 to 25,000 pulses per second (PPS) for topographic mapping applications were manufactured and deployed in the mid-1990s by laser scanner manufacturers [19]. LiDAR is a distant sensing technique that works on the principle of producing infrared or laser light pulses that reflect off of target objects. The equipment detects these reflections, and the time between emission and reception of the light pulse allows for distance estimate. LiDAR sensors produce data in the form of a series of points, also known as point cloud data (PCD), in 1D, 2D, and 3D areas, as well as object intensity information. The PCD comprises the x, y, and z coordinates as well as the intensity information of the obstacles inside the scene or surrounds for 3D LiDAR sensors. Table 2, depicts specifications of various LiDAR sensors."}
{"doc577": "3. *Radars* Before World War II, Radio Detection and Ranging, or Radar, was developed. It worked on the idea of emitting electromagnetic (EM) waves within the region of interest and receiving dispersed waves (or reflections) from targets for signal processing and determining range information. It determines the relative speed and position of identified obstacles using the Doppler property of EM waves [20]. The Doppler effect, also known as Doppler shift, describes how relative motion between a wave source and its targets causes variations or shifts in wave frequency. When the target travels towards the radar system's direction, the frequency of the detected signal rises (shorter waves) [21]. The general mathematical equation for a radar's Doppler frequency shift can be written as .\n\n$f_D\\;=\\;\\frac{2\\times V_r\\times f}{2}$ $=\\frac{2\\times V_r}{\\Delta}$ . \n = 2 \u00d7  \u00d7\n = 2 \u00d7 \n (1)\nWhere  is the Doppler frequency in Hertz (Hz),  is the relative speed of the target, () is the frequency of the transmitted signal, is the speed of the light (3 \u00d7 108 m/s) and ( is the wavelength of the emitted energy. Table 3, highlights the specifications of different Radar type sensors.\n\n| Deep Information   |                           |                |          |          |          |                     |            |         |          |        |\n|--------------------|---------------------------|----------------|----------|----------|----------|---------------------|------------|---------|----------|--------|\n| Model              | Baseline                  | HFOV(o )       | VFOV(o ) | FPS(Hz)  | Range    | Img                 | Range      | Res     | FPS      |        |\n| (mm)               | Res                       |                |          |          |          |                     |            |         |          |        |\n| Roboception        | RC Viscard                | 160            | 61       | 48       | 25       | 0.5-3               | 1.2        | 0.5-3   | 0.03-1.2 | 0.8-25 |\n| 160                |                           |                |          |          |          |                     |            |         |          |        |\n| Carnegie           | MultiSense                |                |          |          |          |                     |            |         |          |        |\n| Robotics           | S7 MultiSense S21B        | 70             | 80       | 49/80    | 30 max   | -                   | 2/4        | 0.4min  | 0.5-2    | 7.5-30 |\n| 210                | 68-115                    | 40-68          | 30 max   | -        | 2/4      | 0.4min              | 0.5-2      | 7.5-30  |          |        |\n| Ensenso            | N35-606-16                | 100            | 58       | 52       | 10       | 4max                | 1.3        |         |          |        |\n| Framos             | D435e                     | 55             | 86       | 57       | 30       | 0.2-10              | 2          | 0.2 max | 0.9      | 30     |\n| Nerian             | Karmin3                   | 50/100/250     | 82       | 67       | 7        | 3                   | 0.23/0.45/ | 2.7     | -        |        |\n| 1.14min            |                           |                |          |          |          |                     |            |         |          |        |\n| Intel              | D455 D$35 D415            | \u2264 90 \u2264 90 \u2264 90 |          |          |          |                     |            |         |          |        |\n| Flir               | Bumblebee2 Bumblebee  XB3 | 95 50 55       | 86 86 85 | 57 57 40 | 30 30 30 | 20 max 10max 10 max | 3 3 3      | 0.4 min | \u22641       |        |\n| 0.105min           | \u22641                        |                |          |          |          |                     |            |         |          |        |\n| 0.16mm             | \u22641                        |                |          |          |          |                     |            |         |          |        |\n| 120                | 66                        | 48/20          | 0.3/0.8  | 1.2      | \u2212        |                     |            |         |          |        |\n| 240                | 6                         | 16             |          |          |          |                     |            |         |          |        |"}
{"doc578": "| FoV (HFOV)Horizontal resolution (HR0, Vertical Resolution (VR), Wavelength(\u03bb) Category Company Model Channels/ FPS(Hz) Acc(m) RNG(m)   | VF                                                    | HFO             | HR                       | VR                            | \ud835\udf06\ud835\udf06                               | Ref                  |                     |                                       |                       |                     |      |      |\n|----------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------|-----------------|--------------------------|-------------------------------|------------------------------------|----------------------|---------------------|---------------------------------------|-----------------------|---------------------|------|------|\n| Layers                                                                                                                                 | OV                                                    | V(o )           |                          |                               |                                    |                      |                     |                                       |                       |                     |      |      |\n| ( o )                                                                                                                                  |                                                       |                 |                          |                               |                                    |                      |                     |                                       |                       |                     |      |      |\n| Velodyne                                                                                                                               | VLP-16 VLP\u2013 32C HDL-32E HDL-64E VLS 128 (Alpha Prime) | 16 32 32 64 128 | 5-20 5-20 5-20 5-20 5-20 | \u00b10.03 \u00b10.03 \u00b10.02 \u00b10.02 \u00b10.03 | 1..100 1..200 2-100 3..120 Max 245 | 30 40 41.3 3 26.8 40 | 360 360 360 360 360 | 0.1-04 0.1-04 0.08- 0.33 0.09 0.1-0.4 | 2 0.33 1.33 0.33 0.11 | 903 903 903 903 903 | [15] |      |\n| Mechanical / Spinning LiDARS                                                                                                           | Hesai                                                 | Pandar64        | 64                       | 10,20 10,20                   | \u00b10.02                              | 0.3..20              | 40                  | 360                                   | 0.2,0.4               | 0.167               | 905  | [16] |\n| Pandar40P                                                                                                                              | 40                                                    | \u00b10.02           | 0.3..200                 | 40                            | 360                                | 0.2,0.4              | 0.167               | 05                                    |                       |                     |      |      |\n| Ouster                                                                                                                                 | OSI-64 Gen1 OSI-16 Gen 1                              | 64              | 10,20                    | \u00b10.03                         | 0.8\u2014120                            | 33.2                 | 360                 | 0.7.0.35                              | 0.53                  | 850                 | [17] |      |\n| 16                                                                                                                                     | 10.20                                                 | \u00b10.03           | 0.8120                   | 33.2                          | 360                                | 0.53                 | 850                 |                                       |                       |                     |      |      |\n| RoboSense                                                                                                                              | RS-LiDAR 32                                           | 32              | 5.10,20                  | \u00b10.03                         | 0.4-200                            | 40                   | 360                 | 0.18,10.3                             | 2                     | 905                 | [18] |      |\n| 6                                                                                                                                      |                                                       |                 |                          |                               |                                    |                      |                     |                                       |                       |                     |      |      |\n| LeiShen                                                                                                                                | C32-151A                                              | 32              | 5,10,20 5,10,20          | \u00b10.03                         | 0.5-..70                           | 32                   | 360                 | 0.09                                  | 1                     | 905                 | [19] |      |\n| C16-700B                                                                                                                               | 16                                                    | 0.5..150        | 30                       | 360                           | 0.18,0.36                          | 2                    | 905                 |                                       |                       |                     |      |      |\n| \u00b10.02                                                                                                                                  |                                                       |                 |                          |                               |                                    |                      |                     |                                       |                       |                     |      |      |\n| Hokuyo                                                                                                                                 | YVT-35LXF0                                                       | -               | 20                       | \u00b10.05                         | 0.3..35                            | 40                   | 210                 | -                                     | -                     | 905                 | [20] |      |\n| IBEO                                                                                                                                   | LUX 4L Standard LUX HD LUX SL                         | 4               | 25                       | 0.1                           | 50                                 | 3.2                  | 110                 | 0.25                                  | 0.8                   | 905                 | [21] |      |\n| Solid State  LiDARS                                                                                                                    | 4 8                                                   | 25 25           | 0.1 0.1                  | 50 30                         | 3.2 6.4                            | 110 110              | 0.25 0.25           | 0.8 0.8                               | 905 905               |                     |      |      |\n| SICK                                                                                                                                   | LDMRS400102S 01 HD LDMRS8001S01 HD                                                       | 4               | 50                       | -                             | 30                                 | 3.2                  | 110                 | 0.125- 0.5                            | -                     | -                   | [19] |      |\n| 8                                                                                                                                      | 50                                                    | 50              | 6.4                      | 110                           | 0.125- 0.5                         | -                    | -                   |                                       |                       |                     |      |      |\n\n![4_image_2.png](4_image_2.png)\n\n![4_image_1.png](4_image_1.png)"}
{"doc579": "![4_image_0.png](4_image_0.png)\n\nTable 3: General specification of RADAR sensors. Acronyms first from first column top to bottom , Frequency(Freq), horizontal FoV(HFOV), \nVertical FoV(VFOV), Range Accuracy (Range Acc), Velocity Range(Vel Range), ROS (Robotic Operating System)\n\n| Aptiv Delpi                                                                                                                                 | Continental                                                                                  | SmartMicro           |              |                           |\n|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|----------------------|--------------|---------------------------|\n| Category                                                                                                                                    | ESR2.5                                                                                       | SRR@                 | ARS 408-21   | UMMR-96-T-153             |\n| Freq(GHz)                                                                                                                                   | 76.5                                                                                         | 76.5                 | 76\u202677        | 79(77..81)                |\n| HFOV(o )  Short-Range Mid-Range Long-Range                                                                                                  | \u00b145 \u00b110                                                                                      | \u2265 130 \u2265 130          |              |                           |\n| \u2265 100 (squint beam)                                                                                                                         |                                                                                              |                      |              |                           |\n| VFOV(o )                                                                                                                                    | 20                                                                                           |                      |              |                           |\n| Short-Range                                                                                                                                 | 4.4                                                                                          | 10                   | 14           | 15                        |\n| Long-Range                                                                                                                                  | \u00b175                                                                                          | \u00b19 \u00b160               |              |                           |\n| Range(m) Short-Range Mid-Range Long-Range                                                                                                   | -                                                                                            | \u00b10.5 noise and \u00b10.5% | -            | <0.15 (or) 1% (bigger of) |\n| bias                                                                                                                                        | <0.30 (or) 1% (bigger of) <0.50 (or) 1% (bigger of)                                          |                      |              |                           |\n| Vel Range (km/h) Short-Range Mid-Range Long-Range                                                                                           | -                                                                                            | -                    | \u2212400 \u2026 + 100 |                           |\n| \u2212400\u2026 + 200                                                                                                                                 | \u2212340 \u2026 + 140 \u2212340 \u2026 + 140                                                                    |                      |              |                           |\n| IO Interfaces                                                                                                                               | CAN/Ethernet                                                                                 | PCAN                 | CAN          | CAN/Automotive Ethernet   |\n| Table 4: Common comparison among sensor. \"                                                                                                  | \" sensors operate completely under specific conditions,\"--\" sensors performs reasonably well |                      |              |                           |\n| under specific conditions,\"\u00d7\" sensors does not operate well under the specific factor relative to other sensors. Factors Camera LiDAR RADAR | Fusion                                                                                       |                      |              |                           |\n| Range                                                                                                                                       | --                                                                                           | --                   |              |                           |\n| Resolution                                                                                                                                  | --                                                                                           | \u00d7                    |              |                           |\n| Distance Accuracy                                                                                                                           | --                                                                                           |                      |              |                           |\n| Velocity                                                                                                                                    | --                                                                                           | \u00d7                    |              |                           |\n| Color Perception, e.g Traffic lights                                                                                                        | \u00d7                                                                                            | \u00d7                    |              |                           |\n| Object Detection                                                                                                                            | \u00d7                                                                                            |                      |              |                           |\n| Object Classification                                                                                                                       | \u00d7                                                                                            | \u00d7                    |              |                           |\n| Lane Detection                                                                                                                              | \u00d7                                                                                            | \u00d7                    |              |                           |\n| Obstacle Edge Detection                                                                                                                     | \u00d7                                                                                            |                      |              |                           |\n| Illuminations Conditions                                                                                                                    | \u00d7                                                                                            |                      |              |                           |\n| Weather Conditions                                                                                                                          | \u00d7                                                                                            | --                   |              |                           |\n| 3.4. Challenges associated with sensors                                                                                                     |                                                                                              |                      |              |                           |"}
{"doc580": "3.4. Challenges *associated with sensors*\n\nManufacturing reliable and robust designs of smart sensors for accurate and precise measurements is a \n\nchallenging task for most of the sensor manufacturers. In wireless sensors handling faulty and unreliable communication error is another major challenging issue. The key issues with a wireless sensor networks are (i) selection of appropriate hardware and operating infrastructure, (ii) sensing network calibration, deployment, and programming model, and (iii) synchronization. Calibrating sensors before using them is a difficult task. LIDAR sensors do not provide color information of the perceived data, hence Point Cloud Data is often fused with different data collected from several sensors using eminent fusion algorithms. Due of their coarse resolutions compared to cameras, radar sensors are not often suited for object recognition applications. Bad climatic conditions also have an "}
{"doc581": "impact towards the functioning of the sensors. Researches are still in progress to reduce the existing challenges and improve the efficiency of the sensors.\n\n## 4. **Conclusion**\n\nThis study has analysed several sensor types based on their key characteristics such as mode of operation, data type collected, general specifications and also discusses the strengths and weakness associated with every category of the sensors. The study summarizes the general specifications of different sensors manufactured by leading vendors in the market. In addition to points discussed above, the study also briefs the mechanism involved in the sensors to collect the vehicular data and also investigates and exhibits a sample sensor data format released by leading automobile manufacturer Ford. This analyses guides and motivates the potential AV researchers to acquire a depth knowledge regarding the operation and the data format collected by different AV sensors. Using this prior knowledge the budding researchers can select appropriate sensor type suitable for their research and will also acquire knowledge to organize and process the sensor data efficiently."}
{"doc582": "In Proceedings of the 2020 31st Irish Signals and Systems Conference (ISSC), Letterkenny, Ireland, 11\u201312 June 2020.\n\n[4] Kuutti, S.; Bowden, R.; Jin, Y.; Barber, P.; Fallah, S. A Survey of Deep Learning Applications to Autonomous Vehicle Control. IEEE Trans. \n\nIntell. Transp. Syst. 2021, 22, 712\u2013733\n[5] Hu, J.-W.; Zheng, B.-Y.; Wang, C.; Zhao, C.-H.; Hou, X.-L.; Pan, Q.; Xu, Z. A Survey on multi-sensor fusion based obstacle detection for intelligent ground vehicles in off-road environments. Front. Inform. Technol. Electron. Eng. 2020, 21, 675\u2013692. [CrossRef] \n[6] Mobile Robot Sensors. Available online: http://www.robotiksistem.com/robot_sensors.html (accessed on 24 November 2020) [7] Gonzalez-de-Santos, P.; Fern\u00e1ndez, R.; Sep\u00falveda, D.; Navas, E.; Emmi, L.; Armada, M. Field Robots for Intelligent Farms\u2014 Inhering Features from Industry. Agronomy 2020, 10, 1638. [CrossRef] \n[8] Velasco-Hernandez, G.; Yeong, D.J.; Barry, J.; Walsh, J. Autonomous Driving Architectures, Perception and Data Fusion: A Review. In Proceedings of the 2020 IEEE 16th International Conference on Intelligent Computer Communication and Processing (ICCP 2020), ClujNapoca, Romania, 3\u20135 September 2020. "}
{"doc583": "[9] Giacalone, J.; Bourgeois, L.; Ancora, A. Challenges in aggregation of heterogeneous sensors of Autonomous Driving Systems. In Proceedings of the 2019 IEEE Sensors Applications Symposium (SAS), Sophia Antipolis, France, 11\u201313 March 2019. \n\n[10] Liu, X.; Baiocchi, O. A comparison of the definitions for smart sensors, smart objects and Things in IoT. In Proceedings of the 2016 IEEE \n7th Annual Information\n[11] World Health Organization. Global Status Report on Road Safety; WHO: Geneva, Switzerland, 2018; ISBN 978-9241565684. [12] Wojciechowicz, T. Smart Sensor vs Base Sensor\u2014what's the Difference? | Symmetry Blog. Available online: https: \n//www.semiconductorstore.com/blog/2018/Smart-Sensor-vs-Base-Sensor-Whats-the-Difference-Symmetry-Blog/3538/\\#: ~{}:text=By%20using%20a%20smart%20sensor,achieve%20on%20a%20base%20sensor (accessed on 26 November 2020).\n\n[13] Campbell, S.; O'Mahony, N.; Krpalcova, L.; Riordan, D.; Walsh, J.; Murphy, A.; Conor, R. Sensor Technology in Autonomous Vehicles: \nA review. In Proceedings of the 2018 29th Irish Signals and Systems Conference (ISSC), Belfast, UK, 21\u201322 June 2018."}
{"doc584": "[14] Shahian Jahromi, B.; Tulabandhula, T.; Cetin, S. Real-Time Hybrid Multi-Sensor Fusion Framework for Perception in Autonomous Vehicles. Sensors 2019\n[15] Joglekar, A.; Joshi, D.; Khemani, R.; Nair, S.; Sahare, S. Depth Estimation Using Monocular Camera. IJCSIT 2011, 2, 1758\u20131763. [16] Garg, R.; Wadhwa, N.; Ansari, S.; Barron, J.T. Learning Single Camera Depth Estimation using Dual-Pixels. arXiv 2019, arXiv:1904.05822v3.\n\n[17] Orbbec\u2014Intelligent computing for everyone everywhere. Available online: https://orbbec3d.com/ (accessed on 4 December 2020) [18] Cronin, C.; Conway, A.; Walsh, J. State-of-the-Art Review of Autonomous Intelligent Vehicles (AIV) Technologies for the Automotive and Manufacturing Industry. In Proceedings of the 2019 30th Irish Signals and System Conference (ISSC), Maynooth, Ireland, 17\u201318 June 2019.\n\n[19] Petit, F. The Beginnings of LiDAR\u2014A Time Travel Back in History. Available online: https://www.blickfeld.com/blog/thebeginnings-oflidar/\\#:~{}:text=Lidar%20technology%20emerged%20already%20in,such%20as%20autonomous%20driving%20today (December 2020)."}
{"doc585": "*Correspondence: b.padmaja@gmail.com 1 Department of Computer Science and Engineering, Institute of Aeronautical Engineering, Hyderabad, Telangana, India 2 Department of Mechanical Engineering, Vasavi College of Engineering, Hyderabad, Telangana, India 3 Engineering and Architecture Faculty, Nisantasi University, Istanbul, Turkey 4 Department of Computer Science and Engineering, G. Narayanamma Institute of Technology & Science (Autonomous), Hyderabad, Telangana, India 5 VNR Vignana Jyothi Institute of Engineering and Technology, Hyderabad, Telangana, India Autonomous cars have achieved exceptional growth in the automotive industry in the last century in terms of reliability, safety and afordability. Due to signifcant advancements in computing, communication and other technologies, today we are in the era of autonomous cars. A number of prototype models of autonomous cars have been tested covering several miles of test drives. Many prominent car manufacturers have started investing huge resources in this technology to make it commercialize in the near future years. But to achieve this goal still there are a number of technical and non-technical challenges that exist in terms of real-time implementation, consumer satisfaction, security and privacy concerns, policies and regulations. In summary, this survey paper presents a comprehensive and up-to-date overview of the latest developments in the feld of autonomous cars, including cutting-edge technologies, innovative applications, and testing. It addresses the key obstacles and challenges hindering the progress of autonomous car development, making it a valuable resource for anyone interested in understanding the current state of the art and future potential of autonomous cars.\n\nKeywords: Autonomous Cars, Driverless Cars, Safety, Privacy, Security\n\n## Introduction"}
{"doc586": "Autonomous cars are becoming more pragmatic from year to year as multi-national companies are racing ahead to produce intelligent vehicles. Te projected value for autonomous vehicles in the global market is at $615 Billion by 2026. According to the U.S. Department of Transportation's National Highway Trafc Safety Administration \n(NHTSA) fully automated or autonomous vehicles are \"those in which operation of the vehicle occurs without direct driver input to control the steering, acceleration, and braking and are designed so that the driver is not expected to constantly monitor the roadway while operating in self-driving mode.\". Te advancement and rise of autonomous cars are due to the signifcant research results obtained in the arenas of wireless and embedded systems, sensors, communication technologies, navigation, data acquisition, and analysis.\n\nTe initial thought of autonomous cars was initiated in the year 1920 with the \"phantom autos\" concept, which means a remote-control device, which was used to control the vehicle [1]. Later in the 1980s self-managed autonomous cars were developed. Further, \n\u00a9 The Author(s) 2023. **Open Access** This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creativecommons.org/licenses/by/4.0/.\n\nNavLab of Carnegie Mellon University contributed majorly in this feld by developing an Autonomous Land Vehicle (ALV) [2]. In a major breakthrough in 1987, the \"Prometheus project\" of Mercedes [3] gave the design of their frst automated car with the capability of tracking lanes. At that time, it was not completely autonomous, but it had the ability to automatically switch lanes. In the twenty-frst century, there is a huge demand for low-cost, high-performance autonomous cars. Tere is a fne line of diference between the two terminologies: the automated car and the autonomous car. Te term automated car refers to a vehicle with little human intervention, whereas the term autonomous car refers to a vehicle without any human intervention. Te autonomous car is a fully computer-controlled car which can instruct (guide) itself, make its own decisions, familiar with its surrounding without any human interference (intervention)."}
{"doc587": "Te concept of connected car technology is infuenced by autonomous cars [4] as both technologies are related to each other. Layered architectures are being proposed to address challenges faced due to the internet response time and the compatibility of various components that are being used in connected car technology [5]. Autonomous vehicles need to be connected to each other to improve overall autonomy when driving on the road. For example, the connected car works on a vehicular ad hoc network (VANET) technology and a dedicated short-range communication (DSRC) standard protocol [6] using which communication between vehicles is possible when they are in range. Te VANET [7] provides 2 types of applications; one regarding safety and the other one related to infotainments. In Autonomous cars, communication related security measures are stringent whereas in connected cars, security measures are moderately relaxed. \n\nIn the latest developments regarding the connected cars and VANET technologies, many multinational technology companies such as Google along with car manufacturers such as Tesla and Audi are working together and we see a solid collaboration among the technology companies and vehicle manufacturers to facilitate the development and design of cars.\n\nSimilarly, Microsoft has begun a coalition with Volvo and Toyota for building autonomous cars. Also, companies like NVidia have shown their dedication to making autonomous cars by launching NVidia Drive PX2, a dynamic supercomputer GPU and a deep learning-based computing platform for autonomous cars [8]. A few more Asian companies such as TATA, KIA, and Hyundai are funding in design, development, and research regarding automated cars. Also, the European auto market (Mercedes and BMW) is in the race for autonomous cars, and their goal is the development of full-fedged commercial versions by 2020. Many companies such as Volkswagen and the French PSA group are focusing on developing autonomous cars and they have started test-drive since 2016. "}
{"doc588": "Te PSA group brought together many car manufacturers together and drove their autonomous cars covering hundreds of kilometers from Paris to Amsterdam without any driver supervision in 2016 on a level-3 autonomy [9].\n\nIn the development of an autonomous system, there are several issues that must be addressed properly by the car manufacturing companies such as governments' regulations, consumer satisfaction, cost, reliability, and safety. Further, an important role is played by federal regulations in achieving novel technologies, and autonomous cars are no exemption from that. Te automatic transmission system plays a vital role in autonomous cars and these days as most automobiles use this technology due to its reduction in cost and improvement in quality and management of a feet of electric vehicles [10]. \n\nIn brief, this technology will consume some more time period till it is afordable, and reachable to customers in terms of cost and reliability. Tis paper highlights all the issues and challenges involved in the development of autonomous cars and conducts a survey on the latest autonomous car technologies that are trying to overcome these issues and challenges in an efcient way."}
{"doc589": "## Related Work\n\nTill today, a number of works have been done to explore multiple issues of autonomous car system [11\u201321]. But the majority of surveys focus only on certain aspects of the autonomous car and none of these surveys present a comprehensive (holistic) method towards autonomous car technology.\n\nCampbell et al. [11] discussed the approaches to challenges faced in urban environments by autonomous vehicles. Okuda et al. [12] did a thorough survey on the usage of advanced driving assistance (ADAS) in autonomous cars and the trends in the technology. Fagnant et al. [13] helped in surveying the required policies to make a nation ready for autonomous vehicles. Moreover, Bagloee et al. [14] focused on a few challenges that such diferent policies provide to autonomous cars. Other surveys regarding its functionalities include planning and motion control [15], long-term maps' constructions [18] \nand visual perception from both implementation and operators' perspectives [20, 21]. Furthermore, Abraham et al. [16] conducted a survey on consumer trust and also the preferences of the consumer on already available alternatives. Gupta et  al. [22] aimed to understand the public's attitude towards autonomous vehicles by analyzing large amounts of data from Twitter without the need for manual labeling. Te authors used advanced machine learning techniques to analyze the data and identify patterns in the public's perception of autonomous vehicles. Te study found that the majority of tweets about autonomous vehicles were positive in nature, but there were also concerns about safety and privacy. Joy et al. [17] looked over security and privacy issues in autonomous cars. Madhav et al. [23] presented a study on how to improve human trust in autonomous vehicles through the use of Explainable Artifcial Intelligence (XAI). Te authors focused on bridging the gap between artifcial decision-making and human trust by providing an explanation for the decisions taken by autonomous vehicles. Bairy et al. [24] \npresented a model for explaining the decision-making process of autonomous vehicles. "}
{"doc590": "Te model is based on integrated formal methods, which are mathematical methods used to model and verify systems. Te authors claim that providing explanations for the actions of autonomous vehicles is important for building trust in the technology of autonomous vehicles and for ensuring accountability in the event of an accident.\n\nParkinson et  al. [19] have expansively analyzed cyber threats in autonomous cars and the challenges they pose on the future of connected vehicles. Mazri et  al. [25] proposed a self-defense mechanism against security attacks for autonomous vehicles. \n\nTe mechanism is designed to protect against various types of cyberattacks, including those targeting the communication systems and decision-making processes of the vehicles. Te authors presented a detailed analysis of the potential vulnerabilities and risks of autonomous vehicles, and provide a comprehensive evaluation of the proposed mechanism using various simulation scenarios. Li et  al. [26] investigated the preferences of drivers when it comes to performing secondary tasks and how the vehicle's level of autonomy afects the driver's task engagement. Te study also explored the potential impact of secondary tasks on safety and comfort while driving. "}
{"doc591": "Te fndings of the study can be used to design interfaces and interactions that better support drivers' needs and preferences in highly autonomous vehicles.\n\nTe use of blockchain technology for training autonomous cars has been proposed by G. M. Gandhi et al. [27]. In this process, all connected cars can share their experience with each other. Blockchain can also be used to maintain energy transactions at charging stations [28]. Many recent surveys on autonomous cars have majorly focused on a few topics of autonomous cars. Table  1 presents a summary of related works. Figure 1 depicts the prediction of Autonomous vehicle implementation by 2060.\n\nTis ground-breaking survey delves deep into the latest developments in the exciting feld of autonomous cars. From cutting-edge technologies and innovative applications to in-depth simulations, this paper provides a comprehensive overview of the current state of the art. Additionally, it addresses the key obstacles and challenges that are hindering the progress of autonomous car development, including both technical and non-technical issues."}
{"doc592": "| Table 1 Summary of related works Year Reference no. Existing work 2010 [11] Test drive conducted in urban environment 2014 [12] Trends in Advanced Driving Assistance (ADAS) and its adaptation in autonomous cars 2015 [13] Barriers in autonomous car implementation and policy recommendations 2016 [14] Challenges to autonomous car policies 2016 [15] Planning and motion control for autonomous car in urban environment 2016 [16, 26] Driver Preferences and consumer trust in autonomous car 2017 [17] Location privacy and communication in connected and autonomous vehicles 2017 [18] Building long-term maps for diferent weather environment conditions in autonomous  cars 2017 [19] Cyber threats in connected and autonomous cars 2017 [20] Hardware implementation of visual perception algorithms in autonomous cars 2018 [21] Perception of autonomous cars from users' and pedestrians' perspective 2019 [27] AI integrated blockchain technology for training autonomous cars 2020 [28] Charging energy consumption costs of the autonomous car through blockchain technology 2020 [29] Redundancy Concept for Autonomous Vehicle Functions using Microservice Architecture 2020 [30] Knowledge architecture layer for map data in autonomous vehicles 2020 [31] Current status of development and technical challenges to overcome in self-driving  vehicles 2020 32] Security Evaluation Platform for Autonomous Driving 2021 [33] Combined Trajectory Planning and Tracking for Autonomous Vehicle Considering Driving  Styles 2022 [25] A mechanism to protect Autonomous Vehicles from Cyber threats that interfere with  crucial processes like the decision-making process or communication process 2023 [22, 23, 26,  Analysis of User preference and perspective on Autonomous Vehicles and Advanced traffc optimization methods for Autonomous Vehicles34\u201337]   |\n|---|\n\n![4_image_0.png](4_image_0.png)\n\n## Organization"}
{"doc593": "Organized in a clear and logical manner, this survey begins by summarizing existing works in the feld and outlining the diferent levels of autonomy according to the standards set by the Society of Automotive Engineers (SAE).\n\nTe heart of the paper is dedicated to exploring the underlying technology behind autonomous cars, including detailed descriptions of their design, components, and functionalities. Te benefts of autonomous cars are also discussed, along with a survey of state-of-the-art research outcomes.\n\nTe survey goes on to explore the implementation and design challenges that must be overcome in order to bring autonomous cars to reality. Finally, the paper concludes with a look at the technology and challenges for autonomous car deployment, making it a must-read for anyone interested in this rapidly evolving feld."}
{"doc594": "Te autonomous car has been in the spotlight during the last few decades and prototype models have been improved by various car manufacturers. But, the commercial actualization of autonomous cars is a major challenge. As a basic task, gearing of every \n\n| autonomy as per the standard set by the Society of Automotive Engineers (SAE) Reference No Level Name Technologies Sensors - 0 Driver Only - \u2013 [3, 39] 1 Assisted Active Cruise Control (ACC) Lane Departure Warning System  (LDWS) Ultrasonic Sensor Long Range Radar (LRR) Camera [39] 2 Partial Automation Lane Keep Assist (LKA) All Sensors from Level - 1 Park Assist (PA) Short Range Radar (SRR) [9, 39] 3 Conditional Automation Automatic Emergency Braking  (AEB) Driver Monitoring (DM) Trafc Jam Assist (TJA) Dead Reckoning (DR) All Sensors from Level - 2 LIDAR Long Distance Camera Stereo Camera Thermal Camera [39] 4 High Automation Sensor Fusion All Sensors from Level\u20143 [39] 5 Full Automation Automatic Pilot (AP) All Sensors from Level\u20143 The SAE has defned six levels of autonomy, ranging from Level 0 (no automation) to Level 5 (fully autonomous). The table  presents each level along with a brief description of the level of automation provided by the vehicle, and examples of  features that are commonly found at that level. The table is a useful tool for understanding the diferent levels of autonomy   |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\nThe SAE has defned six levels of autonomy, ranging from Level 0 (no automation) to Level 5 (fully autonomous). The table "}
{"doc595": "![5_image_0.png](5_image_0.png) presents each level along with a brief description of the level of automation provided by the vehicle, and examples of features that are commonly found at that level. The table is a useful tool for understanding the diferent levels of autonomy and the capabilities of autonomous vehicles at each level. It can be used as a reference for comparing diferent autonomous vehicles based on their level of autonomy and understanding the current state of the technology\n\nautonomous car is performed with numerous actuators and sensors that produce vast amounts of data which must be handled and analyzed to take decisions on time. Te amount of data that the car must handle depends on the levels of autonomy [38] as shown in Table 2. Te key point is the requirement of various sensors and actuators to function autonomously, so that the car should foresee, decide and maneuver cautiously according to some strategy. A number of fundamental characteristics of autonomous car design are outlined in this section. Figure 2 depicts a number of elevated functional components of a typical autonomous car.\n\nTe functional architecture of an autonomous car is a layered structure which contains data acquisition, data processing and actuation. Data acquisition is performed by the hardware components, such as sensors, radars, cameras, LIDAR, and transceivers \n[40]. Te collected data is processed by a central computer system, which is later implemented by the decision-support system (DSS). Te DSS activates the autonomous car and the situational awareness is actualized through both short- and long-range imaging devices [41]. Figure 3 shows the system architecture of the autonomous car, where it shows the areas covered by diferent components in the car design. Diferent ranges of situational awareness vary from application to application and it is achieved through multiple components. For instance, prevention of front and rear bumper collisions is done through infrared devices, whereas short-range radars are used for object detection, lane-change cautioning, and trafc view. Equipping autonomous cars with a series of cameras for the surrounding views and LIDAR helps in collision avoidance and emergency brakes. Long-range radars help in cooperative cruise control and long-range traffc view construction. Altogether the aforementioned components are networked and work frmly with each other, as shown in Fig. 2."}
{"doc596": "For movement of an autonomous car from one point A to B, the car performs a number of important steps in an iterative manner until it reaches its destination such as Perceive and aware about its surrounding environment, Path planning and navigation and Controlled movements on the road [42].\n\nAfter perceiving its surrounding environment, it makes path planning along with its destination information and then starts navigating to reach the destination. A number of controlled movements are exercised for a smooth, safe ride on the road with the help of actuators and sensors [43]. Electronic Control Units (ECUs) control most of the components electronically. ECUs communicate with each other and with the decision support system through the controller area network (CAN) bus inside each car. During a drive, the autonomous car exhibits a number of manoeuvres which needs both software/hardware support, extensive coordination, and data sharing among diferent components of the car.\n\n![6_image_0.png](6_image_0.png)"}
{"doc597": "Every year many millions of people lost their lives in road accidents according to the National Highway Trafc Safety Administration (NHTSA). More than 90% of accidents \n[44] happen due to human errors and these errors are caused by various factors such as carelessness, aggressiveness, intoxication and distraction. So, it's essential to have an alternative and safer mechanism like autonomous driving cars to eliminate human errors and save lives.\n\nDaniel Zelle et al. [32] developed a security evaluation platform for autonomous driving \n(SPEAD) to enable researchers to develop, implement and evaluate new security solutions for autonomous vehicles. SPEAD allows us to model realistic autonomous vehicle architectures and test their security mechanisms. Tere is another aspect of safety that is how to protect the car from thieves. Due to high-end on-board sensors, recognition of the car owner is done by the car itself and it sends the owner an alert in case of any unwanted situation. Unlike ordinary cars, autonomous cars do not require keys, but they operate with fnger prints, retina scan and voice recognition software. It is also equipped with fnger-print enabled door-lock system to provide more security.\n\nMobility-as-a-Service (MaaS) benefts the customers by saving multiple resources including money, time, and space. Car sharing and car-pooling are two popular applications among customers today. With the advent of autonomous cars, these applications will become more efective by making use of car resources more efciently. Tese applications create economic benefts, and also reduce air pollution produced by vehicles in urban areas. Tis also generates huge business opportunities for the customers. In future, autonomous cars will transform taxi and car rental business. Tere is no longer requirement of drivers in taxis and rental cars, therefore it will reduce the cost and increase the revenue of owners. "}
{"doc598": "In autonomous cars, car sharing and car-pooling can be a major advantage, hence it will increment per-vehicle occupancy and decrement the number of vehicles on the road, thereby improving the trafc conditions. Inter-vehicle distance is strictly followed in autonomous cars to improve passenger safety; hence in turn it reduces road trafc. Tese cars follow trafc rules more precisely, thereby condensing the requirement for more trafc personnel on the road. Fuel efciency is also improved by automatically choosing the best and shortest path from source to destination [45]. Hence there is also a decrease in air pollution.\n\nBo Liu et al. [29] proposed a redundancy concept for autonomous vehicle functions using microservice architecture in which vehicle-vehicle and cloud-vehicle communication ensure that important vehicle functions keep executing even in the case of a hardware failure. Tese cars also make use of a fuel-efcient mode through programming by eliminating unnecessary braking situations on the road. One such example is regenerative-braking [46] in electric autonomous vehicles which uses the kinetic energy of the car to convert it into electrical energy (fuel) until the car stops naturally. Qiao et al. [36] \nproposed a hybrid model for trafc assignment and control that combines the strengths of both traditional trafc assignment models and control methods for autonomous vehicles. Te model uses a combination of trafc simulation, machine learning, and optimization techniques to assign trafc and control the movement of autonomous vehicles in a given road network. Te authors evaluated the performance of the proposed model using real-world trafc data and show that it can improve the overall efciency and safety of trafc fow in comparison to traditional methods.\n\n## Autonomous Parking"}
{"doc599": "In metropolitan cities, there are a number of issues related to vehicle parking such as getting parking space in peak hours, increased population and maintaining inter-vehicle distance in parking slots. Te advantage of autonomous cars is they can park themselves even in a narrow available parking slot, which is very difcult for a driver to park a car manually. Marvy Badr Monir Mansour et al. [47] implemented a project to demonstrate autonomous parallel car parking that can be used efciently in metropolitan cities. \n\nBaramee Tunyapoo et al. [48] proposed a simulation framework for autonomous-car parking for moderate complexity scenarios. Shiva Raj Pokhrel et al. [49] developed (and evaluated) an experience-driven, secure and privacy-aware framework of parking reservations for automated cars. Since autonomous-cars can communicate with each other, they can reduce trafc congestion by coordinating their movement on the road.\n\n## Consumer\u2011Centric Experience"}
{"doc600": "In autonomous cars passengers and drivers can sit, relax and enjoy the ride. Tey can also simultaneously do their personal work or utilize the car's entertainment system [50]. \n\nWhen the autonomous car is paired with a smart phone then a passenger can command the car to perform some important tasks automatically like picking up children from school, picking up or dropping someone at the airport. Tese kinds of sophisticated features called \"*Summon*\" of autonomous cars are introduced by Tesla Company in its high-end models [51]. Using the \"*Summon\"* application, the car owner can instruct the car to go to the designated parking place even to the basement of the building.\n\nFurther research is going on to understand various driving patterns by analysing the behaviour of the drivers by considering drivers' age, gender, driving experience, personality, emotion, and history of accidents [52]. A number of features of autonomous cars can be customized based on the human behaviour. For example, overtaking and speed while driving depends on gender, age, emotion etc. Young people drive faster than elders, whereas female drivers drive more cautiously. Similarly, people with families and kids drive more carefully than others. So, during autonomous car customization, one should take these factors into consideration. In future, autonomous cars will lead to attract the developers to build a number of customer-driven applications, where customers can personalize their travel experience according to their choice of speed, in-car entertainment, and level of risk Travelling in autonomous vehicles also increases productivity as the user can focus on work instead of driving the vehicle during transit."}
{"doc601": "## Technology Behind Autonomous Cars\n\nIn this section, various technological researches conducted so far in the area of autonomous cars are presented. Tis section also covers the software components and algorithms used in this technology. Broggi et al. [53] discussed regarding a number of tests performed on driverless cars in diferent scenarios such as roads with less to heavy trafc during 1990\u20132013. Te outcomes witnessed changes in the behaviours of the drivers in diferent environments such as trafc lights, freeway junctions, pedestrian crossing. Tis car test was named PROUD (Public Road Urban Driverless) and it was one of the biggest achievements in autonomous car technology. PROUD resulted in a few important observations such as precise route maps, efcient learning and perception mechanism. Jo et al. [54, 55] concentrated on the generalization of the autonomous car development procedure independent of any specifc environment. FlexRay was utilized as a communication protocol and software platform to increase the system performance. Traditionally CAN (Controller Area Network) technology is used to communicate among diferent ECUs (Electronic Control Unit) in normal cars. But this technology was not suitable for autonomous cars due to its low speed and vulnerability to diferent attacks [56, 57]. \n\nFlexRay is a faster and more efcient technology, but it's expensive. Some technologies used in fully automated cars are Lane Keep Assist (LKA), Park Assist (PA), Automatic Emergency Braking (AEB), Driver Monitoring (DM), Trafc Jam Assist (TJA), Dead Reckoning (DR) [38]. Most of these rely on sensor data and processing of this sensor data using machine learning/deep learning algorithms."}
{"doc602": "## Computer Vision\n\nAutonomous cars require two essential and critical features such as object detection and computer vision. Using object detection techniques, autonomous cars should see the road and detect the object in the road. Tese two important features along with other modules help to drive safely on the road by avoiding unwanted situations. Janai et al. [58] conducted an accurate survey on computer vision algorithms such as perception, object detection and tracking, and motion planning used in autonomous cars. But still there are a number of unpredictable scenarios creating challenges for autonomous cars. Consequently, the success of computer vision algorithms will presumably take longer time. \n\nIn addition to these algorithms, the decision support system has an important role in analysing the behaviour, learning mechanism of drivers. Also, AI has an important part in the prediction and perception aspects of autonomous cars. Shi et al. [20] studied on computer vision algorithms used for lane detection, object detection and surface detection experimented with GPU (Graphics Processing Unit), FPGA (Field-programmable Gate Array) and ASIC (Application-specifc Integrated Circuit) Among these, the performance of ASICs is better than GPUs and FPGAs."}
{"doc603": "Computer vision is a boundless feld of study, where autonomous cars use only object detection and motion estimation algorithms. Tese cars detect both static and dynamic objects and accurate object detection is always a challenging task due to multiple factors like shadows, identical objects, background lighting, and the size of the object. Te detection algorithms accept these multiple factors into consideration and perform object detection with diferent sensors. Recent Autonomous cars use sensor fusion mechanisms to combine diferent types of sensors to detect day/night time, living/non-living organisms [59, 60]. Sensor-fusion based object detection techniques have more accuracy than traditional object detection methods. Chen et al. [61] proposed a CNN (Convolutional Neural Network) deep learning approach to detect 3D objects with a single camera, which takes generated date in LIDAR and images as input and predicts 3-D representation of that data. Tis method frst detects objects using dissimilar features and then improves it for the identifcation of true objects. Ten with the help of sensors data, it categorizes the objects into diferent types. Tis process of categorization is termed as pixel level semantic segmentation [62]. To support semantic segmentation, shallow and DL approaches are used for classifcation and prediction [62\u201364]. Te approaches used in autonomous cars for object detection, semantic segmentation, and classifcation give improved accuracy, but have some drawbacks such as algorithm complexity, computational overhead, latency and complex design features. Terefore, compared to the shallow learning approach, DL (deep learning) approaches (such as auto-encoders and CNN) are preferred for object detection and classifcation due to its automatic feature selection process [65, 66]. DL-based approaches are also used in the construction of 3D \nimages from the 2D image which are used for motion planning and actuation process in autonomous cars [67, 68].\n\n## Deep And Machine Learning Approaches In Autonomous Cars\n\nAI, ML and DL techniques are essential for autonomous cars as the object behaviour and surrounding environment are unpredictable. ML and DL techniques are used by most computer vision mechanisms. A deep Neural Network (DNN) approach learns features automatically from large data sets. Perception is an important aspect of autonomous cars and analysis of huge data collected from sensors for decision making is done by deep learning techniques. Tian et al. [69] introduced a DNN model called \"*DeepTest*\" to assess the behaviour of autonomous cars and found erroneous behaviour multiple times during testing when the car comes under erratic trafc and environmental conditions. "}
{"doc604": "Tese test results were not satisfactory for the current challenges and increased the need for more meticulous measures for the accurate functioning of autonomous cars. Chen et  al. [70] used a novel mechanism to learn automatically the features from an image to calculate afordance in autonomous cars. Chen computed afordance for each driving action, as a substitute for individual driving scenes, it depends on multiple factors like static and dynamic objects on the road, pedestrian and vegetation Duanfeng Chu et al. [33] proposed a combined trajectory planning and tracking algorithm for autonomous vehicle control. Muhammad Mobaidul Islam et al. [71] proposed an efcient training strategy for pedestrian detection by occlusion handling by classifying body parts. \n\nMohammed Ikhlayel et al. [72] made a car prototype for trafc sign detection using convolutional neural network (CNN). Tere are two types of perceptions used in autonomous cars namely mediated perceptron and behaviour refex mode. In mediated perceptron, current surrounding is not known and in behaviour refex mode, deep neural networks are used to train the system based on human behaviour [70, 73]. Furthermore, Chen et al. also proposed another direct perception technique which is based on CNN. Tis system systematically learns mapping from a captured image to various features related to driving actions. TORCS, an open-source car racing simulator was used to test the car. Laddha et al. [74] proposed an algorithm to identify features from road images required for autonomous driving. In this algorithm an automated labelled training dataset was taken to make the process more scalable. It takes multiple sensor inputs which are mounted on vehicles including localization and camera sensors. Tis algorithm efectively utilized CNN to detect obstacles along the way with a moderately good accuracy. Dairi et al. [74] introduced another DL technique to identify obstacles on the road based on using a hybrid deep autoencoder and stereovision. More than 98% of accuracy was shown on diferent datasets by this method and it outperformed the DBN (Deep Belief Network) and SDA (Stacked Auto-encoders). Tam et  al. [35] proposed a probability-based artifcial potential feld method for autonomous vehicles to avoid uncertain obstacles. Te authors argued that this method is more efective in avoiding uncertain obstacles than traditional methods, and that it can improve the safety of autonomous vehicles.\n\nQizwini et  al. [73] made a system and trained with 5 afordance parameters and tested by simulating with some realistic assumptions. XU et al. [75] used a Long ShortTerm Memory Fully Convolutional Network (LSTM-FCN) by training the multi-modal driving-behaviours to predict future ego-motion problem in autonomous driving. Te LSTM-FCN model was trained by a large video dataset of vehicular actions by the authors [76]. Te author addressed the problems of traditional end-to-end learning by using a very large crowd-sourced dataset and the learning results were promising. Similar to this model, a number of popular DL architectures such as VGG-16, Google LeNet, AlexNet and ResNet are used accurately in semantic segmentation and scene understanding in autonomous cars [77]. Among these models, AlexNet achieved an accuracy of 84.6% and VGG achieved an accuracy of 92.7%, Google LeNet 93.3% and ResNet with 96.4% respectively. So, DL architectures played important roles in the multiple aspects of autonomous cars."}
{"doc605": "unknown situations and environments are dealt with by autonomous cars and it needs ML, DL, AI techniques. Tese ML/DL techniques are data-intensive and these data are collected using various sensors placed within the car. Terefore, it follows a series of procedures such as data acquisition, data processing, communication and controlling among diferent modules inside the car and its surroundings. In addition to that it has to take autonomous decisions based on the circumstances and this feature requires a lot of interaction data with neighbours, infrastructure and the Internet. Communication among diferent modules and the environment is a vital function in autonomous cars and this data helps in sensor data analytics.\n\nAutonomous cars deal with a huge number of sensors which generates a huge volume of data and these data are processed to get maximum utilization of it. *Sensor Fusion* is one of the commonly used techniques to gather data from multiple sensors intelligently to assist in the decision support systems. A number of algorithms have been proposed to deal with heterogeneous data used in autonomous cars. Oliveria et al. [78] proposed a more accurate technique to visualize a scene from 3D data gathered from sensors by using large scale polygonal primitives. Also, a visual scene may change constantly when obstacles come on the road, so there is a need for a stable mechanism to deal with unanticipated environments. So, the reconstructed scene should be calibrated continuously with the current scene to increase the efciency as always, the new data from sensors is processed. Polygonal primitives-based scene reconstruction algorithms are incremental in nature and detection of polygon and reconstruction of new scene is performed using old data. Terefore, time required for detecting these polygons increases with an increase in the number of polygons, hence there is an increase in efciency.\n\nIdentifying the road is one of the important aspects in autonomous cars and it is done using diferent sensors, camera and LIDAR (Fig.  4). Xiao et  al. [79] applied a Hybrid Conditional Random Field (HCRF) to overcome the disadvantages of LIDAR and camera sensors. Te proposed technique used a multi-modal approach and applied a binary labelling mechanism for separating road and background. Tis approach showed a maximum degree of accuracy then the existing point-wise CRF. Jo et al. [54, 55] used a number of existing functionalities along with sensor fusion algorithms that deal with sensors used inside the car, communication systems and also stressed upon communication of autonomous cars with the outside world by implementing diferent algorithms and schemes to establish communication with other entities. Tere exists efcient coupling between connected vehicles and autonomous cars as they are orthogonal to each other and reinforce towards making of intelligent transportation system. Vehicle-to-vehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication technologies are popularly used to exchange their mobility data in platooning and cooperative trafc information system applications. Hobert et  al. [80] worked on applications of cooperative autonomous cars such as convoy management, intersection management, low delay, cooperative sensing and enhanced reliability. It also helps in sharing the information about surrounding environment to operate more efciently, timely and safely."}
{"doc606": "Peng et al. [81] scrutinized the presentation of IEEE 802.11p protocol and considered inter-platoon communication for diferent platoons in terms of network performance, delay, packet loss and other parameters. Platoon management is an important task in platoon communication, but it is LTE-driven to reduce the communication delay in autonomous cars. In recent years, transmitters and receivers are fxed in the front and back lights of the cars which uses visible light communication (VLC) technology, but it is in its initial stage and structured channel modelling is mandatory to meet the requirements of autonomous cars. VLC technology is also afected by the massive amount of data and network bandwidth. So numerous researchers are working on fnding new techniques to reach out the demands of bandwidth requirement. Chang et al. [82] experimented on cooperative motion planning to communicate with pedestrians called \"Eyes\" on car, which means how the autonomous car makes an eye contact with the walker and evaluate the intention of the walker while crossing the road. Te author tested with the real-world users and obtained the results of 86.6% in deciding intention of the users while crossing the road. It is observed that the real users made faster decision around 0.287 seconds then no eyes on the car.\n\nSensors used in an autonomous- car depends on its autonomy level as per the standards of SAE (table \u20132). Tere are a total of 6 levels of autonomy ranging from 0-5. Level 0 (Driver only) has no automation whereas level 5 refers to full autonomy in which the car performs all the Dynamic Driving Tasks (DDT) and also achieves the minimum risk condition (DDT fallback) [38]. A wide range of sensors are used until level 3 of autonomy, from level 4 sensors remain the same but the algorithms and processing of sensor fusion data achieve more autonomy. Te U.S. Department of Transportation's National Highway Trafc Safety Administration (NHTSA) has adopted the standards set by the Society of Automotive Engineers (SAE) in the September of 2016.\n\nAutonomous vehicle control (AVC) module is an important feature in autonomous cars that controls the behaviour and environments in various situations by controlling the hardware level component. AVC module is responsible for trajectory during motion by handling both predicted and unforeseen circumstances in autonomous cars. "}
{"doc607": "Tis module is also used in steering wheels to calculate the steering angle for the next action based on the control algorithm. Tis module is also responsible for speed control, distance travelled and emergency brakes. Apart from this module, the predictive control module is also used in autonomous cars to optimize the predicted motion for inter-vehicular communications. Immense amount of real-time data is required to communicate with neighbours and surroundings to stabilize the operations of autonomous cars. Autonomous cars need a powerful control mechanism to avoid transmission delays and communication errors that arise due to wireless communication. Zeng et  al. [83] suggested an integrated control mechanism, where the communication delays were analysed to fnd the stability in autonomous platoons. Te authors suggested to use the adaptive control mechanism to improve the reliability of the communication mechanism. Te traditional control system is quite diferent then the control mechanism used in autonomous cars. Te central control mechanism of autonomous cars is context oriented and uses adaptive control system to act immediately as the information of the context is highly required. Liu et al. [84] suggested a joint control communication mechanism to understand diferent road situations in autonomous cars.\n\n## Autonomous Decision Making\n\nAutonomous decision making is a complex task in autonomous cars and certain cars are known as \"ego-vehicles\" which focus only on their local surroundings, current speed, direction and destination. But the communication mechanism must be strong enough in autonomous cars, so the concepts of \"ego-vehicles\" are fading away. So, there is a need of diferent prediction algorithms which gives predictions of high probability. And the fnal decision is a combined decision by taking the inputs from sensory data and other modules. But there is a number of other challenges related to environment, noise and limitations in the sensor data, mysterious state of neighbours. Terefore, autonomous cars should have accurate information about the neighbours in order to make predictions with high probability. But sometimes the neighbour information is neither available in public nor shared and this restriction causes serious problems for doing predictions and taking decisions accurately. Mockery of human behaviour in autonomous cars is very difcult, therefore the decision-making process is challenging. Numerous factors afect the decision-making process in autonomous cars such as behaviour of the car, prediction and perception, information about the neighbours, data processing done by sensors, calibration of equipment's A number of present decision-making mechanisms are based on machine/deep learning, AI (Artifcial Intelligence), Markov decision process. "}
{"doc608": "Hubmann et al. [85] highlighted the decision-making process for uncertain prediction of the surrounding vehicles from the sensor data. Many such AI based decision making approaches have been discussed by Claussmann et al. [86]. Several external factors impact the decision-making process in autonomous cars and these issues are addressed in a comprehensive way.\n\nIssues such as ego-motion and inter-vehicle communication play a key role in crowd sensing and perception of neighbour's behaviour. For commercializing autonomous cars in future, a major role will be played by connected car technology and it is seen today in many high-end cars [87]. Te cloud infrastructure connected to the autonomous-car can also provide more computational resources for the car to execute its software processing functions, ensuring the car functions even in case of a hardware failure. Cloud infrastructure can also provide many new applications including entertainment [88]. But few issues arise while using the cloud services such as communication delay between cloud infrastructure and autonomous car. Any kind of delay can't be tolerated by the decision-making module of autonomous cars due to cloud infrastructure, hence mostly decision-making is done locally in real-time environments. Similarly, fog computing techniques are also implemented which gives low delays in providing real-time services [89].\n\n## Testing Of Autonomous Cars In Real\u2011Time"}
{"doc609": "In today's scenario, numerous tests of autonomous cars have been carried out to evaluate its performance. Campbell et al. [11] took part in the DARPA grand challenge (DGC) \nand conducted 3 rounds of test for autonomous cars and documented the results from those tests. Campbell tried to incorporate the autonomous car mechanism in a regular car and tested it without any human intervention. In DGC challenge a route network defnition fle (RNDF) was given for self-driving using a road map to follow [90]. \n\nTis challenge helped Campbell to understand the problems and issues that need to be addressed and how to commercialize the vehicle. Endsley et  al. [91] considered Tesla autonomous car Model S for a period of 6 months and analysed diferent issues related to situation awareness, response to unanticipated circumstances on the road He also studied a number of other parameters related to consumer behaviour, trust, complexity, interface design and feedback from the customers. Broggi et al. [92] invented a BRAiVE (Brain Drive) system to conduct tests on autonomous car at Intelligent Systems and Artifcial Vision Lab. Broggi's test accumulated a huge amount of test data of real-time driving that is now used for upgrading the existing autonomous cars. Further Broggi tested autonomous cars on streets and he named his project as PROUD. Jo et al. [54, 55] designed an autonomous car and participated in South Korea in 2012. Jo developed the architecture of the car and experimented in various environments.\n\nAUTOSTAR [93] is one of the open standard architectures popularly used in many autonomous cars, but it has its limitations due to high cost and high complexity to implement. Later AUTOSTAR-lite came into market as a replacement to AUTOSTAR. "}
{"doc610": "Jo tried a distributed architecture instead of a centralized architecture to reduce the complexity and to group the functional components. Tis architecture also increased the efciency and performance through parallel computations. A number of automotive industries along with academia experimented and \"*Drive Me*\" is one of the special projects done by Volvo in autonomous cars. Tis project in Sweden collected information from 100 consumers about their daily routines, driving behaviour, their preferences and other important aspects of driving. Tis consumer data helped researchers to improve the commercial autonomous cars. Blockchain technology can also be used for shared training of autonomous-cars where cars can share their experience over a blockchain network [27]. Blockchain technology can also be used to charge electric vehicles with no human intervention as shown in [28] with the help of a public ledger recording each transaction.\n\n## Design And Implementation Issues\n\nA number of factors such as safety, robustness, hardware / software designs, customer behaviour will decide the future of autonomous cars. And also, these cars need to be designed with utmost precision, safety and reliability features [94]. Te major components of autonomous cars are LIDAR, sensors, radar, positioning systems and various optimized software's. A number of issues have direct impact on the autonomous car industry such as cost, maps, software complexity and simulation. First, the software/\nhardware cost is a major barrier in manufacturing autonomous cars. LIDAR is one of the expensive products in the car. Second, the maps used in autonomous cars contain a number of road details and it difers from the normal maps generated by the GPS systems. Memory requirements and processing power are enormous to store all the road details. Te log fles generated from these cars also requires memory to store and it contains detailed information about localization and mapping. Tird, the software program of the car decides the various operations of the car such as move, stop, and lane change and overtake. So, a highly accurate and reliable software program is required which takes inputs from diferent sensors [95]. Te huge data acquired from the sensors, environment and its surroundings create a real challenge for the autonomous car [96]. Te algorithms processing this huge amount of sensor data should be efcient as well. An example stated in [38] is the use of stereo-camera over normal camera. A stereo-camera can take 3D images that map the environment accurately. Even though the data generated by stereo-camera is huge, it takes less time to process this data then conventional image processing."}
{"doc611": "Autonomous cars still need to be tested in adverse conditions such as mist, rainstorms, night-time and densely populated cities. Te software used in autonomous cars also records the driving patterns and behaviours such as obstacle management, pedestrians crossing, and overtaking. Simulation technology is becoming the self-driving technology for autonomous car designers and Google is one among the top leading company in the market along with hardware giants like Nvidia announcing the launch of support hardware for autonomous cars [8]. To check the software reliability and safety, large-scale simulation is necessary. After simulation it is tested on real hardware with all built-in functionalities. Simulation tools developed specifcally for the requirement of autonomous vehicles are utilized to simulate diverse aspects such as path planning and testing, mobility dynamics, fuel economy in urban scenarios [97]. Sajjad et al. [49] proposed an efcient and scalable simulation model for autonomous vehicles with economical hardware. A reduced reality gap for testing autonomous vehicles has been proposed by Patel et al. [98]. Te simulation tool designed by Buzdugan et al. [34] provides a realistic environment for students to learn about the behaviour of autonomous vehicles and how they interact with their surroundings. Te authors also evaluated the efectiveness of the tool in teaching the behaviour of autonomous vehicles. Te study can help in the development of new methods of teaching autonomous vehicles and to improve the understanding of the behaviour of autonomous vehicles. When such simulation and testing models are combined, the industry can use various models for training autonomous cars both efciently accurately.\n\n## Challenges For Autonomous Car Deployment\n\nA number of challenges still exist and it must be resolved by various stakeholders, manufacturers, developers, academicians, policy makers and designers [99]. Tese challenges can be categorized into technical, non-technical, social and policy related. "}
{"doc612": "A number of technical challenges arise during car deployment such as validation and testing, hardware / software resources, quality, safety, privacy and security. Validation and testing are time consuming process and it varies from model to model and it also \n\n![17_image_0.png](17_image_0.png)\n\ndepends on the degree of sophistication. Diferent of testing techniques are used such as simple bug fxing to quality testing. A number of safety and mission-critical testing are performed to fne tune the performance of autonomous cars and to check whether the rigorous necessities are met or not. Koopman et al. conducted widespread overview of the validation and testing trials for autonomous cars when deployed at scale \n[100]. Te author applied ISO 26262 development V process which maps each design of autonomous vehicles to an appropriate testing method while focusing more on specifc advanced challenges and divided the work into 3 phases namely phased deployment, monitor architecture, and fault inoculation. Tis testing framework is popularly used in in automotive industry for validation and testing and it checks the specifc requirements of vehicles minutely and test all expected functionalities. "}
{"doc613": "Autonomous cars have specifc set of complex requirements, and it is diferent from traditional validation and testing process. Te author also discussed the challenges in the testing of autonomous vehicles as vehicle level testing is not thorough enough to ensure systems with ultimate dependencies which, in this case, are the various technologies employed in autonomous cars discussed in the prior sections. Younang et al. \n\n[37] examined how the concerns of users and government policies regarding autonomous vehicles compare and contrast. Tey analysed data from surveys and government policy documents to understand user's concerns and government policies on autonomous vehicles (Fig. 5).\n\nSafety and reliability are the second core aspects to be addressed in autonomous cars. Te degree of reliability can be identifed to some extent by statistical analysis by using a huge database of distance travelled by the car. Safety is one of the major concerns for autonomous cars, so a number of new methods are required for measuring the reliability parameter. Similarly, legislation is another prime challenge in autonomous cars. Safety is an important and interdisciplinary issue, so a lot amount time and money are spent on safety measures of the car [101]."}
{"doc614": "Software quality is third aspect in autonomous cars as the car is run by complex and sophisticated software. Validation and testing of these software's play a major role due to mission-critical and complex software system used by these cars. Tese software's responds to a number of unanticipated situations and in all situations, it must be fail-safe.\n\nComputational resource requirement is the fourth aspect in autonomous cars due to a number of high-resolution cameras used for monitoring various operations of the car. Apart from that a number of sensors are used for object recognition such as LIDAR. So autonomous cars require GPU processors with FPGA (feld-programmable gate array) \nand SoC (system on a chip) to meet the functional and operational requirements of the car. Optionally these can be connected to a cloud infrastructure which provides the necessary computational power as a service. But in case of a connection timeout, it can cause problems. A number of sophisticated algorithms are used for data processing and provide an efcient and reliable system.\n\nSecurity requirement is the ffth and one of the important aspects in autonomous cars. "}
{"doc615": "Te data shared between various components and among other vehicles and infrastructure must be kept safe and inaccessible to unauthorized people. All type of communication information must be safe from hackers, so a number of cryptographic techniques are used to provide internal security and privacy.\n\n## Conclusion\n\nAutomotive industry is fast changing and a number of auto maker's companies are now making autonomous cars. A number of new business opportunities are there for car makers along with few challenges such as safety for car and passengers. In this paper, we discussed the current solutions regarding design, operation issues, and forthcoming challenges. A number of major benefts and technical challenges are thoroughly discussed. A number of research areas to be focussed for autonomous cars have been outlined such as computer vision using deep learning, decision-making using machine learning, navigation, planning, control, perception, blockchain technology, cloud infrastructure integration, A number of real-life tests conducted so far are also outlined on autonomous cars. Tis work has focussed on the recent technologies behind autonomous cars like AI decision-making-based path planning, layered architectures, cyber threat protection mechanism, use of blockchain for transaction management and shared training of autonomous vehicles and also provides a valuable reference to the feld of autonomous cars. Tis paper focussed on a number of technical and non-technical issues that exist in the design and implementation, including the analysis of the consumer and driver preferences, of autonomous cars. A number of issues were reviewed regarding object tracking and detection, data acquisition from sensors, safety and reliability, decision support, security, simulation models and privacy. Even though notable results are achieved in the research and development of autonomous cars and now that we have entered the commercialization phase, but still this feld still has several areas of research like user experience and precautions and hardware for efcient decision making on the vehicle. Te future of autonomous cars is promising, but further research and development is needed to overcome the remaining obstacles like autonomous vehicle testing for component compatibility, accurate simulations, large scale training and to fully realize their potential. Te paper concludes with a call for further research in the feld of autonomous cars to address the remaining technical and non-technical issues and to maximize the potential and adoption of autonomous cars in the future."}
{"doc616": "Acknowledgements We would like to acknowledge Prof. G Chandrasekhar, Prof. E Krishna Rao Patro and Mr. Habeeb for their assistance in editing and proofreading the paper. Author's Contributions BP has made substantial contributions towards literature survey and compiling the contents of this paper. CHVKNSNM has performed the analysis and manuscript preparation. NV has given signifcant contributions in writing and arranging the contents in proper order. MMB contributed to data collection and analysis on tools and techniques. All authors read and approved the fnal manuscript. Authors' information Dr. B Padmaja is currently working as an Associate Professor and Head, CSE (Artifcial Intelligence and Machine Learning), Institute of Aeronautical Engineering, Hyderabad, Telangana, India. She has received her B.Tech from North Eastern Regional Institute of Science and Technology (NERIST), Arunachal Pradesh, India in May 2001. She completed her M.Tech from School of IT, JNTUH, and Hyderabad, India in 2010. She was awarded the Ph.D. degree in Computer Science and Engineering in 2021 by JNTUH, Hyderabad. She has vast teaching and research experience of 20 years. She has published more than 20 research papers in various International journals and presented more than 15 papers in various International conferences. She is also a reviewer for 08 International journals. Her current areas of research interest include Machine Learning, Deep Learning, Computer Vision, and Social Network Analysis. She is a life member of ISTE, CSI, IAENG and CSTA. Prof. Dr. CH V K N S N Moorthy is working as Director R&D, Vasavi College of Engineering, Hyderabad, Telangana, India. He is a multidisciplinary and cross domain researcher having experience in the felds of Computer Science and Mechanical Engineering. He received Master of Technology both in the felds of Computer Science Engineering and Heat Power Refrigeration & Air Conditioning. He received Doctoral degree for research in the feld of Thermo-Nano Fluid Heat Transfer from GITAM University, Vishakhapatnam and pursuing his Doctoral degree in the feld of Machine Learning too. \n\nHe has nearly two decades of teaching and research experience with a total research grant of 424.46 K USD from Department of Science and Technology, Ministry of Science and Technology, Government of India for various projects under cross domain research, more than 40 research publications, International Research Collaborations, Awards and Patents to his credit. He is a Chartered Engineer and Fellow Member of Institution of Engineers, India (IEI), a Life Member of Indian Society for Technical Education (ISTE), Member of American Society of Mechanical Engineers (ASME) and Institute of Electrical and Electronics Engineers (IEEE). His thrust areas of research include Cognitive Science, Data Analytics and Data Science, Machine Learning, Artifcial Intelligence, Thermo-Nano fuid Heat Transfer, Nanotechnology, Carbon Nano Tubes, Computational Fluid Dynamics.\n\nMr. N. Venkateswarulu is working as Assistant Professor, Department of Computer Science and Engineering, G. Narayanamma Institute of Technology & Science, Shaikpet, Hyderabad, Telangana, India. He is a research scholar currently persuing Ph.D in KL University, Andhra Pradesh, India. He has received his master's from Sree Vidyanikethan Engineering College, Tirupathi, Andhra Pradesh, India. He has received his bachelor's degree from Sreenivasa Institute of Technology and Management Studies, Chittoor, Andra Pradesh, India in June 2003. He has total thirteen years of teaching experience. He has six research publications in international journals out of which one got indexed in SCOPUS and one got published in SCI journal JSIR in February 2023. His thrust areas of research include Computer Algorithms, Data Mining, Data Science, Machine Learning, and Artifcial intelligence."}
{"doc617": "Dr Madhu Bala Myneni is working as a professor and Head of computer science and engineering at Institute of Aeronautical Engineering, Hyderabad. She received her Ph.D in Computer Science and Engineering from JNTUH. She has Twenty-one years of academic and research experience. Her research interests are Data Science frameworks, Image Mining, Text mining, Machine learning, Artifcial Intelligence, Deep Learning and Data Analytics. She has published 57 articles in reputed Journals indexed in SCOPUS, SCI etc. She has published 2 patents. She is the Principal Investigator of a DST-funded sustainable smart city development project. And has received various grants from AICTE for organizing Short Term Training Programs; Infrastructure Development; and Faculty Development Programs. And selected a part of AICTE national mission programs such as Student Learning Outcomes Assessment (SLA); Technical Book Writing (TBW). She is a reviewer for Elsevier, Springer, and more indexed journals. She acted as session chair, organizing member, and advisory member for various International Conferences. She delivered various invited talks on Data Modelling, Data Science, and Analytics. She is a Life member of professional bodies like CSI and ISTE, Sr. Member for IEEE, WIE & International association IAENG, ICST, and SDIWC. Funding This research received no specifc grant from any funding agency. There is no funding information available for this research work. Availability of data and materials Not applicable. For any collaboration, please contact the authors.\n\n## Declarations\n\nEthics approval and consent to participate Not applicable. Consent for publication Not applicable. Competing interests The authors declare that they have no competing interests. Received: 13 January 2022 Accepted: 17 February 2023"}
{"doc618": "24. Bairy A. (2022). Modeling Explanations in Autonomous Vehicles. In: ter Beek, M.H., Monahan, R. (eds) Integrated Formal Methods. IFM 2022. Lecture Notes in Computer Science, vol 13274. Springer, Cham. https://doi.org/10. 1007/978-3-031-07727-2_20 25. Mazri T, Tibari S. The Proposed Self-defense Mechanism Against Security Attacks for Autonomous Vehicles. In: Ben Ahmed M, Boudhir AA, Kara\u0219 \u0130R, Jain V, Mellouli S, editors. Innovations in Smart Cities Applications Volume 5 SCA 2021 Lecture Notes in Networks and Systems. Cham: Springer; 2022.\n\n26. Li Q, Wang Z, Wang W, Yuan Q. Understanding Driver Preferences for Secondary Tasks in Highly Autonomous Vehicles. In: Long S, Dhillon BS, editors. Man-Machine-Environment System Engineering. MMESE 2022. Lecture Notes in Electrical Engineering, vol. 941. Singapore: Springer; 2023.\n\n27. Gandhi GM, Salvi. Artifcial Intelligence Integrated Blockchain For Training Autonomous Cars. In: 2019 Fifth International Conference on Science Technology Engineering and Mathematics (ICONSTEM), 2019, pp. 157\u2013161, https://\ndoi.org/10.1109/ICONSTEM.2019.8918795."}
{"doc619": "28. Aguilar Cisneros JR, Fern\u00e1ndez-y-Fern\u00e1ndez CA, Ju\u00e1rez V\u00e1zquez J. Blockchain Software System Proposal Applied to Electric Self-driving Cars Charging Stations: A TSP Academic Project. In: 2020 8th International Conference in Software Engineering Research and Innovation (CONISOFT), 2020, pp. 174\u2013179, https://doi.org/10.1109/CONIS OFT50191.2020.00033.\n\n29. Liu B, Betancourt VP, Zhu Y, Becker J. Towards an On-Demand Redundancy Concept for Autonomous Vehicle Functions using Microservice Architecture. IEEE International Symposium on Systems Engineering (ISSE). 2020;2020:1\u2013\n5. https://doi.org/10.1109/ISSE49799.2020.9272016.\n\n30. Qiu H, Ayara A, Glimm B. A Knowledge Architecture Layer for Map Data in Autonomous Vehicles. In: 2020 IEEE \n23rd International Conference on Intelligent Transportation Systems (ITSC), 2020, pp. 1\u20136, https://doi.org/10.1109/ ITSC45102.2020.9294712."}
{"doc620": "31. Coicheci S, Filip I. Self-driving vehicles: current status of development and technical challenges to overcome. In: \n2020 IEEE 14th International Symposium on Applied Computational Intelligence and Informatics (SACI), 2020, pp. 000255\u2013000260, https://doi.org/10.1109/SACI49304.2020.9118809.\n\n32. Zelle D, Rieke R, Plappert C, Krau\u00df C, Levshun D, Chechulin A. SEPAD - Security Evaluation Platform for Autonomous Driving. In: 2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP), 2020, pp. 413\u2013420, https://doi.org/10.1109/PDP50117.2020.00070.\n\n33. Li H, Wu C, Chu D, Lu L, Cheng K. Combined Trajectory Planning and Tracking for Autonomous Vehicle Considering Driving Styles. IEEE Access. 2021;9:9453\u201363. https://doi.org/10.1109/ACCESS.2021.3050005. 34. Buzdugan ID, Ro\u0219u IA, Antonya C. Development of a Simulator Tool for Teaching the Autonomous Vehicles Behavior. In: Auer ME, El-Seoud SA, Karam OH (eds) Artifcial Intelligence and Online Engineering. REV 2022. Lecture Notes in Networks and Systems. Springer, Cham. 2013."}
{"doc621": "35. Tam PM, Anh HPH. A Probability-Based Artifcial Potential Field for Autonomous Vehicles in Avoiding Uncertain Obstacles. In: Huang YP, Wang WJ, Quoc HA, Le HG, Quach HN, editors. Computational Intelligence Methods for Green Technology and Sustainable Development GTSD 2022 Lecture Notes in Networks and Systems. Cham: Springer; 2023.\n\n36. Qiao J, de Jonge D, Zhang D, Sierra C, Simof S. A Hybrid Model of Trafc Assignment and Control for Autonomous Vehicles. In: Aydo\u011fan R, Criado N, Lang J, Sanchez-Anguix V, Serramia M, editors. PRIMA 2022: Principles and Practice of Multi-Agent Systems. PRIMA 2022. Lecture Notes in Computer Science. Cham: Springer; 2023.\n\n37. Wakam Younang VC, Yang J, Jacuinde LG, Sen A. A Comparative Analysis of User's Concerns and Government Policies on Autonomous Vehicles. In: Tekinerdogan B, Wang Y, Zhang LJ, editors. Internet of Things \u2013ICIOT 2022 Lecture Notes in Computer Science. Cham: Springer; 2023."}
{"doc622": "40. Dom\u00ednguez R, Onieva E, Alonso J, Villagra J, Gonz\u00e1lez C. LIDAR based perception solution for autonomous vehicles. In: Intelligent Systems Design and Applications (ISDA), 2011 11th International Conference on, 2011, p. 790\u2013795.\n\n41. Hasch, E.Topak, R. Schnabel, T. Zwick, R.Weigel, and C.Waldschmidt, \"Millimeter-wave technology for automotive radar sensors in the 77 GHz frequency band,\" IEEE Transactions on Microwave Theory and Techniques, vol. 60, no. 3, pp. 845\u2013860, 2012 42. Fu M, Song W, Yi Y, Wang M. Path planning and decision making for autonomous vehicle in urban environment. In: \n2015 IEEE 18th International Conference on Intelligent Transportation Systems, pp. 686\u2013692, 2015.\n\n43. Lee M-H, Chen Y-J, Li THS. Sensor fusion design for navigation and control of an autonomous vehicle. In: Systems, Man, and Cybernetics (SMC), 2011 IEEE International Conference on, 2011, p. 2209\u20132214."}
{"doc623": "65. Sermanet P, Kavukcuoglu K, Chintala S, Lecun Y. Pedestrian detection with unsupervised multi-stage feature learning. In: 2013 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3626\u20133633, 2013. 66. Xu D, Ouyang W, Ricci E, Wang X, Sebe N. Learning cross-modal deep representations for robust pedestrian detection. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4236\u20134244, 2017.\n\n67. Luo W, Schwing AG, Urtasun R. Efcient deep learning for stereo matching. in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5695\u20135703, 2016.\n\n68. Mayer N, Ilg E, H\u00c3dusser P, Fischer P, Cremers D, Dosovitskiy A, Brox T. A large dataset to train convolutional networks for disparity, optical fow, and scene fow estimation. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4040\u20134048, 2016."}
{"doc624": "92. Broggi A, Buzzoni M, Debattisti S, Grisleri P, Laghi MC, Medici P, Versari P. Extensive tests of autonomous driving technologies. IEEE Trans Intell Transp Syst. 2013;14:1403\u201315.\n\n93. Bunzel S. Autosar - the standardized software architecture. Informatik-Spektrum. 2011;34:79\u201383. 94. Chakraborty S, Laware H, Castanon D, Zekavat SR. High precision localization for autonomous vehicles via multiple sensors, data fusion and novel wireless technologies. In: Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON), IEEE Annual, 2016, p. 1\u20139.\n\n95. Li Q, Chen L, Li M, Shaw S-L, Nuchter A. A Sensor-Fusion Drivable-Region and Lane-Detection System for Autonomous Vehicle Navigation in Challenging Road Scenarios\". IEEE Trans Vehic Technol. 2014;63(2):540\u201355."}
{"doc625": "![0_image_2.png](0_image_2.png)\n\n| Contents lists available at ScienceDirect                                        |\n|----------------------------------------------------------------------------------|\n| Expert Systems With Applications  journal homepage: www.elsevier.com/locate/eswa |\n\nAutonomous driving system: A comprehensive survey Jingyuan Zhao a,*, Wenyi Zhao b, Bo Deng b, Zhenghong Wang c, Feng Zhang b, Wenxiang Zheng b, Wanke Cao b, Jinrui Nan b,*, Yubo Lian d, Andrew F. Burke a a Institute of Transportation Studies, University of California Davis, Davis, CA 95616, USA b Shenzhen Automotive Research Institute, Beijing Institute of Technology, Beijing 100811, China c Hubei Longzhong Laboratory, Hubei University of Arts and Science, Xiangyang 441000, China d *BYD Automotive Engineering Research Institute, Shenzhen 518118, China* "}
{"doc626": "| ARTICLE INFO  Keywords:  Autonomous driving  Deep learning  Scene perception  Localization  Motion planning  Decision-making   |\n|--------------------------------------------------------------------------------------------------------------------------------|\n\n## Abstract\n\nAutomation is increasingly at the forefront of transportation research, with the potential to bring fully autonomous vehicles to our roads in the coming years. This comprehensive survey provides a holistic look at the essential components and cutting-edge technologies that are driving the development and implementation of autonomous driving. It starts by evaluating two critical system architectures that are fundamental to the operation of autonomous vehicles: the layered and end-to-end structures. It then examines the critical areas of scene perception and localization, emphasizing the importance of sensor technologies. These technologies are vital for tasks such as object detection and semantic segmentation, which allow vehicles to understand and navigate their environment. A special focus is given to the complex topic of object detection, along with suggestions for how it can be enhanced. The survey then proceeds to provide detailed discussions on path planning, trajectory prediction, and decision-making processes. These elements are crucial for the smooth navigation of autonomous vehicles, and the survey highlights the role of artificial intelligence (AI) and machine learning in these processes. "}
{"doc627": "Overall, the survey presents the rapid progress in the field of autonomous driving, offering a comprehensive assessment of the technologies and innovations that are essential for moving toward a safe and efficient autonomous future. \n\nAbbreviations: AI, Artificial intelligence; ALV, Autonomous land vehicle; ADs, Autonomous driving systems; ALVINNs, Autonomous land vehicles in systems based on neural networks; BC, Behavior cloning; CNNs, Convolutional neural networks; CIL, Controlled imitation learning; CVAT, Computer vision annotation tool; CRFs, Conditional random fields; DDQN, Dueling deep q-network; DDP, Differential dynamic programming; DNNs, Deep neural networks; DRL, Deep reinforcement learning; DGMs, Deep generative models; DARPA, Defense advanced research projects agency; E-RPN, Euler-region-proposal network; FCN, Fully convolutional network; FNNs, Feedforward neural networks; FSM, Finite state machine; GRUs, Gated recurrent units; GANs, Generative adversarial networks; GCN, Graph convolutional network; GMF, Gaussian mean field; GPU, Graphic processing unit; GAIL, Generative adversarial imitation learning; GPS, Global positioning system; HD, \nHigh-definition; IL, Imitate learning; IMU, Inertial measurement unit; IoV, Internet of vehicles; IRL, Inverse reinforcement learning; IMLS, Implicit moving least squares; ILC, Iterative learning control; JPDA, Joint probabilistic data association; LFA, Local feature aggregation; LaneRoI, Lane-graph region-of-interest; LQR, \nLinear quadratic regulator; LSTM, Long short-term memory; MIT, Massachusetts institute of technology; MV3D, Multi-view 3d networks; MOT, Multi-object tracking; MHT, Multi-hypothesis tracking; MDP, Markov decision process; MARL, Multi-agent reinforcement learning; MPC, Model predictive control; NMS, Non-maximum suppression; MFRL, Multi-fidelity reinforcement learning; POMDP, Partially observable Markov decision process; RCNNs, Region-based convolutional neural networks; RNNs, Recurrent neural networks; RGBD, Red-green\u2013blue-depth; RCNN, Region-based CNN; RPN, Region proposal network; RRL, Road research laboratory; SAE, Society of automobile engineers; SVO, Semi-direct visual odometry; SLAM, Simultaneous localization and mapping; SSD, Single shot detector; SVM, Support vector machine; STGCNNs, Spatio-temporal graph cnns; SSGP, Sparse spectral gaussian process; TPCN, Temporal point cloud networks; VFE, Voxel feature encoding; V2X, Vehicle to everything; V2I, Vehicle to infrastructure; V2N, Vehicle to network; V2P, Vehicle to pedestrian; V2V, Vehicle to vehicle; VO, Visual odometry; YOLO, You only look once. \n\n* Corresponding authors. "}
{"doc628": "E-mail addresses: jyzhao@ucdavis.edu (J. Zhao), 3220210332@bit.edu.cn (W. Zhao), db98@bit.edu.cn (B. Deng), 202208551062@hbuas.edu.cn (Z. Wang), \nzhangfeng@szari.ac.cn (F. Zhang), zhengwenxiang@szari.ac.cn (W. Zheng), caowanke@bit.edu.cn (W. Cao), nanjinrui@bit.edu.cn (J. Nan), lian.yubo@byd.com \n(Y. Lian), afburke@ucdavis.edu (A.F. Burke). https://doi.org/10.1016/j.eswa.2023.122836 Received 17 August 2023; Received in revised form 14 November 2023; Accepted 1 December 2023 Available online 2 December 2023 0957-4174/\u00a9 2023 Elsevier Ltd. All rights reserved.\n\n## 1. **Introduction**\n\nOver the past decade, self-driving/driverless cars have gained increasing popularity worldwide, promoting the autonomous driving revolution (Baruch, 2016). The use of autonomous driving technology can improve mobility in crowded cities, reduce traffic congestion, and improve travel safety (Nunes & Axhausen, 2021). The British Road Research Laboratory showed a video of autonomous driving, in the early 1970 s, which aroused huge interest in both academia and industry. Since then, huge efforts have been devoted worldwide by researchers and engineers from around the world to improve the autonomous technology. In 1984, the U.S. Defense Advanced Research Projects Agency (DARPA) partnered with the army to launch the Autonomous Land Vehicle (ALV) program. Since the 1980 s, many famous universities such as Carnegie Mellon University (CMU), Stanford University, and Massachusetts Institute of Technology (MIT) etc., have successively joined the research on autonomous driving. Good examples include the NavLab series of intelligent vehicles developed by Carnegie Mellon University in the United States (Thorpe et al., 1988) and the ARGO test vehicle developed by the VisLab Laboratory of the University of Parma in Italy (Bertozzi et al., 2006). In addition to active research in the field of unmanned driving underpinned by scientific and research institutions, many automobile manufacturers such as Audi, BMW, Ford, General Motors, Mercedes, Tesla, Volvo and so on also began to deploy in the field of unmanned vehicles since the start of the decade of the 2010 s (Greenblatt, 2016). Some companies even adopt the \"one-stop\" SAE Level 4 + development route for designing commercial autonomous driving. Since the DARPA Grand Challenge in 2004 and 2005, datadriven, machine learning-based techniques have been widely used in autonomous driving and is translating into a world of computercontrolled vehicles with autonomy and intelligence. "}
{"doc629": "In order to eliminate the inconsistency and confusion in the terminology used in the autonomous industry, Society of Automobile Engineers (SAE) proposed to define an accurate and consistent vocabulary, launched as an official document named SAE-J3016 in 2014, which clearly classified Levels of Driving Automation on a scale of 0 to 5 (International, 2023), as shown in Fig. 1. The higher the level, the higher the degree of automation. However, the current autonomous driving is still not a fully stable technology per se, and has been at the level 2 for years. The jump from Level 2 to Level 3 require craftsmanship, complex formulations and elaborate implementations, which presents severe challenges and introduces excessive cost and uncertainty to the autonomous process. Safety and robust security operation remain major factors in the market for the foreseeable future. Careful consideration should be given to how to transform autonomous driving from niche to widespread commercial viability. Moreover, the accuracy and sensitivity of hardware seriously affect the safety of autonomous driving during the daily operation. Various high-cost sensors are difficult to put into use on a large scale. Deep learning has brought about a paradigm shift in the field of AI, empowering computational models with the ability to learn intricate data representations through multiple layers of processing (LeCun et al., 2015). These state-of-the-art methods have made significant advancements across various domains, such as enhancing speech recognition accuracy, achieving remarkable success in visual object recognition tasks, enabling precise object detection, and impacting numerous other areas of research and application. The remarkable achievements of deep learning algorithms have propelled the boundaries of what was previously thought possible in the realm of AI. Deep learning methods offer opportunity to perceive, make predictions about future scenarios, and take decisions that are rational/ \noptimal given these predictions (Ghahramani, 2015). In the realm of autonomous driving, machine learning and deep learning have permeated various domains (Bachute & Subhedar, 2021). However, the blackbox and inexplicable nature of neural networks have a huge impact on the perception, decision, and execution, which makes autonomous driving vulnerable to environmental influences and external interference (Van Brummelen et al., 2018). The current decision planning is mainly based on the planner and lattice state algorithms using vehicle and road models. Therefore, we must carefully consider the security and robustness of deep learning, which has been an unsolved problem for several years. In cloud services, unstable vehicle-to-vehicle (V2V) links and centralized resource allocation methods with high signaling overhead become bottlenecks for safety\u2013critical applications. This can be described as an NP-hard problem that is expected to be solved by specialized network architectures (Tkatek et al., 2020). \n\n## 2. **Scope Of The Survey**\n\nTo extract insights into the structure and patterns embedded within "}
{"doc630": "planning and decision-making (Section 5). A crucial facet of autonomous driving development\u2014simulators and scenario generation tools\u2014receive a methodical examination in Section 6. The survey culminates with Section 7 spotlighting prevailing challenges, followed by Section 8 which canvasses promising trajectories for impending research in this dynamic field. \n\n## 3. **System Architectures For Autonomous Driving**\n\nThe architectural framework underpinning the functionality of autonomous driving systems plays an indispensable role in fortifying their robustness and prognosticating their capacity for prospective expansion (Fig. 3). Herein, we provide an overview of the system architecture essential for autonomous driving. This includes the layered and end-to-end architectures, with the goal of giving readers a foundational understanding of the architectural principles that operate at the systemic level in the field of autonomous driving. These driving systems exemplify autonomous decision-making agents, necessitating the realtime processing of voluminous data streams emanating from a constellation of diverse sensors. It is imperative to acknowledge that architectural variances among different autonomous driving systems induce disparities in data processing flows and decision-making trajectories, thereby engendering a spectrum of operational dynamics. "}
{"doc631": "## 3.1. Layered Architecture\n\nThe layered architecture is a widely used architecture (Fig. 4). Unmanned driving systems can be divided into three levels: perception and simultaneous localization and mapping (SLAM) layer, planning layer, and control layer (Grigorescu et al., 2020). Commencing with the perception system, this layer harnesses data derived from an array of sensors, encompassing GPS, inertial measurement units (IMUs) and so on. This data fusion is pivotal for establishing dynamic information and generating a coherent internal environmental representation, utilizing additional sensors such as cameras, radar, and lidar. The localization subsystem, which is part of the SLAM system, is responsible for estimating the state of the vehicle (attitude, linear velocity, angular velocity, etc.) to construct the environment map. The first-order mapping subsystem, also part of the SLAM system, receives offline maps and the vehicle's state as input and produces online maps as output, which can improve the information available to the decision-making system. The motion planning system is responsible for navigating the vehicle from its starting position to a user-defined final position, while considering the vehicle's current state, an internal representation of the environment, traffic rules, and passenger safety and comfort. The motion controller system receives the motion decision, and the obstacle avoidance subsystem modifies and calculates steering wheel angle, accelerator opening, brake force, and other signals, sending instructions to the actuator to execute the modified motion as efficiently as possible (Badue et al., \n2021). \n\n## 3.2. End-To-End"}
{"doc632": "The \"end-to-end\" approach is a method of learning driving policies directly from raw sensor data (e.g., images, point clouds, outputs brake, accelerator, and steering operations) without the need for manual feature engineering or modules. This paradigm first appeared in the 1990 s and established autonomous land vehicles in systems based on neural networks (ALVINN) (Pomerleau, 1988). At the time, ALVINN was designed to drive along predefined roads. In the mid-2000 s, research on end-to-end driving reached a climax again as Darpa's Autonomous Vehicle (DAV) successfully navigated a road full of obstacles (H. Xu et al., 2017). The development of computing hardware is also the basis for the use of the end-to-end model. Compared to layered architectures, end-to-end architectures are less demanding for sensor data annotation, so they are becoming more and more popular(Janai et al., 2020; Tampuu et al., 2020). Next, this paper briefly introduces some of the development of end-to-end autonomous driving technology in recent years, and the specific content is introduced in the following chapters. \n\nIn the past few years, end-to-end control methods based on CNNs, RNNs, and reinforcement learning have been continuously proposed. NVIDIA and Comma AI developed an unmanned demonstration system using end-to-end deep learning (George et al., 2018). REF. (Innocenti et al., 2017) applied vision-based end-to-end steering angle prediction to the lane keeping task. Using lidar data, REF. (Rhinehart et al., 2018) \nmade expert vehicle trajectory prediction based on imitation learning \n(IL) and model-based reinforcement learning. However, the driving policy of IL training may appear uncontrollable during testing. REF. (Codevilla et al., 2018) proposed a conditional IL method: conditioning IL into high-level command input, which enables IL to be effective in complex urban environments. In the other hand, REF. (D. Chen et al., 2021) assumed that neither the agent nor its operations will affect the environment, the model is simplified. Although there is little true independence, it does improve the training efficiency, simplifies the \n\n![3_image_0.png](3_image_0.png)"}
{"doc633": "reward function, and performs better than the previous IL. In some complex urban traffic, REF. (Toromanoff et al., 2020) used a model-free DRL method Rainbow-IQN-Apex, which introduces end-to-end autonomous driving is much larger networks than in previous reinforcement learning work, enabling autonomous driving to handle tasks such as intersection management and traffic light detection. REF. (Chitta et al., \n2021) proposed the neural attention field, NEAT, a continuous function that maps the location of BEV scene coordinates to waypoints and semantics, and iteratively compresses high-dimensional 2D image features into a compact representation with an intermediate attention map. This approach allows the model to selectively focus on relevant input regions while ignoring information irrelevant to the driving task, effectively associating images with BEV representations. \n\nThere are many kinds of sensors on autonomous driving. For the endto-end architecture, if only one kind of sensor data (such as RGB image) \nis used for driving control of the vehicle, it is difficult to guarantee the accuracy and safety. Therefore, multi-modal end-to-end autonomous driving based on the fusion of multiple sensors is also one of the key directions of current research (Xiao et al., 2020). The multi-modal controlled imitation learning (CIL) model is obtained by fusing the camera (RGB) and lidar (depth information). Compared with the singlemodal CIL model, the multi-modal CIL model has better driving performance, especially in the early stage. Fusion shows better performance relative to other epoch fusions. REF. (Prakash et al., 2021) used an attention mechanism to integrate image and LiDAR representations, and proposes a new multimodal fusion Transformer. The Transformer's selfattention mechanism fuses the global context about the 3D scene into the feature extraction layers of different modalities and integrate different modal information for vehicle autoregressive waypoint prediction. \n\n## 3.3. Merits Of The Two Architectures"}
{"doc634": "The choice of system architecture plays a critical role in determining the performance and reliability of vehicle systems. One can distinguish between two main approaches: layered and end-to-end architectures based on their fundamental operational paradigms, each offering distinct benefits. Layered architectures are highly regarded for their modular design and reliability. This design approach results from their sophisticated structure, which, unfortunately, can also lead to increased complexity and the possibility of delays in system responses. These architectures typically involve separate modules for perception, decision making, and control, which communicate in a sequential manner. On the other hand, end-to-end architectures offer a more streamlined approach, enhancing efficiency by processing input data through a single neural network that outputs control commands directly. This architecture is often implemented with deep learning techniques that can learn complex representations of the data. However, this comes at the cost of a heavy reliance on the quality of the training data and challenges in understanding how the system makes decisions, often referred to as the \"black box\" problem. End-to-end systems require extensive and diverse datasets to learn effectively and are only as good as the data they are trained on. The decision to opt for one architecture style over the other is greatly influenced by the specific requirements and constraints of the autonomous driving application in question, as summarized in Table 1. \n\n## 4. **Scene Perception And Localization**\n\nMachine learning play a pivotal role, providing a powerful tool to simplify the complexities of environmental perception and spatial referencing in autonomous driving. This, in turn, promotes a paradigm deeply rooted in data analysis and algorithmic functionalities. This part of the text explores the application of machine learning, with a particular focus on its ability to address challenges related to hardware deployments, especially sensors. Sensors are crucial for tasks such as object "}
{"doc635": "| Table 1  Comparing layered and end-to-end architectures in autonomous systems.  Aspect Layered Architecture End-to-End Architecture  Advantages Modular design facilitates easier  Simplified structure reduces  updates and development.  system complexity.  Structured approach simplifies  Reduced latency as data  debugging and testing.  processing occurs in a single  pass.  Allows specialized optimization at  each layer for improved  performance.  Strengths Independent layer development  leads to increased system  reliability.  Adaptable to changes and new  environments with adequate  training.  Compatible with a wide range of  sensors and algorithms for better  integration.  Can achieve high performance  levels through advanced  learning.  Challenges Processing across multiple layers  Requires extensive, welllabeled datasets for effective  can introduce latency.  training.  Complex inter-layer  Debugging can be challenging;  communication maintenance.  low interpretability of  decisions.  Outlook Focus on reducing latency to  Efforts to enhance model  increase efficiency.  interpretability.  Incorporating learning-based  methods for greater adaptivity and  responsiveness.  Developing more efficient  training methods to improve  learning.   |\n|---|\n\nrecognition and semantic segmentation. Through this concise but rigorous exploration, our goal is to establish a clear connection between the fields of AI and autonomous vehicle technology. We want to highlight the potential for synergistic development and mutual evolution in these intricate and technologically advanced domains (Fig. 5). \n\n## 4.1. Characteristics Of Sensor Technologies In Autonomous Driving"}
{"doc636": "In the intricate tapestry of technologies that undergird the functionalities of autonomous driving, three sensor technologies stand prominent: camera, lidar, and radar, each bringing to the fore unique strengths and facing distinct challenges, outlined in Table 2. The camera, a cornerstone in this triad, is unparalleled in its capability to interpret the subtle nuances of textures and colors with finesse. This ability renders it indispensable for critical tasks inherent to autonomous navigation, such as lane detection and traffic sign recognition, along with distilling insights crucial to comprehending the driving milieu. \n\nHowever, it is imperative to acknowledge that these advantageous attributes come tethered to the demand for significant computational resources requisite for processing high-definition imagery. In contrast, lidar sensors are lauded for their precision, a trait quintessential for executing tasks pivotal to autonomous driving, ranging from object and pedestrian detection to meticulous mapping, thereby playing an indispensable role in navigation and obstacle avoidance. Nevertheless, lidar sensors, despite their acknowledged precision, are not without their challenges; they exhibit sensitivity to meteorological conditions and have been burdened by issues related to bulkiness and high cost\u2014although the relentless tide of technological advancement is gradually alleviating these constraints. Radar technology demonstrates robust performance under adverse weather, providing reliable data on the distance and velocity of nearby objects. With a wide field of view and the capability to detect entities at considerable distances, radar is crucial for adaptive cruise control and collision avoidance applications. However, while beneficial, radar has limitations, including lower spatial resolution than lidar and challenges in angular accuracy. \n\n## 4.2. Object Detection"}
{"doc637": "Object detection serves as the bedrock upon which autonomous driving systems construct their perceptive understanding of surrounding \n\n![5_image_0.png](5_image_0.png)\n\n| Aspect                                                                                                                         | Camera                                                                                                    | Lidar                                                                                             | Radar   |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|---------|\n| detection and  traffic sign  recognition. Can  be used for visual  SLAM. Often  combined with  other sensors for  data fusion. | - Commonly used  in adaptive cruise  control, blindspot warning,  collision warning, and collision  prevention. Wellsuited for velocity  estimation of surrounding objects.                                                                                                           |                                                                                                   |         |\n| perspective  Excellent  texture  interpretation  Cost-effective  Easily  accessible                                            | - Utilized for highprecision localization. Used for  obstacle avoidance and detection  of pedestrians.  Critical for HD  map creation.                                                                                                           | - Robust against  adverse weather.  Wide field of  view  Precise speed  and distance  information |         |\n| significant  computational  resources  Vast data  generation                                                                   | - High spatial  resolution  Detailed 3D  point clouds  Excellent for  object  identification and  mapping | - Lower angular  accuracy  compared to  Lidar  Limited  resolution,  especially  vertically       |         |\n| - Sensitive to  weather  conditions  Traditionally  high-priced and  large-sized  Requires substantial processing                                                                                                                                |                                                                                                           |                                                                                                   |         |"}
{"doc638": "end-to-end \n\ndriving \n\nenvironments, standing as a paramount facet of autonomous driving technologies. The fundamental objective steering object detection mechanisms is the astute identification, meticulous classification, and precise localization of objects that punctuate the environmental landscape within which these autonomous entities navigate. In the landscape of recent technological advancements, there has been a discernible acceleration in the refinement and deployment of deep learning algorithms specifically tailored for object detection tasks. This swift paradigmatic shift has precipitated enhancements in the performance metrics of detection systems. These advanced algorithms leverage the foundational structure of neural networks as their computational backbone, utilizing these sophisticated networks to effectuate the extraction of salient features from image data with enhanced accuracy and efficiency. Through the systematic application of these evolved algorithms, the field has witnessed a substantial elevation in the reliability and functionality of autonomous driving systems in real-world, dynamically shifting environments. "}
{"doc639": "| deep learning for  advanced  perception  Humanmachine  interaction  Applications in  segmentation and  end-to-end  driving   | - Becoming more  compact and  affordable  Enhanced  performance in  diverse conditions  Integration with  other sensors for  better mapping   |\n|---|-----------------------------------------------------------------------------------------------------------------------------------------------|\n\n| autonomous  driving  Integration  with other  sensors for better  perception  Improved  resolution and  data processing   |\n|---------------------------------------------------------------------------------------------------------------------------|\n\n4.2.1. *Image object detection* Two techniques dedicated to image object detection are investigated in this section (Table 3), both of which enjoy extensive application within the domain of autonomous driving. The techniques under examination include region-based convolutional neural networks (RegionBased CNNs) and single-stage detection methods, with particular reference to you only look once (YOLO) and single shot detector (SSD). These methodologies have garnered popularity for their efficacy and reliability in facilitating object detection, thereby contributing significantly to the operational proficiency of autonomous driving systems. "}
{"doc640": "4.2.1.1. *Region-based CNNs.* Region-based CNNs (RCNNs) revolutionized object detection by initially generating around 2000 bottom-up region proposals through selective search, and subsequently extracting features for each region using CNNs, followed by classification via linear support vector machines (SVMs) (Girshick et al., 2015). The advent of Fast RCNN (Ren et al., 2015) and Faster RCNN (Mansour et al., 2021) \nbrought significant improvements. Fast RCNN introduced ROI Pooling to circumvent the issue in RCNN where pre-convolution image \n\n| Characteristics of different image object detection techniques.  Method Description Key Features   | Limitations                                                                    | Applications                                    |                     |\n|----------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|-------------------------------------------------|---------------------|\n| Region  Based  CNNs                                                                                | - High precision in localization and                                           |                                                 |                     |\n| Utilizes a two-step process for object  detection with CNNs.                                       | classification  Two-stage process: region proposal and  refinement             | - Slower inference speed Higher                 | Fine-grained object |\n| computational resources needed                                                                     | detection, complex scenes                                                      |                                                 |                     |\n| YOLO and                                                                                           | Single-stage models predicting object                                          | - High detection speed                          |                     |\n| SSD                                                                                                | classes and bounding boxes directly.                                           | Single-stage process: simultaneous              |                     |\n| prediction of class labels and bounding  boxes                                                     | - Slightly compromised localization  accuracy  Less effective on small objects | Real-time object detection,  video surveillance |                     |\n\nsegmentation led to deformation or feature loss. By leveraging fast RCNN and region proposal network (RPN), the attention-based detection framework shows promise in addressing the challenge of detecting small objects in large, high-resolution images (Fig. 6). "}
{"doc641": "4.2.1.2. *YOLO and SSD.* YOLO's swift, single-pass image processing is \n\n![6_image_0.png](6_image_0.png)\n\npivotal for real-time object detection, a necessity for responding to dynamic traffic situations. Complex-YOLO (Simony et al., 2018), a variant specifically crafted for 3D object detection within Lidar point clouds \n(Fig. 7a), facilitates real-time environmental perception\u2014critical for decision-making and navigation in autonomous vehicles. Unlike traditional YOLO, it employs Euler-region-proposal network (E-RPN) using complex numbers for regression, enhancing orientation estimation's robustness and avoiding singularities. This innovative approach, effective especially during training, distinguishes Complex-YOLO for its unparalleled speed and efficiency. According to KITTI benchmark tests, Complex-YOLO outstrips other techniques, processing at a rate five times faster than its closest counterpart and simultaneously estimating various object classes, including cars, vans, and pedestrians. Remarkably, Complex-YOLO operates on Lidar data, bolstering its efficiency and making it apt for deployment on embedded platforms such as NVIDIA \nTX2 without reliance on additional sensors. "}
{"doc642": "Future enhancements for Complex-YOLO envision the incorporation of height data into the regression, laying the foundation for genuine 3D \nobject detection. By tapping into tempo-spatial dependencies, there is potential to further boost class differentiation and elevate accuracy levels. Complex-YOLO stands as a monumental stride in the domain of 3D object detection for autonomous driving. By harnessing the agility of YOLO and pioneering with complex number-driven regression via ERPN, it achieves a commendable blend of speed and efficiency. \n\nSSD (W. Liu et al., 2016), on the other hand, belongs to the category of one-stage object detection algorithms that circumvent the region proposal phase. SSD can directly generate category probabilities and positional coordinates for objects (Y. Zhang et al., 2020). This streamlined approach allows for faster detection speeds as the final detection results are acquired through a single forward pass of the network. As depicted in Fig. 7b, the structure of the SSD algorithm is twofold: (1) The Backbone network, which is constituted by segments of the VGG16 convolutional layers. Notably, the last two layers, conv6 and conv7, are substituted by fully connected layers for image classification purposes. \n\n(2) The SSD testing framework comprises two parts: the frontend employing the VGG16 model for preliminary feature extraction from the image, and the backend multi-scale feature detection network, which operates at varying scales to extract features from different layers. This allows the SSD to detect both large and small objects by examining shallow feature maps with larger receptive fields and deeper feature maps with finer details. SSD's emphasis on multi-scale features allows it to detect objects of varying sizes, which is essential for recognizing "}
{"doc643": "4.2.2. *Point cloud object detection* Point cloud object detection, a field within computer vision, facilitates three-dimensional environmental perception. Point clouds, aggregations of spatial coordinates and attributes such as color or intensity, offer rich scene information. Enhanced sensor technologies, notably LiDAR, enable the acquisition of dense, high-resolution point cloud data, whose unique qualities, such as representing complex geometries and detailed structures, are invaluable for object detection. \n\nThese point clouds' spatial and geometric features have been leveraged to craft various object detection methodologies in 3D space. This section introduces three leading approaches in point cloud object detection: \npoint-based, voxel-based, and 2D-projection-based methods, each presenting distinct advantages and challenges in computational efficiency, 4.2.2.1. *Point-based.* PointNet offers a unified architecture, leveraging point methods, that processes point clouds directly for either holistic input classification or segment-specific labeling. Meanwhile, Grid-GCN \n(Q. Xu et al., 2020), a variant employing point convolutions, utilizes graph convolution networks for point cloud learning, aggregating feature information of points through Fourier transforms within its various GridConv layers. Each layer consists of two steps: central node sampling and neighboring node selection, followed by information aggregation from queried nodes to the center. In this process, each point generates a local graph, and then GCN aggregates the information of the points according to the local graph (Z. Liu et al., 2019; Zarzar et al., 2019). However, the efficacy of these models is somewhat constrained \n\n| Method                     | Description                                                                | Features                | Advantages                                                  |\n|----------------------------|----------------------------------------------------------------------------|-------------------------|-------------------------------------------------------------|\n| Point-based                | Operates directly on raw point clouds, preserving spatial and geometric    | Raw point cloud         | Preserves complete information, handles complex point       |\n| characteristics.           | operation                                                                  | cloud data effectively. |                                                             |\n| Voxel-based                | Converts point clouds into 3D voxel grids, enabling the use of traditional | 3D voxel grid           | Utilizes traditional CNN structures, simplifies analysis of |\n| CNNs for object detection. | conversion                                                                 | structured data.        |                                                             |\n| 2D-Projectionbased                            | Projects 3D point clouds onto 2D planes, creating simplified views while   | 3D to 2D projection     | Simplifies data processing, retains significant object      |\n| retaining object details.  | details.                                                                   |                         |                                                             |"}
{"doc644": "by the farthest sampling process, even though it enhances memory efficiency and operational speed. To mitigate this, KPConv (Thomas et al., \n2019) employs a learnable radius neighborhood input method to formulate kernel points, offering a flexible and robust local neighborhood representation. RandLA-Net (Hu et al., 2020) introduces a random sampling strategy paired with a local feature aggregation (LFA) module to counteract feature loss, expanding the receptive field layer by layer to accommodate complex local structures efficiently. For detecting 3D \nobjects from raw point clouds, REF. (Shi et al., 2019) designed a network based on RCNN, which generates high-quality 3D proposals directly from point clouds. The introduced KCA module, incorporating a selfattention mechanism, selectively highlights key points and features, minimizing redundancy (H. Wang et al., 2021). However, Point-based methods see computational complexity increasing linearly with point numbers, with data structure construction costs, such as for KD trees, becoming a technical bottleneck. \n\n4.2.2.2. *Voxel-based.* VoxeNet (Maturana & Scherer, 2015) and VoxelNet (Y. Zhou & Tuzel, 2018) both take raw point cloud data as input partitions the space into voxels and input voxels into a 3D neural network for detection. Occupancy grid reduces the amount of data and preserves the shape of the point cloud, the representation is more informative than that of the point cloud, since the distinction between free space and unknown space can be a valuable piece of information. \n\nVoxNet just feeds the voxels into the neural network, convolves and pools the output point cloud fragments. VoxelNet designs a novel voxel feature encoding (VFE) layer and via stacked VFE layers, which enables inter-point interaction within a voxel. Finally, a volume representation is output by the RPN network as the detection result. Recently, researchers have proposed different voxel structures to represent point clouds. PointPillars (Lang et al., 2019) converts the raw point cloud into a stacked pillar tensor and pillar index tensor. It uses a novel encoder that learns features on pillars (vertical columns) of the point cloud to predict 3D oriented boxes for objects. There are several advantages of this approach. Firstly, PointPillars can exploit the full information of point clouds by learning point cloud features instead of relying on fixed encoders. Secondly, the operation of the column does not require manual adjustment of the vertical bins, which simplifies the operation process. Finally, since all key operations can be performed by 2D \nconvolution, it is very fast to compute on CPU. Another benefit of the learning function is that PointPillars can use different point cloud configurations, such as multiple lidar scans or even radar point clouds, without manual tuning. PolarNet, represents the point cloud as a ringbased structure and proposes a ring CNN to extract special data distribution characteristics. Compared with conventional voxelization methods, this representation can reduce the effects of non-uniform distribution of point clouds. PolarNet (Y. Zhang et al., 2020) represents the point cloud as a ring-based structure and proposes a ring CNN to extract special data distribution characteristics. Compared with conventional voxelization methods, this representation can reduce the effects of nonuniform distribution of point clouds. Cylinder3D uses 3D polar voxels instead of 2D polar voxels. In future development, there will be more and more shaped voxels that can be used to process point cloud data. 4.2.3. *Challenges and prospects: Object detection* Object detection is crucial for interpreting the contours of external environments, which is fundamental to the decision-making processes inherent in various systems. Despite the critical role of object detection, it frequently encounters challenges arising from the unpredictable and complex nature of real-world driving scenarios. These challenges are manifold, marked by variable environmental conditions and the inherent complexity found within the dynamics of driving conditions. "}
{"doc645": "Nevertheless, it is essential to recognize that the direction of technological advancement and methodological innovation in this field is decidedly positive. With a consistent flow of developments emerging in both the technological and theoretical domains, there is a clear vision of promise and potential. The technologies and strategies signal a future where the capabilities of object detection systems are not only enhanced but also refined. This progress is set to facilitate more sophisticated, reliable, and effective implementations in autonomous navigation and driving systems. Table 5 succinctly summarizes the challenges and prospects in object detection, providing a critical overview necessary for understanding and advancement in this arena. Despite the formidable challenges, the encouraging prospects provide avenues for future enhancements and applications in the realm of object detection. \n\n## 4.3. Semantic Segmentation\n\nIn autonomous driving, semantic segmentation offers pixel-level environmental discernment, a computer vision task that classifies image pixels into distinct classes, thus mapping the scene intricately. However, its application faces challenges, given the dynamic driving landscapes. The algorithm must handle diverse lighting, object occlusions, varied appearances, and unforeseen incidents. "}
{"doc646": "4.3.1. *Annotation for semantic segmentation* In the domain of semantic segmentation, there is a necessity for precision in annotations. This precision demands a process where each pixel within an image is accurately labeled, identified with the class of its encompassing object or region. The requirement for such fine-grained precision inherently renders the annotation task for semantic segmentation as time-intensive and laborious. Nevertheless, this challenge can be mitigated and the process expedited through the adoption of specialized annotation methodologies and tools, purposefully crafted to aid in this detailed endeavor. Subsequently, a succinct introduction to a selection of four annotation tools, including (i) Labelbox (Labelbox, 2023), (ii) Roboflow (Roboflow, 2023), (iii) Encord (Encord, 2023) and \n(iv) CVAT (CVAT, 2023), are provided, aiming to shed light on their functionalities and afford the insightful considerations regarding their application in the field of semantic segmentation. \n\n## (1) Labelbox\n\nTable 5 "}
{"doc647": "development of more fair, private, and \n\nrobust detection systems. \n\nLabelbox provides an efficient milieu for the data labeling. This datacentric tool is engineered, not solely as a crucible for the genesis of pristine-quality data but also as a robust platform fostering the processes of training, fine-tuning, and human-centric evaluations - elements for the execution of semantic segmentation tasks. With features enabling users to visualize, peruse, classify, and disseminate data subsets with precision, Labelbox provides support for the processing of datasets through AI mechanisms. Furthermore, it facilitates insights through workflows assisted by both human intellect and mechanized algorithms, enhancing efficiency in data preparation for AI model training. Its suite, with model-assisted labeling and collaborative annotation capabilities, has been enabling enterprises to institute standardized protocols for data creation and management, culminating in savings in time and financial resources. "}
{"doc648": "## (2) Roboflow\n\nIts AI-assisted labeling feature supports various annotation types, allowing teams to work collaboratively and securely in real-time. This not only speeds up the process but also ensures accurate annotations, thanks to pre-trained models that automatically detect and label common objects in your dataset. Roboflow is designed for effective teamwork, providing a smooth platform for managing annotation projects where tasks such as uploading, searching, assigning, reviewing, and approving annotations are streamlined. With features facilitating easy communication and project management, and secure, role-based access, it supports safe collaboration both within and outside your organization. It supports a range of labeling tools for various use cases and allows for importing or exporting to over 26 formats, supporting model building with any architecture without the need for relabeling. Its fully managed labeling services are scalable and cost-effective, ensuring high-quality annotations by skilled, expert labelers. \n\n## (3) Encord"}
{"doc649": "Encord emerges as an advanced platform, offering tools for enterprises committed to advancing in semantic segmentation. The integration of AI-assisted labeling methodologies not only underscores its innovation but also accelerates the intricate processes of data annotation. This functionality proves important for segmenting various computer vision modalities. With its intuitive interface, Encord not only good at operational efficiency but also fosters a conducive environment for collaboration among other annotators, catering to expansive projects. Recognizing the diverse needs of businesses, Encord provides the option to engage with annotators possessing domain-specific expertise, thereby assuring impeccable accuracy and reliability of AI training datasets. \n\n## (4) Computer Vision Annotation Tool (Cvat)\n\nCVAT offers a flexible tool for or semantic segmentation annotation, crafted meticulously using machine learning. Its intuitive, fast interface addresses diverse annotation needs. CVAT's versatility is evident in its ability to manage tasks ranging from image classification and object detection to point clouds/Lidar and video annotation, adapting to different data types and delivering results that professionals can rely on. The tool facilitates a smoother, more accurate annotation process with features such as auto-annotation and AI integration. With a vibrant, collaborative community of users and contributors, CVAT continuously evolves and improves. Whether you're embarking on a small project or a substantial annotation task, CVAT stands ready to assist, committed to supporting users in achieving excellence in semantic segmentation and a variety of computer vision projects. "}
{"doc650": "4.3.2. *Decoder variants* At present, most of the advanced deep learning methods for semantic segmentation trace their roots to a shared progenitor: the fully convolutional network (FCN) (Long et al., 2015). The genius behind this approach was to harness the capabilities of existing CNNs as potent visual models capable of learning feature hierarchies. Aside from the FCN \nstructure, the segmentation model arena has witnessed the rise of numerous alternative strategies that strive to adapt classification networks for segmentation tasks, such as VGG16, into segmentationfriendly architectures. These methodologies generally involve stripping away fully connected layers from the classification network to form what is often termed an \"encoder.\" This modified component of the segmentation network then generates low-resolution feature maps or image representations. The principal challenge, however, is the translation of these low-resolution images into pixel-wise predictions that are essential for segmentation. This decoding task is often where these architectures show their distinct approaches. \n\nTake, for example, SegNet, an innovative deep FCN model tailored for semantic pixel-wise segmentation (Badrinarayanan et al., 2017). The architecture of SegNet is underpinned by a core segmentation engine, consisting of an encoder network and a corresponding decoder network, topped off with a pixel-wise classification layer. The encoder network is structurally identical to the 13 convolutional layers found in the VGG16 network. The role of the decoder network, on the other hand, is to transform the low-resolution feature maps from the encoder into full input resolution feature maps suitable for pixel-wise classification. In assessing SegNet's performance, it is compared against other renowned architectures such as FCN, DeepLab-LargeFOV, and DeconvNet. This comparative analysis underscores the balancing act between memory utilization and accuracy to secure robust segmentation performance. SegNet was primarily conceived with scene understanding applications in mind; hence, its design prioritizes efficiency in both memory use and computation time during inference. Furthermore, SegNet stands out for having markedly fewer trainable parameters compared to its competitors, while also offering support for end-to-end training via stochastic gradient descent. 4.3.3. *Integration of information across spatial scales* Semantic segmentation integrates data across various spatial scales, requiring a balance between local details and global context. Strategies examined in this section include post-processing refinement via conditional random fields (CRFs), the utilization of dilated convolutions, and the application of RNNs. \n\n(1) CRFs: It offer a structured framework facilitating the integration of low-level image information (for instance, pixel interactions) with the outputs produced by multi-class inference systems that yield per-pixel class scores (Sutton & McCallum, 2012). This integration process is pivotal, serving to encapsulate long-range dependencies and subtle local details effectively, elements often not adequately addressed by conventional CNNs. To secure a representation that is not only adaptable but also continuous, reflecting the probability distribution inherent in image data, a novel deep network dubbed the Gaussian Mean Field (GMF) \nnetwork was introduced (Vemulapalli et al., 2016). This innovative Gaussian CRF network is architecturally segmented into three distinct sub-networks. The initial sub-network, grounded in CNNs, is assigned the function of generating unary potentials. Sequentially, the second sub-network, also reliant on CNNs, is entrusted with the generation of pairwise potentials. The concluding segment, the GMF network, undertakes the task of Gaussian CRF inference. Within this architectural configuration, the GMF network sustains a continuous model, systematically refining its outputs to approximate the maximum a posteriori solution intrinsic to the Gaussian CRF. Intriguingly, empirical evidence indicates that the Gaussian CRF network, despite sustaining a continuous model, exhibits proficiency in tackling discrete labeling tasks effectively. This observed performance underscores the network's potential as a robust instrument for semantic segmentation, enhancing its ability to discern and interpret both global and local contextual elements within images. "}
{"doc651": "(2) Dilated Convolutions: Dilated Convolutions serve as a variant of Kronecker-factored convolutional filters, adept at facilitating the exponential expansion of receptive fields without concurrent loss of resolution. Noteworthy contributions employing dilated convolutions encompass the multi-scale context aggregation module \n(F. Yu & Koltun, 2015), the expedient network ENet (Paszke et al., 2016), and a refined iteration of DeepLab (L.-C. Chen et al., 2017). The aforementioned multi-scale context aggregation module (F. Yu & Koltun, 2015) ingeniously incorporates dilated convolutions, a strategic integration aiming at the accrual of contextual information spanning multiple scales. This incorporation fosters an enhanced comprehension of the global context, executed without relinquishing the granularity of local information. ENet (Paszke et al., 2016), architecturally crafted to suit real-time applications, strategically deploys dilated convolutions for the efficient processing of images manifesting diverse resolutions. Through the application of dilated convolutions, ENet demonstrates a commendable capability to capture both local and global features, thereby facilitating image analysis that is both swift and precise. Furthermore, an advanced version of the DeepLab model (L.-C. Chen et al., 2017) operationalizes dilated convolutions to address and surmount challenges related to the capture of minute details pivotal for semantic segmentation tasks. The model, by broadening the receptive field through the use of dilated convolutions, attains a deeper understanding of both object boundaries and the contextual information, culminating in enhanced accuracy in segmentation. \n\n(3) RNNs: RNNs, celebrated for their specialized topology, are proficient in modeling sequences across diverse temporal spans, thus skillfully capturing global contexts and enhancing semantic segmentation. However, the challenges materialize due to the intrinsic lack of sequential structure in images and the predisposition of traditional RNN architectures toward onedimensional inputs. A novel architecture, ReSeg (Visin et al., \n2016), which draws upon the ReNet model, navigates through these challenges. The methodology embarks with an initial processing of the input image through the primordial layers of the VGG-16 network, subsequently extracting feature maps which are refined by one or several ReNet layers to envelop global contexts. These polished maps are then upsampled to their original resolution using transposed convolutions. Within the ReNet layers, gated recurrent units (GRUs) are employed, esteemed for their equilibrium between memory usage and computational power. To manage challenges associated with modeling longterm dependencies and the vanishing gradients issue, innovations such as long short-term memory (LSTM) (Y. Yu et al., \n2019) and GRUs (Kanai et al., 2017) are incorporated. These networks, fashioned to preserve pivotal information across lengthy sequences, augment the ability to model intricate dependencies vital for semantic segmentation tasks. Architectures like ReSeg combine the strengths of various neural network designs, enhancing semantic segmentation by considering the bigger picture in images and addressing challenges to improve the system's performance.\" \n4.3.4. *Challenges and prospects: Semantic segmentation* Semantic segmentation occupies a critical role in the realm of autonomous driving systems, serving as an indispensable tool for the extraction and interpretation of environmental data. This process is central to the functionality of these systems, facilitating judicious and strategic decision-making that underpins autonomous navigation models. The domain of semantic segmentation presents a labyrinth of complexities, mirroring the unpredictable and vibrant dynamics of the real-world environment. Despite the inherent challenges, this field is characterized by considerable potential. The collaborative energies of academia and industry are fueling a dynamic cycle of innovation and enhancement, reflecting the dedication of researchers and practitioners in this specialty. Their collective endeavors are progressively establishing robust capabilities, providing avenues for advancement and opportunity within the landscape of semantic segmentation. The challenges inherent in this field are not prohibitive; rather, they serve as benchmarks guiding us towards a future where the capabilities of semantic segmentation are ever-increasing. Table 6 offers a detailed overview of the challenges and prospects in the scope of semantic segmentation. \n\n## 4.4. Multi-Object Tracking"}
{"doc652": "Multi-Object Tracking (MOT) is like the sharp eyes and keen senses of autonomous vehicles as they navigate the ever-changing city traffic scene (Ravindran et al., 2020). Urban streets are a bustling canvas, with vehicles and pedestrians moving in their own unique ways, speeds, and paths. In general, MOT doesn't work in isolation; it teams up with SLAM \ntechniques in a smooth partnership (Bescos et al., 2021). These advanced technologies work together, allowing vehicles not only to see and track what's happening around them but also to build a detailed, responsive map of their surroundings at the same time. \n\n## 4.4.1. Framework Of Mot\n\nMOT bears the responsibility of detecting multiple objects within its purview, retaining the unique identity assigned to each and charting their respective trajectories over time, all while assimilating a steady stream of incoming video data. Whether the object in question is a pedestrian or another vehicle, it is duly recognized, identified, and monitored, with its trajectory outlined and updated upon the virtual canvas of the roadmap. MOT can be classified into two distinct modalities: online tracking and offline tracking. Each modality shares foundational principles but diverges in approach and application, enriching the broader MOT framework with multifaceted capabilities. "}
{"doc653": "| Challenges                                                                                                                                                                                       | Prospects                                                                                                                                                                                       |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Quality and Quantity of Annotations:  High-quality, extensive annotations  are essential for training semantic  segmentation algorithms but are costly  and error-prone when produced  manually. | Deep Learning Enhancements:  Advances in deep learning, particularly  convolutional neural networks, are  expected to boost the accuracy and  resilience of semantic segmentation  techniques.  |\n| Real-time Processing: Algorithms must  process high-resolution images swiftly  for autonomous vehicles to make  immediate decisions.                                                             | Transfer Learning and Data  Augmentation: Employing pre-trained  models and expanding dataset  variability can reduce the need for large  annotated datasets and enhance  algorithm efficiency. |\n| Environmental Robustness:  Algorithms must perform reliably  under various conditions such as fog,  rain, nighttime, or direct sunlight.                                                         | Edge Computing and Hardware  Acceleration: New developments in  edge computing and specialized  hardware aim to reduce latency,  facilitating real-time processing.                             |\n| Class Imbalance: Disproportionate  representation of object classes in  training data can bias predictions  toward more common classes.                                                          | Active Learning and Unsupervised  Learning: These methodologies can  minimize the need for large annotated  datasets by focusing annotation efforts  and utilizing unlabeled data.              |\n| Computational Resources: The  significant computational power  required for high-resolution image  processing in semantic segmentation  poses training and real-time  application challenges.    | Multi-modal Sensor Fusion:  Combining data from various sensors  such as cameras, LIDAR, and radar can  enhance environmental adaptability and  segmentation precision.                         |\n\n(i) Online Tracking: This method stands out for its timely and stepby-step handling of image frames (Bescos et al., 2021; Xiang et al., 2015). It creates a real-time picture of motion, tracing the paths of objects as they move and interact in traffic (Z. Wang et al., 2020). Past movements are shown with arrows, forming a visual story of their paths. This visual representation is essential for online tracking, capturing the dynamic journey of each object. \n\nThese objects aren't passive; they are actively highlighted, pinpointed, and given unique identifiers. Their paths are continuously updated as the scene unfolds, showcasing adaptability in response to changing traffic conditions. By tuning into the realtime flow of traffic and skillfully understanding its intricate patterns, it plays a crucial role in safely and efficiently guiding autonomous vehicles through the varied and ever-changing urban traffic landscape. Built upon its dedication to up-to-theminute data, Online tracking lays the foundation for the advancing story of autonomous driving technologies. "}
{"doc654": "(ii) Offline Tracking: It presents a holistic approach to data analysis, diverging from the frame-by-frame scrutiny characteristic of other techniques. Rather than evaluating frames in isolation, this method aggregates requisite data prior to initiating analysis, fostering a comprehensive examination where individual frames are analyzed collectively, thereby amalgamating diverse data into a coherent result. However, this simultaneous processing of frames encounters constraints, notably computational power and memory capacity limitations. A pragmatic resolution to these constraints is the segmentation of extensive data into smaller, manageable portions or abbreviated video clips. These truncated segments are individually analyzed, adhering to either a hierarchical or sequential methodology as necessitated by the specific task. Subsequently, the analytical outcomes of these discrete segments are meticulously integrated, yielding a coherent and precise depiction of the intricate environment under observation, effectively synthesizing the individual analyses into a unified and accurate representation that encapsulates the complexity of the observed scenario. \n\nMOT for autonomous driving unfolds as a refined system with crucial components, each contributing to efficient tracking of multiple objects. \n\nObject detection, the system's bedrock, identifies and pinpoints objects within the vehicle's perception using pre-trained algorithms such as YOLO, Faster R-CNN, or SSD, as discussed earlier. These tools discern and distinguish between various objects with precision. Feature extraction follows detection, distilling the essence of each detected object and carving out distinctive features pivotal for tracking algorithms. "}
{"doc655": "This process ensures each object is identified and tracked through frame sequences. \n\nData association matches detected objects across sequential frames with precision. The matching process considers appearance and motion, employing cost functions and techniques such as the Hungarian algorithm (Weng et al., 2020), joint probabilistic data association (JPDA) \n(Shenoi et al., 2020), or multi-hypothesis tracking (MHT) (Xie et al., 2021) to solve assignment problems, associating current detections with pre-existing tracks accurately. Motion models predict future object locations, with models embodying constant velocity or acceleration providing essential foresight into object movements. Filtering techniques, such as Kalman filters (G. Guo & Zhao, 2022) or particle filters \n(Xia et al., 2021), estimate an object's state, providing accurate and reliable tracking output. Finally, the system manages and updates tracks, initiating new tracks for newly detected objects and terminating old tracks for irrelevant objects. Mechanisms for handling occlusions are integrated, ensuring accurate tracking even in complex driving environments. \n\nIn the world of traffic, especially in the realm of autonomous driving, every part of MOT has its role, working diligently and precisely. "}
{"doc656": "Together, they weave a story that prioritizes safety and responsiveness. \n\nEach piece in this MOT system adds to the smooth and secure experience of autonomous driving, bringing technology and safety together in the name of innovation. 4.4.2. *Challenges and prospects: Multi-object tracking* Within the technological framework, MOT emerges as a crucial focus, navigating through sequential frames with precision, thereby becoming essential for applications crucial to the areas of traffic control and oversight. The ability to understand the subtle trajectories and directions of multiple concurrently moving objects unfolds as a source of valuable insights, highlighting ways to alleviate traffic bottlenecks and efficiently manage the rerouting of vehicles through areas of lesser congestion. For scholars, practitioners, and policymakers deeply engaged in the complex field of autonomous driving and traffic management, developing a deep, subtle understanding of the challenges and prospects (Table 7) within MOT is essential. The journey through this terrain is filled with challenges; however, the prospects appearing on the horizon are enticing. Advanced MOT techniques offer the promise of a future where the movement and flow of traffic are not only efficient but also intelligent and responsive, moving gracefully in response to the dynamic and constantly changing urban environment. This narrative serves as a concise, yet insightful introduction, leading the reader into a deeper, more subtle exploration and consideration of the complex challenges and bright prospects closely connected to the practice of MOT within the context of autonomous driving. \n\n## 4.5. Localization And Mapping"}
{"doc657": "At present, the most widely used positioning method is based on communication positioning, such as GNSS (Joubert et al., 2020) and Internet of Vehicles (IoV) (Ji et al., 2020). However, Under the conditions of high buildings, underground garages, indoor or mountainous terrain, GNSS signals will be blocked and have multi-channel effect, which will lead to decreased positioning accuracy or even errors. GNSS is susceptible to interference from electromagnetic wave, atmosphere, and other factors, with long transmission delay and low update frequency (1 Hz ~ 50 Hz). IoV positioning is currently expensive. So SLAM \nhas the potential to become a mainstream location approach. This section will introduce several commonly used SLAM systems, including the \n\n| Challenges                                                                                                                                               | Prospects                                                                                                                                                               |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Data Association Challenges:  Associating data from various sensors  and timeframes introduces ambiguity  and uncertainty, especially in multiobject tracking.                                                                                                                                                          | Advanced Algorithms: Emerging  algorithms specialized in data  association promise to resolve  ambiguities and enhance the precision of  multi-object tracking.         |\n| Real-time Processing: Ensuring realtime performance with high accuracy  is difficult due to the complexity of  tracking algorithms.                                                                                                                                                          | Hardware Improvements: Cutting-edge  computing hardware is expected to boost  real-time processing capabilities,  enabling more accurate and faster  tracking.          |\n| Occlusion Handling: Accurately  tracking multiple objects in scenarios  where they may obscure each other is  particularly challenging in dense  scenes. | Deep Learning Techniques: Advanced  deep learning and AI techniques are  being developed to improve occlusion  handling, thereby enhancing tracking in  complex scenes. |\n| Variable Illumination and  Appearance: Variations in lighting  and object appearance add complexity  to tracking, affecting reliability.                 | Adaptive Methods: Research into  adaptive techniques aims to better cope  with environmental variations,  improving tracking reliability under  changing conditions.    |\n| Limited Resources: Computational,  energy, and memory constraints in  embedded systems pose challenges for  the deployment of tracking  algorithms.      | Optimization Techniques: Ongoing  research focuses on optimizing  algorithms to be resource-efficient  without compromising accuracy,  enabling effective tracking in limitedresource settings.                                                                                                                                                                         |\n\narchitecture and development of visual SLAM, lidar SLAM and fusion SLAM. "}
{"doc658": "## 4.5.1. Visual Slam\n\nVisual SLAM, a cornerstone of autonomous navigation, discerns a vehicle's precise location and its environment through a four-part system: front-end or Visual Odometry (VO), back-end, loop closure detection, and mapping (Sun et al., 2021). This process primarily uses vehicleinstalled sensors and GPS. While VO estimates sensor motion using either feature point or direct methods, its data requires optimization to prevent error accumulation and resultant drift. The back-end enhances this data for globally consistent trajectories and maps. Loop closure detection aids in drift reduction, while mapping establishes critical navigational and obstacle avoidance features. Based on image information use, visual SLAM methods fall into direct, indirect, and semidirect categories (Table 8), each explored in depth in subsequent sections. \n\n4.5.1.1. *Direct methods.* The direct method estimates the motion of the camera according to the brightness information of the pixels, and can eliminate the calculation of key points and descriptors. Therefore, it not only avoids the calculation time of features, but also avoids the situation of missing features. The direct method works if there are light and dark changes in the scene (which can be gradients, without forming local image gradients). The direct sparse mapping (Zubizarreta et al., 2020) \nscheme is a complete monocular SLAM system based on the direct method. The direct method SLAM system usually uses the photometric error for BA optimization, but the direct method cannot rely on itself to solve the reobservation problem of the same scene and the fusion problem of the same point (so the loop closure detection of the direct method relies on feature points to solve, such as LSD-SLAM). DSM solves this problem and is the first SLAM system based entirely on the direct method to achieve loop closure detection and map reuse, and achieves the highest accuracy in the direct method SLAM on the EuRoC dataset. "}
{"doc659": "DL-SLAM (Li et al., 2019) solves the problem that the map cannot perform efficient loop detection by extracting segment features from the 2.5D heightmap and integrated the 2.5D segment-based loop closure to DLO. \n\nAnother approach grabbed attention since the advent of deep learning with focus on CNNs. Quite interesting results were observed especially with the work on CNN-SLAM (Tateno et al., 2017). It was shown through experiments that robot pose or localization could be achieved from a pair of images acquired by a moving robot through deep learning or CNN. Even though the CNN-SLAM approach is promising, this approach has invited few challenges that needs to be addressed. Deep learning requires high-end Graphic Processing Unit (GPU) systems, which is still a challenge for robotic embedded systems. Moreover, SLAM systems are seen to be directed on continuous open-world scenes where the environment keeps changing. These changes need to be learned on a continuous basis for a deep learning system. From the various techniques introduced in SLAM, one can observe that SLAM is inclined to combine various fields such as signal processing, deep learning (CNN-SLAM) and more significantly computer vision. CubeSLAM (Yang & Scherer, 2019) demonstrates that object detection and SLAM benefit each other. This also shows that neural networks can be used for feature extraction of SLAM instead of geometrically extracting features. DROID-SLAM (Teed & Deng, 2021) is an end-to-end system, which builds a neural network into the SfM pipeline to improve keypoint localization accuracy. Since neural network eliminates the manually designed feature extraction link, more and more researchers begin to introduce it into SLAM object recognition and segmentation, and even the pose estimation and loop detection of SLAM itself. At present, some papers based on Gaussian process regression and deviation correction are expected to be replaced by neural networks (Oliveira et al., 2020; Tang et al., 2018). 4.5.1.2. *Indirect method.* The indirect method uses the features (points or lines) in the image for matching, and then solves it according to the matching relationship. Its optimization objective function is the reprojection error of the feature, and the optimized variable is generally the relative pose. SLAM has the problem of being difficult to start in unknown locations in unknown environments. ORB-SLAM is a system built on PTAM that is robust to severe motion clutter, allows wide baseline loop closure and repositioning, and includes fully automatic initialization. Due to the use of ORB feature extraction, feature matching between image frames is very easy, reducing the phenomenon of feature point loss and mismatching, and the speed of image feature extraction is greatly improved. REF. (Mur-Artal & Tardos, \u00b4 2017) built ORB-SLAM2 based on ORB-SLAM that can be used on monocular, stereo and RGBD cameras. ORB-SLAM3 (Campos et al., 2021) supports more devices and functions, supporting monocular, binocular, RGB-D cameras, pinhole, fisheye, visual inertial odometry, multi-map SLAM, etc., covering almost all branches of visual SLAM. In general, the basic framework and code structure of ORB-SLAM3 are extensions of ORBSLAM2, but many new methods have been added to achieve better results, which are reflected in the following three aspects: the construction of a feature-based highly integrated vision -Inertial navigation SLAM \nsystem, more robust, suitable for indoor/outdoor large/small scenes, and the accuracy is improved simultaneously. \n\n4.5.1.3. *Semi-direct method.* The realm of autonomous navigation has witnessed remarkable strides with the advent of Semi-Direct Visual Odometry (SVO-SLAM) (Engel et al., 2014; Forster et al., 2014), presenting an approach to camera pose estimation that deviates notably from conventional strategies. SVO-SLAM introduces a semi-direct method wherein the camera pose is determined not by directly matching an entire image, but through identifying and aligning feature points within specific image blocks. This divergence proffers an alternative to the prevailing direct matching methodologies commonly associated with red\u2013green\u2013blue-depth (RGBD) sensors, which innately have the ability to procure depth data for an entire image, thereby facilitating the direct matching process. Opting for a distinct pathway, the semi-direct "}
{"doc660": "| Table 8  Classification and characteristics of simultaneous localization and mapping techniques.  Techniques Direct SLAM Indirect SLAM   | Semi-Indirect SLAM                                        |                                           |                                              |\n|------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------|-------------------------------------------|----------------------------------------------|\n| Definition                                                                                                                               | Using pixel-level intensity information for feature       | By extracting and matching feature points | Combines pixel-level information and feature |\n| extraction and matching                                                                                                                  | or descriptors                                            | points                                    |                                              |\n| Map Representation                                                                                                                       | Dense or sparse point cloud                               | Sparse feature-based map                  | Sparse feature-based map                     |\n| Feature Tracking                                                                                                                         | No explicit requirement                                   | Needed for operation                      | Necessary for operation                      |\n| Camera Motion                                                                                                                            | Simultaneous estimation of camera poses and 3D points     | Sequential estimation of camera poses and | Simultaneous estimation of camera poses and  |\n| Estimation                                                                                                                               | feature depths                                            | feature depths                            |                                              |\n| Computational                                                                                                                            | High computational complexity                             | Efficient computational requirements      | Moderate computational requirements          |\n| Efficiency  Robustness                                                                                                                   | Less robust to feature occlusions and repetitive patterns | More robust to feature occlusions and     | Moderately robust to feature occlusions and  |\n| repetitive patterns                                                                                                                      | repetitive patterns                                       |                                           |                                              |\n| Scale Drift                                                                                                                              | Prone to scale drift                                      | Less prone to scale drift                 | Less prone to scale drift                    |\n\n13 method, rather than strictly adhering to a feature-based method\u2014which can be computationally intensive and potentially fallible in texturedeficient environments\u2014amalgamates the merits of the direct method. \n\nConsequently, it employs pixel intensity information intrinsic to images to establish correspondences, engendering more astute and efficient pose estimation. The adeptness and scalability of SVO-SLAM are illuminated through this approach, capacitating it to accommodate a wide spectrum of scenarios, from feature-rich environments to those characterized by sparse or poor textural features, while maintaining impeccable performance and precision. "}
{"doc661": "## 4.5.2. Laser Slam\n\nHector_SLAM (Kohlbrecher et al., 2011) uses the optimization method for the laser SLAM algorithm for inter-frame matching. The search space is not large, odometer information is not required, and the code is short. And only the endpoints of the scan are processed (the laser scan structure is not used), so the IMU can be used to adjust the laser scan attitude. The disadvantage is that the effect is not good on devices with insufficient radar frequency, and it is easy to match incorrectly when turning quickly; there is no loop closure, so if the cumulative error is too large, HectorSLAM has no map adjustment ability, and the optimization and matching between frames is also performed on the global map, cpu resources. consumes a lot. Karto is graph-optimized SLAM, including loopback detection, is suitable for large-area mapping. The VO frame matching adopts the method of correlative scan matcher to perform rough and fine matching. Karto does not have the concept of submap in loopback detection, and it is all stored in the Mapper-sensorManager in the form of keyScan. The window generates a localMap for matching. The loop closures of local and global store the assigned ID \ninformation sequentially according to the graph structure and Mappersensor-Managerss, select candidates to generate localMap for matching, and further determine the closed loop according to the score. \n\nCooperation of the two algorithms allows accurate motion estimation and mapping in real-time. Compared with LOAM, LeGO-LOAM \n(Shan & Englot, 2018) changed the extraction form of feature points and added back-end optimization, so that the constructed map is more perfect. IMLS-SLAM (Deschaud, 2018) uses 3D data directly by scan-tomodel matching from 3D radar and representing them with implicit moving least squares (IMLS) and achieves the effect of reducing drift. "}
{"doc662": "This is a solution for mapping and positioning based on the extraction of line segments in 3D point clouds (Y. Guo et al., 2020). The 3D point cloud is segmented, and different environmental objects are divided into different segments, thus a new map representation method is proposed: \nSegmap. Compared with existing feature extractors that are only used for localization, Segmap uses data-driven (deep learning) descriptors to extract semantic feature information. Data processing at the semantic information layer greatly reduces the amount of computation, and the semantic feature descriptor with smaller dimensions solves the real-time data compression problem of single-robot and multi-robot systems. This 3D laser SLAM framework utilizing CNN semantic information has more advantages than traditional SLAM in multi-robot global path planning scenarios (Dub\u00b4e, Cramariuc, et al., 2018; Dub\u00b4e et al., 2017; Dub\u00b4e, Gollub, et al., 2018). \n\n## 4.5.3. Fusion Slam\n\nNavigating the multifaceted domain of high-precision positioning, modern vehicles adroitly utilize a spectrum of sensors, synchronizing their operations to secure enhanced locational accuracy. BAD SLAM (Schops et al., 2019), for instance, presents a calibration benchmark that harmonizes synchronized global shutter RGB cameras with depth sensors, assuring a tightly knit and calibrated interaction among assorted sensors. LIC-Fusion (Zuo et al., 2019) strategically employs an algorithm that melds Inertial Measurement Unit (IMU) measurements with sparse visual features and extracted lidar points, enhancing multimodal sensor fusion. This integration notably improves accuracy and robustness, especially in contexts involving aggressive motions. DM-VIO, \nintroduced in (Von Stumberg & Cremers, 2022), navigates through monocular visual-inertial odometry, wielding two pioneering techniques: delayed marginalization and pose graph bundle adjustment. It gracefully manages visual data, weaving dynamic weight into visual residuals and solidly embracing photometric uncertainties. The \n\"delayed marginalization\" strategy allows for a meticulous approach where marginalization is postponed, facilitating subsequent graph updates and enabling the creation of a fresh, consistently linearized marginalization prior. This permits the intertwining of IMU data into already marginalized states, forming the bedrock for the innovative pose graph bundle adjustment and assisting IMU initialization. When put to the test across various scenarios and datasets, DM-VIO not only outperforms existing methodologies in visual-inertial odometry but also surpasses stereo-inertial methods using a singular camera and IMU, \nmarking a notable advancement in visual-inertial navigation. Both initiatives underscore the continual evolution of algorithmic approaches aiming to refine the precision of sensor data integration in complex environments. ORB-SLAM3 (Campos et al., 2021), on the other hand, expands support for fish-eye cameras and integrates visual and IMU systems, enabling the capture of a more generous field of view and thus, becoming valuable in restricted environments. The scrupulous integration and fusion of various sensors, along with the perpetual progression of algorithms, are pivotal in augmenting the precision and robustness of SLAM systems in automotive applications. "}
{"doc663": "Maps hold a pivotal position in SLAM applications, embodying various forms\u2014ranging from point cloud maps, octree maps, and grid maps to topological maps\u2014each serving distinctive purposes. The selection of both map type and associated algorithm is inherently tethered to the unique requirements and specifications of the given SLAM \napplication. Broadly speaking, maps within this context can be compartmentalized into three primary categories: metric maps, topological maps, and semantic maps. Point cloud-based mapping and localization emerge as prevalent methodologies within this spectrum of mapping techniques, garnering widespread acclaim and utilization. However, it is imperative to acknowledge the inherent limitations of these methods; the expansive scale of point cloud maps, coupled with their constraints in accommodating dynamic objects, presents tangible challenges. In light of these limitations, octree maps\u2014which boast superior compressibility\u2014have been identified and employed as viable alternatives for diverse SLAM applications (Vespa et al., 2018). When navigating the process of map type selection for SLAM, a multitude of factors warrant careful consideration, including the requisite spatial accuracy, inherent complexity, overall scale of the application, and the imperative for semantic information. These considerations are instrumental in aligning the selected map type with the demands and expectations of the specific SLAM application in focus. \n\nSLAM is experiencing robust advancements. In environments with low texture, where salient features are scarce, SLAM's efficacy diminishes. Radar-based SLAM is hindered by the substantial cost of radar and its struggle with low texture and dynamic environments. Fusion SLAM, integrating data from various sensors, is progressing rapidly; however, it necessitates uniform processing of data types, timestamps, and coordinate systems. Deep learning-based Semantic SLAM holds promise for high-precision, real-time positioning in extensive settings, and is likely to supersede traditional geometric SLAM, excelling in global optimization, loop closure, and relocalization. Additionally, deep neural networks (DNNs) are being employed in self-supervised motion estimation to mitigate multimodal data discrepancies, thereby enhancing the accuracy and dependability of all-weather autonomous driving (Fig. 8). \n\n4.5.4. *Challenges and prospects: Localization and mapping* Advancements in sensor technology, artificial intelligence, and computational power are continually reshaping the domain of localization and mapping for autonomous driving systems. High-definition mapping, combined with sophisticated algorithms for SLAM, is empowering vehicles "}
{"doc664": "![14_image_0.png](14_image_0.png)\n\nwith unprecedented spatial awareness. The integration of real-time kinematic positioning with IMUs and advancements in machine learning for sensor fusion contribute to an ever-improving accuracy in vehicle localization. Furthermore, the proliferation of 5G connectivity and edge computing offers the prospect of cloud-assisted driving, where vehicles can access updated maps and localization data with minimal latency. As these technologies mature, they promise to mitigate current limitations, such as the dependency on high-visibility conditions and the need for intensive computational resources. The anticipated synergy between these technological developments is poised to significantly elevate the robustness and reliability of localization and mapping systems, reinforcing them as pivotal components in the autonomous driving stack, which are meticulously summarized in Table 9. \n\n## 5. **Motion Planning And Decision-Making**"}
{"doc665": "Deep learning has profoundly reshaped the field of autonomous driving, particularly in the facets of motion planning and decisionmaking, thereby drastically boosting both the performance and safety standards of such vehicles. Motion planning is the process of devising an optimal route from a starting point to a destination, while skirting around obstacles and abiding by a set of constraints. Conversely, decision-making and behavior arbitration involve the intelligent processing of decisions, leveraging real-time environmental perceptions, sensor data, and established rules to enable vehicles to suitably respond to dynamic traffic conditions. Key elements in these domains, such as path planning, trajectory prediction, and behavior arbitration, witness \n\n## 5.1. Path Planning\n\nMotion planning includes path planning and trajectory planning, both of which belong to the planning layer. The path planning is to move the autonomous driving from the starting position to the ending position according to a certain path strategy. Path planning is one of the main research contents of motion planning. Global path planning requires all environmental information to be mastered, and global path planning can be performed based on high-definition (HD) maps. Local path planning requires the real-time information of sensors to understand the environment, and then determine the distribution information such as obstacles, so as to select the local optimal path. Traditional path planning methods can be divided into search-based path planning algorithms, such as Dijkstra (Daniel et al., 2010; T. Zhang et al., 2021), \nwhich are also raster map-based search algorithms. Probability-based path planning algorithms, such as the RRT series (Karaman et al., \n2011) of algorithms. This section focuses on the neural network algorithms most relevant to AI. "}
{"doc666": "For autonomous driving, AI can imitate and reproduce human reasoning and learning behavior. This requires autonomous driving to think like humans in order to adapt to the environment and predict future trajectory behaviors. From this aspect, AI is of great significance \n\n| Challenges and prospects of localization and mapping.  Research Area Challenges Prospects for Improvement  Dynamic  Rapid environmental  Environments  changes, such as construction  and weather variations, make  it difficult to maintain up-todate maps.  Sensor fusion integrating  data from diverse sensors to  improve localization  accuracy and adapt to  changes, ensuring effective  navigation.  GPS  In urban areas or tunnels, GPS  Dependability  signals can be unreliable or  unavailable, affecting  localization.  Advanced AI and machine  learning techniques to  predict and compensate for  GPS loss, using historical   |\n|---|\n\nAdvanced AI and machine "}
{"doc667": "## 5.2. Trajectory Prediction\n\n5.2.1. *Generative models* Generative models have shown good results in tasks such as imageto-image translation and image synthesis, super-resolution, which have multiple possibilities for a given input and output. The authors of \n(Petrovich et al., 2021) introduce a Deep Stochastic IOC1 RNN encoderdecoder framework that uses a conditional variational autoencoder to obtain a set of different hypothetical future prediction samples for future prediction tasks on multiple interacting agents in dynamic scenes. \n\nHowever, they lack the simulation of human interaction in crowded scenes. An alternative approach, generative adversarial networks (GANs) offers a promising tool that contains two models, one is a generative model and the other is a discriminative model. The task of a generative model is to generate instances that look natural and real, similar to the original data. The task of a discriminative model is to judge whether a given instance appears to be naturally real or artificial, where the training process is a minimax game between a generative model and a discriminative model; this overcomes the difficulty of approximating intractable probability calculations (G. Zhang et al., 2021). A generative adversarial pipeline for crowd trajectory prediction and group membership identification in a crowd was proposed by REF. (Fernando et al., 2018a). Dimension extracts the most discriminative features and reduces them by DBSCAN clustering. They model the local neighborhood of a pedestrian of interest with a soft and hard attention framework (Fernando et al., 2018b), where the soft attention context vector is used to embed trajectory information from the pedestrian of interest, and the hardwired attention context vector is used for adjacent trajectories. The method exhibits encouraging results on learning complex real-world human navigation behaviors on multiple public benchmarks. REF. (Gupta et al., 2018) integrated the extraction and dimensionality reduction of crowd trajectory features into the same framework, in which the encoding module is responsible for trajectory feature extraction, and the pooling module replaces clustering for feature dimensionality reduction. The authors also propose a simple diversity loss function, coupled with pooling layers to encourage the network to produce globally consistent, socially compatible diversity samples. In addition to the generative models of the above methods, some researchers use the generative model of flow-base to predict the agent \n(Rhinehart et al., 2019). "}
{"doc668": "## 5.2.2. Gnn-Based Models\n\nAggregation of feature states in aggregation layers of earlier recurrent architectures is neither intuitive nor straightforward, and may not correctly model interactions between pedestrians. In recent years, variants of GNNs (J. Zhou et al., 2020), such as graph convolutional network (GCN) (S. Zhang et al., 2019) have demonstrated groundbreaking performances across a wide range of tasks. A social spatiotemporal graph CNNs (STGCNNs) (Mohamed et al., 2020) pedestrian trajectories as a spatiotemporal graph, the edges of the graph represent the interactions between pedestrians, and an adjacency matrix with a kernel function measures pedestrians influence between. The STGCNN \nand time-extrapolator (TXP)\u2013CNN in the model operate on the spatiotemporal graph, so that the model can be in one shot to predict the entire sequence. Experiments show that Social-STGCNN outperforms previous models in both prediction accuracy and inference speed. Like SocialSTGCNN, temporal point cloud networks (TPCN) (Ye et al., 2021) also divides trace prediction into spatial and temporal dimensions to capture spatial and temporal information, but the author believes that it is difficult to deal with large-scale scenes containing a large number of nodes and vertices based on GCN, so a point cloud learning strategy is adopted. The prediction task is accomplished through joint learning between spatial and temporal modules. The spatial module takes advantage of the complementary information between voxel and point representations, preserving the geometric information of the graph. The temporal module utilizes the proposed dynamic temporal learning method: multi-interval learning and instance pooling to capture more fine-grained sequential information. \n\n## 5.2.3. Multimodal Deep Learning Fusion"}
{"doc669": "In the realm of trajectory prediction, the extrapolation of observed motion patterns from historical data into future estimates is paramount. Sequence models rooted in deep learning, especially RNNs, have demonstrated proficiency in navigating such challenges due to their capacity to articulate temporal dependencies. In a discernible trend towards amplifying accuracy and extending the predictive time horizon in recent endeavors, there is an incorporation of multimodal models. This synthesis enables the intelligent models that not only project trajectories across temporal horizons but also capture the intricate spatial relationships and temporal patterns, thereby enhancing the model's predictive acumen and reliability in trajectory forecasting. \n\nThe combination of RNN and DRL to predict the behavior of pedestrians and vehicles is a hotspot. RNNs can encode the motion information of pedestrians of interest and other surrounding pedestrians, and map these encoded dynamics into feature maps, maintaining the structural integrity of neighbors. A DRL model will choose the best predictive strategy. REF. (Fernando et al., 2019) proposed an inverse reinforcement learning (D-IRL) method based on an attention framework together with LSTMs to predict human trajectories in the far future. The reward prediction network of this architecture is a FCN, ensuring that the learned reward map covers all regions of the environment, incorporates structural factors such as buildings and paths that affect pedestrian behavior, and utilizes a combination of soft and hardconnected attention to embed features from the agent's local neighborhood. The method achieves encouraging results in predicting pedestrian behavior in the far future. To validate the effectiveness of DIRL, the authors of (Fernando et al., 2020) quantitatively and qualitatively evaluate these frameworks on two public driver benchmark datasets and demonstrate the utility of D-IRL, especially when predicting longer trajectories. good performance. Nowadays, reinforcement learning is also widely used in navigation and vehicle following (Cai et al., 2019; Gao et al., 2018) proposes a CIL end-to-end model that receives camera images, high-level commands, and the autonomous driving's previous trajectory, and learns to output a collision-free trajectory 3 s later. The network consists of 3 sub-networks for performing 3 basic driving tasks: going straight, turning left and turning right. These sub-networks are then fed into the LSTM/FCC network to output trajectories. (Everett et al., 2018) proposes a collision avoidance algorithm, GA3C-CADRL (GPU/CPU Asynchronous Advantage Actor-Critic for Collision Avoidance with Deep RL), which does not require any other agents Simulation training with DRL with knowledge of dynamics, and a strategy borrowed from LSTM networks in natural language processing, which enables the algorithm to use the observations of any number of other agents, rather than Previous methods with fixed observation size. \n\n## 5.3. Decision-Making 5.3.1. Ai Logic-Based Approach"}
{"doc670": "Introducing inference into motion planning for intelligent driving is a reasonable choice. An inference engine is a component of an AI system that applies logical rules to a knowledge graph (or foundation) to reveal new facts and relationships. The inference engine can be implemented inductively or deductively. Among all reasoning engines, the rule-based reasoning algorithm (expert system) is the most famous, with the statement: \"if observe, then act\". Expert systems rely on a knowledge base and an inference engine to automate the inference system and solve specific complex tasks. When the knowledge base is updated, a recursive mechanism must be used to ensure the convergence of the new rule system. The recursive mechanism can transform a big problem into many small problems and solve it conveniently. The advantages of this system are clear semantics, intuitive performance, and the ability to clearly describe the objective laws or domain concepts implicit in data distribution. However, the disadvantage is that designing a large number of rules and circular reasoning is necessary, which prolongs calculation time, requires expert guidance in the field, and has poor portability and learning ability. \n\nThe emergence of finite state machine (FSM) (Y. Chen et al., 2019) \nsolves the problem of infinite exhaustive rules. FSM describes states and transitions between states that are triggered in response to changes in the environment. Logical assertions and conditions contribute to reasoning explanatory power. The system is simple and controllable, easy to develop, and can describe complex state relationships. The main disadvantages are the acquisition, maintenance and storage of knowledge bases, the expert generation of engines, the discretization of a large number of environmental variables, and due to the determinism based on knowledge, it cannot be generalized to unknown situations. \n\nIn the realm of autonomous driving, decision-making tools are critical for assessing various scenarios and making informed choices. The Decision Tree is one such tool that elucidates the mechanics of rulebased decision-making (Charbuty & Abdulazeez, 2021). It comprehensively enumerates possible strategies, making it well-suited for applications such as vehicle lane-change predictions (C. Wang et al., 2019), \ncollision predictions in autonomous driving (Osman et al., 2019), and pedestrian behavior predictions (Xin et al., 2022) in relatively simple scenarios. In scenarios characterized by dynamic uncertainty, more sophisticated models come into play. For instance, REF. (Luque & Straub, 2019) employed a Dynamic Bayesian Network which hinges on a statistical representation of causality based on probability transitions. "}
{"doc671": "Moreover, REF. (X. Liu et al., 2022) tackled the problem of tentacle trajectory selection by modeling it as a markov decision process (MDP), wherein among navigable trajectories, a tentacle acts as the local reference trajectory for the vehicle (Lin et al., 2021). \n\nWhen dealing with environments that are both dynamic and uncertain, the partially observable markov decision process (POMDP) offers a mathematically sound model that links perception and planning. This is particularly useful for decision-making problems involving interdependent behaviors of multiple agents. REF. (Cubuktepe et al., 2021) utilized a robust convex optimization technique amenable to computing solutions for multi-state, uncertain, and partially observable problems. However, solving POMDPs in complex scenarios is computationally challenging due to the iterative nature of the solutions. This has led to the coupling of POMDPs with DRL (G. Singh et al., 2021; Song et al., 2022). Notably, advancements in time-series models have further bolstered the synthesis of POMDPs and DRL, circumventing the intricate solution process (S. Kumar et al., 2020; Parisotto et al., 2020). \n\nThe way autonomous driving systems make decisions is varied and complex. They use everything from simple decision trees to more advanced systems like dynamic Bayesian networks and partially observable Markov decision processes (POMDPs). The choice of which method to use depends on how complicated and unpredictable the driving environment is. As these decision-making systems get better, they are becoming more capable of making the precise and critical decisions needed for safe and smart self-driving. We're entering a time when these systems can adapt and respond with incredible accuracy, which is a big step forward for the reliability and independence of autonomous vehicles in the real world. "}
{"doc672": "## 5.3.2. Ai Heuristic Algorithms\n\nHeuristic algorithms are proposed relative to optimization algorithms. A heuristic algorithm (Goli et al., 2021) can be defined as follows: an algorithm based on intuition or empirical construction that gives a feasible solution for each instance of the combinatorial optimization problem to be solved at an acceptable cost (referring to computing time and space), and the feasible solution is the same as the optimal solution. The degree of deviation of the solution cannot generally be predicted. When faced with complex problems, the heuristic algorithm has lower complexity and faster calculation speed than the traditional exhaustive method, but cannot guarantee the convergence to the global optimal solution. The basic idea in motion planning is to discretize the state space into a graph in a certain way, and then use various heuristic search algorithms to search for feasible solutions or even optimal solutions. This kind of algorithm has analytical completeness and even analytical optimality, and this kind of algorithm is relatively mature now. A support vector machine (SVM) is a statistical learning classifier that relies on information search for the intent of an agent. The literature (Vallon et al., 2017) proposes a classifier autonomous lane changing algorithm based SVM. Several SVMs are trained using data from human drivers' actual lane changing and lane keeping demonstrations. \n\nMetaheuristic algorithms are widely used heuristic algorithms, which include the tabu search algorithm, simulated annealing algorithm, genetic algorithm, ant colony optimization algorithm, particle swarm optimization algorithm, artificial fish swarm algorithm, artificial bee colony algorithm, and artificial neural network algorithm (Osaba et al., 2021). This paper mainly focuses on the research status of the artificial neural network algorithm. An artificial neural network is an information processing system designed to mimic the structure and function of the human brain. Like the multilayer perceptron, neural networks learn based on misguided, constantly adjusting weights. "}
{"doc673": "Neural networks can handle supervised learning, unsupervised learning, and reinforcement learning, and their main advantage in autonomous driving is their ability to learn through training on multi-dimensional data with strong learning capabilities. However, the reasons for their decisions lack interpretability and are not as intuitive as rule-based learning. Many researchers treat neural networks as black boxes. If the training method is incorrect, they may make poor decisions due to the variety of vehicle states. Specifically, the system must learn the rules to apply in each environment, and large amounts of human-labeled data are required to improve accuracy. \n\n5.3.3. *Reinforcement learning* Deep reinforcement learning has gained significant popularity in the field of motion planning for autonomous vehicles (Aradi, 2020). Modelbased methods generally provide better data efficiency and can employ models for various purposes, including planning and data augmentation. \n\nFor example, an explicit model of the environment's dynamics, including a transition function and a reward function, is constructed. The model is then leveraged to derive a policy that aims to maximize cumulative rewards through these functions (Deisenroth & Rasmussen, 2011). In contrast, model-free reinforcement learning does not incorporate a known model of the environment. Instead, it estimates the action-value function Q(s, a) or the state-value function V(s) directly and selects actions based on these estimates. In essence, model-free methods learn from interactions with the environment without a predefined model, often using neural networks for approximation. For example, REF. (Kendall et al., 2019) represents a pioneering attempt to apply deep reinforcement learning to autonomous driving. The authors used a model-free deep reinforcement learning algorithm for lane-keeping, one of the fundamental tasks in autonomous driving. The salient feature of this study is the simplicity and generality of the reward function; the distance travelled without intervention from a safety driver. This is an ingenious approach as it doesn't require meticulously crafted reward functions. The study uses a single monocular image, which signifies a minimalist approach. The research puts forward a new paradigm in autonomous driving by minimizing the dependency on predefined rules, mapping, and direct supervision. The reliance on on-vehicle exploration and optimization is noteworthy, but it may also imply challenges regarding safety during training. "}
{"doc674": "To tackle a specific scenario in autonomous driving: overtaking on highways, one research presents a hierarchical control framework \n(Fig. 10), where the upper level is responsible for making driving decisions, and the lower level supervises vehicle speed and acceleration \n(Liao et al., 2020). This division mimics how human drivers operate, with cognitive decision-making coupled with fine motor control, which adds intuitiveness and logic to the system design. The study incorporates dueling deep Q-network (DDQN) for decision-making, an advanced algorithm variant known for its efficiency in learning value functions. The in-depth mathematical exploration and the comparison between DQN and DDQN in the study offer valuable insights into the decision-making algorithm's workings. However, it is crucial to strike a balance between reacting to unforeseen behavior and maintaining fluidity in driving without being excessively cautious, as this can hinder traffic flow. \n\nThe infusion of multi-agent reinforcement learning (MARL) casts a deliberate lens on the interactions amongst various agents\u2014vehicles, pedestrians, and more\u2014mirroring the complexity intrinsic to real-world scenarios. A wave of recent research (Bhalla et al., 2020; Palanisamy, 2020; Wachi, 2019; C. Yu et al., 2019) has navigated through the challenges of autonomous driving with a focus on MARL, attracted by its ability to adapt to the dynamic interactions and inherent unpredictability commonplace in traffic environments. Diverging from singleagent systems, MARL respects the non-static nature of various agents, each potentially adhering to their unique objectives and policies. Moreover, it can orchestrate coordination and negotiation amongst autonomous vehicles, proving indispensable in scenarios such as traffic merging, lane-changing, and intersection navigation\u2014enabling more fluid traffic flows and augmenting safety and efficiency. Nonetheless, autonomous vehicles navigate through perpetually evolving environments, often interacting with a vast number of agents, posing a formidable scalability challenge. Additionally, the non-stationarity of agents' policies compounds the complexity of learning within MARL settings when juxtaposed with single-agent reinforcement learning. Thus, as MARL research in the context of autonomous driving propels forward, a pivotal focus on scalability, real-time adaptation, and sturdy coordination mechanisms becomes imperative, steering toward the realization of resilient and efficient autonomous driving systems that adeptly weave into the multifaceted fabric of contemporary traffic environments. \n\n5.4. *Challenges and prospects: Motion planning and behavior arbitration* Motion planning and behavior arbitration collectively constitute the "}
{"doc675": "![18_image_0.png](18_image_0.png)\n\n![18_image_1.png](18_image_1.png)\n\nintellectual core essential for the effective operation of autonomous vehicles, playing a crucial role in facilitating intelligent decision-making processes and meticulous planning corresponding to diverse environmental contexts. The significance of these elements extends beyond their central role, as they are indispensable in ensuring safety and enhancing operational efficiency - both fundamental to the practical application of autonomous driving. Nevertheless, the domains of motion planning and behavior arbitration are laden with multifarious challenges demanding urgent resolution and thoughtful consideration. Such challenges encompass issues related to real-time decision-making amidst uncertainties and the necessity for behavior optimization in the everchanging landscape of traffic scenarios. These existing obstacles inevitably hinder the unobstructed deployment of autonomous driving technologies. Nevertheless, the present technological milieu is characterized by a series of remarkable advancements and innovations, providing a canvas of opportunity that has the potential to substantially impact the future direction of autonomous driving. These developments, ranging from advanced algorithms with learning and adaptive capabilities in complex environments to hardware innovations offering increased computational power, signal a future where challenges within motion planning and behavior arbitration are not merely addressed but also converted into opportunities for improved functionality and performance. This delicate balance between challenges and opportunities as outlined in Table 10 provides a fertile ground for the ongoing refinement of processes related to motion planning and behavior arbitration, vital for the development of autonomous vehicles. "}
{"doc676": "## 6. **Simulator & Scenario Generation**\n\nGiven that deep learning involves a process of trial and error along with data sampling, it is typically essential to initially assess algorithms within a simulated environment before evaluating their performance in a real-world setting (Fig. 11). Hence, the creation of a simulation environment is indispensable for training models, especially in reinforcement learning (Kiran et al., 2021). State-action pairs used for learning can be acquired through the interaction of autonomous driving systems with their simulated surroundings. Currently, various autonomous driving task simulators are used to train and validate reinforcement learning algorithms. Such as Motion Planning, Intersections, Table 10 Challenges and prospects of motion planning and decision-making. \n\nResearch Area Challenges Prospects for Improvement Complex Traffic Scenarios The unpredictability in traffic due to variable driver behavior and dynamic conditions creates substantial challenges for autonomous vehicle motion planning. "}
{"doc677": "Overtaking, Lane Change, Lane Keep and more. Some simulators also incorporate vehicle state dynamics. REF. (Beard & Baheri, 2022) proposed a Multi-Fidelity Reinforcement Learning (MFRL) framework available for multiple simulators. Enables training and validation of RL algorithms by representing state dynamics (and thus computational cost) using a cascade of simulators with increasing fidelity, while using RC cars to find real-world examples in fewer expensive real-world samples close to the optimal strategy. Experiments on RC cars (Abbeel et al., 2006) demonstrate the reliability of the MFPL framework and the possibility of porting reinforcement learning algorithms to real vehicles. \n\nCarla Simulator is currently a popular open simulator for urban autonomous driving (research, 2023). The competition evaluates autonomous driving systems in a variety of special scenarios based on the National Highway Traffic Safety Administration report (Najm et al., 2007), such as: vehicle loss of control, vehicle reacting to invisible obstacles, lane changing to avoid slow preceding vehicles, etc. \n\nSince online reinforcement learning needs to interact with the environment in the process of finding the optimal strategy, the construction of simulators or simulators increases the learning cost, so many researchers now start research on offline reinforcement learning to achieve real data-driven This will be of great significance for the reinforcement learning decision-making experiment of unmanned driving. The current main problem of offline reinforcement learning is nondistribution operation guidance and overfitting (Prudencio et al., \n2023). The main research methods are policy constraints (Fujimoto et al., 2019; Kumar et al., 2019; Nair et al., 2020), regularization (A. "}
{"doc678": "Kumar et al., 2020; A. Singh et al., 2020), trajectory optimization (L. \n\nChen et al., 2021; Janner et al., 2021) and model-based policy optimization (T. Yu et al., 2021). \n\nA crucial impediment to the progression and implementation of autonomous driving technology lies in the formidable costs\u2014both temporal and financial\u2014necessary for verifying the safety of these systems within the intricate tapestry of real-world driving scenarios. This verification challenge is intensified by the rarity of safety\u2013critical events. In response, scholars and practitioners have collaboratively fashioned an intricate testing ecosystem, which ingeniously employs AIbased background agents (Feng et al., 2023). These agents, meticulously trained through a dense deep-reinforcement-learning (D2RL) methodology applied to a corpus of naturalistic driving data, are pivotal in impartially and efficiently assessing the safety functionalities inherent to autonomous driving systems (Fig. 12). The D2RL methodology is characterized by a judicious manipulation of Markov decision processes, encompassing the excision of non-crucial states and the linkage of critical ones, culminating in a data set enriched with densified, safety\u2013critical information. This enhancement in turn facilitates the acquisition of invaluable knowledge by neural networks during safety\u2013critical events, enabling the accomplishment of tasks previously deemed unfeasible through conventional deep-reinforcement learning techniques. To illuminate the efficacy of this approach, experimental trials were orchestrated utilizing a highly automated vehicle within the controlled environments of both highway and urban testing tracks. This innovative approach presents a viable pathway for harnessing AI in the verification of other safety\u2013critical autonomous systems, offering a significant enhancement over existing methodologies by overcoming their limitations in real-world applications. "}
{"doc679": "## 7. **Current Challenges And Limitations**\n\nAutonomous mobility is not just about innovating sophisticated systems; it requires the seamless integration of complex subsystems. \n\nWhile both academia and industry are working diligently, the success of autonomous driving systems remains deeply intertwined with the performance of its individual subsystems. This interdependence introduces certain challenges and limitations (Fig. 13): \n(1) **Higher Safety Standards**: While autonomous driving systems leverage cutting-edge technology to improve safety, achieving and maintaining higher safety standards presents significant challenges. Advanced sensors and AI algorithms must perform flawlessly in real-time, necessitating relentless testing and validation to ensure reliability. The integration of lidar, radar, and cameras, despite providing a comprehensive sensory network, introduces intricate interdependencies and potential points of failure that must be meticulously managed. The need for robust "}
{"doc680": "Additionally, ensuring that these systems can handle unexpected scenarios without human intervention continues to be a formidable challenge that the industry must overcome to fully realize reliable autonomous driving. \n\n(2) **Complexity of Urban Environments**: The urban environment poses one of the most intricate challenges for autonomous vehicles, where a high density of dynamic and unpredictable elements exists. Advanced mapping systems and data-driven machine learning algorithms are pivotal in these settings; however, they must contend with the constant variability and unpredictability of city landscapes. Real-time data processing must be incredibly fast and accurate to interpret the actions of pedestrians, cyclists, and other vehicles\u2014tasks that humans perform intuitively but are highly complex for machines. There are also challenges related to the scalability of these systems in different urban areas with their own unique traffic patterns and infrastructure. Ensuring consistent performance across the various of scenarios encountered in urban settings underscores the monumental task facing developers of autonomous vehicle systems. Achieving a seamless and safe integration of autonomous vehicles into the already complex tapestry of urban traffic is not only a technological hurdle but also a regulatory and infrastructural one. \n\n(3) **Robust Performance in Adverse Weather**: The aspiration for autonomous vehicles to perform robustly in adverse weather conditions introduces a gamut of challenges that significantly complicate research and development. Sensors such as lidar and cameras, which are critical for navigation and obstacle detection, can be severely impaired by rain, snow, fog, or extreme temperature fluctuations. The attenuation of signals and distortion of data in such conditions can lead to reduced visibility and sensor reliability, necessitating the creation of more resilient sensor systems. Despite ongoing research into novel sensing techniques, enhancing sensor fusion, and crafting adaptive algorithms, achieving consistent performance in all weather conditions remains an elusive target. The difficulty lies not only in developing technologies that can withstand such environmental stresses but also in ensuring these systems can make safe and accurate decisions in the face of rapidly changing or extreme weather phenomena. "}
{"doc681": "(4) **Dynamic and Unpredictable Scenarios**: Dynamic and unpredictable scenarios present a thicket of challenges for autonomous vehicles. Navigating through construction zones, reacting to sudden obstacles, managing complex traffic dynamics, and safely interacting with pedestrians and cyclists require a level of situational awareness and decision-making sophistication that current technology struggles to achieve. Beyond the technical complexities, there are additional layers of challenges involving legal frameworks, ethical considerations, data privacy concerns, and the imperative for continuous learning and adaptation of the AI systems. Crafting algorithms that can make split-second decisions in such scenarios, implementing redundant sensor systems to cover potential failures, updating legal regulations, and establishing clear ethical guidelines are monumental tasks that researchers and policymakers must address. Ensuring that autonomous vehicles can not only cope with but excel in handling these various unpredictable elements is critical to their acceptance and success in the real world, where every day brings a new set of variables. \n\n(5) **Interpreting and Reacting to Human Behavior**: Autonomous vehicles must be adept at interpreting human behavior\u2014a challenge that remains one of the most formidable hurdles to widespread adoption. Human actions are often situationally dependent, with subtle cues such as eye contact or hand gestures being key indicators of intent, particularly in shared spaces. Machines must be trained to not only recognize these cues but also understand their context, which can vary widely across different cultures and social norms. The individuality of human behavior adds another layer of complexity, making it difficult for machine learning models to predict and adapt to every potential scenario. This challenge calls for advancements in artificial intelligence that go beyond mere pattern recognition, requiring a sophistication that allows for an almost empathic understanding of human behaviors and intentions within an infinitely variable range of situations. \n\n(6) **Ethical Concerns**: The deployment of autonomous vehicles transcends technical challenges and delves into profound ethical considerations. Decisions made by these systems in split-second scenarios\u2014often referred to as \"moral dilemmas\"\u2014evoke questions about the value of life and the prioritization of safety. "}
{"doc682": "Establishing ethical guidelines for autonomous driving systems is as crucial as it is complex, involving multifaceted issues that intersect with our deepest values, legal systems, and societal norms. This domain of ethics is not just about programming a set of rules but about how these machines can embody ethical principles that are universally accepted and understood. It necessitates a collaborative approach involving ethicists, engineers, legal experts, and the broader public to ensure that the moral compass guiding autonomous vehicles aligns with societal expectations and preserves the fabric of trust and safety in our communities. \n\n(7) **Legal and Regulatory Frameworks**: Establishing legal and regulatory frameworks for autonomous driving is a complex task that has to accommodate a diverse range of traffic environments and conditions. The intricate interplay between software and hardware in autonomous vehicles, compounded by the unpredictability of external factors, creates a tangle of liability issues. \n\nDetermining responsibility in the event of malfunctions or accidents is a contentious and unresolved issue. Furthermore, these vehicles generate vast amounts of data, which introduces substantial privacy concerns. The imperative to secure this sensitive information against various threats, and the necessity to comply with stringent data protection laws, adds to the regulatory maze. "}
{"doc683": "The evolving nature of this technology means that legal systems are perpetually playing catch-up, striving to create regulations that balance innovation with public safety, privacy, and security. \n\n(8) **High-Definition Mapping and Localization**: Creating and continuously updating high-definition maps for autonomous vehicles is a task of herculean proportions. These maps must reflect the real-time dynamics of the driving environment, capturing changes such as road works, temporary obstructions, and shifts in traffic patterns. To achieve the required level of detail and accuracy, there is a need to synthesize an enormous volume of data from a variety of sources. This synthesis must be both rapid and reliable, presenting substantial technical and computational challenges. Moreover, the storage, processing, and dissemination of this high-fidelity mapping data demand robust infrastructure and significant computational resources. Keeping these maps current is a relentless endeavor that necessitates constant data collection and processing, highlighting the formidable challenge of ensuring that the virtual representations used for navigation are always an accurate reflection of the physical world. \n\n(9) **Cybersecurity**: As autonomous vehicles become more interconnected, they are increasingly vulnerable to sophisticated cyber threats that could compromise passenger safety and privacy. The complexity of these systems, with their various sensors, actuators, and communication modules, presents a broad attack surface for potential hackers. Developing comprehensive cybersecurity measures for these vehicles is a monumental challenge. It involves not only safeguarding the communication channels with robust encryption and secure protocols but also ensuring the integrity of the software and hardware against tampering and intrusions. Regular vulnerability assessments and penetration testing are crucial to identify and address security gaps. However, the evolving nature of cyber threats means that these measures must be continually updated and adapted. Moreover, building resilient systems that can detect, isolate, and respond to cyberattacks in real time is critical to maintaining safety and functionality, thereby creating multiple layers of security that can adapt as quickly as new threats emerge. "}
{"doc684": "(10) **Public Trust and Confidence**: Earning public trust and confidence in autonomous driving technology is an ongoing challenge that hinges not just on demonstrating technical competence but also on addressing deeper concerns around safety, reliability, and privacy. These concerns are rooted in a natural apprehension towards surrendering control to machines, compounded by highprofile mishaps and privacy breaches. Overcoming this skepticism requires transparent communication about the capabilities and limitations of autonomous vehicles, as well as clear demonstrations of their benefits in improving traffic efficiency, reducing accidents, and enhancing mobility for the disabled and elderly. Moreover, it calls for a consistent track record of performance that stands up to public scrutiny. Education campaigns and the involvement of community stakeholders in testing and development can further bridge the gap between technology and public sentiment. Ultimately, building trust is a process that encompasses not only technical excellence but also an empathetic understanding of the public's concerns and a commitment to addressing them. \n\n## 8. **Outlook And Future Directions**\n\nTo truly advance autonomous driving, we need to encourage research partnerships between various industries and academic institutions. The main goal is to make these systems safer and more reliable, ultimately changing how we view and experience travel. Some critical areas to focus on are: \n(i) **Tech Innovation Growth**: The horizon of autonomous driving is linked to the pace of technological innovation. Progress in sensor technology, artificial intelligence, processing capabilities, and network connectivity is vital for advancing the sophistication of self-driving vehicles. Enhanced sensors are being developed to provide greater precision and range, while AI is evolving to make more nuanced decisions. Increased processing speed will allow for quicker response times and more complex scenario analysis, and stable, high-speed connectivity is essential for real-time data exchange and vehicle to everything (V2X) communications. Additionally, augmented reality (AR) and virtual reality (VR) are emerging as pivotal tools in creating highly detailed simulations for training autonomous systems, allowing them to navigate virtual environments that closely mirror the real world. These advancements in simulation technology will lead to higher levels of accuracy and reliability in autonomous driving systems, fostering greater trust in their ability to operate safely and efficiently in the real world. "}
{"doc685": "(ii) **Elevating Road Safety Paradigms**: The transformative potential of autonomous driving in the domain of road safety is profound. \n\nBy removing human error\u2014a significant factor in road mishaps\u2014autonomous vehicles offer the promise of substantially reducing accidents caused by distractions, fatigue, impaired driving, and other human-related issues. The shift towards more autonomous systems on the roads is expected to usher in a new era of safety standards, with vehicles equipped to consistently adhere to traffic rules, maintain safe distances, and execute defensive maneuvers. The ripple effects of this technological shift could be extensive, not only improving individual passenger safety but also revolutionizing transportation systems at large. \n\nThe overall safety of roadways could be improved, and emergency response services might be able to operate more efficiently. "}
{"doc686": "In the broader context, the enhancement of road safety through autonomous driving technologies contributes significantly to the global vision of creating safer living environments, potentially saving thousands of lives annually and leading to a paradigm shift in how safety is perceived and achieved on the roads of the future. \n\n(iii) **Optimizing Traffic Flow**: Future developments in autonomous driving are set to revolutionize the way traffic flows on our roads. \n\nWith the integration of advanced navigation systems and vehicleto-vehicle (V2V) communication, autonomous vehicles can travel in harmonized swarms, seamlessly negotiating intersections and adapting to the ebb and flow of traffic. This synergy allows for the minimization of bottlenecks and the mitigation of the start-stop rhythm that characterizes congested roadways. In effect, it is anticipated that traffic will become more fluid, reducing commute times and enhancing the predictability of travel schedules. This orchestrated vehicular ballet not only benefits individual commuters but also has the potential to elevate the efficiency of the entire transportation ecosystem, cutting down on fuel consumption and reducing the environmental footprint of road travel. "}
{"doc687": "(iv) **Enhancing Mobility and Accessibility**: One of the most impactful prospects of autonomous driving is its potential to greatly enhance mobility and accessibility for individuals who have traditionally faced transportation challenges. By removing the need for a human driver, self-driving technology can grant newfound autonomy to the elderly, people with disabilities, and those who do not drive for various reasons. This advancement could profoundly enhance the quality of life for these groups by providing them with reliable transportation options. Beyond mere mobility, autonomous vehicles can facilitate better access to essential services, employment opportunities, and social interactions. This inclusivity extends the benefits of autonomous technology far beyond the individual, fostering a more connected, engaged, and equitable society. As this technology matures and becomes more integrated into our daily lives, it promises to reshape our communities into more inclusive spaces, where transportation barriers are significantly diminished, allowing everyone to contribute to and participate in the community more fully. \n\n(v) **Promoting Sustainable Transportation**: As we navigate towards a more environmentally conscious future, autonomous driving stands at the forefront of promoting sustainable transportation. These vehicles are engineered for optimal route efficiency, smoother acceleration, and braking patterns that contribute to lower fuel consumption and reduced greenhouse gas emissions. In electric vehicle (EV) formats, autonomous technologies complement the shift away from fossil fuels, leading to a cleaner transportation sector. Additionally, the potential for autonomous vehicles to function within shared mobility services can lead to a decrease in the number of vehicles on the road, further diminishing the transportation sector's carbon footprint. \n\nThe ripple effect of such innovation is significant, aligning with international goals for sustainability and the mitigation of climate change, and it accelerates our journey towards achieving a low-carbon future. "}
{"doc688": "(vi) **Transforming Logistics and Delivery Services**: The domain of logistics and delivery services stands on the cusp of a major transformation powered by autonomous driving technology. \n\nAutonomous delivery vehicles and drones are carving out a path towards round-the-clock operations, enabling a level of precision and reliability previously unattainable. These technologies are set to streamline supply chains, drastically reducing delivery times, cutting costs, and minimizing human error. The capacity for continuous operation without the constraints of driver work hours will drive the efficiency of these systems to unprecedented levels. The prospect of a more optimized logistics infrastructure holds promise for both urban and rural areas, enhancing accessibility to goods and services. As a result, we can anticipate a future where the delivery of packages, groceries, and even medical supplies is more efficient, reliable, and accessible, propelling the logistics sector into a new era of innovation and performance. \n\n(vii) **Synchronizing with Smart City Infrastructure**: Autonomous driving is set to become an integral part of the smart city revolution, converging with other technological advancements to create highly efficient urban ecosystems. Vehicles capable of communicating with traffic signals, road sensors, and other infrastructural elements will usher in an age of synchronized mobility, reducing congestion and enhancing safety. Smart city infrastructure is poised to provide real-time data that will enable autonomous vehicles to navigate optimally, adjust to varying traffic conditions, and integrate with public transportation systems. This harmony between autonomous vehicles and urban design has the potential to enhance the livability of cities by making transportation more adaptive and responsive to the needs of the residents, and by extension, transforming the urban landscapes to be more sustainable and resilient. "}
{"doc689": "(viii) **Navigating the Regulatory and Legal Frameworks**: As autonomous driving technologies progress, there is an increasing need for updated regulatory and legal frameworks to guide their deployment and integration into public roadways. Ensuring the safety and reliability of these systems is paramount, necessitating regulations that can keep pace with technological advancements. \n\nPolicymakers are called upon to establish clear guidelines addressing liability in the event of an accident, standards for data privacy to protect user information, and ethical codes to manage the decision-making algorithms within autonomous systems. \n\nEffective policy will need to balance safety and innovation, provide clear directives for manufacturers and users, and consider the societal implications of widespread autonomous vehicle adoption. The evolution of these frameworks is crucial for building public trust and facilitating the responsible introduction of autonomous vehicles into society. "}
{"doc690": "(ix) **Building Public Confidence and Trust**: The trajectory of autonomous driving technologies towards mainstream acceptance is contingent upon building a foundation of public confidence and trust. This process involves not just demonstrating the capabilities of such systems, but also actively engaging in transparent discussions about their limitations and the measures in place to address them. It is essential that the public is wellinformed about how autonomous vehicles work, the benefits they offer, and the safety protocols they follow. Moreover, rigorous testing and validation must be communicated and observed, with a clear emphasis on the meticulousness of safety standards. Public policy debates and educational initiatives can play a pivotal role in demystifying the technology, addressing concerns, and shaping a positive public perception. By fostering an environment where the dialogue between technology providers, regulators, and the public is open and ongoing, there can be a gradual building of trust which is critical for the successful integration of autonomous driving into societal norms and daily routines. \n\n## 9. **Conclusions**\n\nThe evolution of autonomous driving technology signifies a transformative juncture in transportation history and societal norms. This survey methodically examines the foundations of autonomous driving, covering system design methodologies, environmental perception, localization, path planning and decision-making. In terms of environmental perception, we underscore the pivotal role of sensors\u2014such as cameras, Lidar, and radar\u2014in object detection and semantic segmentation. The survey also navigates through the inherent challenges and opportunities in these areas, shedding light on various localization and mapping strategies, particularly emphasizing SLAM variations. Our exploration of motion planning and decision-making underscores key components, including trajectory forecasting, decision-making protocols, and behavioral regulation. In conclusion, we outline the prospective future trajectories and opportunities in the autonomous driving landscape, underscoring its potential to redefine transport. Autonomous driving represents more than just a technological leap; it marks a fundamental shift in our understanding of mobility. Our aspiration is that this detailed, comprehensive survey provides an overview of autonomous vehicle technology for researchers, industry frontrunners, and all stakeholders in the autonomous driving sector, towards the development of safer, more intelligent, and efficient transportation systems. "}
{"doc691": "## References\n\nAbbeel, P., Quigley, M., & Ng, A. Y. (2006, June). Using inaccurate models in reinforcement learning. Proceedings of the 23rd international conference on Machine learning, Pittsburgh, Pennsylvania, USA. \n\nAlmalioglu, Y., Turan, M., Trigoni, N., & Markham, A. (2022). Deep learning-based robust positioning for all-weather autonomous driving. Nature Machine Intelligence, 4, 749\u2013760. https://doi.org/10.1038/s42256-022-00520-5 Aradi, S. (2020). Survey of deep reinforcement learning for motion planning of autonomous vehicles. *IEEE Transactions on Intelligent Transportation Systems, 23*, \n740\u2013759. https://doi.org/10.1109/TITS.2020.3024655 Bachute, M. R., & Subhedar, J. M. (2021). Autonomous driving architectures: Insights of machine learning and deep learning algorithms. *Machine Learning with Applications,* 6, Article 100164. https://doi.org/10.1016/j.mlwa.2021.100164 Badrinarayanan, V., Kendall, A., & Cipolla, R. (2017). Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE Transactions on Pattern \nAnalysis Machine Intelligence, 39, 2481\u20132495. https://doi.org/10.1109/ \nTPAMI.2016.2644615 Badue, C., Guidolini, R., Carneiro, R. V., Azevedo, P., Cardoso, V. B., Forechi, A., \u2026 \nMutz, F. (2021). Self-driving cars: A survey. *Expert Systems with Applications, 165*, \nArticle 113816. https://doi.org/10.1016/j.eswa.2020.113816 Baruch, J. (2016). Steer driverless cars towards full automation. *Nature, 536*, 127. "}
{"doc692": "Cai, P., Sun, Y., Chen, Y., & Liu, M. (2019, October). Vision-based trajectory planning via imitation learning for autonomous vehicles. 2019 IEEE Intelligent Transportation Systems Conference (ITSC), Auckland, New Zealand. \n\nCampos, C., Elvira, R., Rodr\u00edguez, J. J. G., Montiel, J. M., & Tardos, \u00b4 J. D. (2021). Orbslam3: An accurate open-source library for visual, visual\u2013inertial, and multimap slam. *IEEE Transactions on Robotics, 37*, 1874\u20131890. https://doi.org/10.1109/ \nTRO.2021.3075644 Charbuty, B., & Abdulazeez, A. (2021). Classification based on decision tree algorithm for machine learning. *Journal of Applied Science Technology Trends, 2*, 20\u201328. https:// \ndoi.org/10.38094/jastt20165 Chen, D., Koltun, V., & Kr\u00a8ahenb\u00fchl, P. (2021, October). Learning to drive from a world on rails. Proceedings of the IEEE/CVF International Conference on Computer Vision, Montreal, QC, Canada. \n\nChen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., & Yuille, A. L. (2017). Deeplab: \nSemantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. *IEEE Transactions on Pattern Analysis Machine Intelligence, 40*, \n834\u2013848. https://doi.org/10.48550/arXiv.1606.02147 Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., & \nMordatch, I. (2021, December). Decision transformer: Reinforcement learning via sequence modeling. Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, Online. "}
{"doc693": "Feng, S., Sun, H., Yan, X., Zhu, H., Zou, Z., Shen, S., & Liu, H. X. (2023). Dense reinforcement learning for safety validation of autonomous vehicles. *Nature, 615*, \n620\u2013627. https://doi.org/10.1038/s41586-023-05732-2 Fernando, T., Denman, S., Sridharan, S., & Fookes, C. (2018a, December). Gd-gan: \nGenerative adversarial networks for trajectory prediction and group detection in crowds. Computer Vision\u2013ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2\u20136, 2018, Revised Selected Papers, Part I 14, Perth, Australia. \n\nFernando, T., Denman, S., Sridharan, S., & Fookes, C. (2018). Soft+ hardwired attention: \nAn lstm framework for human trajectory prediction and abnormal event detection. \n\nNeural Networks, 108, 466\u2013478. https://doi.org/10.1016/j.neunet.2018.09.002 Fernando, T., Denman, S., Sridharan, S., & Fookes, C. (2019, October). Neighbourhood context embeddings in deep inverse reinforcement learning for predicting pedestrian motion over long time horizons. Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, Seoul, Korea (South). "}
{"doc694": "Fernando, T., Denman, S., Sridharan, S., & Fookes, C. (2020). Deep inverse reinforcement learning for behavior prediction in autonomous driving: Accurate forecasts of vehicle motion. *IEEE Signal Processing Magazine, 38*, 87\u201396. https://doi.org/ \n10.1109/MSP.2020.2988287 Forster, C., Pizzoli, M., & Scaramuzza, D. (2014, May). SVO: Fast semi-direct monocular visual odometry. 2014 IEEE international conference on robotics and automation (ICRA), Hong Kong, China. \n\nFujimoto, S., Meger, D., & Precup, D. (2019, June). Off-policy deep reinforcement learning without exploration. International conference on machine learning, Long Beach, California, USA. \n\nGao, H., Shi, G., Xie, G., & Cheng, B. (2018). Car-following method based on inverse reinforcement learning for autonomous vehicle decision-making. International Journal of Advanced Robotic Systems, 15, 1729881418817162. https://doi.org/ 10.1177/1729881418817162. "}
{"doc695": "George, L., Buhet, T., Wirbel, E., \u00b4 Le-Gall, G., & Perrotton, X. (2018). Imitation learning for end to end vehicle longitudinal control with forward camera. *arXiv preprint arXiv:* 1812.05841, https://doi.org/10.48550/arXiv.1812.05841. \n\nGhahramani, Z. (2015). Probabilistic machine learning and artificial intelligence. Nature, 521, 452\u2013459. https://doi.org/10.1038/nature14541 Girshick, R., Donahue, J., Darrell, T., & Malik, J. (2015). Region-based convolutional networks for accurate object detection and segmentation. *IEEE Transactions on* Pattern Analysis Machine Intelligence, 38, 142\u2013158. https://doi.org/10.1109/ \nTPAMI.2015.2437384 Goli, A., Khademi-Zare, H., Tavakkoli-Moghaddam, R., Sadeghieh, A., Sasanian, M., & \nMalekalipour Kordestanizadeh, R. (2021). An integrated approach based on artificial intelligence and novel meta-heuristic algorithms to predict demand for dairy products: A case study. *Network: Computation in Neural Systems, 32*, 1\u201335. https:// \ndoi.org/10.1080/0954898X.2020.1849841 Greenblatt, N. A. (2016). Self-driving cars and the law. *IEEE Spectrum, 53*, 46\u201351. https:// \ndoi.org/10.1109/MSPEC.2016.7419800 Grigorescu, S., Trasnea, B., Cocias, T., & Macesanu, G. (2020). A survey of deep learning techniques for autonomous driving. *Journal of Field Robotics, 37*, 362\u2013386. https:// \ndoi.org/10.1002/rob.21918 Guo, G., & Zhao, S. (2022). 3D multi-object tracking with adaptive cubature Kalman filter for autonomous driving. *IEEE Transactions on Intelligent Vehicles, 8*, 512\u2013519. \n\nhttps://doi.org/10.1109/TIV.2022.3158419 Guo, Y., Wang, H., Hu, Q., Liu, H., Liu, L., & Bennamoun, M. (2020). Deep learning for 3d point clouds: A survey. *IEEE Transactions on Pattern Analysis Machine Intelligence, 43*, \n4338\u20134364. https://doi.org/10.1109/TPAMI.2020.3005434 Gupta, A., Johnson, J., Fei-Fei, L., Savarese, S., & Alahi, A. (2018, June). Social gan: \nSocially acceptable trajectories with generative adversarial networks. Proceedings of the IEEE conference on computer vision and pattern recognition, Salt Lake City, UT, USA. "}
{"doc696": "Ji, B., Zhang, X., Mumtaz, S., Han, C., Li, C., Wen, H., & Wang, D. (2020). Survey on the internet of vehicles: Network architectures and applications. IEEE Communications Standards Magazine, 4, 34\u201341. https://doi.org/10.1109/MCOMSTD.001.1900053 Joubert, N., Reid, T. G., & Noble, F. (2020, October). Developments in modern GNSS and its impact on autonomous vehicle architectures. 2020 IEEE Intelligent Vehicles Symposium (IV), Las Vegas, NV, USA. \n\nKanai, S., Fujiwara, Y., & Iwamura, S. (2017). Preventing gradient explosions in gated recurrent units. *Advances in Neural Information Processing Systems, 30*. https://doi. org/10.5555/3294771.3294813 Karaman, S., Walter, M. R., Perez, A., Frazzoli, E., & Teller, S. (2011, May). Anytime motion planning using the RRT. 2011 IEEE international conference on robotics and automation, Shanghai, China. \n\nKendall, A., Hawke, J., Janz, D., Mazur, P., Reda, D., Allen, J.-M., Lam, V.-D., Bewley, A., \n& Shah, A. (2019, May). Learning to drive in a day. 2019 International Conference on Robotics and Automation (ICRA), Montreal, QC, Canada. "}
{"doc697": "Kiran, B. R., Sobh, I., Talpaert, V., Mannion, P., Al Sallab, A. A., Yogamani, S., & P\u00b4erez, P. \n\n(2021). Deep reinforcement learning for autonomous driving: A survey. IEEE \nTransactions on Intelligent Transportation Systems, 23, 4909\u20134926. https://doi.org/ \n10.48550/arXiv.2002.00444 Kohlbrecher, S., Von Stryk, O., Meyer, J., & Klingauf, U. (2011, November). A flexible and scalable SLAM system with full 3D motion estimation. 2011 IEEE international symposium on safety, security, and rescue robotics, Kyoto, Japan. \n\nKumar, A., Fu, J., Soh, M., Tucker, G., & Levine, S. (2019). Stabilizing off-policy qlearning via bootstrapping error reduction. Advances in Neural Information Processing Systems, 32. https://doi.org/10.1145/3452296.3472936 Kumar, A., Zhou, A., Tucker, G., & Levine, S. (2020, December). Conservative q-learning for offline reinforcement learning. Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, Online. "}
{"doc698": "Pointpillars: Fast encoders for object detection from point clouds. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, Long Beach, CA, USA. \n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. *Nature, 521*, 436\u2013444. https:// \ndoi.org/10.1038/nature14539 Li, J., Zhao, J., Kang, Y., He, X., Ye, C., & Sun, L. (2019, June). Dl-slam: Direct 2.5 d lidar slam for autonomous driving. 2019 IEEE Intelligent Vehicles Symposium (IV), Paris, France. \n\nLiao, J., Liu, T., Tang, X., Mu, X., Huang, B., & Cao, D. (2020). Decision-making strategy on highway for autonomous vehicles using deep reinforcement learning. *IEEE Access,* \n8, 177804\u2013177814. https://doi.org/10.1109/ACCESS.2020.3022755 Lin, H., Lin, X., Labiod, H., & Chen, L. (2021). Toward multiple-phase MDP model for charging station recommendation. IEEE Transactions on Intelligent Transportation Systems, 23, 10583\u201310595. https://doi.org/10.1109/TITS.2021.3094926 Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., & Berg, A. C. (2016, October). Ssd: Single shot multibox detector. Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11\u201314, 2016, Proceedings, Part I 14, Amsterdam, The Netherlands. "}
{"doc699": "Liu, X., Masoud, N., Zhu, Q., & Khojandi, A. (2022). A markov decision process framework to incorporate network-level data in motion planning for connected and automated vehicles. *Transportation Research Part C: Emerging Technologies, 136*, Article 103550. https://doi.org/10.1016/j.trc.2021.103550 Liu, Z., Zhou, S., Suo, C., Yin, P., Chen, W., Wang, H., Li, H., & Liu, Y.-H. (2019, October). \n\nLpd-net: 3d point cloud learning for large-scale place recognition and environment analysis. Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South). \n\nLong, J., Shelhamer, E., & Darrell, T. (2015, June). Fully convolutional networks for semantic segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition, Boston, MA, USA. "}
{"doc700": "Lu, Y., Lu, J., Zhang, S., & Hall, P. (2018). Traffic signal detection and classification in street views using an attention model. *Computational Visual Media, 4*, 253\u2013266. \n\nhttps://doi.org/10.1007/s41095-018-0116-x Luque, J., & Straub, D. (2019). Risk-based optimal inspection strategies for structural systems using dynamic Bayesian networks. *Structural Safety, 76*, 68\u201380. https://doi. org/10.1016/j.strusafe.2018.08.002 Mansour, R. F., Escorcia-Gutierrez, J., Gamarra, M., Villanueva, J. A., & Leal, N. (2021). \n\nIntelligent video anomaly detection and classification using faster RCNN with deep reinforcement learning model. *Image Vision Computing, 112*, Article 104229. https:// doi.org/10.1016/j.imavis.2021.104229 Maturana, D., & Scherer, S. (2015, September). Voxnet: A 3d convolutional neural network for real-time object recognition. 2015 IEEE/RSJ international conference on intelligent robots and systems (IROS), Hamburg, Germany. "}
{"doc701": "Najm, W. G., Smith, J. D., & Yanagisawa, M. (2007). *Pre-crash scenario typology for crash* avoidance research. United States: National Highway Traffic Safety Administration. \n\nNunes, A., & Axhausen, K. W. (2021). Road safety, health inequity and the imminence of autonomous vehicles. *Nature Machine Intelligence, 3*, 654\u2013655. https://doi.org/ \n10.1038/s42256-021-00382-3 Oliveira, G. L., Radwan, N., Burgard, W., & Brox, T. (2020, November). Topometric localization with deep learning. Robotics Research: The 18th International Symposium ISRR. \n\nOsaba, E., Villar-Rodriguez, E., Del Ser, J., Nebro, A. J., Molina, D., LaTorre, A., \u2026 \nHerrera, F. (2021). A tutorial on the design, experimentation and application of metaheuristic algorithms to real-world optimization problems. Swarm Evolutionary Computation, 64, Article 100888. https://doi.org/10.1016/j.swevo.2021.100888 Osman, O. A., Hajij, M., Bakhit, P. R., & Ishak, S. (2019). Prediction of near-crashes from observed vehicle kinematics using machine learning. Transportation Research Record, 2673, 463\u2013473. https://doi.org/10.1177/0361198119862629 Palanisamy, P. (2020, July). Multi-agent connected autonomous driving using deep reinforcement learning. 2020 International Joint Conference on Neural Networks \n(IJCNN), Glasgow, UK. "}
{"doc702": "Prudencio, R. F., Maximo, M. R., & Colombini, E. L. (2023). A survey on offline reinforcement learning: Taxonomy, review, and open problems. arXiv preprint arXiv: \n2203.01387, https://doi.org/10.48550/arXiv.2203.01387. \n\nRavindran, R., Santora, M. J., & Jamali, M. M. (2020). Multi-object detection and tracking, based on DNN, for autonomous vehicles: A review. *IEEE Sensors Journal, 21*, 5668\u20135677. https://doi.org/10.1109/JSEN.2020.3041615 Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. *Advances in Neural Information Processing* Systems, 28. https://doi.org/10.1109/TPAMI.2016.2577031 research, C. O.-s. s. f. a. d. (2023). Retrieved from https://carla.org/. Accessed July, 6, 2023. \n\nRhinehart, N., McAllister, R., Kitani, K., & Levine, S. (2019, October-November). Precog: \nPrediction conditioned on goals in visual multi-agent settings. Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Korea (South). "}
{"doc703": "Shan, T., & Englot, B. (2018, October). Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain. 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain. \n\nShenoi, A., Patel, M., Gwak, J., Goebel, P., Sadeghian, A., Rezatofighi, H., Martin-Martin, R., & Savarese, S. (2020, October). Jrmot: A real-time 3d multi-object tracker and a new large-scale dataset. 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV, USA. \n\nShi, S., Wang, X., & Li, H. (2019, June). Pointrcnn: 3d object proposal generation and detection from point cloud. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, Beach, CA, USA. "}
{"doc704": "Singh, G., Peri, S., Kim, J., Kim, H., & Ahn, S. (2021, July). Structured world belief for reinforcement learning in pomdp. International Conference on Machine Learning, Online. \n\nSong, C., Zhang, C., Shafieezadeh, A., & Xiao, R. (2022). Value of information analysis in non-stationary stochastic decision environments: A reliability-assisted POMDP approach. *Reliability Engineering System Safety, 217*, Article 108034. https://doi.org/ 10.1016/j.ress.2021.108034 Sun, C.-Z., Zhang, B., Wang, J.-K., & Zhang, C.-S. (2021, June). A review of visual SLAM \nbased on unmanned systems. 2021 2nd International Conference on Artificial Intelligence and Education (ICAIE), Dali, China. \n\nSutton, C., & McCallum, A. (2012). An introduction to conditional random fields. "}
{"doc705": "Foundations and Trends\u00ae *in Machine Learning, 4*, 267-373. https://doi.org/10.1561/ \n2200000013. \n\nTampuu, A., Matiisen, T., Semikin, M., Fishman, D., & Muhammad, N. (2020). A survey of end-to-end driving: Architectures and training methods. IEEE Transactions on Neural Networks and Learning Systems, 33, 1364\u20131384. https://doi.org/10.1109/ \nTNNLS.2020.3043505 Tang, T. Y., Yoon, D. J., Pomerleau, F., & Barfoot, T. D. (2018, May). Learning a bias correction for lidar-only motion estimation. 2018 15th Conference on Computer and Robot Vision (CRV), Toronto, ON, Canada. \n\nTateno, K., Tombari, F., Laina, I., & Navab, N. (2017, July). Cnn-slam: Real-time dense monocular slam with learned depth prediction. Proceedings of the IEEE conference on computer vision and pattern recognition, Honolulu, HI, USA. "}
{"doc706": "Thorpe, C., Hebert, M. H., Kanade, T., & Shafer, S. A. (1988). Vision and navigation for the Carnegie-Mellon Navlab. IEEE Transactions on Pattern Analysis Machine Intelligence, 10, 362\u2013373. https://doi.org/10.1109/34.3900 Tkatek, S., Bahti, O., Lmzouari, Y., & Abouchabaka, J. (2020). Artificial intelligence for improving the optimization of NP-hard problems: a review. *International Journal of* Advanced Trends Computer Science, 9, https://doi.org/10.30534/ijatcse/2020/ 73952020. \n\nToromanoff, M., Wirbel, E., & Moutarde, F. (2020, Jun). End-to-end model-free reinforcement learning for urban driving using implicit affordances. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, Seattle, United States. \n\nVallon, C., Ercan, Z., Carvalho, A., & Borrelli, F. (2017, June). A machine learning approach for personalized autonomous lane change initiation and control. 2017 IEEE Intelligent vehicles symposium (IV), Los Angeles, CA, USA. "}
{"doc707": "Van Brummelen, J., O'Brien, M., Gruyer, D., & Najjaran, H. (2018). Autonomous vehicle perception: The technology of today and tomorrow. Transportation Research Part C: \nEmerging Technologies, 89, 384\u2013406. https://doi.org/10.1016/j.trc.2018.02.012 Vemulapalli, R., Tuzel, O., Liu, M.-Y., & Chellapa, R. (2016, June). Gaussian conditional random field network for semantic segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition, Las Vegas, NV, USA. \n\nVespa, E., Nikolov, N., Grimm, M., Nardi, L., Kelly, P. H., & Leutenegger, S. (2018). \n\nEfficient octree-based volumetric SLAM supporting signed-distance and occupancy mapping. *IEEE Robotics Automation Letters, 3*, 1144\u20131151. https://doi.org/10.1109/ \nLRA.2018.2792537 Visin, F., Ciccone, M., Romero, A., Kastner, K., Cho, K., Bengio, Y., Matteucci, M., & \nCourville, A. (2016, June-July). Reseg: A recurrent neural network-based model for semantic segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition workshops, Las Vegas, NV, USA. "}
{"doc708": "Von Stumberg, L., & Cremers, D. (2022). Dm-vio: Delayed marginalization visual-inertial odometry. *IEEE Robotics Automation Letters, 7*, 1408\u20131415. https://doi.org/10.1109/ \nLRA.2021.3140129 VOSviewer. (2023). *Visualizing scientific landscapes*, Retrieved from Accessed July 6, 2023. \n\nWachi, A. (2019). Failure-scenario maker for rule-based agent using multi-agent adversarial reinforcement learning and its application to autonomous driving. arXiv preprint arXiv:1903.10654, https://doi.org/10.48550/arXiv.1903.10654. \n\nWang, C., Delport, J., & Wang, Y. (2019). Lateral motion prediction of on-road preceding vehicles: A data-driven approach. *Sensors, 19*, 2111. https://doi.org/10.3390/ s19092111 Wang, H., Xu, H., Zhao, C., & Liu, Y. (2021, October). KC-PointNet: attentional network for 3D point cloud processing. 2021 China Automation Congress (CAC), Beijing, China. "}
{"doc709": "Wang, Z., Zheng, L., Liu, Y., Li, Y., & Wang, S. (2020, August). Towards real-time multiobject tracking. European Conference on Computer Vision, Glasgow, UK. \n\nWeng, X., Wang, J., Held, D., & Kitani, K. (2020). Ab3dmot: A baseline for 3d multiobject tracking and new evaluation metrics. *arXiv preprint arXiv:2008.08063,* https:// \ndoi.org/10.48550/arXiv.2008.08063. \n\nXia, Y., Qu, S., Goudos, S., Bai, Y., & Wan, S. (2021). Multi-object tracking by mutual supervision of CNN and particle filter. *Personal Ubiquitous Computing, 1\u201310*. https:// \ndoi.org/10.1007/s00779-019-01278-1 Xiang, Y., Alahi, A., & Savarese, S. (2015, December). Learning to track: Online multiobject tracking by decision making. Proceedings of the IEEE international conference on computer vision, Santiago, Chile. "}
{"doc710": "Xiao, Y., Codevilla, F., Gurram, A., Urfalioglu, O., & Lopez, \u00b4 A. M. (2020). Multimodal end-to-end autonomous driving. IEEE Transactions on Intelligent Transportation Systems, 23, 537\u2013547. https://doi.org/10.1109/TITS.2020.3013234 Xie, W., Ide, J., Izadi, D., Banger, S., Walker, T., Ceresani, R., Spagnuolo, D., Guagliano, C., Diaz, H., & Twedt, J. (2021, September). Multi-object tracking with deep learning ensemble for unmanned aerial system applications. Artificial Intelligence and Machine Learning in Defense Applications III, Online. \n\nXin, X., Jia, N., Ling, S., & He, Z. (2022). Prediction of pedestrians' wait-or-go decision using trajectory data based on gradient boosting decision tree. Transportmetrica B: \nTransport Dynamics, 10, 693\u2013717. https://doi.org/10.1080/ \n21680566.2022.2027294 Xu, H., Gao, Y., Yu, F., & Darrell, T. (2017, July). End-to-end learning of driving models from large-scale video datasets. Proceedings of the IEEE conference on computer vision and pattern recognition, Honolulu, HI, USA. \n\nXu, Q., Sun, X., Wu, C.-Y., Wang, P., & Neumann, U. (2020, June). Grid-gcn for fast and scalable point cloud learning. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA. "}
{"doc711": "Yang, S., & Scherer, S. (2019). Cubeslam: Monocular 3-d object slam. IEEE Transactions on Robotics, 35, 925\u2013938. https://doi.org/10.1109/TRO.2019.2909168 Ye, M., Cao, T., & Chen, Q. (2021, June). Tpcn: Temporal point cloud networks for motion forecasting. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA. \n\nYu, C., Wang, X., Xu, X., Zhang, M., Ge, H., Ren, J., \u2026 Tan, G. (2019). Distributed multiagent coordinated learning for autonomous driving in highways based on dynamic coordination graphs. IEEE Transactions on Intelligent Transportation Systems, 21, 735\u2013748. https://doi.org/10.1109/TITS.2019.2893683 Yu, F., & Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions. \n\narXiv preprint arXiv:1511.07122, https://doi.org/10.48550/arXiv.1511.07122. "}
{"doc712": "org/10.1162/neco_a_01199 Zarzar, J., Giancola, S., & Ghanem, B. (2019). PointRGCN: Graph convolution networks for 3D vehicles detection refinement. *arXiv preprint arXiv:1911.12236,* https://doi. org/10.48550/arXiv.1911.12236. \n\nZhang, G., Pan, Y., & Zhang, L. (2021). Semi-supervised learning with GAN for automatic defect detection from images. *Automation in Construction, 128*, Article 103764. https://doi.org/10.1109/TIM.2021.3087826 Zhang, S., Tong, H., Xu, J., & Maciejewski, R. (2019). Graph convolutional networks: A \ncomprehensive review. *Computational Social Networks, 6*, 1\u201323. https://doi.org/ \n10.1186/s40649-019-0069-y Zhang, T., Song, W., Fu, M., Yang, Y., Tian, X., & Wang, M. (2021). A unified framework integrating decision making and trajectory planning based on spatio-temporal voxels for highway autonomous driving. IEEE Transactions on Intelligent Transportation Systems, 23, 10365\u201310379. https://doi.org/10.1109/TITS.2021.3093548 Zhang, Y., Zhou, Z., David, P., Yue, X., Xi, Z., Gong, B., & Foroosh, H. (2020, June). \n\nPolarnet: An improved grid representation for online lidar point clouds semantic segmentation. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA. "}
{"doc713": "Zhou, J., Cui, G., Hu, S., Zhang, Z., Yang, C., Liu, Z., \u2026 Sun, M. (2020). Graph neural networks: A review of methods and applications. *AI Open, 1*, 57\u201381. https://doi.org/ \n10.1016/j.aiopen.2021.01.001 Zhou, Y., & Tuzel, O. (2018, June). Voxelnet: End-to-end learning for point cloud based 3d object detection. Proceedings of the IEEE conference on computer vision and pattern recognition, Salt Lake City, UT, USA. \n\nZubizarreta, J., Aguinaga, I., & Montiel, J. M. M. (2020). Direct sparse mapping. IEEE \nTransactions on Robotics, 36, 1363\u20131370. https://doi.org/10.1109/ \nTRO.2020.2991614 Zuo, X., Geneva, P., Lee, W., Liu, Y., & Huang, G. (2019, November). Lic-fusion: Lidarinertial-camera odometry. 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Macau, China. "}
{"doc714": "Emerging technologies are changing our preferences for transportation solutions, which focus on service efficiency, safety, and sustainability. Mobility as a service (MaaS) is a user-oriented transportation solution that integrates both public and private operators into the same platform. The implementation of MaaS aims to simplify users' booking procedures and increase the usability of various kinds of transportation resources. \n\nHowever, the integration of a myriad of transportation subsystems raises interpretation challenges from associated multi-stakeholder and subsystems. To overcome these challenges, the authors have involved different stakeholders from related subsystems to reveal concerns. This study aims to analyse a novel public transportation system - the self-driving mini-bus service in Shenzhen. The result shows that system characteristics and stakeholder concerns can be established using an Action, Factor and Goal structure. Stakeholders involved described their perceptions of self-driving bus integration in MaaS. The description could be used by analysts to uncover integration gaps further and could be updated by involving more stakeholders according to project developments. This study highlights the complexity of self-driving mini-buses integration challenges in MaaS from a stakeholder perspective, which provides learnings to advance the MaaS adoption in the future. \n\n## 1. **Introduction**"}
{"doc715": "Mobility as a service (MaaS) is a comprehensive service package for fulfilling travellers' needs by both public and private mobility operators through a unified platform (Hensher, 2017; Viswanath & Mathew, 2014). MaaS is the evolution of 'as a service' 1 transportation solutions, which are expected to bring a wide range of social and economic benefits through personalised mobility (Datson, 2016). Since 2014, the idea of MaaS has received much attention from companies and authorities in providing integrated mobility services (Frank, 2018). Several ongoing projects in EU are furthering the MaaS concept and the self-driving bus service separately (KPMG, 2017; Smith, Sochor, & Karlsson, 2018 a; Smith, Sochor, & Sarasini, 2018 b). For example, the MaaS Global company has already launched the Whim app for MaaS in Finland, and the UK with different transportation services (public transportation, taxi, car, bike) integrated (MaaS Global - Mobility as a Service, 2018). \n\nAlthough there are examples of MaaS, there are still challenges caused by complex engineering disciplines and organisations involved. Changes \n* Corresponding author. Kungliga Tekniska Hogskolan, Sweden. \n\n![0_image_2.png](0_image_2.png)"}
{"doc716": "E-mail addresses: qiuchen@kth.se (W. Qiuchen), jmbh@kth.se (H.B. Jannicke), smeijer@kth.se (M. Sebastiaan). 1 *Anything as a service* refers to the integration of tools, technologies and solutions for one service for customers over a platform, instead of customers buying services from providers separately (Rouse & Bigelow, 2017). \n\nContents lists available at ScienceDirect in transportation systems can enable social transformation such as a sharing economy, environmental awareness, and personalised consumption trends (Milakis, Van Arem, & Van Wee, 2017). For example, with the development of vehicle and infrastructure technology, the Kutsuplus project could be tested on the demand-responsive bus service \n(Honabach & Sargent, 2016). Whereas the efficiency of transportation resources and usage are essential drivers for ITS and MaaS development, few studies have examined the extent to which these developments are aligned with the needs and wishes of stakeholders (Nikitas, Kougias, Alyavina, & Njoya Tchouamou, 2017). \n\nSystem-level assessments call for a new integration of methods for structuring stakeholder perspectives that have rarely been applied to the ITS and MaaS domain. Some studies focus on the technology acceptance analysis of ITS or MaaS separately. In Sweden, system thinking methods are being applied to the stakeholder perspective to analyse how MaaS and autonomous transportation systems can create value for an urban system (Karlsson, Sochor, & Stromberg, \u00a8 2016). A systematic analysis from the actor perspective is necessary in order to illustrate the https://doi.org/10.1016/j.retrec.2021.101070 Received 15 March 2020; Received in revised form 2 March 2021; Accepted 8 April 2021 Available online 4 May 2021 0739-8859/\u00a9 2021 Published by Elsevier Ltd."}
{"doc717": "complexity and solve potential conflicts (Nguyen, Mohamed, & Panuwatwanich, 2018), (Christiaanse, 2019, pp. 83\u201392). In the public sector, the complexity of decision making has increased because the control process relies more on multiple actors than on single actors (Dewulf, 2007). To understand gaps from different stakeholders and subsystems, the authors conducted actor analysis to learn the opportunity for small self-driving bus service integration in a MaaS solution. \n\nActor analysis methods can capture an actor's views of a policy problem to help analysts and decision-makers to understand the mechanisms behind complex situations (Bijlsma, Bots, Wolters, & Hoekstra, 2011; Hermans & Cunningham, 2013) to make better decisions. The actor analysis method was also implemented in a complex technology innovation case using the electric road system as the case study to reveal different stakeholders' perceptions and challenges at the early stage \n(Wang, Hauge, & Meijer, 2019; Wang, Hauge, & Meijer, 2019). The emergence of ITS solutions and the intention to integrate MaaS also involved multi-systems and stakeholders, in which the actor analysis method is needed to sort out the complexity uncover more insights from different stakeholder perspectives. \n\nThis paper addresses the following question: What challenges influence the self-driving mini-bus system integration in MaaS using the actor analysis approach to revealing the stakeholders' concerns? To answer these questions, the authors first summarised the characteristics of the MaaS and ITS self-driving bus system from the current literature and projects and then revised these characteristics with experts in order to compile Action, Factor and Goal (AFG) list Va, Vb1 and Vb to describe stakeholder perceptions. This study builds on the China Bus System of the Future (CBFS) project in Shenzhen. The development of a new generation urban bus system involved a combination of new vehicle technologies and infrastructures. The gaps for self-driving mini-bus systems integration in MaaS are analysed combined with stakeholder's perspective. This study also discusses the potential future directions and the acceptance of the combination of a self-driving mini-bus system and the MaaS service. "}
{"doc718": "The rest of the paper is organized as follows: Section 2 discusses the methodology and related research work in MaaS and ITS self-driving mini-buses cases. Section 3 introduces MaaS state-of-art, system characteristics and AFG list Va. Section 4 introduces self-driving mini-buses state-of-art, system characteristics and AFG list Vb1. Section 5 illustrates and discusses gaps for the adoption of self-driving buses in MaaS. Section 6 concludes the paper with future directions. \n\n## 2. **Methodology And Related Work** 2\n\nIn order to understand the integration gaps based on the different stakeholders' perceptions using interviews, actor analysis methods were selected in this study to uncover the integration gaps from stakeholders' perspectives for self-driving bus system integration in MaaS. The selection of the methods considers the availability of existing resources, the multi-stakeholder and subsystems characteristics of studied cases, and the possibility of involving different stakeholders. Actor analysis methods are applied in the policy analysis domain to help analysts having insight views in the multi-actor complex policy-making process \n(Hermans & Thissen, 2009). Actor analysis provides the chance to understand different stakeholders' perceptions, especially in complex systems. To be specific, actor analysis methods could help uncover the concerns of different actors and collect relevant knowledge from a multi-actor base. Bots (Bots, 2008) developed the dynamic actor network analysis (DANA), which provides the analyst with competitive insights into multi-actor opinions about complex policy problems. The causal map structure of DANA method can be translated to formal semantic definitions, which allow inference of intuitive meaning (Bots, 2009). This method had been implemented in water resource management problems to help experts gain a holistic view of the issues and make considered decisions (Hermans, 2005). "}
{"doc719": "Few preparations are needed before conducting actor analysis methods: understand what outcomes that are expected and what information the analysis needs. Strauss and Corbin described the research process of emerging theory from systematically inductive data collection through open coding data collection, axial coding, and selective coding, instead of placing concepts and speculation at the beginning of research as grounded theory (Wuetherick, 2010). In this study, the authors created a novel system-level AFG (Action, Factor and Goal) checklist Va \n(MaaS checklist) and Vb1 (ITS checklist) through desk research and expert reviews in order to collect key stakeholders' perspective through face-to-face interviews. The AFG list is a system-level summary list that provides stakeholders with inspiration and selections to describe their perceptions in a causal diagram during interviews. Two steps were conducted to reach the AFG list, as shown in Fig. 1. The first step was to classify subsystems and summarise MaaS characteristics and ITS conceptions from the desk research. The system characteristics were summarised into the first version of lists (Va and Vb1) and then revised by experts from the related fields. After these two steps, the list was revised and used in interviews with stakeholders in order to uncover the potential challenges of adopting self-driving buses in MaaS. The ITS AFG \nchecklist Vb was used in stakeholder interviews to describe their concern, how they reacted, and the goals they wanted to achieve when a self-driving min-bus service is implemented in MaaS in the future. The analysis process is shown in Fig. 1 below. \n\nIn the following section, the literature review was conducted focuses on MaaS topics and the self-driving mini-bus studies in published journal articles, conference proceedings, book chapters, and reports using the \n\"snowballing technique\" until repeated literature appears. Since MaaS is a newly emerging concept for which there is limited published scientific literature, the authors combined rigorous and non-rigorous search engines to include the relevant literature. The rigorous search engines for published scientific literature are Web of Science core and ACM digital library. Google Scholar was also used to add related grey literature \n(Haddaway, Collins, Coughlin, & Kirk, 2015) in order to provide a complete picture of MaaS and ITS, taking into account the emergence of the technology. The authors chose search results by reading the titles and abstracts and then selected the literature for MaaS and stakeholder topics in order to summarise the system characteristics in the next section. The searching details are listed in Table 1 below. The composition of stakeholder groups and subsystems depends on the development stage and specific scenarios of MaaS projects. More details of potential stakeholder groups and subsystems are discussed in Section 3.2. \n\nTransportation systems require a multidisciplinary approach to solve the challenges of its relations to the complexity of the sectionociety it enables (Sarasini, Marcus, Karlsson, Stromberg, \u00a8 & Friman, 2016). "}
{"doc720": "Spickermann et al. (Spickermann, Grienitz, & Von Der Gracht, 2014) \ndiscussed the complexity of urban mobility systems that require more organisations to fulfil all stakeholder needs. Wong et al. (Wong, Hensher, & Mulley, 2017) proposed an efficiency framework and situated current transportation options in order to assess their efficiency and convenience from a spatial and temporal perspective. Wong et al. also suggested MaaS could be an integrative alternative to bringing together temporal effectiveness and spatial efficiency. Stakeholders are derived from both users of social systems and from the numerous organisations involved in producing and regulating transportation. An analysis from a stakeholder perspective will help researchers uncover the internal relationships in different organisations (Fru et al., 2009). What's more, the societal evolutions will depend on stakeholders' acceptance of the on-demand autonomous mobility (Distler et al., 2018). The identification of stakeholders in organisations is critical in a multisystem project, which also links to the alignment of subsystems. A system engineering approach that focuses on the dynamic management of coherent elements in interdisciplinary complex systems can also be applied to the study of a MaaS project (Moser, 2014). \n\nQualitative approaches provide powerful tools for understanding the complexities of the transportation system and travel behaviours. Expert interviews are a standard method used in social research. Talking to \n\nFig. 1. Research methodology diagram. "}
{"doc721": "| Table 1  Literature searching result.  Search  Searching Criteria                                                                           | Results                                                                                                                                                                                                                                                                                                                                                                     | Used in                                                                                                                      |                                  |                                                                                                  |\n|---------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|----------------------------------|--------------------------------------------------------------------------------------------------|\n| Engines                                                                                                                                     | This  Study                                                                                                                                                                                                                                                                                                                                                                 | Topics                                                                                                                       | Articles                         |                                                                                                  |\n| Web of  Science  Core                                                                                                                       | (Smith et al., 2018 a), (Utriainen & Poll \u00a8 anen, \u00a8 2018), (Faber, Riemhofer, Hernandez-Mendez,  & Matthes, 2018, pp. 88\u201393), (Huwer, 2004), (  Miramontes, Pfertner, Rayaprolu, Schreiner, &  Wulfhorst, 2017), (Gonzalez-Feliu, Pronello, &  Salanova Grau, 2018), (Liyanage, Dia,  Abduljabbar, & Bagloee, 2019), (Bae, Moon, &  Seo, 2019), (Geldmacher & Plesea, 2016) |                                                                                                                              |                                  |                                                                                                  |\n| ACM  digital  library                                                                                                                       | TOPIC: ((Mobility as a service) AND  TOPIC: (Stakeholder)) + TOPIC:  (self-driving bus)  Timespan: 2014\u20132020.  TYPES: (ARTICLE OR  PROCEEDINGS PAPER)  Indexes: SCI-EXPANDED, SSCI,  A&HCI, CPCI-S, CPCI-SSH, ESCI.                                                                                                                                                         | 179 + 135                                                                                                                    | 7 + 2                            | MaaS  Stakeholder perspective and  engagement in transportation  system design, self-driving bus |\n| [All: transportation] AND [All:  stakeholder] AND [All: mobility as a  service] AND [Publication Date:  (January 01, 2014 TO 12/31/  2020)] | 140                                                                                                                                                                                                                                                                                                                                                                         | 3                                                                                                                            | Mobility integration, acceptance | (Distler, Lallemand, & Bellet, 2018), (Mart\u00ed Nez                                                 |\n| and Stakeholder-driven analysis                                                                                                             | Toro et al., 2019), (Christiaanse, 2019, pp.  83\u201392)                                                                                                                                                                                                                                                                                                                        |                                                                                                                              |                                  |                                                                                                  |\n| Google  and KTH  Library                                                                                                                    | Mobility as a service, self-driving                                                                                                                                                                                                                                                                                                                                         | Keep iteration and select                                                                                                    |                                  |                                                                                                  |\n| bus system (on-demand service)                                                                                                              | following the keywords  and methodology of this  study                                                                                                                                                                                                                                                                                                                      | Introduced state of the art of  MaaS, Self-driving bus system  stakeholder-focused and actor  analysis method implementation | The reset of the references      |                                                                                                  |\n\ncrystallisation experts in the exploratory project phase is a more efficient way of gathering data than sending surveys and participatory observation (Bogner, Littig, & Menz, 2009). Moradi and Vagnoni (Moradi & \nVagnoni, 2018) interviewed 11 stakeholders to discuss the regimes and dynamics of future mobility. Sochor et al. (Sochor, Stromberg, \u00a8 & \nMariAnne Karlsson, 2015) discussed the incentives for users to adopt new mobility services using participant questionnaires, interviews, and travel diaries. Miramontes et al. (Miramontes et al., 2017) conducted only surveys to learn users' behaviour for multimodal mobility services in Germany. Smith et al. (Smith, Sochor, & Karlsson, 2019) used participatory observations in meetings conducted by the public transport organisation in Western Sweden and identified seven aspects that are potentially important to the procurement of MaaS. They considered it was still too early for MaaS services to go for public procurement. \n\nSarasini conducted 15 semi-structured interviews with car-sharing organisations and initiatives in four Nordic countries in order to analyse the business models for sustainable forms of car sharing in the Nordic region. He also examined MaaS business models that could generate lasting value that extends beyond the 'profit norm' (Sarasini, Sochor, & Arby, 2017; Sarasini & Langeland, 2015). Karlsson et al. (Karlsson et al., \n2016) used questionnaires and interviews based on UBiGo participants and identified the key attributes of MaaS, including a concept called \n\"transportation smorgasbord\". The success of MaaS business modelling raises the requirements for 'customer-oriented', multi-stakeholder collaborations between the public and private sectors, which rarely exist in the traditional transport sector (Sarasini et al., 2016). "}
{"doc722": "MaaS is intended to contribute to more sustainable transportation of people using integrated multimodal mobility services. Shared mobility services bring more innovative solutions for users, particularly in combination with public transport, to enable various modes of transport to serve as a substitute for private vehicles (Kamargianni, Li, Matyas, & \nSch\u00a8afer, 2016). Nowadays, the isolated all-purpose commute with a personal car and easier access to mobility service showing the sign of car ownership decreasing (Liyanage et al., 2019). The adoption of MaaS could lead to a reduction in car ownership and fits a trend in which younger city dwellers no longer want to own a car (Nikitas et al., 2017). Kamargianni et al. (Kamargianni et al., 2016) stated that a higher integration level of mobility is more appealing to travellers and will potentially shift the demand away from private vehicles to public transport. The direct mobility services consumption instead of having car ownership also leads to behavioural changes, after which the fixed costs will be reduced or disappear (Arby, 2016). Utriainen and Poll \u00a8 \u00a8anen (Utriainen & Poll \u00a8 \u00a8anen, 2018) discussed the role of different transport modes and services in potential MaaS. The car ownership will have significant changes from private owners to car-sharing companies, and the public transportation service needs to be more customer-centred, when MaaS solutions are implemented. Huwer (Huwer, 2004) discussed the dynamic relationship between public transportation and car-sharing and found that car-sharing could complement with public transport and provide integrated service to users. Some researchers also discussed that on-demand transportation services could bridge the gaps between public and private transportation (Inturri et al., 2019). The raising of MaaS services also brings up the discussion of how to capture values in a sustainable MaaS business model (Sarasini et al., 2017), \n(Faber et al., 2018, pp. 88\u201393). Hensher (Hensher, 2017) provided a think piece about the future development of a bus transport contract. He stated that a multi-modal mobility service could be appealing for contractual settings. A public transport agency could potentially contribute to MaaS by coordinating and integrating various service providers using a conceptual architecture that Ambrosino el at \n\n![2_image_0.png](2_image_0.png)\n\n## 4"}
{"doc723": "(Ambrosino, Nelson, Boero, & Pettinelli, 2016). defined as a Flexible and Shared-Use Mobility Agency (FSUM). Sochor el at (Sochor, Arby, Karlsson, & Sarasini, 2017). defined integration levels from 0 to 4, referring to 0: no integration, 1: integration of information, 2: integration of booking and payment, 3: integration of the service offer \n(including contracts and responsibilities), 4: integration of societal goals. Callegati el at (Callegati, Giallorenzo, Melis, & Prandini, 2017). \n\nfocus on the potential threat of individual operators and MaaS providers and present an overlay networking architecture as a countermeasure to mitigate the problem. \n\nAt the current stage, the implementation of self-driving bus systems is still limited due to the self-driving technology readiness, related regulations readiness, and social obstacles (Pettigrew & Cronin, 2019). A \nlot of research discuss the hardware, the planning, and Bae et al. discussed the comfortable criteria and time-optimal velocity planning for self-driving bus service (Bae et al., 2019). Besides the technological aspects, some ongoing discussions attempt to uncover the potential influence self-driving vehicles have on society. Geldmacher et al. "}
{"doc724": "(Geldmacher & Plesea, 2016) conducted the SWOT analysis of self-driving sharing vehicle future implementation from the users' perspective. Milakis et al. (Milakis et al., 2017) summarised aspects influenced by autonomous driving with ripple effects at the system level. \n\nHaboucha et al. (Haboucha, Ishaq, & Shiftan, 2017) analysed long-term user preferences when choosing to own or share autonomous vehicles by developing a model and collecting data from questionnaires. Self-driving vehicle adoption in a transportation system could also lead to changes in travel behaviour and habits. Nikitas et al. (Nikitas et al., 2017) provided an analysis of a selection of mobility initiatives, including autonomous vehicles, BRT, Hyperloop and MaaS, and how these new mechanisms could change travel behaviour norms. Docherty et al. (Docherty, Marsden, & Anable, 2018) discussed how essential governance should be developed to enhance public value under the new era of the 'Smart Mobility\" transition. \n\n## 3. **Maas And Afg List Va**"}
{"doc725": "In this section, the authors compared the MaaS definitions through published literature, ongoing MaaS projects to discuss the involved subsystems and potential stakeholders, as preparation to generate the AFG list Va for the stakeholder interviews. In this study, we only focus on the self-driving bus integration in the road public transportation sector of MaaS. \n\n## 3.1. System Characteristics Of Maas\n\nIn order to summarise the characteristics of MaaS, the authors started by comprising the definitions of MaaS in recent published literature. Even though MaaS is still in an early stage of development, there are various recent definitions that all share three keywords '*integrated,* "}
{"doc726": "mobility service and *user-centric*', as shown in Table 2 below. There are several similar definitions regarding Mobility as a Service (MaaS), Combined Mobility (CM), and Integrated Mobility Services (IMS). MaaS \nfocuses on customer demand and integrated service packages, CM emphasises a combination of transportation modes (Christiaanse, 2019, pp. \n\n83\u201392), while IMS focuses on integrated information, booking, and payment services (Sochor et al., 2017). \n\nMobility as a service (MaaS) is one of the solutions inspired by ITS \ntechnology and sharing economies, such as route planning, ridesharing, pop-up bus services, and e-hailing services (Utriainen & Poll \u00a8 anen, \u00a8\n2018). MaaS solution initiates from the user perspective to integrate all kinds of transportation solutions into a service package. MaaS is unified and simplified for users so they can submit their travel requests. The integration of different transportation solutions in MaaS increases efficiency but also creates challenges regarding the cooperation of multi-layer and multi-stakeholder systems. After MaaS was first introduced in Helsinki, several MaaS solutions have been tested and implemented in different countries, as summarised below. The implementation of MaaS demo project needs to fit the local transportation situations, the stakeholders' requirements, and be lead by the local government with suitable governance solutions (Veeneman, van der Voort, Hirschhorn, Steenhuisen, & Klievink, 2018), (Hirschhorn, Paulsson, S\u00f8rensen, & Veeneman, 2019). "}
{"doc727": "In Sweden, MaaS service has been implemented by UbiGo as a result of the research project Go Smart 2012\u20132014, supported by the EUH2020 CiViTAS Eccentric project (In the Spotlight: MaaS in Stockholm - UITP Summit, 2018). The aim of forming the UbiGo Company was to test the business model for MaaS operators under real commercial conditions. \n\nDuring the research, 83 households in Gothenburg paid UbiGo to provide their everyday travel needs for six months (Arby, 2016). The reasons for participation in the field tests were curiosity, flexibility, economic and environmental concerns, to gain access to cars, test living without cars, and some were encouraged by family members (Karlsson et al., 2016). Researchers found that users expected to have personalised integration mobility services with more personal support services in the mobile phone (Sochor, Stromberg, \u00a8 & MariAnne Karlsson, 2015). The environmental friendly transportation modes should also be prioritized in order to achieve a sustainable transportation system (Sochor, Stromberg, \u00a8 & Karlsson, 2015 a). \n\nIn Finland, the Ministry of Transport and Communications proposed that citizens towards using environmentally sustainable, economic and safe modes of transport, which encouraged the development of new, customer-oriented transportation services in 2009 to reform the transportation market legalization (LVM, 2009). There were two phases for improving; the first one is 'tearing down silos between transport markets,' and the second is to 'enhance the interoperable data and interface' \n(Smith et al., 2018 b). The MaaS concept was then first introduced, and MaaS Global is the first MaaS operator in the world to implement MaaS services in Finland and the UK using the Whim app. In Whim, the "}
{"doc728": "| Table 2  MaaS definitions examples in literature (Kamargianni et al., 2016; Kamargianni & Matyas, 2017; Viswanath & Mathew, 2014).  Paper title Definition Authors   | Year of  publication                                                                                                                                                          |                                                                                           |      |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|------|\n| PETRA: Governance as a key success                                                                                                                                   | MaaS provides a platform approach that can help users integrate the                                                                                                           |                                                                                           |      |\n| factor for big data solutions in mobility                                                                                                                            | informational interactions with all these services and their providers,  consequently merging the services for end users.                                                     | Wijnand Veeneman, Haikovan der  Voort,  Fabio Hirschhorn, Bauke St  eenhuisenBramKlievink | 2018 |\n| The business ecosystem of mobility-as-aservice                                                                                                                                                                      | User-centric, intelligent mobility distribution model in which all mobility  services are aggregated by an operator and supplied to users through a single  digital platform. | Maria Kamargianni and Melinda                                                             | 2017 |\n| Matyas                                                                                                                                                               |                                                                                                                                                                               |                                                                                           |      |\n| A critical review of new mobility services                                                                                                                           | The term \"Mobility as a Service\" stands for buying mobility services as                                                                                                       |                                                                                           |      |\n| for urban transport                                                                                                                                                  | packages based on consumers' needs instead of buying the means of  transport.                                                                                                 | Maria Kamargianni, Weibo Li,                                                              | 2016 |\n| Melinda Matyas, Andreas Schafer \u00a8                                                                                                                                    |                                                                                                                                                                               |                                                                                           |      |\n| Mobility as a Service - A Proposal for  Action for the Public Administration  Case Helsinki                                                                          | Mobility as a Service (MaaS) - a system, in which a comprehensive range of                                                                                                    | Sonja Heikkil\u00a8 a                                                                          | 2014 |\n| mobility services are provided to customers by mobility operators.                                                                                                   |                                                                                                                                                                               |                                                                                           |      |\n\ntraveller can select three subscriptions: Whim to go - for no commitment and no surcharges, Whim Urban - as regular travellers, or Whim Unlimited - for access to all transport services (MaaS Global - *Mobility as a* Service, 2018). \n\nBesides Sweden and Finland, the integrated mobility service projects were also tested in Vienna and Berlin. WienMobile is the MaaS application in Vienna, Austria. It provides travellers door-to-door mobility services using different modes of transport (public transport, bicycle, car sharing, and taxi, on foot or using a combination of these modes of transport) for their personalised journeys in one app. This service offers more convenience to travellers, and they can purchase a mobility service and also display their ticket in the app (The Mobility as a Service MaaS success story: WienMobil, 2017; Wiener Linien, 2018). In Berlin, the SiMobility project has been launched to create the mobility platform \n'Smile,' which provides users with all available transportation solutions. "}
{"doc729": "Before the project ended, there were 1000 pilot users registered who could discover the smile app and experience the future of mobility as a service. The benefits of Smile implementation are on-demand offerings increased the transportation system efficiency with also increase customer satisfaction. The SiMobility project has also been implemented in London and Abu Dhabi to test the influence on local transportation systems (SiMobility Flow - Mobility - Siemens, 2016; smile - simply mobile The future of mobility, 2018). \n\nFuthermore, in Asian countries such as Singapore, MaaS was tested by the joined forces of Nanyang Technological University, JCT Corporation, and SMRT Service Pte Ltd. The project testbed was on the NTU \ncampus and JTC CleanTech Park, as shown in Table 1 above. In the test eScooters, bicycles and autonomous vehicles were integrated with shuttle buses and MRT networks in current transportation systems \n(Jalan Mobility, 2017; Shen, Zhang, & Zhao, 2018). China, with the vast populations, which face the challenges of high travel demand, also initiates the concept of MaaS based on the booster of sharing economy and the development of ITS technologies (KPMG, 2018). According to some researches, China will become one of the largest markets of MaaS by 2030. The reasons for the rapid growth of shared mobility adoption are: the large percentage of non-drive populations, the pay-out for vehicle ownership, and the difficulty of apply for license plates (Keeney, 2017). Although there are several mobility service companies start providing the MaaS form products, the governments need to participate more to lead the integration of multi-modal transportation solutions (Streeting, Chen, Teng, Edgar, & Koh, 2016). \n\n## 3.2. Potential Subsystems And Stakeholders In Maas"}
{"doc730": "Potential stakeholders play a crucial role in user-centric MaaS systems. In the integration of a variety of services in MaaS, the composition of potential stakeholders is also complex and depends on the implementation scenarios. Several MaaS cases involve stakeholders discussing the challenges of implementation. Gonzalez el at (Gonzalez-Feliu et al., 2018). addressed the functional classification of stakeholders in the urban transportation system. Steven el at (Sarasini et al., 2016). \n\ndiscussed critical stakeholder groups, including mobility providers, private and public sector organisations, infrastructure providers, urban developers, and citizens, while Sochor el at (Sochor et al., 2017). discussed key stakeholders, including MaaS operators, transport service providers, researchers, and funders in Table 3 below. \n\nSmith el at. (Smith et al., 2018 a) explored how MaaS could be developed by interviewing 19 MaaS actors in Western Sweden. The emergence of MaaS has also resulted in changes to the transport ecosystem by bringing more stakeholders on board, as shown in Fig. 2 below. "}
{"doc731": "From the limited literature, the authors found two studies discussed the components of MaaS system. A scalable IT platform brand recognition and acceptance are crucial for the future adoption of MaaS (Callegati et al., 2017). Kamargianni et al. (Kamargianni et al., 2016) \ndiscussed three key components for integrated and seamless MaaS \nimplementation: ticket and payment integration, mobility package service, and ICT integration. Fig. 3 shows an example of users submitting and paying for their travel requests through the MaaS app according to their needs. \n\nIn considering the functionality of the future implementation of MaaS, combined with the discussion from the literature, as shown in Table 3, the authors summarised MaaS potential stakeholders in 6 groups, corresponding to 6 MaaS subsystems: operating group, regulatory group, energy, and environment group, technology group, road group, and social group, as shown in Fig. 4 below. The composition of each stakeholder group will depend on different implementation scenarios. In Section 4, the introduction of involved stakeholders is summarised. \n\n5\nFig. 2. **MaaS introduce stakeholders groups in transport ecosystem** (Smith "}
{"doc732": "![4_image_0.png](4_image_0.png) et al., 2018 a). \n\n| Table 3  MaaS potential stakeholder groups (Eckhardt, Aapaoja, Sochor, & Karlsson, 2016; Moradi & Vagnoni, 2018; Sochor et al., 2017; Spickermann et al., 2014).  Paper title MaaS stakeholders Authors Year of  publication  A multi-level perspective analysis of urban mobility  system dynamics: What are the future transition  pathways?  The national government, Regional administration, Local  authorities, Public transport providers, Statutory planning  authorities, Automotive industry, Academia, Civil  Afsaneh Moradi, Emidia Vagnoni 2018  A topological approach to Mobility as a Service: A  proposed tool for understanding requirements and  effects, and for aiding the integration of societal goals  MaaS operator, Transport service provider, Researcher, Funder Jana Sochor, Hans Arby,  Marianne Karlsson, Steven  Sarasini  2017  David Konig, \u00a8 Jenni Eckhardt, Aki  Aapaoja, Jana Sochor, MariAnne  Karlsson  MAASiFiE, Business and operator models for MaaS,  Mobility service providers, National and European Public  Deliverable No. 3  authorities/regulators, ITS associations and organisations, Road  operators and authorities, Research organisations  2016  Heading towards a multimodal city of the future? Multistakeholder scenarios for urban mobility  Mobility providers, Private and public sector organisations,  Sprickermann, A. Grienitz, V. &  2014  Infrastructure providers, Urban developers and Citizens  Von Der Gracht, H.A   |\n|---|\n\n![5_image_0.png](5_image_0.png)"}
{"doc733": "## 3.3.  Maas Afg List Va Gaps. 3.4. Expert Validation Of Va List\n\nIn order to visualise potential stakeholders' concerns in the interviews, the AFG list was summarised based on the MaaS ongoing project and characteristics in Section 3.1 and Section 3.2 . In order not get lost when selecting the related elements to compose the list, the AFG\nlist Va was generated by combining the existing literature, the six stakeholder group categories in section 3.1 to identify potential MaaS\nstakeholders' actions, factors, and goals as shown in Table 4 . From the literature, we find that currently, most studies discussed the designed MaaS operation process, related variety of challenges, and preparation of MaaS testing. In this table, the columns from left to right comprise 9 action selections, 29 factor selections, 12 before project testing goals, and 6 during project testing goals. The AFG list will be revised by experts and compared with the self-driving bus AFG list, then used as a tool for stakeholders to describe their perceptions to uncover the integration To revise the MaaS Va, we conducted an online validation discussion with two MaaS experts each works more than five years in public transportation and MaaS domain: one from Finland (interviewee F) and one from China (interviewee C). The interview F is the CEO of a MaaS service company and has extensive experience in MaaS implementation and operation in several cities. Interviewee C has extensive research experience and serves as a member of an expert group in several international MaaS and public transportation research projects. These two experts are from the operation and society subsystems, as shown in Fig. 4 . In the validation discussion, the authors talked with expert F and C separately through online calls and showed the Va list and discussed if anything in the Va list should be revised.\n\n| MaaS system characteristic Va list.  Actions   | Factors                          | Goal B (Before Testing)   | Goal D (During  Testing)      |                                            |                                       |       |                               |\n|------------------------------------------------|----------------------------------|---------------------------|-------------------------------|--------------------------------------------|---------------------------------------|-------|-------------------------------|\n| A1                                             | Promote cooperation and          | F1                        | License                       | GB1                                        | New entrance of new market            | GD1   | Sustainable business          |\n| exchange                                       | model                            |                           |                               |                                            |                                       |       |                               |\n| A2                                             | Mobility service integration     | F2                        | Policy                        | GB2                                        | Attract new customers                 | GD2   | Build trusting  relationships |\n| A3                                             | Service testing                  | F3                        | Incentive                     | GB3                                        | Seamless travel                       | GD3   | Promote customer  loyalty     |\n| A4                                             | Transportation data collection   | F4                        | Regulation                    | GB4                                        | Vehicle utilization                   | GD4   | MaaS scalability              |\n| A5                                             | Dynamic data-based journey       | F5                        | MaaS infrastructure readiness | GB5                                        | Value chain reorganisation            | GD5   | Boost service                 |\n| planning                                       | reputation                       |                           |                               |                                            |                                       |       |                               |\n| A6                                             | Dynamic traffic control          | F6                        | Information and communication | GB6                                        | Reduced environmental impacts         | GD6   | Enabling lifestyles           |\n| technology                                     |                                  |                           |                               |                                            |                                       |       |                               |\n| A7                                             | Dynamic journey management       | F7                        | Vehicle autonomy level        | GB7                                        | Improved energy efficiency            | F22   | Car ownership                 |\n| A8                                             | Staff training                   | F8                        | MaaS system reliability       | GB8                                        | Reduced car ownership                 | F23   | User behaviour                |\n| A9                                             | Provide support                  | F9                        | Data and information          | GB9                                        | Cross-sector innovation opportunities | F24   | Interests                     |\n| standardization                                |                                  |                           |                               |                                            |                                       |       |                               |\n| F15                                            | Mobility service mode            | F10                       | Data sharing                  | GB10                                       | Stakeholder legitimacy                | F25   | Consumer  expectations        |\n| F16                                            | Mobility resources accessibility | F11                       | Business model                | GB11                                       | Accessibility and affordability       | F26   | Curiosity                     |\n| F17                                            | Multimode mobility service       | F12                       | Payment method                | GB12                                       | Attractive urban spaces               | F27   | Passenger rights              |\n| transactability                                |                                  |                           |                               |                                            |                                       |       |                               |\n| F18                                            | Multi-model transportation       | F13                       | Personalised service          | F20                                        | Transportation data                   | F28   | Safety                        |\n| service  Public transportation usage           | F14                              | Mobility service cost     | F21                           | Transportation services sharing (car, bike | F29                                   | Trust |                               |\n| F19                                            | and rideshare)                   |                           |                               |                                            |                                       |       |                               |"}
{"doc734": "Both interviewees stated that complex multisystem integration and the negotiation process to bring different stakeholders onboard are the biggest challenges in the start phase (GB 1-9 and GD2-3). In the initial stage, authorities and key stakeholders should take the lead and encourage discussions, training and information sharing during the project testing stage (A1-9). At the same time, related regulations, policies, and licenses (F1-4, F9) should be established. During the testing process, the technology solution will be improved (F5-8). The operational factors will also be tested and improved for better solutions (F1023). According to the experts' experience, the interest and trust of MaaS appeal to more service collaboration and involved users' selection. Also, the interviewee F emphasised the importance of the MaaS system reliability (F8) is essential and will influence potential partners' decisions. \n\nThe information and communication technology (F6) are crucial enablers for the MaaS service implementation to integrate current taxis, car sharing, and rental services. The self-driving vehicles will bring more flexible mobility services, based on dynamic travel requests through the MaaS platform (F10, F18). At the same time, different stakeholders could learn from the mobility services demo process (F19\u201320, F23). The results will also strengthen the development of fully L5 self-driving vehicles in the near future. The successful implementation of MaaS is aiming to provide convenience to customers and increase the efficiency of the entire transportation system in the long-term (GB10-12 and GD1, GD4-6), there are a variety of considerations, expectations (F25) and goals from each stakeholder groups like listed in the Va list. Both interviewees agreed that MaaS is a complex and multi-layered system that needs to be analysed from the system level to get clear structures and potential challenges. The interviews conducted by researchers using the Va list can collect different stakeholders to express their opinions at the system level. This process will help to shorten the negotiation process for MaaS implementation. \n\n## 4. **Self-Driving Bus Systems And Afg List Vb**"}
{"doc735": "In the literature, several terms are used to describe whether a vehicle can drive on its own, such as autonomous vehicles or connected and automated vehicles (Elliott, Keen, & Miao, 2019). Brenden el at (Pernest\u00e5l Brenden, Kristoffersson, & Mattsson, 2017). discussed the definition of a self-driving vehicle: a road automated transport solution that can operate fully or partly with no driver on-board during the operation process. The key question is whether a car can operate without external system support. SAE International established the five-level classification of autonomous driving from L0 no automation to L1 adaptive cruise control or driver assistance, L2 partial automation for two or more primary control functions, L3 conditional automation, L4 high-level automation and L5 full automation (Greenblatt & Shaheen, 2015). The more automation level, the more technologies and systems integration will need. In this section, we will discuss the AFG list Vb by considering the needs of the CBFS L3 Self-driving mini-buses system as the starting point and discuss the future implementation of the L4 and L5 self-driving bus system. \n\nIn a self-driving bus system, vehicles range from last-mile mini-buses \n(6\u201312 persons per vehicle) to artery mini-buses (10\u201320 passengers per vehicle). There are various self-driving bus demo cases worldwide. The Easymile company, which started with the CityMobil2 project, has now launched its EZ10 autonomous shuttle bus in 20 countries (in Europe, North America, Asia Pacific and the Middle East) to test self-driving smart mobility solutions (EasyMile, 2014). In Japan, Softbank's self-driving bus HINNO has also been tested in rural areas. China is currently engaged in several self-driving mini-buses research projects (Apollo self-driving small bus information, 2018), (Yutong L4 self-driving small bus testing in public road, 2019). The CBSF project is the first open road-testing self-driving bus that combining MaaS \nconcept, which aims to achieve next-generation sustainable and self-driving mini-bus systems. \n\nIn this section, two cases were involved in establishing the selfdriving bus AFG list Vb. The first self-driving mini-bus case is used in Section 4.1 to summarise the characteristics of self-driving mini-bus systems using stakeholder surveys. The second case CBFS project in Section 4.2 and 4.3 is used for conducting the actor analysis and involved different stakeholders in describing their concerns of selfdriving mini-bus integration with MaaS. See below for details. "}
{"doc736": "## 4.1. Self-Driving Bus System Vb1 List In Case1\n\nA self-driving bus system, which aims to improve the operational efficiency of the existing transportation facilities, involves a wide range of traffic information and services. A self-driving bus system involves many subsystems for technology and service integration. It is a complex system with multiple stakeholder groups, including governments, transport authorities, industries, passengers, and research institutes involved. Appropriate role orientation and task-sharing collaborations are essential prerequisites for effective system development. A selfdriving bus system integrates many technical fields such as vehicle engineering, traffic engineering, information engineering, control engineering, communications technology, and computer technology. A selfdriving bus system will be supported by information and communication technology such as mobile communication, broadband networks, RFID, \nsensors, and cloud computing. Besides the technological supports, the challenges and real stakeholders' concerns rose from the testing process should also be collected and considered to overcome the gaps between technology feasible and implementation feasible. \n\nIn order to summarise the characteristics of a self-driving mini-bus system, a survey was conducted in an adoption self-driving mini-bus project in Changzhou, China, to complement the system characteristics list from real stakeholders. This project, which was based on the selfdriving bus prototype of a British company Westfield, aimed to uncover the challenges of a wireless charging self-driving bus system in the Chinese transport environment. The questionnaires were handed out at one of the project meetings. The participants were asked what they will concern for self-driving mini-bus system implementation in the current transportation system. The workshop included 25 participants from different stakeholders shown in Fig. 4: local government (6), the local transportation authority (4), national transportation authority (3), the vehicle industry (2), public transportation service providers (2) technology and infrastructure providers (5) and research institutes (3) to be representative and comprehensive. The participants were the key stakeholders who make decisions in the project. The results of the questionnaires are summarised in the AFG structure, which is the Vb1 list, as shown in Table 5 below. "}
{"doc737": "From Table 5, we found that the action selections relate more to the promotion of self-driving solutions, staff training, and system setup at the current stage. The factor selections are focus on the policy and regulation, technology, and the operational related issues for the selfdriving system. The goal selections focus is on technology acceptance, implementation and achieving a more efficient and sustainable transportation system. This list is used in the CBFS stakeholders' interviews in the following section. \n\n## 4.2. Case 2: Cbfs Introduction\n\nThe CBFS project is the first commercialized L3 self-driving mini-bus system with MaaS concept in China in 2017 (Autonomous buses go on trial in Shenzhen - YouTube, 2017), which aimed at testing an autonomous bus service and increasing the attractiveness of an urban bus system. In the CBFS project, the test route is 1.5 km long with three bus stops, as shown in Fig. 5 below. The bus can avoid pedestrians, accelerate, decelerate, make emergency stops, change roads and navigate traffic lights at speeds of up to 30 km/h - and it can carry up to 19 passengers. "}
{"doc738": "Five subsystems have been defined in the future implementation of CBFS, as shown in Fig. 6 below. The passenger flow management system will receive real-time passengers' travel demand and send the mobility service request to the CBFS central control system for bus scheduling and operation. The safety management system will check the bus operation process and send a potential risk report to the central management system. The charging management system will receive the bus operation schedule and pre-charge for each bus while the maintenance system will keep monitoring the real-time operation status to increase system reliability. \n\nIn the CBFS project testing stage, six stakeholder groups that cover \n\n| Table 5  Self-driving bus system characteristics Vb1.  Action Factor   | Goal                               |              |                                            |        |                                  |\n|------------------------------------------------------------------------|------------------------------------|--------------|--------------------------------------------|--------|----------------------------------|\n| A1                                                                     | Set up project                     | F1           | Investment                                 | G1     | Technical  recognition           |\n| A2                                                                     | Provide  technical  support        | F2           | Policy                                     | G2     | Participant  recognition         |\n| A3                                                                     | Promote  cooperation and  exchange | F3           | Subsidy                                    | G3     | Technology  interoperability     |\n| A4                                                                     | Promote project                    | F4           | Regulation                                 | G4     | User-friendly                    |\n| progress                                                               | system                             |              |                                            |        |                                  |\n| A5                                                                     | Organize                           | F5           | Standard-setting                           | G5     | MaaS system                      |\n| meetings                                                               | implementation                     |              |                                            |        |                                  |\n| A6                                                                     | Operation                          | F6           | Job opportunity                            | G6     | Complete laws                    |\n| dispatching                                                            | and regulations                    |              |                                            |        |                                  |\n| A7                                                                     | Data collection                    | F7           | Travel habits                              | G7     | Standards  complete and  unified |\n| A8                                                                     | Self-driving bus                   | F8           | Charging                                   | G8     | Social system                    |\n| system planning                                                        | technology                         | acceptance   |                                            |        |                                  |\n| A9                                                                     | Road testing                       | F9           | Information and  communication  technology | G9     | Transport  efficiency            |\n| A10                                                                    | Staff training                     | F10          | Safety                                     | G10    | System  integration              |\n| A11                                                                    | Control system                     | F11          | VI communication                           | G11    | Sustainable                      |\n| testing                                                                | environment                        |              |                                            |        |                                  |\n| A12                                                                    | Vehicle setup                      | F12          | Total system cost                          |        |                                  |\n| A13                                                                    | Regulation study                   | F13          | Convenience                                |        |                                  |\n| A14                                                                    | Operation  platform  supervision   | F14          | Road facilities                            | Factor |                                  |\n| A15                                                                    | Passenger flow                     | F15          | User needs                                 | F22    | Road layout                      |\n| analysis                                                               |                                    |              |                                            |        |                                  |\n| A16                                                                    | Promote new  transportation  mode  | F16          | Passenger flow                             | F23    | System report                    |\n| A17                                                                    | Expert                             | F17          | Bus scheduling                             | F24    | System                           |\n| discussion                                                             | reliability                        |              |                                            |        |                                  |\n| A18                                                                    | Transportation                     | F18          | Vehicle status                             | F25    | Mobility service                 |\n| system planning                                                        | mode                               |              |                                            |        |                                  |\n| A19                                                                    | Promote                            | F19          | Vehicle                                    | F26    | Mobility service                 |\n| operation plan                                                         | maintenance                        | satisfaction |                                            |        |                                  |\n| A20                                                                    | Case summary                       | F20          | Travel mileage                             | F27    | Travel costs                     |\n| F21                                                                    | Road environment                   |              |                                            |        |                                  |"}
{"doc739": "the subsystem structure, as shown in Fig. 4 are involved in the project: the national transportation authority, the technology provider company, the research institute, the bus operation company, the local transportation authority and the urban road association. The representatives of the six groups of stakeholders participated in the interviews. \n\n## 4.3. Stakeholder Interview And Afg List Updates\n\nDue to the project being at demo testing stage, the face-to-face interviews were conducted with the available stakeholder representative of six groups, as shown in Table 6. During the interviews, stakeholders were providing the Vb1 list to describe their perceptions for self-driving bus adoption in the CBFS case study. Their perception of the CBFS working process and concerns is shown in Appendix 1. Some updates were made by the interviewees based on Vb1, and the revised AFG list Vb are summarised in Table 7 below. "}
{"doc740": "From the literature, we find that the main drivers that bring in MaaS \nconcept are resources utilization and user-centred service satisfaction which also shows in the summarised AFG list Va. After the implementation of actor analysis with stakeholders, the authors summarised the stakeholders' concerns in Vb. The factors in MaaS AFG list Va as shows in Table 4 starting with technology, infrastructure and regulation \nalready familiar with the existing regulations and will propose updates and suggestions to improve the current regulations for self-driving bus and MaaS. A21-24 were newly added actions by national ITS research centre, local public transport operator and technology provider for more information sharing, operation planning, and the system and vehicle maintenance. In the factor selections, F14 (route planning) and F18 (vehicle maintenance) were removed and considered as the actions A22 and A24 by stakeholders. F3 (subsidy) and F6 (job opportunity) in Vb1 also didn't select by involved stakeholders due to no subsidy and unknown influence of job opportunity at the current stage. F12 (VI \n\n| Stakeholders introduction.  Group Responsibility in this case   | Descriptions                                                                                                                                             |                                                                                                                                                                     |\n|-----------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Technology and                                                  | 1. Technology provider company                                                                                                                           | Response to test, provide and maintain integrates electrification, intelligence, connected and shared-mobility                                                      |\n| Energy                                                          | services technologies, training related staffs for CBFS implementation.                                                                                  |                                                                                                                                                                     |\n| Regulation and                                                  | 2.National intelligent transportation                                                                                                                    | This organisation is a national technology research and application centre in the intelligent transportation                                                        |\n| Infrastructure                                                  | system (ITS) research centre                                                                                                                             | field. Responsible for ITS infrastructure design consulting, standard testing, solutions and product provision  in CBFS project.                                    |\n| Society and                                                     | 3.Transportation innovation industry and                                                                                                                 | This organisation is aiming at boosting the development of self-driving vehicles and EV industry. This                                                              |\n| Environment                                                     | academia forum                                                                                                                                           | organisation provides an information sharing platform among industry and academia, which promotes  convergence and collaborative innovation across multiple fields. |\n| Regulation                                                      | 4. National urban public transport                                                                                                                       | This organisation cooperate with government authorities and guide public transportation providers to                                                                |\n| association                                                     | promote the development of public transportation functions; publicise and implement national policies and  regulations on the public transport industry. |                                                                                                                                                                     |\n| Operation                                                       | 5. Local public transportation operator                                                                                                                  | The public transportation operator in this region. This organization is responsible for public transportation  service operation and future CBFS operation.         |\n| Regulation and                                                  | 6. Local transportation authority                                                                                                                        | This organisation is responsible for drafts, approves and implements transportation laws, regulations, and                                                          |\n| Operation                                                       | policies in this region.                                                                                                                                 |                                                                                                                                                                     |\n\n| Table 7  CBFS revised AFG list Vb.  Action   | Factor                                   | Goal                  |                                            |     |                                  |\n|----------------------------------------------|------------------------------------------|-----------------------|--------------------------------------------|-----|----------------------------------|\n| A1                                           | Set up project                           | F1                    | Investment                                 | G1  | Technical  recognition           |\n| A2                                           | Provide                                  | F2                    | Policy                                     | G2  | Participant                      |\n| technical support                            | recognition                              |                       |                                            |     |                                  |\n| A3                                           | Promote  cooperation and  exchange       | F3                    | Regulation                                 | G3  | Technology  interoperability     |\n| A4                                           | Promote project                          | F4                    | Standard setting                           | G4  | User-friendly                    |\n| progress                                     | system                                   |                       |                                            |     |                                  |\n| A5                                           | Organize                                 | F5                    | Passenger flow                             | G5  | MaaS system                      |\n| meetings                                     | implementation                           |                       |                                            |     |                                  |\n| A6                                           | Operation                                | F6                    | User needs                                 | G6  | Complete laws                    |\n| dispatching                                  | and regulations                          |                       |                                            |     |                                  |\n| A7                                           | Operation data  collection and  analysis | F7                    | Travel demand                              | G7  | Standards  complete and  unified |\n| A8                                           | Self-driving bus                         | F8                    | Operation                                  | G8  | Social system                    |\n| system planning                              | flexibility                              | acceptance            |                                            |     |                                  |\n| A9                                           | Road testing                             | F9                    | Charging                                   | G9  | Transportation                   |\n| technology                                   | system efficiency                        |                       |                                            |     |                                  |\n| A10                                          | Staff training                           | F10                   | Information and  communication  technology | G10 | System  integration              |\n| A11                                          | Control system                           | F11                   | Safety                                     | G11 | Sustainable                      |\n| testing                                      | environment                              |                       |                                            |     |                                  |\n| A12                                          | Vehicle setup                            | F12                   | VI                                         | G12 | Transportation                   |\n| communication                                | service revolution                       |                       |                                            |     |                                  |\n| A13                                          | Regulations                              | F13                   | Road facilities                            |     |                                  |\n| study                                        |                                          |                       |                                            |     |                                  |\n| A14                                          | Operation  platform  supervision         | F14                   | Route planning                             | F22 | System report                    |\n| A15                                          | Passenger flow                           | F15                   | Bus scheduling                             | F23 | System                           |\n| analysis                                     | reliability                              |                       |                                            |     |                                  |\n| A16                                          | Promote new  transportation  mode        | F16                   | Travel mileage                             | F24 | Convenience                      |\n| A17                                          | Expert discussion                        | F17                   | Vehicle status                             | F25 | Travel habits                    |\n| A18                                          | Transportation                           | F18                   | Vehicle                                    | F26 | Mobility service                 |\n| system planning                              | maintenance                              | mode                  |                                            |     |                                  |\n| A19                                          | Promote                                  | F19                   | Road layout                                | F27 | Mobility service                 |\n| operation plan                               | satisfaction                             |                       |                                            |     |                                  |\n| A20                                          | Test case                                | F20                   | Road                                       | F28 | Mobility service                 |\n| summary                                      | environment                              | user cost             |                                            |     |                                  |\n| A21                                          | Attend seminars                          | F21                   | Emergency                                  | F29 | Operation cost                   |\n| management                                   |                                          |                       |                                            |     |                                  |\n| A22                                          | Operation route                          | F30                   | Total system cost                          |     |                                  |\n| planning                                     |                                          |                       |                                            |     |                                  |\n| A23                                          | System                                   | A24                   | Vehicle                                    | F31 | Transportation                   |\n| maintenance                                  | maintenance                              | system  integrability |                                            |     |                                  |"}
{"doc741": "related factors (F1-10). Then the factors are operational and economic concerns (F11-22). The factors from F23 to F29 are user experiencerelated factors. Table 4 has few action selections since there are insufficient studies or cases could show the real MaaS implementation process. Therefore the goal list is long due to the high expectation from different stakeholders. The goal selections are focused on the service integration, cost, business model and environment impacts. The compassion of Va and Vb shows the potential gaps of self-driving bus integration in limited MaaS practices: In Vb, there are more operation level action selections than Va due to the stakeholders who participated in the CBFS interviews encountered more detailed operational level concerns. In comparison with factor selections, Va and Vb share a similar amount which Va has 29 selections, and Vb has 27 selections. The selections in Vb relate more to vehicle and infrastructure while the selection in Va relates more to passenger behaviour and satisfaction. In the goal selection, Va has two groups of selections with GB represents the goals which stakeholders want to achieve during MaaS testing and GD are the goals which stakeholders want to achieve after MaaS testing for large-scale implementation. The GB selections also show several potential benefits that MaaS will bring to the transportation system. The GD selections focus more on the long-term in order to improve the entire transportation system and customer satisfaction. In Vb, goal list is shorter than Va with focus on the system recognitions, interoperability, efficiency and acceptance. \n\nIn order to understand what stakeholders were most concerning, the authors listed the action, factor and goals selections which mentioned by half (3) and more than half of stakeholders, and shows the causal influence with arrows among these selections as shown in Fig. 7 below. \n\nThe causal map can be translated into formal semantic definitions, which allow inference of intuitive meaning. The structure of the diagram follows directly from the DANA method as mentioned in Section 2. The blue arrow shows the negative causal influence while the black arrows show the positive causal influences among the AFG elements. The number on the arrows means the frequency of the causal influence mentioned by different stakeholders. Most linked action, factor and goal selections are 'promote MaaS', 'system reliability' 'safety', 'MaaS system implementation', 'technical recognition' and 'transportation system efficiency'. From the diagram, we can find, 'promote MaaS', will provide more chance for MaaS test, which increase the 'system reliability'. The mobility service 'safety' factor helps society to accept the innovation service to achieve 'MaaS implementation' and 'technical recognition' goals. In the end, 'transport system efficiency' goal will be increased with MaaS implementation, technical recognition, technology interoperability and social acceptance. More road facilities will help reduce the operation cost to increase the social acceptance. "}
{"doc742": "## 6. **Conclusions And Future Works**\n\nThe major contribution of this paper is to analyse the integration challenges of self-driving mini-bus system integration in MaaS using the actor analysis method. In this study, the AFG list was used in the interviews and analysis to illustrate the relationships between different subsystems from stakeholders' perspective. The analysis and result in this study show the process about how to collect and analysis different stakeholder's concerns in a complex system. The AFG list will be iterated according to the project stage and stakeholders' focus. This study will help potential stakeholders of a self-driving bus system to foresee the inherent challenges when a self-driving bus system is integrated with MaaS in reality. What's more, the involvement of different stakeholders also contributes to providing future modelling opportunities for selfdriving bus system implementation in MaaS using the AFG list. A \nsystem-level analysis will also encourage stakeholders from different groups to further communicate in order to reduce potential conflicts and accelerate the integration and acceptance of new technologies. \n\nThe goal of combining the self-driving vehicle service and MaaS is to achieve a seamless user-centred end-to-end mobility solution to realise a sustainable and efficient transportation system. To achieve this, the dynamic on-demand supply and opened data-sharing subsystems need to integrate with existing transportation systems gradually. As more mobility services are integrated into MaaS system, more sub-systems will be required. The negotiation process and incomplete regulations among this process between different systems will be the main challenges, as reflects from CBFS stakeholders' updates in AFG selections. "}
{"doc743": "From the analysis in this study, we can confirm that an understanding of system structure and stakeholder perception is essential for the encouragement of a technological innovation project implementation. Developing a self-driving mini-bus technology is an engineering problem. However, the implementation of a self-driving mimi-bus in MaaS is a more complex problem involving multiple subsystems and stakeholders. For the emerging concept system, being aware of stakeholder perceptions by applying the AFG structure could help to align the complex relationships and get ready for future self-driving mini-bus and MaaS implementation. \n\nAs MaaS and the self-driving mini-bus system are at a very early stage, the available scientific published literature and data are limited. The composition of the AFG list will be influenced by the project stages and involved stakeholders. Several European researchers conducted the survey and interviews at the project testing stage also to learn the stakeholder expectations and current travel behaviour. In the next step, more relative key stakeholders need to be involving to extend the dataset. The enriching of the dataset both from the published literature \n\n## Appendix 1"}
{"doc744": "https://doi.org/10.1007/s40518-015-0038-5 Haboucha, C. J., Ishaq, R., & Shiftan, Y. (2017). User preferences regarding autonomous vehicles. *Transportation Research Part C: Emerging Technologies, 78*, 37\u201349. https:// \ndoi.org/10.1016/j.trc.2017.01.010 Haddaway, N. R., Collins, A. M., Coughlin, D., & Kirk, S. (2015). The role of google scholar in evidence reviews and its applicability to grey literature searching. PloS \nOne, 10(9), Article e0138237. https://doi.org/10.1371/journal.pone.0138237 Hensher, D. A. (2017). Future bus transport contracts under a mobility as a service \n(MaaS) regime in the digital age: Are they likely to change? *Transportation Research* Part A: Policy and Practice, 98, 86\u201396. https://doi.org/10.1016/j.tra.2017.02.006 Hermans, L. M. (2005). Actor analysis for water resources management - Putting the promise into practice [Tu Delft] http://www.hydrology.nl/images/docs/dutch/2005.10. \n\n31_Leon_Hermans.pdf. \n\nHermans, L. M., & Cunningham, S. W. (2013). Actor models for policy analysis. In International Series in operations research and management science (Vol. 179, pp. "}
{"doc745": "org/10.3390/su11051262. Switzerland. \n\nLVM. (2009). Finland's Strategy for Intelligent transport,\" *Programmes and strategies*. htt ps://www.lvm.fi/en/publications_series. \n\nMaaS Global. (2018). *Mobility as a service*. https://maas.global/. Mart\u00ed Nez Toro, E. E., Van Der Krogt, A., & Flores, R. S. (2019). *Mobility and integration of* public transport systems in Latin America. https://doi.org/10.1145/3366750.3366760 Milakis, D., Van Arem, B., & Van Wee, B. (2017). Policy and society related implications of automated driving: A review of literature and directions for future research. Journal of Intelligent Transportation Systems: Technology, Planning, and Operations, 21 \n(4), 324\u2013348. https://doi.org/10.1080/15472450.2017.1291351 Miramontes, M., Pfertner, M., Rayaprolu, H. S., Schreiner, M., & Wulfhorst, G. (2017). "}
{"doc746": "Impacts of a multimodal mobility service on travel behavior and preferences: User insights from munich's first mobility station. *Transportation, 44*(6), 1325\u20131342. \n\nhttps://doi.org/10.1007/s11116-017-9806-y Moradi, A., & Vagnoni, E. (2018). A multi-level perspective analysis of urban mobility system dynamics: What are the future transition pathways? Technological Forecasting and Social Change, 126, 231\u2013243. https://doi.org/10.1016/j.techfore.2017.09.002 Moser, H. A. (2014). *Systems engineering, systems thinking, and learning : A case study in* space industry (dan Braha;P\u00b4eter Erdi;Karl \u00b4 Friston;Hermann Haken;Viktor Jirsa;Janusz Kacprzyk;Kunihiko Kaneko;Scott Kelso;Markus Kirkilionis;J\u00fcrgen Kurths;Andrzej Nowak; Linda Reichl;Peter schuster. In F. Schweitzer, & D. Sornette (Eds.). Springer. https:// \ndoi.org/10.1007/987-3-319-03895-7. \n\nNguyen, T. S., Mohamed, S., & Panuwatwanich, K. (2018). Stakeholder management in complex project: Review of contemporary literature. Journal of Engineering, Project, and Production Management, 8(2), 75\u201389. https://doi.org/10.32738/ \njeppm.201807.0003 Nikitas, A., Kougias, I., Alyavina, E., & Njoya Tchouamou, E. (2017). How can autonomous and connected vehicles, electromobility, BRT, Hyperloop, shared use mobility and mobility-as-A-service shape transport futures for the context of smart cities? *Urban Science, 1*(4), 36. https://doi.org/10.3390/urbansci1040036 Pernest\u00e5l Brenden, A., Kristoffersson, I., & Mattsson, L.-G. (2017). *Future scenarios for selfdriving vehicles in Sweden* (Vol. 35) (Anna Pernest) https://kth-primo.hosted. "}
{"doc747": "Smith, G., Sochor, J., & Karlsson, I. C. M. A. (2018a). Mobility as a Service: Development scenarios and implications for public transport. *Research in Transportation Economics,* \n69(April), 592\u2013599. https://doi.org/10.1016/j.retrec.2018.04.001 Smith, G., Sochor, J., & Karlsson, I. C. M. A. (2019). Public\u2013private innovation: Barriers in the case of mobility as a service in West Sweden. *Public Management Review, 21*(1), \n116\u2013137. https://doi.org/10.1080/14719037.2018.1462399 Smith, G., Sochor, J., & Sarasini, S. (2018b). Research in transportation business & \nmanagement mobility as a service : Comparing developments in Sweden and Finland. *Research in transportation business & management* (pp. 1\u201310). https://doi. \n\norg/10.1016/j.rtbm.2018.09.004 Sochor, J., Arby, H., Karlsson, M., & Sarasini, S. (2017). A topological approach to mobility as a service: A proposed tool for understanding requirements and effects, and for aiding the integration of societal goals. *ICoMaaS*, 187\u2013201. https://www. \n\nviktoria.se/sites/default/files/pub/viktoria.se/upload/publications/sochor_et_al. _2017.pdf. "}
{"doc748": "Sochor, J., Stromberg, \u00a8 H., & Karlsson, I. C. M. (2015a). An innovative mobility service to facilitate changes in travel behavior and mode choice. In ITS world Congress (issue November 2013). https://doi.org/10.1016/j.jallcom.2007.02.096 Sochor, J., Stromberg, \u00a8 H., & MariAnne Karlsson, I. C. (2015b). The added value of a new, innovative travel service: Insights from the UbiGo field operational test in Gothenburg, Sweden. *Lecture Notes of the Institute for Computer Sciences, SocialInformatics and Telecommunications Engineering, LNICST, 151*. https://doi.org/ \n10.1007/978-3-319-19743-2_26 Spickermann, A., Grienitz, V., & Von Der Gracht, H. A. (2014). Heading towards a multimodal city of the future: Multi-stakeholder scenarios for urban mobility. \n\nTechnological Forecasting and Social Change, 89, 201\u2013221. https://doi.org/10.1016/j. \n\ntechfore.2013.08.036 Streeting, M., Chen, H., Teng, Y., Edgar, E., & Koh, J. (2016). Mobility as a Service the next transport disruption - a perspective from China. *Nowiny Lekarskle*. http://www \n.lek.com. "}
{"doc749": "Wang, Q., Hauge, J. B., & Meijer, S. (2019). Adopting an actor analysis framework to a complex technology innovation project: A case study of an electric road system. Sustainability, 12(1), 313. https://doi.org/10.3390/su12010313 Wong, Y. Z., Hensher, D. A., & Mulley, C. (2017). Emerging transport technologies and the modal efficiency framework: A case for mobility as a service (MaaS). In International conference Series on competition and ownership in Land passenger transport, 1\u201324. https://doi.org/10.1006/jcat.1999.2742 Wuetherick, B. (2010). Basics of qualitative research: Techniques and procedures for developing grounded theory. In (2nd ed.)*, Vol. 36. Canadian journal of University* Continuing Education. SAGE. https://doi.org/10.21225/D5G01T. Issue 2. \n\nYelin, M. (2017). *Self-driving buses take public road test in Shenzhen - Caixin Global*. https \n://www.caixinglobal.com/2017-12-05/self-driving-buses-take-public-road-test-in \n-shenzhenself-driving-buses-take-public-road-test-in-shenzhen-101180843.html. \n\nYutong L4 self-driving small bus testing in public road. (2019). Bjnews http://www.bj news.com.cn/auto/2019/05/17/580208.html. "}
{"doc750": "smile - simply mobile The future of mobility. (2018). http://smile-einfachmobil.at/inde x_en.html. \n\nQiuchen Wang is a doctoral student from the Department of Biomedical Engineering and Health Systems. She received her degree of Bachelor of Science in Transportation Engineering from Beijing Jiaotong University and degree of Master of Science in Transportation and Geo-information from KTH Royal Institute of Technology. Her Ph.D. \n\nresearch is focused on stakeholder influence in technology innovation complex systems. Jannicke Baalsrud Hauge is an associate professor in production logistics at KTH. She holds a PhD in Engineering from the University of Bremen. In 2003 she joined BIBA (Bremer institute f\u00fcr Produktion und Logistik), where she is head of the BIBA Gaming Lab as well as coordination of the BIBA contribution in several national and international projects in the field of Serious Gaming as well as ICT in production and supply chain networks and CPS. In 2015 she also joined KTH, where she is now working as an associate professor for production logistics. She is responsible for the master programs in Sustainable Production Development and Applied Logistics. Her two main research topics are ICT in logistics (including CPS) and engineering education. Jannicke is a member of several boards and has authored 250+ papers. "}
{"doc751": "Keywords:\nshared, autonomous, Waymo, e3*value,* \nPhoenix, modeling, economic benefits The research objective of this work is to analyze what is behind the self-driving offer implemented in Phoenix (Arizona), by Waymo, a service called Waymo One, and model it in e 3*value*. Through a comprehensive literature review and the application of e 3*value* modeling, this study focuses on the fundamental principles and technological advancements of self-driving vehicles and shared mobility services. Waymo's operations and ecosystem are systematically modeled, providing a detailed representation of the service. Results demonstrate the potential improvements in road safety, traffic reduction, and emissions mitigation achieved through shared autonomous mobility. The e 3*value* model offers a holistic perspective on the interactions and value exchanges among stakeholders, including passengers, vehicle operators, infrastructure providers, and regulatory bodies, elucidating their roles within the shared autonomous mobility ecosystem. The idea is to support the development of other shared autonomous vehicles trials around the world. Main goal is to improve the shared autonomous mobility offer, which means better safety on the road, reduced traffic, and lower emissions in the metropolitan areas of cities. Therefore, modeling Waymo One can be a basis for the extension of shared autonomous vehicles businesses to other companies in different geographies.\n\n## 1. Introduction\n\nA self-driving car is a vehicle that can operate autonomously with the help of sensors and software without the need for human intervention. Autonomous vehicles, driverless vehicles, and robotic vehicles are other terms for self-driving cars [1]. Self-driving cars are already on the road, but most countries have yet to license fully autonomous vehicles. Currently, cars are semi-automated and require human intervention. Autonomous cars work with the use of different technologies, including LiDAR, sensors, laser lights, GPS, computer vision and radar, among many others."}
{"doc752": "All of the sensors' input is processed by sophisticated software, which plots a path and sends instructions to the car's actuators, which control the throttle, brakes, and steering. The software follows traffic rules and navigates through the roads due to obstacle avoidance algorithms, predictive modeling, and object recognition.\n\nWe focus on the use of self-driving cars in the United States in this paper because we are modeling a Waymo project implemented in Phoenix. The technology for self-driving cars has received a lot of attention in this country, not to mention the business, policy, legal, ethical, and regulatory challenges. It is safe to say that almost every day, journalists and columnists cover the latest developments in this technology, owing largely to safety concerns about these vehicles. The business models of automotive manufacturers operating in the US are in the spotlight of the world, namely because of the great advances on part of Tesla. Autonomous vehicles have the potential to remake not only the automotive industry but as well transportation services and infrastructure requirements for cities [2].\n\nThe combined awareness of energy issues and extreme pollution within cities have also boosted the big push of autonomous vehicles technology innovation. Regulations have imposed restrictions on vehicles in cities and the relationship between the user and the vehicle has been changing and will continue to change. In city metropolitan areas the concept of ownership of the vehicle replaces its use. As the relationship to everyday objects turned into customary contracts with the mobile phone, and the laptop computer, the idea of becoming a single user of a means of transport is becoming a reality with the appearance of autonomous cars [3]. "}
{"doc753": "In the context of autonomous vehicles, extensive literature has highlighted their potential benefits in terms of mobility, traffic, emissions, and safety [4, 5].\n\nAs autonomous cars start gaining relevance, it is becoming important for companies to conduct trial runs along with services such as ride-hailing in different regions of the world. \n\nHowever, there are gaps in research regarding the business models and operational dynamics of shared autonomous vehicle services, particularly in the context of the ride-hailing industry. This study addresses these gaps by analyzing and modeling Waymo One, a shared autonomous vehicle ridehailing service in Phoenix, Arizona, using the e 3*value* methodology. Filling these research gaps, this study contributes to the advancement of shared autonomous mobility and provides insights for future research."}
{"doc754": "The primary objective of this research is to analyze the business model behind Waymo One, a shared autonomous vehicle ride-hailing service implemented in Phoenix, Arizona by Waymo, and to model it using the e 3*value* methodology. It is also our goal to understand the operational dynamics, stakeholder interactions, and value propositions within the shared autonomous mobility domain, with the goal of supporting the development and expansion of similar initiatives globally.\n\nTo support our work, we resort to using the e 3*value* methodology to model this business that has been implemented in Phoenix by Waymo, called Waymo One. \n\nUnderstanding Waymo One business concepts in-depth is the first step in developing such ideas. "}
{"doc755": "The e 3*value* methodology, a recognized approach for designing e-Business models, plays a pivotal role in this study. \n\nBy employing e 3*value* modeling, we can comprehensively analyze the intricate dynamics and interdependencies within the shared autonomous mobility domain. This methodology facilitates a thorough and collaborative understanding of the underlying concepts and profit drivers involved in the business model of Waymo One, Waymo's shared autonomous vehicle ride-hailing service in Phoenix. Through the e 3*value* approach, we gain valuable insights into the value propositions, stakeholder interactions, and revenue generation mechanisms that drive the success of such services. This detailed understanding of the e 3*value* model allows us to advance our knowledge of autonomous vehicle implementation in the ridehailing industry and provides a solid foundation for future developments and improvements in the broader autonomous mobility market segment.\n\nThe final goal is to reach an understanding of how autonomous vehicles are being implemented in ride-hailing businesses, through the Phoenix ecosystem, and how they can evolve incorporated in the future of the autonomous mobility market segment."}
{"doc756": "This document is structured as follows. In section 2 we define research background, in section 3 we describe what is the research methodology adopted in this paper. The modeling of what is behind shared autonomous vehicles in Phoenix using the e 3*value* is presented in section 4, along with a comprehensive interpretation of those models. In section 5 we establish what we have learned throughout the study and writing of this paper. Finally in section 6 we set up the final conclusions.\n\n## 2. Research Background\n\nAccording to the information collected at an early stage and to answer the central questions of the present study, it was pertinent to frame and conceptualize the main topics, namely Autonomous Vehicles, Waymo and e 3*value* once these are central topics from which our work is based on. It was important to have a good background research supported with a solid literature review as a starting point to our work. In this way, the three topics presented are centered on relevant and current studies to better understand how they relate to each other and sustain the framework of this work."}
{"doc757": "## 2.1 E 3Value\n\nThe e 3*value* methodology [6] is a conceptual modeling tool for analyzing the feasibility and sustainability of a business idea. The e 3*value* methodology [7] provides means to explore value webs. Value webs consist of organizations or enterprises that offer a service to the market, it symbolizes the linked links that exist between different businesses inside a business ecosystem, where value is created, exchanged, and consumed. The concept of a value web highlights the collaborative aspect of value production and distribution among participating actors. The e 3*value* methodology makes the exploration of a networked business idea easily comprehensible. The \"e 3\" stands for \"Economics of Electronic Environments\", and the \n\"Value\" stands for the value exchanges in business environments.\n\nThe e 3*value* was chosen as the modeling methodology for this study because it provides a comprehensive framework for analyzing the feasibility and profitability of a business idea within a networked context. It allows the study of value webs and the exchange of value objects through value interfaces, showing economic reciprocity in business transactions. The e 3*value* methodology's modeling components gives a deeper understanding of online business models and support profitability assessment for all stakeholders involved. Its focus on value networks and economic value aligns well with the objectives of this study, which aims to analyze and model the business dynamics of shared autonomous vehicles. By utilizing e 3*value*, this research can gain valuable insights into the value exchanges, stakeholders' roles, and profitability drivers within the shared autonomous mobility ecosystem."}
{"doc758": "The value objects, such as money, services, products, data, etc., are exchanged through value ports which are grouped into value interfaces. These value interfaces model the economic reciprocity that exists in every business transaction [8].\n\nFor example, a customer's need is satisfied if a customer can successfully order a service from a company. To satisfy this need, an exchange of value objects (service against money) via an interface is conducted. These activities are performed in exchange for value objects. For instance, in the case of a service provider, the value object, which is the service, is exchanged in return for money. The boundary element at the company indicates the end of value transfers.\n\nThe e 3*value* ontology stipulates that the actors exchange value objects by means of value activities. The value activity should generate profit for the actor. Production, trade, distribution, and consumption of value objects are examples of these activities. Value actions are undertaken with the goal of generating profit for the actors involved and are critical to the value web's operation. Deeper insight in e 3*value* modeling shows that this method only covers exchange and trade processes but leaves out production and conversion processes. The e 3*value* model only focuses on operational level (what has happened) and not on management policies (what could or should happen). It also enables value network modeling, aiming to provide a common understanding of a business idea executed by a network of actors that jointly create, distribute, and consume value in inter-organizational business models. We can assume that it considers the economic value of a value proposition. The purpose for which the e 3*value* was created is to reach a better understanding of an online business model by the stakeholders, and to be able to do profitability assessment for all parties involved [6]. It provides a group of modeling components that are used to build the models [7]."}
{"doc759": "At Level 0, no automation is present, and the driver has complete control of the vehicle. In Level 1, there are already driver assistance systems, offering features like lane monitoring and adaptive cruise control. Level 2 vehicles have partial automation capabilities, enabling it to handle specific tasks such as steering and acceleration under certain conditions, while the driver remains responsible for monitoring the surroundings [10].\n\nModern vehicles are labeled as level 3, where multiple safety systems are handled by the system (lane monitoring, adaptive cruise control, brake assistance, parking assistance), \nbut the driver needs to be always alert to intervene and cannot leave his hands out of the steering wheel (although many modern cars can drive autonomously for a period of time, by law it is required that the driver keeps the hands in the steering wheel all the time). Level 4 vehicles handle multiple safety systems and operate in a wider range of environments. \n\nLevel 5 automation is the end goal of autonomous driving, where all the systems in the car are operated by the Advanced Driver Assistance Systems, under all driving conditions (such as snow-covered roads and unmarked dirt roads) and would not require any human intervention. In practice, the steering wheel is useless [10]."}
{"doc760": "This, however, still requires significant advances in multiple areas, such as sensor technology, computing systems and automotive networks, as referred by. The Waymo car right now is considered to be between Level 4 and Level 5 [11]. \n\nIn the last few years, we have seen a big development in the technology that supports this, such as sensors, cameras, LiDAR, Artificial Intelligence (along with Machine Learning and Deep Learning), Neuronal Networks, 5G, Big Data and the Cloud. \n\nMany research articles have been published in the academic literature describing the technological advancement of Autonomous Vehicles [12]. However, academic literature outlining the autonomous vehicle can be very contradictory in terms of opinions (both positive and negative) in cities and how policies are being introduced to promote or address various disruptive effects is fairly limited [13]. Anyway, a recent prediction suggests that by 2045 autonomous vehicles would take up half of all the traffic on the roads in the world \n[4, 14]."}
{"doc761": "## 2.3 Waymo\n\nTo understand the reason that Waymo is entering this new market of shared vehicles, we first need to understand the value propositions which the company is governed by. It is important to note that Waymo is a subsidiary of Alphabet Inc, the parent company of Google, and as such, shares the same values of these companies. \n\nAs advertised, Google has strong social and moral awareness in all its businesses ramifications, and this is a principle of the Alphabet Inc. group that is transversal to all its companies, where Waymo is no different. Waymo's spin-off is based on a set of fundamental value propositions that are critical in determining its business scope. To begin, the company strives to improve transportation for people all over the world by making it safe and simple to move people and things. Second, Waymo intends to build a more efficient network by leveraging new technologies such as self-driving cars, which will significantly reduce the cost of public transportation. Furthermore, Waymo intends to transition to a fully autonomous service that is less expensive than car ownership while improving urban quality of life. Another important goal is to reduce CO2 emissions and maximize people's useful time when traveling, whether for work, tasks, rest, or other reasons. As stated by Margulis and Goulding [15], these goals are the foundation on which Waymo was founded, to improve people's lives and help promote planet sustainability. "}
{"doc762": "Google started investing in the autonomous vehicle's technology in 2009, with the creation of Google car. With the growing importance of this technology the company decided to create Waymo in order to have an entire company fully dedicated to the research and development of the technology. \n\nAt the same time Waymo was founded, Tesla was also starting to invest a lot of its resources in this area of expertise.\n\nNevertheless, since then, Waymo has led the pack of autonomous vehicle developers, setting the stage for what could be a massive transformation in personal mobility. The company was among the first to deploy fully driverless cars, and its sights were set on ride-hailing and freight-hauling as its commercial pursuits."}
{"doc763": "Waymo's mission to reduce traffic injuries and fatalities while also improving mobility for all has led to the company expanding the deployment of automated vehicles on public roads without a human driver behind the wheel. As part of this process, the company is committed to providing the public with relevant and informative data about the demonstrated safety of their driving system that is named Waymo Driver.\n\nWaymo is not the only company transforming the market with autonomous vehicles and mobility-as-a-service. Several other companies and players have emerged, each with their own unique perspectives and contributions to the sector. Tesla, a major contender, has made significant efforts in self-driving technology, as evidenced by their advanced autopilot feature\n[16]. Automakers such as General Motors, Ford, and BMW are aggressively expanding their autonomous car projects, frequently forming alliances with ride-hailing firms to investigate creative mobility options [17]. Uber and Lyft have already entered the fray, incorporating self-driving cars into their ride-hailing platforms [18]. Meanwhile, rising firms like Cruise, Zoox, and Aurora are making significant gains toward deploying autonomous vehicles at scale [19].\n\nIt is important to realize that Waymo self-driving cars go through a more comprehensive set of tests than humans do, as proven by its safety report. Its approach to safety is the scope of the design and testing regime present in the company's assessment of the vehicle's safety. For such vehicles to work at all, a raft of sensors is needed to always provide the "}
{"doc764": "![3_image_0.png](3_image_0.png) vehicle's software with situation awareness. Unlike human drivers, the self-driving car can continuously sense its 360degree surroundings using multiple sensors: color-aware visible light cameras, radar transceivers, three Lidar sensors (short, medium, and long-range), audio detectors, and GPS receivers. Moreover, a great deal of redundancy is built into the system to provide backup capacity in the event of various failure scenarios.\n\nThe Waymo vehicles have accumulated four million miles of driving on city streets of California, Washington state, Arizona and Texas. In addition, each day, as many as 25,000 virtual Waymo self-driving vehicles drive up to eight million miles in simulation for an accumulated total of 2.5 billion simulated miles during self-driving car development.\n\nAccording to the safety report, Waymo has established a private 91-acre closed-course testing facility in California, specifically designed and built for their own unique testing needs. This private facility is set up like a mock city, with everything from high-speed roads to suburban driveways to a railroad crossing. The team uses this and other closed-course facilities to validate new software before it is released to the fleet of vehicles on the road, as well as to test rare scenarios so vehicles gain experience with unusual situations. The simulation capability is especially important because it allows Waymo to test any new software or hardware in parallel, which would take far too long to test in the real world."}
{"doc765": "Right now, Waymo is running a fully autonomous ridehailing service, Waymo One, in the East Valley of Phoenix, Arizona, in Figure 1 is represented the area of operations. This service is already fully functional and operating with the population of Phoenix for anyone to use [20]. It is a simple service that uses an application like Uber and Lyft to request a taxi service from any point A to any B, within the designated area, but without the presence of a human at the wheel. This service is now expanding its operations to San Francisco, California, using a new fleet of fully electric cars, the Jaguar I-Pace, instead of the Chrysler Pacifica Minivan (hybrid car)\nused in Arizona.\n\n## 3. Literature Review\n\nA complete and comprehensive description of what supports Metro Phoenix ride-hailing service based on autonomous vehicles does not exist at all, either in stakeholders' official communications or in scientific papers. Therefore, the research was made through an extensive literature review in spread and unstructured information available on the several Waymo and other stakeholders' websites, in media articles and in some papers matching specific aspects of the existing Phoenix offer. This was important to support the modeling in e 3*value*, identify the stakeholders and understand their relationship with Waymo and what type of value transactions they executed."}
{"doc766": "Waymo made available a perception dataset comprising high-resolution sensor data and labels for 1,950 segments. In March 2021, Waymo Open Dataset was expanded to also include a motion dataset comprising object trajectories and corresponding 3D maps for 103,354 segments. Waymo, therefore, aims to aid the research community in making advancements in machine perception and autonomous driving technology.\n\n## 3.3 Safety And Performance Data\n\nWaymo's official information also includes The Emergency Response Guide and Law Enforcement Interaction Protocol\n[23], and documents like Safety Report [24] and the Safety Methodologies and Safety Readiness Determinations. Waymo also shares papers like The Public Road Safety Performance Data [24] and Waymo Simulated Driving Behaviour in Reconstructed Fatal Crashes within an Autonomous Vehicle Operating Domain [23]. These information helped us comprehend how seriously Waymo has taken safety issues in the development of their technology, it has been their main focus since its creation."}
{"doc767": "Other studies focused on evaluating the safety and performance of shared autonomous vehicle services, analyzing technology reliability, how they interact with humans, and traffic flow impacts [20, 25]. Our research aims to provide insights for strategic decision-making, operational action, and verify the overall success of shared autonomous mobility services.\n\nMost of the relevant information comes from Waymo's website [21, 22]. The company has been very keen on sharing the most information possible without compromising its own authenticity as an innovative company, protecting itself from giving away all the knowledge. On the other hand, as expected, some important information was only available by searching alternative sources, namely publications like Wall Street Journal, The Verge, The Drive, Electrek, Business Insider, Electronic Design, The Atlantic or even some MIT Lectures with Waymo Engineers as guests. \n\nWaymo is very clear about further needed information for research projects, when it states on its FAQ \"Everything we have to share is available on this website and on our blog, so they are the best places to look for details on Waymo. We can't provide any other information at the moment\"."}
{"doc768": "Based on available formal and informal information, it was possible to identify the various stakeholders and actors that are present in this ecosystem. Information provided by Waymo itself or its own partners through literature, articles, formal speeches [26] and interviews was vital to understand how all the actors present in the ecosystem interact and exchange value with each other.\n\nAs an Alphabet Inc. company, Waymo may not publicly reveal all the information regarding its business strategies, value networks, or specific partnerships. Some information may be restricted due to confidentiality agreements or competitive reasons, reducing the amount of information provided. Furthermore, the autonomous car market is fast expanding, and businesses such as Waymo are constantly refining their business models and value networks. As new developments and partnerships emerge, this dynamic nature might cause information to become outdated or incomplete.\n\nWhen a business formalizes its operations, it is part of a network of companies exchanging value, a value network, that is represented in Figure 3."}
{"doc769": "In the proposed e 3*value* model for the Waymo One Phoenix components in Figure 3, there is one partnership between two Alphabet companies, the actors Waymo and Waymo One. There are seven outside actors involved: Intel, Roush Enterprises, Phoenix Government, Trov Insurances, Avis, Bosch and Stellantis. And there still three market segments: Investors, Clients, and Satellite Providers.\n\nIn the following research we take a deeper look into each main actor and how it relates with the outside ones. This type of analysis will help us later understand the plans that Waymo has for the future as creator of Waymo One. \n\nThis first overview over the several Phoenix components is helpful to understand how Waymo and Waymo One are operating in this pilot project city. As until now, in this first phase, we modeled the ecosystem in the software through information, insights, documents and articles that were available."}
{"doc770": "![6_image_0.png](6_image_0.png)\n\nChrysler and Jaguar to use their cars. They produce most of the sensors and computing technology in-house with tailored deals with Bosch and Intel, which makes custom sensors and software for Waymo to install in their cars. This is particularly important in terms of future business strategy for the company, being able to adapt its own technology to different types of cars from different manufacturers and then provide it to a buyer (mobility provider), in this case Waymo One. \n\nIn the following Figure 4, we look closer to how Waymo executes its value transitions with other companies, the outside (partnership) actors, in order to be able to create, develop and implement its business values, so reaching the final goal of creating autonomous cars. This is considered the business model that provides the product."}
{"doc771": "The central actor, Waymo, exchanges value with four different actors. To help safely navigate the complexities of the road, Waymo's self-driving technology needs to see and identify what is around it. To perceive its surroundings, Waymo created its own technology called Waymo Driver, which relies on a powerful custom sensor suite of LiDAR, \ncameras and radars, while neural nets empower the selfdriving system to understand the sensor data and respond to a wide range of scenarios [25]. This technology has been developed not only through inhouse intelligence but also with the help of partnerships created with two other outside actors: Roush Enterprises, an engineering consultant company working with Waymo since 2015 providing engineers and knowledge in the autonomous cars sector supporting directly the development of Waymo Driver, it has been also developing autonomous vehicles technology for other companies [27], Intel, that is a big partner of other companies of the group, which has been developing a custom-made software, providing car chips and sensor-data processing for Waymo since the launch of Google's [28]. As Waymo's selfdriving technology becomes smarter and more capable, its high-performance hardware and software will require even more powerful and efficient computing. By working closely with Waymo, Intel is providing Waymo's fleet of vehicles with the advanced processing power required for autonomy levels 4 and 5.\n\nIn terms of hardware, Waymo has a big partnership with Stellantis, the manufacturer of the Fiat Chrysler Pacifica [29], that provides Waymo with the fleet operated in Phoenix. One of the great advantages of Waymo is the manufacturing of its own sensors and LiDAR's fitted in the cars, which is the main reason why Waymo is considered to be the leader in autonomous driving. Even though these sensors are overly complex and expensive, they are a significant improvement when compared to the cameras and sensors self-driving pack of Tesla, as stated by Rice [30]. A collaboration with Bosch helps Waymo build all of the sensors and LiDARs needed to put together the self-driving Pacifica [31].\n\nIn terms of market segments, Waymo exchanges value with Investors that fulfil the need for funding and investment. One of Waymo's investor partners is Magna International [11], that is one of the largest companies headquartered in Canada and the largest automobile original equipment parts supplier in North America. Like Magna, there are other societies of investment, one of them being Alphabet for obvious reasons, that fund Waymo's technology investigation, and in return for "}
{"doc772": "After months of testing and millions of miles of developing self-driving vehicle technology, Waymo launched the country's first commercial autonomous ride-hailing service, the Waymo One, a spin-off that was created with the purpose of using its parent company autonomous cars to run this new business. The following image, Figure 5, is a representation of how Waymo One interacts through value exchange with outside (partnership) actors in order to run its ride-hailing service in a sustainable and optimal way. \n\nIn the present model, the central actor Waymo One is responsible for the ride-hailing service with Waymo's autonomous cars. It consists of a company that runs a platform that processes customers' requests, fleet management, control management, legal issues (legislations), accident handlings and cars supply. \n\nThe value flow starts in the client, which has a need of going from point A to point B, wherever those locations are within Chandler designated area. This need is solved through the service provided by Waymo One. The customer needs to pay a fee and provides his personal data in exchange for the service. The payment is processed by the platform itself, that collects provided data from client's personal information and also the data gathered from the trip. As soon as the payment proceeds, the platform is going to communicate the nearest car to meet the customer, and then the trip starts. "}
{"doc773": "Depending on what type of information the platform receives, there are signals that can be emitted through different value actions of the platform. If, by any chance, there is a problem with a car or an accident, the client can give that information through his phone, and accident follow-up actions are triggered. The platform is directly in contact with Trov [32], \nthe insurance company responsible for Waymo cars for this matter.\n\nIn terms of fleet management, it is known that Waymo has a hangar where it keeps its cars. This is where the cars are s stationed when they need to be cleaned, charged, or refueled, get checkups to prevent breakdowns and get fixed when needed. All this maintenance is AVIS' responsibility [32]. It is important to note that an autonomous car needs more maintenance than a normal car due to the lack of presence of a human figure, especially preventive maintenance. These types of cars need not only normal maintenance, such as oil and brake pad changes, but also frequent checkups on the LiDARs, sensors and cameras that support the autonomous driving.\n\nThe Phoenix Government actor is responsible to legislate and regulate this service, in a continuous way. We must not forget what was stated in the beginning of this study, autonomous cars are still at an early stage in terms of their development, and due to the lack of human presence, there is a bigger social responsibility associated to it. As for all of this, governments reserve to itself a strict and continuous presence when controlling and legislating these services."}
{"doc774": "Conceptually, what has been done in Phoenix is a Value Network between two distinct companies. As previous highlighted, Waymo is responsible for developing the technology and applying it to the vehicles, creating its own autonomous vehicles. On the other hand, Waymo One is a company that provides a ride-hailing service in the city of Phoenix, which uses a fleet of autonomous vehicles provided by its parent company, Waymo. Even though the information about how these two companies is run is minimal, it is correct to assume their relation as a partnership between a supplier and a client, as it was modeled in Figure 6, representing the value that is exchanged between these two companies.\n\nAs referred before, Waymo is developing an Autonomous Driving Technology, called Waymo Driver, as well as all the sensors, LiDARs and cameras that are needed in an \n\n![8_image_0.png](8_image_0.png) autonomous car. Waymo is also responsible for the application of this technology, as previously stated. Waymo One, on the other hand, pays Waymo for its product (car and technology)."}
{"doc775": "Waymo has kept this relation/partnership between Waymo and Waymo One very indoor, and so it is known very little about how exactly these two works with each other, how they interact or how much Waymo One pays for the cars, if indeed there is a payment. This makes it more difficult to extrapolate these scenarios to other markets and situations, since we do not have a clue of how much Waymo is charging for its autonomous vehicles. Such information would help this research since we would be able to use e 3*value* to perform a profitability assessment and analyze the feasibility of this business model and future other investments that pretend to use Waymo Technology.\n\n## 5. Discussion\n\nThe e 3*value* tool allowed us to perceive how the value actors exchange value with each other in order to reach a sustainable business model. It also allowed us to understand what is needed in order to reach a sustainable system to a similar business like this. By studying and analyzing all the information and insights gathered from this study, we can simulate and predict a business model for a ride-hailing service, using Waymo's autonomous cars, in other cities in the world. "}
{"doc776": "The great advantage of using e 3*value* to model businesses is not only to understand how the value networks interact but also to use it as references for future businesses. As stated, e 3*value* provides a mutual understanding of a business idea executed by a network of actors that jointly create, distribute, and consume value in inter-organizational business models, providing an overview of operations.\n\nFrom the models it was clear to understand that Waymo tried to partner every type of companies that could provide complimentary products or services to development of the technology. Right now, the company focus all of its own resources developing the Waymo Driver and its implementation, everything else is outsourced through partnerships with leading companies in each sector. These companies also have high interest in being present in the initial phases of the development of these cars, making them ready and prepared for the future.\n\nWe believe that there are two perspectives of doing business in the shared autonomous mobility market: To develop the needed technology to implement in a mobility service, or to buy the technology already developed and implement it in a service of its business area, such as Uber or Lyft. This Waymo business study can help us understand both business paths."}
{"doc777": "## 5.1 Technology Development And Implementation\n\nAs acknowledged, Waymo is responsible for developing the technology and executing it through Waymo One. Although vehicles are not the business scope of Alphabet, the developing of the autonomous technology goes in hand with its value propositions of innovation, social awareness, and emissions reduction. It always has been the purpose of the group to be leaders in any technology field.\n\nThis path of business can be compared to what Tesla has been doing the past years. They have been developing their own selfless driving technology and implementing it in their own vehicles. For Tesla it makes sense to develop and implement all the knowledge gathered throughout the years once they are a company specialized in automobiles and innovative mobility. Unlike Tesla, Waymo does not have the facilities or the capability of manufacturing their own cars, parts and sensors, thus Waymo has the need to resort to other companies. From the outset this will always be a limitation in relation to the rest of the market segment."}
{"doc778": "On the other hand, Waymo is a company fully focused on the development of the autonomous technology, although the company does not develop its own cars, this has not been a problem for Waymo. Since the Google project car Waymo changed its strategic directions to develop a system that is implemented in normal vehicles. For this reason, Waymo as company only has one objective and that is to develop the best autonomous deriving system. In consequence Waymo right now is one of the best companies in the autonomous driving market while Tesla is considered to be dead last [33].\n\nFrom the e 3*value* model of Waymo, we can see that the value network involves value exchanges with many companies that provide hardware and software to the construction of the autonomous car. Waymo's role is to set up everything and through specialized labour and know-how develop the technology.\n\n## 5.2 Technology Purchase"}
{"doc779": "Companies that already have a big presence in the mobility market prefer to buy this type of technology in order to increase their engagement with the clients. It is not profitable for a company that is specialized in mobility services to operate outside its area and develop a new technology, so it makes sense for these mobility companies to go to the market of autonomous vehicles and buy the product already developed. It is as simple as buying a product and monetize it through a service. \n\nLiterature says that large companies are no longer developing all the applications, at this point they work much more through partnerships with smaller companies that specialize in sub-segments. As stated by Doz [34], partnerships between larger and smaller firms have multiplied over the last few years. To large firms, partnerships usually offer a channel for tapping into the innovative and entrepreneurial potential of smaller companies, and for overcoming some of their own rigidities. In most of the observed partnerships, smaller firms perform research and development for, and/or transfer innovations to, the larger firms. These larger firms offer their smaller partners the ability to reach world markets quickly without having to build their own technology.\n\nWaymo's former CEO John Krafcik stated in an event in New York back in 2018 [35] that their future focus is to improve the driverless technology through Waymo Driver and leave the rest of the car production and ride-hailing business to others in the industry. This is especially important because it sustains what we concluded from our investigation."}
{"doc780": "It is important to understand that Alphabet Inc.'s business scope is focused on investing and acquiring technology companies to profit from them in the future [36]. The literatures teach us that Alphabet is operating this way with its other companies. Google developed the Android, and phone manufacturers use the Android on their phones. Though Waymo has started to create ride-hailing services in a couple of areas, there is a possibility that the creation of the company will serve to validate and demonstrate its technology as a showcase to other companies.\n\nWaymo is already partnering with Uber, the plan is for Uber being responsible for all the ride-hailing service while Waymo keeps on focusing and developing the technology [37]. This partnership will permit each company to focus on their specific business models, Waymo as autonomous car technology developer, and Uber as mobility provider. Both companies were fierce rivals not long ago, it started to turn very costly for Uber to develop a new and complex technology like this, being the partnership with Waymo the only path to transform its fleet into autonomous cars [38].\n\nIn Figure 7, we module a simple value network possible for the future of Waymo, modeled in e 3*value*. It represents the business model that Alphabet Inc. is using with Android for example, which consists of Waymo continuing to invest and develop the autonomous driving technology, Waymo Driver, and then selling it to all types of market customers, such as ride-hailing services companies that already exist and operate, like Uber and Lyft, or to car manufacturers that do not have the capacity of developing this type of technology but see here a window of opportunity to enter the market of autonomous vehicles. Note that this technology was not only designed to serve a ride-hailing service, but it transforms lower autonomy levels into a level 5 autonomous car by just applying it. This means that the technology developed by Waymo can be seen as an application to normal cars. Anyone that has this technology can apply a \"package\" to a regular car and make it autonomous. "}
{"doc781": "![9_image_0.png](9_image_0.png)\n\nThe Waymo business study shows us that the company is developing and implementing the technology. The creation of Waymo One can be seen as a support to the research and development of Waymo itself. Having its own service where the technology is implemented, facilitate the information and data exchange that assists the program progress. The literature revealed that Waymo One was created with this purpose, and not to be a profitable company that will compete against other companies in the autonomous mobility market. \n\nWaymo has also announced that it will partner with Uber Freight in order to keep developing its autonomous trucks and support their deployment [39]. Waymo's self-driving trucks will focus more on logistics companies that want to convert or expand their fleet into autonomous driving. This once again shows how Waymo is committed to invest the technology itself so it can apply to all types of mobility solutions. The plan is for any type of mobility provider or dependent company to be able to implement autonomous driving in their business."}
{"doc782": "We can only assume what will be Waymo's next step in terms of its business plan for the future. It can continue to develop the technology while running a parallel ride-hailing service, that keeps close communication for support, or it can simply sell the technology to other mobility companies, and through partnerships keep the support to the development.\n\nIt is not our goal to predict what the disclosure will be, the aim of this paper is to model Waymo business in Phoenix to understand how and what do shared autonomous vehicles companies need to operate in an ecosystem.\n\n## 6. Conclusions"}
{"doc783": "This study illustrated how a value network has been implemented in Phoenix through the creation of ride-hailing of autonomous cars. The modeling of this ecosystem in e 3*value* helped us understand how all the value actors interact with each other.\n\nThe e 3*value* methodology has helped us understand what a company does, like Waymo One, needs to run a successful autonomous ride-hailing service. Modeling the business in e 3*value* helped us identify all the stakeholders that need to be involved in a service like this, and what type of value each one of them exchanges. We were able to get a macro-overview of Waymo One operations and the key products and services it requires. This fulfills exactly what we aimed as research objective, to provide a comprehensive understanding of Waymo One's business model and its key drivers of success.\n\nIt is important to state that documentary sources research were limited to articles launched until May 2022, which means that any paper launched after that date can change the model, with the need of a new confrontation of the reference model with another real situation."}
{"doc784": "For the best of our knowledge, the value proposition of this research, which involves creating a reference model for the introduction of autonomous cars in Phoenix, is liable with some adaptations to be used for other different situations.\n\nA reference model should be evaluated using different perspectives. In our case, for instance, listening to stakeholders about their eventual participation would bring important value in terms of model validation. That direct survey, as stated before, was not possible in Phoenix, and would acknowledge if the now improved model does make sense or not, if identified stakeholders should be part of the model or are needlessly, and if relationships among them are as represented in the reference model or not.\n\nFinally, it is important to refer that one of the tools of the e 3*value* software is the net value flow analysis of the value activities [4]. Studying this analysis in a market scenario as Phoenix would be interesting, nonetheless, it could not be done due to the lack of information provided or documented. "}
{"doc785": "However, this analysis still does not make sense at this point, once Waymo is still developing the technology and the ridehailing service, being in a phase of hard investment and not yet profitable.\n\nAs referred before, we have information regarding all the interactions between the partnership and the outside actors, however all the value transactions that occur inside the partnership is kept as a secret turning impossible to study the economic flow of a business model between Waymo and a potential client for its technology. The e 3*value* methodology is essential for analyzing complex socio-technical systems like shared autonomous mobility services. It provides a systematic framework to understand stakeholder roles, value exchanges, and system dynamics. It also helps to identify and optimize value creation, with risk assessment and mitigation, and also supports decision-making by evaluating different scenarios. Employing e 3*value* can help stakeholders gain valuable insights, optimize system performance, and make informed decisions to create sustainable and efficient shared autonomous mobility services.\n\nThe creation of a separate organization, which runs the same way as its future clients (Uber, Lyft) makes it possible for Waymo to \"showcase its product\" to whoever wants to follow this path of industry. In a straightforward way, Waymo created the technology, then provided it to its own subsidiary who then assessed the business economic and operations sustainability. Result is a proven concept ready to be implemented."}
{"doc786": "![0_image_1.png](0_image_1.png) environment: A comprehensive review Md. Mokhlesur Rahman a,b, Jean-Claude Thill c,* \na Department of Urban and Regional Planning, Khulna University of Engineering & Technology, Khulna 9203, Bangladesh b The School of Information Studies, 343 Hinds Hall, Syracuse University, Syracuse, NY 13244, United States c *Department of Geography and Earth Sciences & School of Data Science, University of North Carolina at Charlotte, 9201 University City Blvd, NC 28223, United States* The article discusses the short, medium, and long-term effects of Autonomous Vehicles (AVs) on the urban transportation and environment by means of a systematic review of the extant literature on the subject matter. A \ncorpus of 130 articles was collected from multiple sources using selected keywords. The review critically analyzes key findings of these papers in the light of a SWOT (Strength, Weakness, Opportunity, and Threat) analysis. \n\nAlthough the technology remains to be commercially deployed, broad consensus is found in the literature. First, AV would influence urban transportation and human mobility by reducing vehicle ownership, public and active travel, traffic delay and congestion, travel costs, and by increasing accessibility, mobility, Vehicle Miles Traveled, and revenue generation for commercial operators. Second, AVs would have long-term effects by encouraging dispersed urban development, reducing parking demand, and enhancing network capacity. Third, AVs would reduce energy consumption and protect the environment by reducing Greenhouse Gas emissions. Fourth, AVs would reduce traffic crashes involving human errors and increase the convenience and productivity of passengers by facilitating for multitasking. However, most people are very concerned about personal safety, security, and privacy. Finally, the study identifies critical research gaps and advances priority directions for further research. \n\nhas the potential to bring dramatic changes to the transportation system, to urban mobility in terms of where people live, where they work, shop and recreate individually and collectively, and hence to the spatial structure of urban environments. This study investigates the impacts of Connected and Autonomous Vehicles (CAVs) on urban transportation and on the geography of urban environments by conducting a state-of-the-art review of the literature. "}
{"doc787": "A number of high tech firms and more traditional automobile companies have been working assiduously to develop Automated Vehicles \n(AVs), which can arguably be seen as a new mobility option (Moorthy et al., 2017; Narayanan et al., 2020). While institutional bottlenecks and socio-technological challenges continue to frustrate the meaningful commercial deployment of AVs (Day, 2021), it is often anticipated that AVs would deeply change human mobility, the built environment, the socio-economic fabric of cities, and city planning and governance \n(Fayyaz et al., 2022; Grindsted et al., 2022; Lee et al., 2022). Meanwhile, decision makers and city planners should prepare policies and plans consistent with a mobility landscape where AVs occupy a prominent position. To date, much research has been conducted on the potential People have used the automobile as a primary mode of travel within and between urban areas since the mid-twentieth century (Howard & \nDai, 2014). Nowadays, it has become an integral part of urban life. \n\nTechnological advancements such as the introduction of Internal Combustion Engines (ICEs), transmission systems, electric motors, steering and cruise control, and emission control technologies are easing people's life and reorganizing city structure (Kim, 2018). While providing benefits to populations, automobiles are also adversely affecting human societies and their environment. The massive use of Single-Occupancy Vehicles (SOVs) is associated with travel delays, traffic congestion, traffic crashes, energy consumption, air pollution, and urban sprawl. \n\nMutation of the transportation system by shifting from ICEs to Electric Vehicles (EVs), and by introducing Intelligent Transportation Systems \n(ITS), ride-sharing, on-demand services, and Travel Demand Management (TDM) measures has shown evidence to reduce energy use and carbon emission, traffic crashes and congestion (Bansal & Kockelman, 2017; Howard & Dai, 2014). However, a combination of these strategies \n* Corresponding author. "}
{"doc788": "E-mail addresses: mrahma18@syr.edu (Md.M. Rahman), jfthill@uncc.edu (J.-C. Thill). \n\nhttps://doi.org/10.1016/j.scs.2023.104649 Received 1 January 2023; Received in revised form 11 May 2023; Accepted 11 May 2023 Available online 20 May 2023 2210-6707/\u00a9 2023 Elsevier Ltd. All rights reserved.\n\nARTICLE INFO \nimpacts of AVs on people's travel behaviors and on the urban built environment to facilitate the process (Fagnant & Kockelman, 2015; Fraedrich et al., 2019; Kapser & Abdelrahman, 2020; Meyer et al., \n2017). Considering the preeminence of people's safety and security in shaping travel patterns, previous studies have also explored urban futures with AVs from the perspectives of personal safety, privacy, and security. These studies have serious drawbacks including a heavy reliance on assumptions, simulations and hypothetical driving settings, which may deviate from real-world situations. Nonetheless, they are significantly contributing to the current body of literature aimed at unraveling the possible responses to AV adoption in human travel patterns and in the urban built environment. Thus, it is timely to have a comprehensive overview of the current literature and to synthesize the existing knowledge domain. "}
{"doc789": "Some of the early reviews of the extant literature systematically evaluated the short-term (i.e., within 3 - 5 years) \u2013such as travel time, convenience, people's productivity, and medium-term (i.e., within 6 - 10 years) effects \u2013such as car ownership, privacy, cyber security, of AVs, but disregarded the long-term (i.e., more than 10 years) effects on the urban built environment, such as people's household and employment location decisions and parking demand (Ahmed et al., 2022; Bahamonde-Birke et al., 2018; Kopelias et al., 2020; Othman, 2022; Tafidis et al., 2021; Tengilimoglu et al., 2023). Although the phasing of the effects is still unsettled, may remain in question for some time, and is subject to adjustments (Hancock et al., 2019; Milakis, 2019), it is assumed that short-term effects will be realized starting with the introduction of AVs for public use rather than in the more distant future. On the other hand, long-term effects will continue for a long time period after adoption of AVs. However, researchers have argued that long-term effects of AVs are uncertain and largely depend on the level of market penetration of AVs and on the evolution of vehicle travel demand (Milakis et al., 2017). Mid-term effects fall in between short- and long-term effects of AVs. To the best of our knowledge, no prior review has explored the current status of AV adoption and the anticipated evolution over a certain time horizon. In this study, we aim to understand current scenarios and potential benefits and costs of AVs after reviewing relevant published scholarship. Considering the timeliness of the research topic and gaps in the literature, the following research questions are investigated in this systematic review: \n\n1) What is the current status of AV research and adoption in different study contexts around the globe? \n\n2) What are the impacts of AVs on human mobility, transportation system, energy and environment, and the built environment? "}
{"doc790": "3) What are the impacts of AVs on people's safety from traffic, privacy from cyber-attacks, travel convenience, and productivity? \n\n4) What are the research gaps in the existing literature that warrant further investigation? \n\n2\nThus, the present review makes significant contributions to the literature by consolidating existing bodies of literature. Its main contributions are threefold. First, the paper critically reviews the state-of the-art literature on the short, medium, and long-term effects of AVs on urban transportation and mobility. Second, it looks at the possible longer-term adjustments to the geography of the built and natural environments of urban regions in the wake of shifts towards more AVs as future markets for AVs become more grounded. Finally, the paper identifies key concepts and provides a foundation for future research by pinpointing research gaps in the literature. "}
{"doc791": "The rest of the paper is structured as follows. Our study approach is presented in Section Two. The third section discusses the definition, concept, evolution, and adoption of AVs in different countries. The potential impacts of AVs are presented in the fourth section. Under Section Four, Subsection 4.1 outlines the impacts of AVs on transportation and human mobility, Subsection 4.2 explains the impacts of AVs on traffic safety and convenience to people, Subsection 4.3 summarizes the impacts on energy and environment, and Subsection 4.4 discusses impacts on the urban built environment. Research problems and directions for future study are discussed in the Fifth Section. Finally, conclusions are drawn in Section Six. \n\n## 2. **Study Approach**\n\nThis systematic literature review is conducted to identify, evaluate, and critically analyze relevant scholarship on the current status and impacts of AVs. To this end, a literature search is conducted to select published articles and reports to be included in the review process. The articles and reports are selected based on (1) whether the article/report was written in English, (2) whether the study was conducted within the last five years, and (3) whether the study has investigated the impacts of AVs, Shared Autonomous Vehicles (SAVs), and CAVs, on transportation and mobility, environment, and urban form. However, a few studies conducted before 2015 are included in this systematic review to provide a comprehensive overview of possible scenarios and technological developments related to AVs, SAVs, and CAVs. ScienceDirect, Scopus, SAGE Journals, SpringerLink, Taylor & Francis, and Web of Science, the website of different organizations, and Google Scholar are the primary sources to search for suitable articles and reports. "}
{"doc792": "The search identified 360 articles and reports. However, after careful assessment of each item, only 130 items were deemed directly pertinent to the search terms and objectives of the study. They form the basis of this systematic review. Of these items, 18.84%, 7.25%, and 4.35% of the articles have been published in the following three periodicals, respectively: Transportation Research Part C: Emerging Technologies, Transportation Research Part A: Policy and Practice, and Transportation Research Record. About 87% of the articles and reports were published from 2015 to 2020. Also, 46.27% and 18.66% of articles/reports pertained to North American and European countries, respectively. In addition, 8.21% and 3.73% of studies have been conducted in Asian countries and Australia, respectively. Moreover, about 11.94% of them are review studies and 11.19% have been conducted in multiple countries. During the selection process of articles/reports, the researchers were careful to select them from different study contexts to get a comprehensive review. These research items are critically analyzed to understand the current and future implementation of AVs and their impacts on transportation and mobility, environment, and urban form. However, we would like to acknowledge that the vast majority of studies \n(about 69%) are conducted in a Global North setting. Although we attempted to generalize findings from different studies, considering the socioeconomic, cultural, and geographic diversity in the Global South and North contexts, all research findings may not equally apply to all national contexts. \n\nThe key concepts and themes discussed in the extant literature are presented in Fig. 2. Many studies focused on the impacts of AVs on energy consumption (26.15%) and traffic delay and congestion (23.85%) \nfollowed by Vehicle Miles Traveled (VMT) (20%) and Greenhouse Gas \n(GHG) emission (20%). Also, a considerable number of studies have explored the effects of AVs on parking demand (19.23%), travel costs and revenue generation (19.23%), safety, security, and personal privacy \n(18.46%). In contrast, a few studies discussed the possible integration of shared mobility, AV, and EV (3.85%), impacts of AVs on employment opportunity (6.15%), infrastructure capacity (8.46%), and public transportation (9.23%). \n\nFig. 3 shows the data sources of the reviewed articles/reports. The results indicate that 29.17% and 25.69% of studies conducted webbased household surveys and simulations (e.g., field test, experimental driving), respectively, to collect data. In contrast, only 1.39% and 6.25% \nof studies used data from census and national surveys, respectively. Most of these studies used data from census and national surveys to generate "}
{"doc793": "![2_image_2.png](2_image_2.png)\n\n## 3. **The Concept And Evolution Of Autonomous Vehicles**\n\nAV (also known as a self-driving car, driverless car, robotic car) is able to drive and navigate without direct human inputs by using sensing technology (e.g., radar, Global Positioning System (GPS), and computer vision) and advanced control systems (i.e., sensors) (Howard & Dai, 2014; Narayanan et al., 2020). These automated vehicles are expected to bring revolutionary changes in people's mobility, transportation systems, and land-use patterns (Brown et al., 2014; Meyer et al., 2017). A \ndistinctive feature of AVs is to have some level of automation to assist drivers or to replace drivers to take full control of the vehicle (Narayanan et al., 2020). According to the Society of Automotive Engineers \n(SAE International, 2018), the level of vehicle autonomy ranges from Level 0 (i.e., no autonomy) to Level 5 (i.e., full vehicle autonomy) according to technical specifications (Fig. 5). "}
{"doc794": "The National Highway Traffic Safety Administration (NHTSA) of the United States Department of Transportation (USDOT) proposed a safety rule in 2016 that all vehicles produced after 2020 would be equipped with Vehicle to Vehicle (V2V) communication technology to send and receive safety messages (Administration, 2016b). Although NHTSA has yet to mandate any V2V safety measures, it is expected that vehicles would gradually be equipped with safety equipment (i.e., short-rage communication, safety messages) to protect lives. Moreover, NHTSA has adopted the standard of vehicle automation prescribed by SAE (Administration, 2016a, 2017). These interventions from a top-tier transportation safety agency demonstrate their seriousness towards vehicle automation for curbing traffic crashes. \n\nIt is anticipated that on-demand mobility services and vehicle automation will grow rapidly in the coming decades (Jones & Leibowicz, 2019). The annual global sales of AVs would grow to $173.15 billion by 2030, with a 65.31% contribution from shared mobility (Sullivan, 2018). Thus, AV is a reality now and it is expected that it would become a daily travel mode for many people shortly (i.e., 10 - 30 years) (Stocker & Shaheen, 2018; Zakharenko, 2016). \n\nDespite enormous efforts by different companies and agencies to bring AVs to market, AVs are yet to be a regular transportation mode. Some studies have investigated the current implementation status of AVs and their future evolution across the world (Bansal & Kockelman, 2017; Nieuwenhuijsen et al., 2018). For example, Zhang and Wang \n(2020) estimated that the market share of AVs may vary from 20 to 90% \nby 2040 in Atlanta, the United States (US). Conducting a web-based survey of 246,642 Japanese residents between November and December 2015, Shin et al. (2019) reported that 53% of respondents expect AVs to be on the market in 15 years, whereas 40% expect a 6-to 10-year timeframe. Considering 2030 as the year of introduction of level 4 and 5 AVs, Trommer et al. (2018) calculated that the market share of AVs (level 4 and 5) would be 17% in Germany and 11% in the US, by 2035. Another study predicted that the market share of AVs would be about 80% in Korea in 2060 (Kim et al., 2015). Litman (2017) commented that level 5 AVs would be able to operate commercially and legally in the 2020s within certain jurisdictions and with limited performance. However, most benefits of AVs will be prominent and significant in the 2050s to 2060s when AVs would be common and affordable. "}
{"doc795": "Based on this discussion, an expected timeline from planning to full implementation of AVs is portrayed in Fig. 6. This implementation timeline is compiled on several articles such as Litman (2017), Bansal and Kockelman (2017), Kim et al. (2015), Shin et al. (2019), \nNieuwenhuijsen et al. (2018), and Zhang and Wang (2020). The figure illustrates that AVs would be available for people's regular use incrementally over the coming decades. Literature shows that countries around the world are resolute to test and employ AVs. At the same time, city planners are putting in place strategies to adjust to a new reality. However, most urban policymakers are yet to start formulating plans for AV adoption due to a lack of real-world experience (Gonz\u00b4alez-Gonzalez \u00b4\net al., 2019). Thus, it is necessary to understand the merits and demerits of AVs through their impacts on people, communities, and cities for informed decision-making. \n\n## 4. **The Potential Impacts Of Avs**\n\nAVs would have both positive and negative effects on people and society. To better understand the potential impacts of AVs and their associated advantages and disadvantages, a SWOT (Strength, Weakness, Opportunity, and Threat) analysis is performed after reviewing the existing literature, following (Litman, 2017; University of Kentucky, 2020). This SWOT analysis provides a framework and helps us organize and discuss the Strengths, Weaknesses, Opportunities, and Threats of AVs in a single structure. The SWOT analysis also reveals the internal (e. g., users) and external (e.g., pedestrians) factors associated with AV adoption. While Strengths and Weaknesses respectively indicate the advantages and disadvantages of AVs for their users, Opportunities and Threats illustrate their advantages and disadvantages for other people and the surrounding environments. With the underpinning provided by Fig. 7, we discuss the anticipated positive and negative effects of AVs in four segments. First, Subsection 4.1 explains the impacts on human mobility and transportation systems. Second, Subsection 4.2 summarizes the impacts on traffic safety and on convenience to people. Next, Subsection 4.3 outlines the impacts on energy and the natural environment. Finally, the impacts on the urban built environment are illustrated in Subsection 4.4. "}
{"doc796": "## 4.1. Impacts On Human Mobility And Transportation Systems\n\nThe main anticipated strengths associated with AVs include delay and congestion reduction, increased accessibility and mobility, travel cost savings, and revenue generation for ride-sharing companies (Fig. 7). \n\nThe opportunities afforded by AVs include the reduction in vehicle ownership and the integration of SAV and EV. On the other hand, the main weaknesses of AVs are higher vehicle purchase costs and higher VMT, while critical threats would consist in an increase in travel demand and a reduction in public and active transportation. Based on the findings from the extant literature articulated in Fig. 7, this section discusses the potential impacts of AVs on human mobility and transportation system. The aspects related to human mobility encompass vehicle ownership, VMT, and accessibility and mobility. The transportation aspects discussed here include public transportation, traffic delay and congestion, travel costs and revenue generation, and integration of shared mobility, AV, and EV. User's travel costs and revenue generated by transportation companies can influence overall transportation systems. Similarly, integration of shared mobility, AV, and EV can change the overall landscape of transportation systems. 4.1.1. *Vehicle ownership* The introduction and adoption of commercial AVs are likely to reduce the need for households to own cars by way of an increase in ride-\nFig. 5. Level of vehicle autonomy. "}
{"doc797": "![4_image_1.png](4_image_1.png)\n\nsharing services (e.g., SAVs) (Clements & Kockelman, 2017 ; Krueger et al., 2016 ; Tirachini et al., 2020 ). Fagnant and Kockelman ( 2014 ) reported that each SAV can serve 31-41 passengers per day and therefore many people can do away with owning a car. A sharper reduction could even be achieved at a higher rate of SAVs adoption in areas with low household density and more long-distance trips ( Fagnant & Kockelman, 2018). Since a driver is not required for AV operation, it can be assumed that a household of 3-4 people could own a single private AV and share that vehicle for their travel purposes. Thus, like SAVs, personal AVs would likely reduce household vehicle ownership. Additionally, privately owned AVs could even be rented out to generate income when they are not driven by the owners and could further reduce vehicle ownership (Sparrow & Howard, 2017). Along this line, Arbib and Seba \n(2017) forecasted that the number of vehicles would drop from 247 million in 2020 to 44 million in 2030 in the US due to the expected popularity of AVs. Consequently, it can be anticipated that the fleet of cars and trucks would be reduced by 70%. Using the 2011 Atlanta travel survey data, Zhang et al. (2018) found a reduction in vehicle ownership among over 18% of households. Each of these households would experience a drop of about 1.1 vehicles, while maintaining their current travel pattern. Thus, as reported in Table 1, AVs and SAVs have the potential to reduce vehicle ownership without affecting people's existing travel demand. \n\nResearch has shown that dynamic ride-sharing (i.e., serving multiple travelers with similar origins, destinations, and departure times) can significantly reduce the number of vehicles. For example, Levin et al. "}
{"doc798": "(2017) found that dynamic ride-sharing would reduce vehicle ownership, provide low-cost service, and attract more people by combing multiple trips with the same travel route and destination neighborhood. Additionally, accepting some flexibility in activity scheduling can reduce vehicle ownership (i.e., allowing up to 15-minute delays in arrival at the destination can reduce private AV ownership by 18.3 to 24.1%) (Zhang et al., 2018). \n\n## 4.1.2. Vehicle Miles Traveled\n\nWith better accessibility and mobility, more empty-vehicle travel, and the relocation of parking spaces outside of the city center, AVs would increase per capita travel distance and VMT (Trommer et al., \n2018; Wadud et al., 2016; Zhang & Wang, 2020). People would choose to live further away from their workplace due to lower transportation costs and to the drop in the opportunity cost of travel time by multitasking, which all would lead to additional VMT (Childress et al., 2015; Gelauff et al., 2019). Thus, AVs are anticipated to increase travel distance and VMT, as summarized in Table 2. "}
{"doc799": "Some studies have mentioned that the average travel distance by AVs would not be significantly higher than a conventional car or taxi (Ma et al., 2017; Moorthy et al., 2017). They argued that increased VMT can be compensated by a reduction in the total number of vehicles required for passenger transport and by optimizing trip chaining (Ma et al., 2017). VMT could also be reduced by increasing dynamic ride-sharing \n(Fagnant & Kockelman, 2018; Milakis et al., 2017). Fagnant and Kockelman (2018) observed that a 20 to 30 % increase in shared trips would reduce VMT by 4.4 miles per shared-trip (i.e., a 4.2 % reduction). Thus, increasing SAVs, particularly within a high-density area, may reduce empty VMT (Fagnant & Kockelman, 2014; Levin et al., 2017). Furthermore, the implementation of a flexible work schedule could reduce the average VMT per traveler (Greenblatt & Saxena, 2015; Kyriakidis et al., \n2015). A flexible work schedule will allow workers to work at variable work rosters and SAV drop-offs and pick-ups can be coordinated to reduce empty VMT. \n\n| scope to achieve a more socially sustainable transportation system                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Impact of AV on vehicle ownership.  Study Car ownership reduction  (Kim, 2018) 44% reduction in ownership per household  (Zhang et al., 2018) 9.5% reduction in private vehicles  (Fagnant &  10-fold reduction in private vehicles  Kockelman, 2014)  (Arbib & Seba, 2017) 80% reduction in vehicles  (Fagnant &  10-fold reduction in private vehicles  Kockelman, 2018)  (Levin et al., 2017) -One SAV could replace 3.6 private vehicles  -Each SAV can carry up to 4 people with 1000 SAVs and  serve 31.4-person trips with 2000 SAVs in the system  (Fagnant &  10% penetration reduces vehicles by 4.7% (23.7% in 50%  Kockelman, 2015)  and 42.6% in 90% penetration)  (Zhang et al., 2018) Private vehicle ownership reduced from 9.5% (no delay) to  12.3% (15 min delay).  (Narayanan et al.,  Occupancy increases from 1.2 to 3, 10 vehicles are  2020)  replaced by 1.18 SAVs  (Loeb & Kockelman,  Low-range and slow charge Shared Autonomous Electric  2019)  Vehicles (SAEVs) replace 3.75 vehicles, long-range and  fast charge SAEVs replace 8 - 11.5 vehicles  (Milakis et al., 2017) 67% to over 90% reduction  (Frey, 2017) -30,000 AVs will displace 50% peak commuters for 2  million people in the US  -4 million AVs will replace 50% of all commuter traffic  (Ma et al., 2017) Each SAV replaces over 13 private vehicles or traditional  taxis.  (Chehri & Mouftah,  30% reduction in vehicle number  2019)  (Cyganski et al., 2018) 35% reduction in personal car use and 11.6% to 8.6%  reduction in car drive with a reduced fleet size in 2030  than 2010  (Chen et al., 2016) -an 80-mile and a 200-mile range Level 2 SAEVs could  replace 3.7 and 5.5 private cars, respectively  -Level 3 fast charger can replace 5.4 vehicles for 80-mile  and 6.8 vehicles for 200-mile | Table 2  Impact on travel distance and VMT.  Study Impact on travel distance/VMT  (Narayanan et al., 2020) Trip length: -15% to +14%, VMT: -45% to +89%  (Gelauff et al., 2019) 5 - 25% increase in VMT  (Fagnant & Kockelman,  Up to 10% increase in travel distance  2014)  (Fagnant & Kockelman,  2 - 9% increase in VMT  2015)  (Zhang et al., 2015) 15.3 - 62.3% increase in daily VMT  (Zhang et al., 2018) Median VMT increase of 26.5 miles per household, total  VMT increase of 13.3%  (Loeb & Kockelman,  6.05 - 14.2% increase in empty VMT per SAV  2019)  (Wadud et al., 2016) 2 - 10% increase in VMT  (Tirachini et al., 2020) VKT increase of SAV: 7 to 10 km/passenger, VKT increase  of buses: 0.4 to 1.1 km/passenger  (Childress et al., 2015) 11 - 20% more empty VMT by SAVs  (Loeb et al., 2018) SAEV on average generate 19.6 - 31.5% more vacant  VMT  (Levin et al., 2017) Personal AV has a 2.5% lower VMT than a personal  conventional vehicle  (Harper et al., 2016) 2 - 14% increase in annual VMT  (Ma et al., 2017) 15% increase in VMT  (Carrese et al., 2019) 100% penetration of ride-sharing reduces VMT up to  19%  (Auld et al., 2018) 42% increase in travel distance  (Alam & Habib, 2018) 15% (20%) share of SAV increases VKT by 1.73% (14%)  (Horl, \u00a8 2017) 28.01% and 30.57% empty VMT in Taxi and taxi pool,  respectively for 1000 AVs on the fleet  (Zhang &  5 - 14% VMT increase  Guhathakurta, 2017)  (Arbib & Seba, 2017) VMT increased by 50% in 2030 over 2015 |\n\n(Hess, 2020; Milakis et al., 2017). "}
{"doc800": "According to the US Bureau of Transportation Statistics, about 25.5 million Americans face travel restrictions due to disabilities (Brumbaugh, 2018). Among them, about 3.6 million do not leave their homes due to low vehicle ownership, lack of driver's license, and unemployment. They mostly depend on other family members and friends for reaching activity sites away from home. Information on the travel strategies of US people with disabilities (ages 18-64) is collected from the 2017 National Household Travel Survey (NHTS) and presented in Fig. 8. It is estimated that 70.6% of them curtail their day-to-day travel, whereas 44.3% depend on others for travel. Also, it is reported that 21.6% of them have given up driving and 14.4% use less public transport. Moreover, 14.4% of people use special transportation facilities (i. \n\ne., dial-a-ride or reduced-fare taxi). The deployment of AV technologies offers the opportunity to better serve this market through shared mobility services. AV technologies can substantially raise the mobility of people who are unable to drive and travel otherwise due to disabilities \n(Brumbaugh, 2018). \n\n## 4.1.4. Public Transportation"}
{"doc801": "It has been argued that AVs are the most disruptive technologies in the transport sector, having the potential to weaken public transit ridership (Hess, 2020; Kapser & Abdelrahman, 2020; Meyer et al., \n2017). The availability of shared vehicles and the use of SAVs may be particularly effective at curtailing public transportation, as well as active transportation (Clements & Kockelman, 2017; Cyganski et al., 2018; Narayanan et al., 2020). Thus, AVs may be regarded as a major existential threat to present and future transit systems (Handsfield, 2011). \n\nHowever, when seen as a shared mobility option, AVs could be integrated with an efficient public transport system to ensure the sustainability of urban transportation systems (Narayanan et al., 2020; Sparrow & Howard, 2017). Public transport carries a large number of passengers from one station to another, but some other transport option may facilitate the transfer of people between home / workplace and the stations. AVs can solve this last-mile problem and attract passengers away from private vehicles to public transit (Moorthy et al., 2017; Sparrow & Howard, 2017). Thus, AVs should be mobilized so they would not disrupt the current transport system but increase its efficiency and cost-effectiveness instead. \n\nFurthermore, patterned after the successes of Transit-Oriented Development (TOD), Robocar-Oriented Development (ROD) (Templeton, 2012) could be promoted in areas surrounding transit stations. ROD \nwould be a high residential density and mixed-use development with minimal auto facilities. People would mainly use AVs and SAVs to travel to transit stations as a short-distance shuttle service would. There would be convenient drop-off and pick-up zones very close to stations. Multilevel drop-off or pick-up zones also could be built to optimize space utilization where land value is comparatively higher. There would be a vehicle-waiting zone from where personal and shared AVs would drop and pick up riders. Thus, through a strategic partnership with AVs, public transport would avert a declining market share and a more sustainable transportation system could be achieved. "}
{"doc802": "4.1.5. *Traffic delay and congestion* AVs have the potential to reduce traffic delay and congestion by promoting ride-sharing options, and by smoothing traffic flows using Adaptive Cruise Control (ACC) measures and traffic monitoring systems \n(Alam & Habib, 2018; Daziano et al., 2017; Krueger et al., 2016). A \nhigher rate of automation, dedicated lanes for AVs/CAVs, and dynamic control of the fleet size could significantly reduce travel time and delay by increasing roadway capacity and throughput of vehicles and by reducing empty trips (Amirgholy et al., 2020; Levin et al., 2017; Zhang et al., 2015). Under a 100% AV scenario in 2060, Kim et al. (2015) calculated that about 3 million vehicle hours will be saved in the Seoul Metropolitan Area (SMA), which is equivalent to saving one hour for each trip to the SMA in 2013. Thus, SAVs in a dynamic ride-sharing situation could be an effective policy option to reduce traffic delay and congestion, as also reported in Table 3. \n\nResearchers also reported that an heterogeneous traffic stream (i.e., a mixture of PAVs and SAVs) could increase delay and congestion by reducing the average speed on the network (Narayanan et al., 2020). Carrese et al. (2019) reported that SAVs would yield a positive impact for intra-urban trips, but suburban commuters may experience extra traffic congestion due to the sizeable relocation of residents to the suburbs. Some people also believe that AVs are unlikely to reduce congestion and travel time in suburban, exurban, rural areas and in urban commercial districts due to higher travel demand and empty VMT in these particular areas (Meyer et al., 2017; Piao et al., 2016; Schoettle \n& Sivak, 2014b; Van Brummelen et al., 2018). To sum up, considering the potential for congestion reduction by AVs, policymakers should implement appropriate policy measures to achieve a higher rate of AV \npenetration and vehicle ride sharing. For example, a service of large SAVs (e.g., vans, buses) could be implemented to reduce traffic congestion and empty VMT by transferring groups of passengers simultaneously. 4.1.6. *Travel costs and revenue generation* Many researchers have reported that the automation of vehicles may lower travel costs for users by reducing vehicle operation and maintenance costs (e.g., fuel, insurance fees) (Kopelias et al., 2020; Nunes & \nHernandez, 2020; Zakharenko, 2016) (Table 4). SAVs could further reduce travel costs by avoiding parking fees and by reducing fleet size \n(Loeb et al., 2018). AVs ride-sourced by Transport Network Companies (TNCs) are much cheaper to users than solo driving because there are no labor costs and depreciation and insurance are lower (Compostella et al., 2020). Although the initial purchase is a major sunk cost, total lifetime costs remain minor when amortized over service life spanning as much as 400,000 miles. AVs also could reduce the opportunity cost of travel \n\n![6_image_0.png](6_image_0.png)"}
{"doc803": "| Table 3  Impact on traffic delay and congestion.  Study Impact on delay/congestion/speed  (Fagnant &  Drop of 15% in freeway congestion delay at 10% AV  Kockelman, 2015)  penetration  (Carrese et al., 2019) At 100% penetration of SAV, travel time reduction of 10 -  19%  (Levin et al., 2017) -Personal AV (PAVs) can reduce average travel time by  73% over personal car  -160% increase in SAVs reduces travel time by 70%  (Amirgholy et al.,  A higher market share and optimal lane management  2020)  strategy reduce delay up to 78%, limit increase of travel  time to 5%, and reduce delay cost by 66%  (Atiyeh, 2012) 35 - 39% less congestion and 8 - 13% higher traffic speeds  at 50% penetration  (Zhang et al., 2015) Average waiting time reduced by 98.4% with a 45.45%  increase in SAVs  (Zhang et al., 2018) -V/C ratio increased by 6.79 - 8.44% due to increased  travel demand  -V/C ratio increased by 4.99% and 4.39% on expressways  and minor arterials, respectively  (Papadoulis et al.,  Travel time increased by 20% in a 100% penetration rate  2019)  (Auld et al., 2018) 30%-50% reduction in the opportunity cost of travel time  (Qi et al., 2018) -10.7% time saving due to driving assistance via HMI  (human-machine interface)  -Increase of time by 3.2% due to partially automated  driving  (Chehri & Mouftah,  Urban travel time reduction of 30%  2019)  (Martinez & Viegas,  30% congestion reduction with full adoption of SAVs  2017)  (Kockelman et al.,  78% reduction in travel time at a 100% AVs penetration  2017)  (Wellik & Kockelman,  3.4 to 8.1% increase in travel time to work at 100% AV  2020)  scenario   | Table 4  Impacts of AVs on travel costs and revenue generation.  Study Impacts on travel costs and revenue generation  (Fagnant & Kockelman,  SAVs reduce average trip costs by 30 to 85%  2014)  (Van den Berg &  2 to 40% reduction in total travel costs by AVs compared  Verhoef, 2016)  to no-AV condition  (Milakis et al., 2017) Social benefits/AV/year could reach $3900 at 90% AV  adoption  (Wadud, 2017) At least a 15% reduction in the total cost of ownership  from full automation  (Moorthy et al., 2017) Travel cost of AV ($13.71) is less than personal vehicle  ($14.01), higher reduction of travel time in AV ($18.20)  than personal vehicle ($15.9)  (Fagnant & Kockelman,  Fleet operator paying $70,000/SAV could earn 19  2018)  %/year while offering services at $1.00/mile for a nonshared trip (i.e., 33% less from traditional taxi fare)  (Greenblatt & Saxena,  Cost/mile is lower for SAV (30 - 50 US\u00a2/mile) than  2015)  private vehicles (80 US\u00a2/mile)  (Gelauff et al., 2019) Up to 10% of welfare benefits due to population  relocation and land-use changes  (Narayanan et al., 2020) Opportunity cost of travel time reduced from 10 to 31%,  household savings per year increased by $5600, and  revenue generation increased by 19%  (Fagnant & Kockelman,  -$2,000 to $4,000/year/AV safety benefits, travel time  2015)  reduction, fuel efficiency, and parking benefits  -Parking saving $3.2, $250 savings per AV, 756 million  hours travel time saving, 102 million gallons fuel saving  (Compostella et al.,  -Cost reduced by 4 - 10%/year after commercial  2020)  introduction  -50% decrease in maintenance and insurance costs  reduce $0.04 per VMT  -Decreasing AV cost to $3,333 per vehicle lowers cost by  $0.06 per mile  (Nunes & Hernandez,  Revenue increased by 30% with increasing occupancy  2020)  from 1.67 to 2.2 and 75% with increasing occupancy  from 1.67 to 2.92, whereas single AV lowered profits by  37%  (Chehri & Mouftah,  Travel costs reduced by 50%  2019)  (Martinez & Viegas,  SAV reduce travel cost by 45%/km than public transport  2017)  (Clements &  Higher share of CAV saves $3,800/American/year by  Kockelman, 2017)  reducing costs related to insurance, crashes, vehicle  repair, personal travel, legal services, etc.  (Kockelman et al., 2017) 75% reduction of crash costs, $1,357 per year cost  savings per driver   |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|\n| time as people can spend time on other activities (e.g., reading, talking  with friends, e-work) while riding in a vehicle (Van den Berg & Verhoef,  2016). On the other hand, some studies have also reported that AVs  would increase third-party liability insurance coverage (Xu & Fan,  2019). Uncertainty persists though, as policymakers have yet to decide  whether travelers or manufacturers would pay higher insurance premium for AVs due to newly perceived cyber risks besides risks of traffic  crashes (Yeomans, 2014). Thus, there is still tremendous uncertainty on  whether the overall costs of AV ownership and use would be lower,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |   |\n\ntime as people can spend time on other activities (e.g., reading, talking with friends, e-work) while riding in a vehicle (Van den Berg & Verhoef, 2016). On the other hand, some studies have also reported that AVs would increase third-party liability insurance coverage (Xu & Fan, 2019). Uncertainty persists though, as policymakers have yet to decide whether travelers or manufacturers would pay higher insurance premium for AVs due to newly perceived cyber risks besides risks of traffic crashes (Yeomans, 2014). Thus, there is still tremendous uncertainty on whether the overall costs of AV ownership and use would be lower, considering diverse insurance expenses such as third-party insurance, comprehensive vehicle insurance, public liability insurance, product liability insurance, and self-insurance. (Abu Bakar et al., 2022). \n\nThe adoption of AVs would increase the welfare benefits of citizens and the revenue generation of commercial transportation operators (Narayanan et al., 2020). It has been estimated that AVs could yield up to 5 billion Euros in savings per year in the Netherlands alone under full automation by reducing generalized transport costs and with expected changes in modal split (Gelauff et al., 2019). Fagnant and Kockelman (2015) found a total of $196 billion economic benefits with a 90% AV \nmarket share in the US due to cost reduction for congestion, crashes, travel time, fuel use, and parking fees. It has been noted also that these benefits, although small compared to commercial taxi operation, will disproportionately be enjoyed by households in the wealthiest percentiles under full automation in personal cars (Wadud, 2017). "}
{"doc804": "In summary, the extant literature shows that AVs and SAVs are likely to reduce transportation costs and increase revenue generation for commercial fleet operators. Thus, researchers have suggested to expand funding for R&D and formulating guidelines for AVs to accelerate AV use (Fagnant & Kockelman, 2015). \n\n4.1.7. *Integration of shared mobility, AV, and EV* \nSAVs would be more popular than other vehicles operated by TNCs due to cheaper, safer, and more efficient transport options. Researchers have indicated that SAVs can further influence people's travel behaviors by embracing cutting-edge EV technologies (Kova\u02c7ci\u00b4c et al., 2022; Loeb & \nKockelman, 2019; Offer, 2015; Zhang et al., 2020). Hence, SAEVs will be efficient (travel costs, energy use, emission, and empty VMT would be low) and reliable (Dlugosch et al., 2022; Golbabaei et al., 2021; Huber et al., 2022; Pan et al., 2021; Roca-Puigros ` et al., 2023). Chen et al. \n\n(2016) mentioned that long-range and fast charging SAEVs can serve 96 - 98% of trip requests with a rather small average wait time of 7 - 10 minutes per trip. In contrast, short-range and slow charging SAEVs would be unable to serve 55% of trip requests due to poor response time and an additional 5.4% of trips due to trip length constraints (Loeb & \nKockelman, 2019). In addition, simulating a similar scenario for Austin, TX, Chen et al. (2016) found that empty VMT could drop to 3 - 4%, \naverage wait times could shrink to 2 - 4 minutes per trip, and each SAEV \nwould replace 5 - 9 private vehicles. Thus, SAEVs have the potential to further reduce vehicle ownership, empty VMT, response time, and wait time. In short, long-range and fast charging SAEVs are important for the successful deployment of vehicle automation. "}
{"doc805": "By coupling with a renewable power source, SAVs also provide environment-friendly transport options. An SAEV can reduce energy use by 90 - 100% compared to ICEs due to efficient travel and electrification of vehicles (Milakis et al., 2017). Conducting agent-based modeling, Zhang and Wang (2020) found that each SAEV can reduce carbon emission by 75% in California. They also observed that SAEVs are likely to reduce travel costs by reducing vehicle operation costs. Thus, the integration of AVs and EV technologies with adequate vehicles has a synergistic effect on reducing VMT, vehicle ownership, travel cost, and GHG emissions (Offer, 2015). Researchers have mentioned that future transportation would consist of shared and on-demand mobility, CAVs, and EVs to provide improved transportation services to populations. \n\nFig. 9 illustrates this paradigm shift in the transportation system with the advent of technologies where a proper integration of SAEVs will provide reliable transportation. \n\n## 4.2. Impacts On Traffic Safety And On Convenience To People"}
{"doc806": "Key strengths of AVs include people's travel safety, increased convenience, and productivity of riding time, and reduced driving stress, as indicated in Fig. 7. Prominent weaknesses AV users would confront include personal privacy breaches, technology misuse, and systems failure. On the other hand, one of the main threats people would experience is increased criminal activities. This subsection describes the potential impacts of AVs on passengers' safety, security, productivity, and convenience factors. \n\n## 4.2.1. Traffic Safety\n\nThe extant literature indicates that AVs would reduce the exposure of passengers to traffic crashes (Duan et al., 2020; Karbasi & O'Hern, 2022; Trommer et al., 2018; Underwood & Firmin, 2014; Vahidi & Sciarretta, 2018). Equipping vehicles with ADDS, higher levels of automation (i.e., level 3 or higher), and a high rate of AV adoption would all increase people's safety (Milakis et al., 2017). It is estimated that AVs can avoid more than 90% of all crashes that involve human errors by adding collision avoidance technologies (Chehri & Mouftah, 2019; Daziano et al., 2017; Nunes & Hernandez, 2020). More than 40% of fatal crashes due to human factors can be avoided by using AV technologies (Fagnant \n& Kockelman, 2015). Conducting a simulation study in England, Papadoulis et al. (2019) reported that CAVs would reduce traffic crashes by 12 to 94% with a 25 to 100% penetration rate. The majority of these crashes, particularly at a higher rate of penetration, would be eliminated by designing the control system of vehicles to avoid collisions in traffic merging and diverging areas due to high variations of vehicular speeds and to lane change occurrences. Using data from crash reports from 2005 to 2008, Najm et al. (2010) estimated that V2V and Vehicle to Infrastructure (V2I) communication could reduce crashes by 72 to 83%. Thus, vehicle automation and various connectivity technologies are likely to reduce vehicle crashes (Begg, 2014). "}
{"doc807": "Conducting online surveys, researchers found that 37.30 to 88.80% \nof respondents would like to adopt AVs owing to their capability to reduce the number and severity of crashes and to improve emergency response to crashes (Piao et al., 2016; Schoettle & Sivak, 2014a, 2014b). \n\nAlthough AVs could reduce the number of crashes caused by human errors, they are also prone to accidents themselves due to faulty system design (Bansal et al., 2016). Additionally, AVs would pose a threat to personal security and privacy in smart city contexts due to the reliance on electronic sensors and devices to exchange information. The main sources of concern are cyberattacks, maliciously controlled vehicles, and software hacks by harnessing technologies (Milakis et al., 2017). 4.2.2. *Convenience, productivity, and privacy* Many researchers have mentioned that AVs would increase the convenience, efficiency, and productivity of riders while incurring low transportation costs (Clements & Kockelman, 2017; Hess, 2020; Vahidi & Sciarretta, 2018). People would be involved in a variety of productive activities (e.g., reading, messaging, talking on the phone, resting or relaxing) rather than passing time idling or stressing out, which makes the journey more meaningful and useful (Piao et al., 2016; Schoettle & \nSivak, 2014b). Wadud and Huda (2019) reported that car passengers engage in 3.6 different types of activities in each leg of a journey. \n\n![8_image_0.png](8_image_0.png)"}
{"doc808": "Talking or texting friends and looking out of the window are the most appealing tasks among people traveling in AVs (Howard & Dai, 2014; Schoettle & Sivak, 2014b). Thus, automated driving can significantly increase the convenience and efficiency of the journey by engaging people in various activities. \n\nAVs can also increase the convenience to passengers by reducing waiting time, particularly during peak hours via dynamic ride-sharing \n(Fagnant & Kockelman, 2014; Fagnant & Kockelman, 2018). Fagnant and Kockelman (2018) found that total service time (i.e., wait, pick-up/drop-off, and in-vehicle) could be reduced from 15 minutes to 14.7 minutes via dynamic ride-sharing. Although SAVs would reduce total service time by a trivial amount (about 2% savings), they can reduce average wait time significantly. Fagnant and Kockelman (2014) found that average wait time could be reduced by 51% when the trip generation rates are doubled and fleet size increased by 92% compared to the base case scenario. In contrast, wait time increased by 86.6% \nwhen trips are halved, and fleet size is reduced by 49%. Similarly, wait time increased by 206.67% when trips are quartered, and fleet size is reduced by 74.34%. Thus, a large enough number of SAVs is necessary to generate enough benefit in the convenience and service quality through a reduction in overall wait time. \n\nMany researchers have found that AVs would open the door to breaches of passengers' privacy by increasing the level of surveillance and monitoring of their mobility patterns, which may threaten people's sense of security and privacy and discourage people to buy and share AVs (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Hess, 2020; Howard & Dai, 2014; Konig \u00a8 & Neumayr, 2017). Consequently, a segment of people would feel disenfranchised and be reluctant to use AVs and SAVs (Hulse et al., 2018). Similar to privacy issues, people are concerned about the misuse of technology by unscrupulous individuals (software hackers) (Kyriakidis et al., 2015; Van den Berg & Verhoef, 2016). Many surveyed riders recommend to increase the security and maintain their privacy to increase AV and SAV use (Gurumurthy & Kockelman, 2020; Panagiotopoulos & Dimitrakopoulos, 2018; Salonen, 2018). "}
{"doc809": "As presented in Table 5, AVs are set to reduce energy use by decreasing vehicle ownership and weight, and operating vehicles efficiently by limiting acceleration and deceleration using ACC with lane assist systems and Vehicle-to-Everything (V2X) communication \n(Haboucha et al., 2017; Han et al., 2023; Loeb et al., 2018; Mersky & \nSamaras, 2016). Energy use could be further reduced by implementing the ride-sharing services of AVs, particularly in the urban areas where travel demand is higher (Greenblatt & Saxena, 2015; Ross & Guhathakurta, 2017). A coordinated flow of CAVs could also increase the energy efficiency of ICE vehicles in mixed traffic situations by establishing a harmonized relationship with the surrounding traffic even at a lower level of CAV market penetration (Vahidi & Sciarretta, 2018). Thus, prior knowledge on the roadway environment (e.g., speed limit, grade, curve), avoidance of frequent starts and stops, efficient lane change, coordinated and smooth traffic flow, proper signal phasing and timing, vehicle weight reduction and right-sizing, and vehicle sharing, could all reduce transport energy consumption significantly (Vahidi & Sciarretta, 2018; Wadud et al., 2016). \n\nIn contrast, some researchers have also found that AVs and ridesharing schemes could potentially increase energy consumption because of increased travel demand, VMT, and traffic speed, and in case automobile-oriented developments are encouraged at the outskirts of urban regions (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Ross & Guhathakurta, \n\n| Table 5  Impact on energy use.  Study   | Impacts on energy use                                                                                                                                                                                                                                                            |\n|-----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| (Fagnant &                              | Each SAV will reduce energy use by 12%                                                                                                                                                                                                                                           |\n| Kockelman, 2014)                        |                                                                                                                                                                                                                                                                                  |\n| (Kopelias et al., 2020)                 | CAVs reduce fuel use by 30 - 90%                                                                                                                                                                                                                                                 |\n| (Qi et al., 2018)                       | 12 - 22% energy savings from driving assistance via HMI  and partially automation                                                                                                                                                                                                |\n| (Atiyeh, 2012)                          | Fuel economy increased by 23 - 39% for all vehicles in  freeway travel stream                                                                                                                                                                                                    |\n| (Chen et al., 2018)                     | As high as a 90% improvement in fuel economy by each  AV                                                                                                                                                                                                                         |\n| (Narayanan et al.,                      | SAV energy consumption reduced by 37 to 80%                                                                                                                                                                                                                                      |\n| 2020)                                   |                                                                                                                                                                                                                                                                                  |\n| (Moorthy et al., 2017)                  | Public transit with last-mile AV would save energy up to  37% over personal vehicle                                                                                                                                                                                              |\n| (Arbib & Seba, 2017)                    | About 30% reduction in energy use in 2030 compared to  2020                                                                                                                                                                                                                      |\n| (Kim, 2018)                             | About 56% reduction in 2030 compared to 2016                                                                                                                                                                                                                                     |\n| (Manzie et al., 2007)                   | Only 7s traffic look-ahead ability (i.e., long distance  information transmission via telematic capability)  improves fuel economy by 33%                                                                                                                                        |\n| (Greenblatt & Saxena,                   | A 10% decrease in single-occupancy VMT reduces energy                                                                                                                                                                                                                            |\n| 2015)                                   | use by about 3%.                                                                                                                                                                                                                                                                 |\n| (Bullis, 2011)                          | 4-m inter-track spacing reduces fuel consumption by 10 -  15%                                                                                                                                                                                                                    |\n| (Milakis et al., 2017)                  | -Up to 45% fuel savings by control algorithms and  optimization systems  -About 90 - 100% of energy saving by battery SAEVs                                                                                                                                                      |\n| (Vahidi & Sciarretta,                   | 2 - 50% energy savings due to advanced knowledge of                                                                                                                                                                                                                              |\n| 2018)                                   | road grade, proper signal phasing and timing, cooperative  car following and lane selection                                                                                                                                                                                      |\n| (Wadud et al., 2016)                    | 0 - 45% reduction in energy use due to congestion  mitigation, platooning, eco-driving, light-weighting, right  sizing, reduced footprint of infrastructure and 0 - 60%  increase in energy use due to higher speed, increased  features in vehicles, and people's travel demand |\n| (Brown et al., 2014)                    | AVs could reduce energy use by over 90%. However,  under rise in service demand and speed of AVs, energy use  could increase to 173%                                                                                                                                             |\n| (Chehri & Mouftah,                      | ACC, eco-driving, and inter-vehicle communication                                                                                                                                                                                                                                |\n| 2019)                                   | reduce fuel use by 2 - 4%                                                                                                                                                                                                                                                        |\n| (Liu et al., 2017)                      | 11 to 55% reduction by CAV                                                                                                                                                                                                                                                       |\n| (Ross & Guhathakurta,                   | Over 50% of energy savings by ride-sharing of full AVs                                                                                                                                                                                                                           |\n| 2017)                                   |                                                                                                                                                                                                                                                                                  |"}
{"doc810": "2017). Vehicle automation can also generate longer and more energy-intensive commutes, replace energy-efficient public transportation, induce urban sprawl, and thus increase energy use (Hess, 2020). Additionally, reduction in the opportunity cost of travel time can increase fuel use substantially by increasing long-distance trips (Auld et al., 2018). Thus, the net effect of AVs on transport energy use is uncertain, which warrants further investigation (Milakis et al., 2017). \n\nAlthough automation would reduce overall energy use, oil demand for electricity generation will increase to charge AVs. Kim (2018) estimated that to charge 44 million AVs with a battery of 70kWh, the industry would require 3080 GWh per day extra energy by 2030 in the US, \nassuming each AV charge once a day. About 33 more nuclear power plants of equal size to Palo Verde nuclear power plant in Arizona would be required with 24 hours of operation each day to generate that amount of electricity. Thus, the policymakers should take appropriate actions to manage additional energy demand considering the anticipated impacts on the electrical grids. \n\n## 4.3.2. Ghg Emissions"}
{"doc811": "Researchers found that AV technologies can significantly reduce GHG emissions (Duan et al., 2020; Fakhrmoosavi et al., 2022; Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Le Hong & Zimmerman, 2021). CAVs, SAVs, and on-demand mobility options can further reduce emissions by lowering the number of engine start, energy consumption, and vehicle ownership (Coulombel et al., 2019; Wadud & Anable, 2016). The integration of EVs and SAVs presents an added potential to sharply reduce emissions. Jones and Leibowicz (2019) found that the adoption of SAVs could be more impactful in controlling vehicle emissions than a carbon tax policy, despite higher VMT. The estimations of emission reduction by different types of AVs are presented in Table 6. Overall, AVs show the potential to reduce emissions and improve air quality. However, a lower share of AVs (i.e., 30%) could instead increase emission due to a slight rise in traffic demand and in traffic speed, and to aggressive acceleration after a stop to reach cruise speed again (Rafael et al., 2020). \n\nAVs operated as shuttle services (6 kg CO2-equivalent per passenger) \nemits lower carbon in the whole life than the AVs operated as a personal vehicle (10 kg CO2-equivalent per passenger) (Moorthy et al., 2017). However, the net effect of AVs on GHG emissions remains ambiguous (Milakis et al., 2017). Travel demand reduction due to shared mobility is canceled out by the increased travel distance and empty running (Wadud et al., 2016). Thus, further research is more likely needed to determine the actual effect of AVs on emission reduction (Rafael et al., \n2020). \n\n## 4.4. Impacts Of Avs On The Urban Built Environment"}
{"doc812": "The SWOT analysis (Fig. 7) indicates that AVs would have the opportunity to reduce parking demand, but would also increase roadway capacity. However, the main threats AVs may cause include increased demand for transport infrastructure and urban expansion. Based on the existing literature, this subsection recognizes the potential impacts of AVs on the urban built environment. \n\n## 4.4.1. Spatial Patterns Of Urban Growth\n\nMany studies have argued that the advent of AVs would influence the layout of urban areas (Biloria, 2023; Cugurullo et al., 2021; Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019; Meyer et al., 2017; Van den Berg & \nVerhoef, 2016). By reducing travel costs, AVs may affect residential and work locations, leading to intensified urban sprawl and the inefficient use of land (Fraedrich et al., 2019; Krueger et al., 2019; Zakharenko, 2016). An agent-based simulation study in Korea found new development scattered throughout the region along with growth near existing urban centers stemming from households' preference for urban amenities in a scenario where 100% of vehicles are assumed to be AVs compared to the business as usual scenario over the next five decades (Kim et al., 2015). The adoption of AVs may increase city radius by 3.5%, developed land area by 7.1%, and residential area by 7.6% (Zakharenko, 2016). Under currently prevailing policies and conditions, AVs may single-handedly result in urban expansion in the order of 10 - 30% (Litman, 2017). Thus, to facilitate the emergence of AVs without hampering urban living and development, policymakers should endeavor to better understand the potential impacts of AVs on the spatial distribution of land uses. "}
{"doc813": "Conducting a web-based survey, Carrese et al. (2019) found that about 40% of respondents would move to the suburbs under the AV \nregime in Rome, Italy. Similarly, Wellik and Kockelman (2020) reported a 5.3 to 5.5% reduction in the number of households living in the metropolitan region of Austin, TX at a 100% AV scenario compared to a 0% AV scenario over a 27-year timespan (2013 - 2040). They also mentioned a 5.8 to 6.2% growth in the number of households living in the non-metropolitan regions of Austin. Thus, AV would influence people's residential locations by increasing accessibility, mobility, and convenience, and by reducing the opportunity cost of travel time. \n\nExperts confirmed that, in conjunction with triggering the emergence of new peripheral centers (edge cities), AVs would also densify the existing urban fabric by reallocating space for residential, economic, and leisure activities (Gonz\u00b4alez-Gonzalez \u00b4 et al., 2019; Milakis et al., 2018). \n\nSpace released from on- and off-street parking could be used for building wider sidewalks, bicycle paths, delivery bays, new public facilities, activity centers, and high-quality recreation spaces (Clements & Kockelman, 2017; Martinez & Viegas, 2017). Since AVs can reduce car ownership, it is likely that less space will be used for streets, parking lots and garages, and possibly expand high density and mixed use developments (Dennis et al., 2017; KPMG International, 2019). Thus, AVs are likely to change the urban landscape by densifying the existing built areas. "}
{"doc814": "A majority of the literature points that AVs would lead to dispersed urban development by reducing travel costs and enhancing the mobility of people. Polycentric development may be seen surrounding the central urban areas due to new development induced by AVs. Consequently, it is likely that city land area and residential and commercial land uses would increase. At the same time, a densification would be observed in the city core by allocating space released from parking spaces for new residential, commercial, and recreational development. \n\n## 4.4.2. Parking Demand\n\nBesides influencing the physical extent of urban areas, AVs are expected to affect urban form by reducing the demand for parking in the established neighborhoods and centers (Clements & Kockelman, 2017; Kopelias et al., 2020; Van den Berg & Verhoef, 2016). As indicated in Table 7, AVs would reduce overall parking demand quite drastically. As a case in point, a recent simulation study estimated a 10% reduction in parking land area by 2020 in the Atlanta core after introducing SAVs \n(Zhang & Wang, 2020); reductions would mushroom to 42 and 75% by 2030 and 2040, respectively. Conducting a study in Los Angeles County, (Chester et al., 2015) observed that about 14% of the county area are currently used for parking. However, this parking area could be reclaimed, particularly in the city center, and repurposed for building "}
{"doc815": "| parking land area by 2020 in the Atlanta core after introducing SAVs  (Zhang & Wang, 2020); reductions would mushroom to 42 and 75% by  2030 and 2040, respectively. Conducting a study in Los Angeles County,  (Chester et al., 2015) observed that about 14% of the county area are  currently used for parking. However, this parking area could be  reclaimed, particularly in the city center, and repurposed for building                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Emission reduction by AVs.  Study Emission reduction  (Milakis et al., 2017) Up to 94% reduction in GHG emission  (Greenblatt & Saxena,  87 - 94% reduction in GHG emissions per mile  2015)  (Kopelias et al., 2020) CAVs reduce GHG emission by 5 to 94%  (Wadud et al., 2016) 20% reduction in carbon emission  (Rafael et al., 2020) 30% reduction of both NOx and CO2 emissions  (Fagnant &  5.6 to 49% reduction in GHG, 34% CO, 19% SO2, 18%  Kockelman, 2014)  NOx, 49% VOC, and 6.5% PM10 emission reduction by  each SAV  (Narayanan et al.,  10 to 94% emission reduction by SAVs  2020)  (Greenblatt &  63 - 82% GHG reduction per mile compared to private  Shaheen, 2015)  gasoline vehicles  (Vahidi & Sciarretta,  1 - 18% emission reduction due to cooperative control  2018)  (Iglinski \u00b4 & Babiak,  40 - 60% reduction in GHG emission  2017)  (Chehri & Mouftah,  66% GHG emission reduction  2019)  (Martinez & Viegas,  40% reduction in carbon emission  2017)  (Liu et al., 2017) 3 to 19.09% reduction in emission  (Eilbert et al., 2017) Up to 215% reduction in emission | Table 7  Impact of AV on parking demand.  Study Impact on parking space  (Fagnant & Kockelman,  Average reduction of 11 parking spaces per SAV  2014)  (Narayanan et al., 2020) 48 to 90% reduction in parking land area  (Milakis et al., 2017) Up to 90% reduction in parking land area  (Zhang et al., 2015) Up to 90% reduction in parking land area at a 2% SAV  penetration and about 8.6% reduction in parking land  area per SAV  (Kondor et al., 2018) 50% reduction of parking land area by SAVs  (Kim, 2018) 40% reduction of parking lots  (Chehri & Mouftah,  40% reduction in overall parking land area and 44%  2019)  reduction in parking spots  (Zhang & Guhathakurta,  4.5% reduction in parking land area at a 5% SAV  2017)  adoption and over 20 parking spots reduction per SAV |\n\nhigh-quality and attractive spaces for economic activities to increase land productivity (Gonz\u00b4alez-Gonzalez \u00b4 et al., 2019; Zakharenko, 2016). \n\nWellik and Kockelman (2020) reported a 19.4 to 62.9% increase in developable land in Austin at a 100% AVs scenario over a 0% AVs scenario due to reduction in parking demand. "}
{"doc816": "In contrast, some studies have also suggested the possibility of an increase in parking demand due to the increase in people's travel demand and in case of ride-sharing services are deficient (Zakharenko, 2016; Zhang & Wang, 2020). However, people's willingness to share vehicles, the availability of AV ride-sharing services, and higher penetration rates of SAVs can significantly reduce parking demand (Milakis et al., 2017; Zhang et al., 2015). Thus, researchers (Narayanan et al., 2020) have suggested to take policy actions to augment the use of SAVs and thereby reduce overall vehicle parking demand. \n\nMost previous studies have argued that higher penetration of AVs and SAVs may lower parking demand in residential areas and in business districts by reducing car ownership and increasing ride-sharing. Moreover, AVs may self-park in less expensive areas outside of city centers and reduce parking demand in the city core (Fagnant & Kockelman, 2015). For people living at the outskirts of the city and choosing to own an AV, parking at the edges of the city center may be attractive and may reduce vehicular traffic in the city. Commuting traffic could use a multi-storied parking deck to reduce space utilization in the urban core. \n\nConvenient drop-off and pick-up locations near residences and workplaces would also effectively provide great convenience to travelers. "}
{"doc817": "## 4.4.3. Infrastructure Capacity\n\nThe extant literature reveals that vehicle automation can increase road and intersection capacity by vehicle platooning, using Cooperative Adaptive Cruise Control (CACC), and by exchanging information between vehicles using Vehicle Awareness Devices (VAD) (Kopelias et al., \n2020; Meyer et al., 2017; Zhang et al., 2018). Study results summarized in Table 8 show that AVs are likely to increase roadway capacity of existing facilities more efficiently without adding any lanes (Fernandes \n& Nunes, 2012). This would curtail the need for roadway expansion. \n\nHowever, capacity could be affected by traffic heterogeneity, which could disrupt communication among vehicles (Milakis et al., 2017). "}
{"doc818": "Greater capacity benefits could be achieved even at a lower penetration of AVs if the non-ACC vehicle populations are equipped with VADs which can serve as the lead vehicles for the CACC vehicles \n(Shladover et al., 2012). In contrast, Narayanan et al. (2020) mentioned that AVs should be more than 20% of the vehicle population to achieve \n\n| Table 8  Impact of AV on roadway capacity.  Study Capacity increase  (Fernandes & Nunes,  367%  2012)  (Van den Berg &  7 - 200%  Verhoef, 2016)  (Narayanan et al.,  43 to 273% on highway, 40% on urban roads, 9.39 to  2020)  39.21% with 100% penetration, 215% at 100%  penetration with connectivity and 9.38% without  connectivity  (Milakis et al., 2017) 40% (100%) penetration of AVs increases capacity by  over 10% (200%).  (Shladover et al., 2012) -10%, 50%, and 90% penetration of CACC increase  capacity 1%, 21% and 80%, respectively.  -20%, 30%, and 50% to 60% penetration of vehicles with  Vehicle Awareness Devices (VAD) increase capacity by  7%, over 10%, and 15%, compared with cases without  VADs  (Tientrakool et al.,  About 43 to 273% capacity increase by CAVs due to  2011)  sensors and communication technologies  -34.85 to 83.5% reduction in gaps between vehicles due to  communication technologies and onboard sensors  (Shladover et al., 2012) A 100% increase in capacity when each vehicle is  equipped with short-range communication radios (e.g.,  CACC, VAD)   |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\nan increase in roadway capacity. Thus, a large enough number of CAVs is essential in the market to increase communication between them and thereby to increase roadway capacity over a mixed traffic situation (i.e., non-, semi-, full AV). "}
{"doc819": "## 5. **Discussion And Directions For Future Study**\n\nInvestigating the current status of implementation, researchers reported that AVs will be available for people's regular use incrementally over the coming decades. The findings from the existing literature show that AV would influence urban transportation and human mobility by reducing vehicle ownership, public and active travel, traffic delay and congestion, travel costs, and increasing accessibility, mobility, VMT, and revenue generation for commercial operators. Some studies also mentioned that AVs can further influence people's travel behaviors by embracing cutting-edge EV technologies and providing shared and ondemand mobility services. Investigating the long-term effects, researchers reported that AVs would encourage dispersed urban development, reduce parking demand in city centers and residential areas, and enhance the capacity of the road network. Some studies also observe that AVs have the potential to reduce energy consumption and protect the environment by reducing GHG emissions. Investigating people's safety, security, and privacy, the extant literature reported that most people are very concerned about personal safety, security, and privacy from strangers, cyberattacks, maliciously controlled vehicles, and software hacks. On the other hand, researchers mentioned that AVs are able to reduce traffic crashes involving human errors and increase the convenience and productivity of passengers by providing amenities for multitasking opportunities. \n\nResearchers also believe that SAVs are well positioned to have greater positive impacts on transportation and on the urban environment than private AVs (University of Kentucky, 2020). SAVs in a dynamic ride-sharing situation could be an effective policy option to reduce vehicle ownership, traffic congestion and travel time, and improve overall performance of the transportation system (Loeb et al., \n2018; Zhang et al., 2015). Researchers proposed to formulate appropriate funding mechanisms and policies to encourage ride-sharing and on-demand mobility among travelers to increase use of SAVs (Ross & \nGuhathakurta, 2017). Thus, pertinent policies in transportation (e.g., \nautomation of transit, integration of transit and non-motorized transport, encourage shared and micro mobility), infrastructure (e.g., \nadjustment, and redesign of existing roads), and urban planning (e.g., update of urban development plans, land-use plans, parking policies and design, green belts) are essential to realize the benefits of AVs. Moreover, the law and order situation needs to be improved to provide safety and security to passengers while sharing AVs. "}
{"doc820": "The extant literature provides consistent and compelling evidence that AVs have the potential to bring dramatic changes to urban transportation systems, to their use by populations and to the spatial structure and conditions of the urban built environment. Previous review papers systematically evaluated the short and medium-term effects of AVs on transportation and human mobility and overlooked their long-term effects on the urban built environment. This updated systematic literature review identified, evaluated, and critically analyzed relevant scholarship to understand the current status and impacts of AVs on urban transportation and urban built environments. \n\nWhile significant progress has been made in unraveling the impacts of the commercial deployment of AV technologies, previous studies display some prominent limitations. Several of them are discussed below to identify research gaps and provide guidance for future studies. The research agenda includes two strands of recommendations, one on issues that have been overlooked, one on shortcomings of research conducted so far. \n\n## 5.1. Shortcomings In Research"}
{"doc821": "1) AVs are not currently available for people to use; thus, many simulation studies estimating impacts of AVs are solely based on assumptions (e.g., same vehicles and speeds, similar travel behaviors, vehicles shared by household members only), imaginaries of riders in simulated urban setting (e.g., grid city, typical city), and limited testing (Compostella et al., 2020; Fagnant & Kockelman, 2015; Zhang et al., 2018). Sometimes, vehicles are operated in a homogeneous traffic environment with little interaction with neighboring vehicles (Piao et al., 2016). Moreover, lower levels of autonomy (i.e., \nLevel 1, 2 or 3) were used to understand people's perceptions and assess the impacts of fully automated vehicles (Level 4 or 5) (Rahman et al., 2017; Xu et al., 2018). Thus, to be reflective of real-world decision environments and gauge the real-world impacts of AVs, future studies should investigate the impacts of AVs considering heterogenous populations of users and heterogenous traffic environments allowing interactions with other vehicles, inclement weather conditions, and full automation of vehicles (Level 5). \n\n2) Conducting stated preference surveys, some studies have investigated travel patterns of persons with prior knowledge on AVs and with technological affinity, while disregarding other segments of people (Haboucha et al., 2017; Kapser & Abdelrahman, 2020; Konig \u00a8\n& Neumayr, 2017). Some studies consider travel by private AVs only, while others consider SAVs only, each representing only part of a larger and more complex transportation system (Duan et al., 2020; Krueger et al., 2016; Salonen, 2018). Thus, future studies should draw samples from all segments of people and investigate people's travel patterns by AVs and SAVs to gain a holistic overview of the complex shifts in the socio-technological system grounded in AV \ntechnologies. \n\n3) Some studies have considered certain travel activities only such as work trips, shopping trips, or long distance leisure trips, while ignoring vehicle operations for fueling and parking to estimate the impact of AVs (Compostella et al., 2020; Ma et al., 2017). Also, in some cases, only a generalized network is studied, for instance excluding local last-mile transportation issues (i.e., travel to and from transit station) (Moorthy et al., 2017), or a small section of the whole network of a typical city is considered (Papadoulis et al., \n2019). Thus, studies would be more generalizable by considering the whole transport network of a city to account for travel activities over the complete range of distances and urban contexts to understand the full scope of impacts of AVs. "}
{"doc822": "4) Most studies only considered the sunk costs of ownership to estimate the travel costs by AVs, disregarding the vehicle operation and maintenance costs (Wadud, 2017). Some studies only consider fare collection to estimate the revenue generation by SAVs, while ignoring the maintenance and refueling costs (Duan et al., 2020; Nunes & Hernandez, 2020). Thus, a comprehensive estimation of travel costs and revenue generation comprising of all factors is necessary to better assess decision making by customers and commercial operators. \n\n5) Some studies have simulated the evolution of AVs in different contexts based on various assumptions (e.g., different levels of autonomy and market penetration of AVs, customers' willingness to pay for AVs, small geographic area of analysis, etc.). However, as discussed in Section 3, there is inconsistency in their predictions of the temporal evolution of AVs. Moreover, the evolution of AVs in different contexts could be different considering the socioeconomic condition of the regions/countries and the acceptance of information and communication technologies. Thus, a comprehensive study considering multiple study contexts to understand the temporal evolution of AVs remains needed. \n\n## 5.2. Overlooked And Understudied Aspects"}
{"doc823": "1) Although researchers have mentioned that AVs would increase the accessibility and mobility of all people, including disabled, elderly, children, and people without driving licenses, there is a lack of empirical evidence on the implications of AVs on diversity and social disparity. Thus, empirical studies investigating the impacts of AVs on transport equity should be conducted to achieve social sustainability of transportation system. \n\n2) Although studies have identified a number of positive effects (e.g., \ndensification, economic growth) and negative effects (e.g., urban expansion, higher trip length) (Gelauff et al., 2019; Kim et al., 2020; Milakis et al., 2018) of AV technologies, there is still little evidence on how AVs would effects people's residential and employment location decisions, recreation spaces, parking spaces, supply of infrastructure, and overall urban layout patterns (Kim et al., 2020; Krueger et al., 2019), and the trade-offs that may arise from these diverse and possibly conflicting outcomes. Thus, future research should investigate the long-term effects of AVs on urban land-use patterns to promote AV adoption without disturbing urban living environment and by ensuring efficient use of land. \n\n3) Regulatory frameworks and business models pertaining to AVs and SAVs are still unsettled, which would influence vehicle ownership, residential and workplace locations (Kim et al., 2020; Zafar et al., \n2022). Similarly, researchers have seldom discussed different challenging aspects of carpooling in CAVs such as scheduling, passenger matching, privacy, communication, new norms, policies, infrastructure, and new attitudes (Nemoto et al., 2023; Zafar et al., 2022). "}
{"doc824": "Additionally, there is a scant research on insurance pricing strategies that could be leveraged to estimate the impacts of these emerging technologies on the transportation system. Adequate field testing and civil society and professional involvements are necessary to realize the benefits of automation and to formulate policies (Crayton \n& Meier, 2017; University of Kentucky, 2020). Further research would identify and validate urban and transport policy measures to promote attractive and livable cities considering the introduction of AVs by conducting adequate field tests and by involving relevant stakeholders (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019). \n\n4) Door-to-door services provided by AVs would reduce walking and cycling trips, increase physical inactivity and related health problems (Gonzalez-Gonz \u00b4 alez \u00b4 et al., 2019). Yet, to the best of our knowledge, there is no empirical study to investigate the impacts of AVs on public health (Crayton & Meier, 2017; Sohrabi et al., 2020). \n\nAlthough many studies have investigated the impacts of AVs on transport energy use and on emissions, the impacts of AVs on noise and light pollutions are rarely explored, which may partly indicate their environmental outcomes (Silva Gomez \u00b4 et al., 2022). Thus, there is a dearth of knowledge and a need to study and evaluate the possible impacts of AVs on public health and environment considering the change in human travel behaviors and urban built environment. "}
{"doc825": "5) Finally, as noted earlier, the overwhelming majority of studies have treated the case of Global North countries where AV technologies and institutional settings are usually regarded as closer to commercial deployment and implementation. The case of Global South countries is poorly understood at this time. Given the sharp rift that separates these two sets of countries, it can hardly be argued that experiences of latter countries will mimic those in the Global North. \n\nResearch on how AVs could touch urban transportation and environments in the Global South is desperately needed to chart pathways towards a sustainable future protecting their natural environment while affording them social and economic opportunities. \n\n## 6. **Conclusion**"}
{"doc826": "This state-of-the-art comprehensive literature review investigated the short, medium, and long-term effects of AVs on urban transportation and urban environments. To understand the advantages and disadvantages associated with AVs, this review study critically analyzed previous papers and summarized the key findings based on a SWOT analysis \n(Fig. 7). The important takeaways from this study include that AVs would encourage dispersed urban development, would reduce parking demand, and would enhance network capacity. AVs would reduce energy consumption and protect the environment by reducing GHG \nemissions. Additionally, AVs would reduce traffic crashes involving human errors and increase the convenience and productivity of passengers. However, most people are very concerned about personal safety, security, and privacy due to increased surveillance and monitoring of their movement and the possibility of cyber-attacks by hackers. \n\nThus, there is agreement among various studies that AVs have the potential to influence urban transportation systems and human mobility by reducing car ownership, public and active travel, congestion, travel costs, and by increasing accessibility, mobility, VMT, and revenue generation for commercial operators. Analyzing results and methodologies, we identified key limitations of previous studies, gaps in our knowledge base, and provided a blueprint with some directions for future research. This research supports decision makers in taking appropriate strategies and actions to manage transportation infrastructure, human mobility, urban built environment, energy consumption and environment and improve safety and security of people. \n\n## Declaration Of Competing Interest"}
{"doc827": "Bansal, P., & Kockelman, K. M. (2017). Forecasting Americans' long-term adoption of connected and autonomous vehicle technologies. *Transportation Research Part A:* \nPolicy and Practice, 95, 49\u201363. \n\nBansal, P., Kockelman, K. M., & Singh, A. (2016). Assessing public opinions of and interest in new vehicle technologies: An Austin perspective. Transportation Research Part C: Emerging Technologies, 67, 1\u201314. \n\nBegg, D. (2014). *A 2050 Vision for London: What are the implications of driverless transport?* \nT. J. P. Ltd.. https://www.transporttimes.co.uk/Admin/uploads/64165-transport-t imes_a-2050-vision-for-london_aw-web-ready.pdf Biloria, N. (2023). Autonomous mobility in the built environment. In P. Droege (Ed.), \nIntelligent Environments (Second Edition): Advanced Systems for a Healthy Planet (pp. "}
{"doc828": "Chen, T. D., Kockelman, K. M., & Hanna, J. P. (2016). Operations of a shared, autonomous, electric vehicle fleet: Implications of vehicle & charging infrastructure decisions. *Transportation Research Part A: Policy and Practice, 94*, 243\u2013254. \n\nChen, Y., Young, S., Qi, X., & Gonder, J. (2018). A First-Order Estimate of Automated Mobility District Fuel Consumption and GHG Emission Impacts. In *Road Vehicle* Automation, 4 pp. 113\u2013123). Springer. \n\nChester, M., Fraser, A., Matute, J., Flower, C., & Pendyala, R. (2015). Parking infrastructure: A constraint on or opportunity for urban redevelopment? A study of Los Angeles County parking supply and growth. *Journal of the American Planning* Association, 81(4), 268\u2013286. "}
{"doc829": "Autonomous vehicles (AV) are rapidly becoming integrated into everyday life, with several countries anticipating their inclusion in public transport networks in the coming years. Safety measures in the context of Vehicle-toVehicle (V2V) and Vehicle-to-Infrastructure (V2I) communication have been extensively investigated. However, ensuring safety measures for the Vulnerable Road Users (VRUs) such as pedestrians, cyclists, and e-scooter riders remains an area that requires more focused research effort. The existing AV sensor suites offer diverse capabilities, covering blind spots, longer ranges, and resilience to weather conditions , benefiting the V2V and V2I scenarios. Nevertheless, the predominant emphasis has been on communicating and identifying other vehicles, leveraging advanced communication infrastructure for efficient status information exchange. The identification of VRUs introduces several challenges such as localization difficulties, communication limitations, and a lack of network coverage. This review critically assesses the state-of-the-art in the domains of V2X and AV \ntechnologies, aiming to enhance the identification, tracking, and localization of VRUs. Additionally, it proposes an end-to-end autonomous vehicle motion control architecture based on a temporal deep learning algorithm. The algorithm incorporates the dynamic behaviors of both visible and non-line-of-sight (NLOS) road users. The work also provides a critical evaluation of various AI technologies to improve the VRU message sharing, identification, tracking and communication domains. \n\n## Introduction\n\nThe autonomous vehicles (AV) domain is one of the fastest growing areas of the current age due to rapid advances in computing, electronics, sensors and communications technologies. The current developments in computer hardware and sensors have led to significant improvements in the situational awareness of autonomous vehicles (AVs). Additionally, the advancements made in communications, networking, security and performance have facilitated the development of AV platforms that can interact more efficiently with the surrounding infrastructure, as well as other road users. This has contributed to the improvement of the safety and reliability of an average autonomous journey for both the AV and vulnerable road users (VRUs) that include pedestrians and bicyclists. In conventional automotive design and safety use cases, automotive manufacturers extensively consider the VRU safety aspect. The term VRU \ncommonly refers to individuals such as cyclists, pedestrians, and other two-wheeler operators who are more prone to injury or fatality in vehicle-dominated road spaces. Under the EU ITS Directive, VRUs are defined as \"non-motorized road users, such as pedestrians and cyclists as well as motorcyclists and persons with disabilities or reduced mobility and orientation\". With the continued focus on advanced driver assistance systems (ADAS) and other safety features, the safety of VRUs has significantly advanced in conventional vehicles. With the progression of increasing availability of more robust sensors, the preemptive advisory and warning systems for drivers, pedestrians and cyclists have improved substantially in the last decade. "}
{"doc830": "Pedestrians are one of the more common and vulnerable types of various VRUs. According to the Department of Transport, UK (Road casualty statistics in Great Britain, 2017), 72,993 pedestrian casualties occurred on urban roads in the period of 2017 - 2020. During the past decade, with increasing congestion on roads along with newer modes of transport, the risk to pedestrians by conventional and AVs is likely to increase. Moreover, several studies have reported a steady increase in cyclist-related deaths particularly in heavily built urban areas. However, \n\n## * Corresponding Author. E-Mail Address: Syusuf@Elm.Sa (S. Adnan Yusuf).\n\nhttps://doi.org/10.1016/j.trip.2023.100980 Received 18 July 2023; Received in revised form 4 October 2023; Accepted 25 November 2023 Available online 15 December 2023 2590-1982/\u00a9 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/bync-nd/4.0/)."}
{"doc831": "## 2\n\nstudies relate this to an increase in the number of cycle trips in addition to an ever-increasing number of vehicles on the road. The Department of Transport (2020) statistics show a 5 % increase in cyclist fatalities between 2004 and 2020 with a 26 % increase in serious injuries subject to the fact that the pedal cyclist traffic increased by 96 % (Road casualties in Great Britain: pedal cycle, 2020). Further information on the UK-level statistics shows 73 % of fatalities that lead to serious injuries occurred in urban areas. It is notable that 56 % of fatalities occurred on rural roads. \n\nThree-quarters of fatal or serious injury cyclist crashes happened on lowspeed roads (30 mph) (Talbot, et al., 2017). Moreover, with the rapid increase in e-scooter usage, there were 1,280 collisions reported in 2021 compared to 460 in 2020 in the UK (Road casualties Great Britain: eScooter, 2021). These statistics show a significant increase from 2020 when there was just one fatality reported and the serious injuries to pedestrians and cyclists were only 13 and 7, respectively. This shows escooters to be a major player in the V2X scope in the presence of AVs in the coming years. "}
{"doc832": "V2X (Vehicle-to-Everything) communication is a technology paradigm that allows the sharing of real-time information between the AV \nand other road users in the surrounding vicinity. This includes Vehicleto-Vehicle (V2V), Vehicle-to-Infrastructure (V2I), and Vehicle-toPedestrian (V2P) with V2P acting as an umbrella term enabling communication with all types of VRUs. V2X describes a vehicle's communication with all other entities in its surrounding environment. This ranges from dynamic entities such as other vehicles, pedestrians, and cyclists, to static elements such as traffic signals, road signs, and road markings. A vehicle communicates with these entities in two distinct ways: \n- By receiving feedback from its onboard sensors as a 360-degree area of awareness \n- By receiving indirect messages via a communication medium from the infrastructure or other road users In conventional vehicles, V2X technologies significantly increase a driver's situational awareness, especially in cases where infrastructure occludes other road users. Some well-known V2X systems include cooperative driving/cruise control (Liu and Kamel, 2016), queue warnings/collision avoidance (Gelbal, et al., 2017; Vazquez-Gallego, \u00b4\net al., 2019; Ni, et al., 2020; Wu, 2020c), hazard warnings, and extended sensor coverage (Yamazato, 2015; Lee et al., 2019; Lee, et al., 2020; Zhou, et al., 2020; Maruta, et al., 2021). For cars driven with V2X, this means improved driver awareness and automotive safety (Karoui et al., \n2020). \n\nDespite the overarching benefits of V2X technologies to conventionally driven vehicles, with the rapid introduction of autonomous vehicles (AV) on public roads, the role of V2X will transform substantially. As AVs heavily rely on onboard sensors to create a 360-degree area of awareness, they can only view other road users that are predominantly in the direct line of sight. For instance, an AV can be equally unaware of a cyclist who is about to pull in front of it from behind a parked bus than a human driver. Similarly, cross-traffic junctions with viewing obstructions such as hedges reduce the response time of an AV \nsubstantially. \n\nHence, one core objective of this review is: \n\"To what extent the existing research has explored the development of an integrated communication and perception framework that could increase the situational awareness of other road users especially the VRUs.\" \nIn similar scenarios, an integrated V2X is likely to improve the situational awareness of an AV. Despite certain research indicating AV as a relatively low risk medium (Hulse et al., 2018), skepticism of the technology has been reported at around 38 % (Nielsen and Haustein, 2018) compared to the feeling of indifference from a quarter of respondents. A major factor that has so far gained less focus is the public's understanding of the level of risk that pedestrians, cyclists, and other road users are exposed to when engaging with AV in close-contact urban settings. "}
{"doc833": "This paper presents a detailed review of the existing V2X technologies employed in the AV domain as well as other support infrastructures to improve VRU safety. The scope of this paper will examine the utilization of V2X and Advanced Driver Assistance Systems (ADAS) to improve the safety of AV platforms (Fig. 1). In doing so, the review will assess the differences in considering AVs in V2X ecosystems by highlighting the technical as well as policy-related differences highlighted in the literature. The work will also consider the role of various sensor technologies that are likely to play a role in improving VRU protection. Moreover, the evolution of the V2X mechanism and the likely route the forthcoming technologies should potential consider. Section II describes various sensors and safety systems onboard vehicles as well as on the VRUs. Section III reports various communication protocols and sensors and reports on ADAS/C-V2X research undertaken so far. Section IV \ncontributes a motion control pipeline in conjunction with various V2X \nmodules. The section describes various AV components that play an essential role in the integration and utilization of the V2X technology along with their strengths and weaknesses. Section V ultimately presents a consolidated explanation of various technologies and research stacks employed leading to a VRU collision avoidance system for AVs. The paper concludes by providing a discussion of potential research venues that could improve the identification and tracking of VRUs in the current state of the art. \n\n## V2X Safety Systems For Vrus\n\nVRU is an umbrella term used for non-motorized road users, such as pedestrians and cyclists, or individuals with disabilities. These users lack an outer shield and hence are at a higher risk of injury on the road in case of a collision. With the rapid advent of newer modes of pedestrian transport, additional VRUs such as electric scooters are now also becoming part of this category. According to the Insurance Institute of Highway Safety (IIHS), pedestrian fatalities count for 17 % of all traffic accident fatalities whereas cyclists account for another 2 % (Users, 2022). Despite significant advancements in ADAS, including pedestrian detection and safety systems, there still appears to be an increase in pedestrian fatalities over the past 10 years. "}
{"doc834": "The incorporation of safer and robust navigation systems for AVs is becoming more crucial in environments with an increased interaction between AVs and VRUs. Modern AV designs consider VRU mobility patterns and characteristics in a bid to make autonomous navigation safer. One such instance is the incorporation of segregated road-spaces with cyclists since their relatively higher speed requires a quicker response from an AV compared to pedestrians. Moreover, cyclists often show varied behavior patterns such as sudden shifting to pedestrian crossings to avoid crossing main road intersections. Such behaviors make safety incorporation more challenging and generate a larger number of edge cases that an AV's motion planner must consider eliminating collision risks. \n\nAccording to statistics shared by Brake (Global road safety statistics | Brake, 2018), more than 1.3 million people die annually from road accidents where 1 in 2 road deaths involve VRUs and 80 % of these belong to developing and rapidly motorizing economies (Radjou and Kumar, 2018). Over the past few years, planning councils and policymakers have been applying progressive approaches to improve VRU safety by taking measures such as speed limit reductions, allocating dedicated cycling lanes, and smart and signaled crossings and improved visibility measures. These safety measures assist human drivers to get real-time information and guidance cues to be careful in areas with more VRU activity. An average human driver uses their sensory perception to identify developing hazards such as pedestrian trajectories. Conventional V2X technologies improve this perception by understanding a pedestrian's trajectory whereabouts to the vehicle's V2X receiver system. Similarly, cyclist proximity or collision warnings at vehicle blind \n\n![2_image_0.png](2_image_0.png)"}
{"doc835": "spots improve reaction times particularly for high-sided vehicles' drivers \n(Anaya, et al., 2015; Naranjo, et al., 2017). For a human driver, such a collision warning can be a vehicle interface with an alarm or other sensor input. The context changes significantly for AVs in similar circumstances. For example, when there is a blind spot area not covered by an AV's sensors, it is crucial to relay the VRU's location, speed, and other orientation variables to the AV's perception system. This information is essential for estimating the possibility of a collision. The context of this review arises from the fact that other road vehicles and sensors in the vicinity, which have better coverage, can supplement this information. \n\nYet, the state of the art of V2X technologies have so far focused on \n- Operational strategies (Pearre and Ribberink, 2019), \n- Vehicle platooning applications (Choudhury, 2016; Nardini, 2018; Lekidis and Bouali, 2021; Segata et al., 2021), \n- Communication and networking mediums (Pearre and Ribberink, 2019; Abboud et al., 2016; Muhammad and Safdar, 2018; Garcia, et al., 2021), \n- Technology testing and validation (Wang, 2019; Jung, 2020; Mafakheri, 2021), \n- Commercially available V2X products (Pearre and Ribberink, 2019; Kiela, et al., 2020; Frank and Hawlader, 2021), \n- Regulations and standards (Machardy, 2018), \n- V2V integration (Zhou, et al., 2020), - Block chain, security, and privacy aspects (Huang, et al., 2020; Shrestha, et al., 2020). \n\nV2X based safety enhancement for VRUs Vehicle-to-Pedestrian (V2P) communication represents a specific category within the broader V2X framework, enabling seamless wireless communication between vehicles and pedestrians. This technology facilitates pedestrians in transmitting their location data effectively to nearby vehicles. Despite sharing an architectural framework akin to V2V \nand V2I communications, V2P mechanisms exhibit unique characteristics. Notably, the deployment of any V2X node necessitates a connectivity unit at both ends of the communication link. In a typical V2P \nscenario, an on-vehicle connectivity device establishes a connection with a pedestrian's smartphone, either directly or indirectly. The data exchange process operates through three distinct modes (Malik, 2020). "}
{"doc836": "In the domain of V2X communication, various scenarios shape the level and mode of interaction between vehicles and their surroundings. These scenarios play a pivotal role in determining the effectiveness and coverage of V2X systems. Each of the following three scenarios offers unique approaches and challenges in enhancing communication and safety on the roads. \n\nScenario 1 - *Infrastructure based sensing*: In this scenario a roadside network of sensors facilitates V2P communication. Infrastructure based sensing is costlier to set up for most cases and used in more specialized or risky situations such as at signaled junctions, or crossings. This type of setup, however, provides crucial safety information in addition to providing a local consolidation of sensor input from all the actors in the vicinity especially in more challenging situations. \n\nScenario 2 - *Vehicle based sensing*: This scenario involves vehiclebased V2X sensors only. It suffers from significantly short coverage such as blind spots, lack of positional information due to GNSS unavailability in dense urban areas and poorer cellular coverage in remote areas. Therefore, in the case of a vehicle not connected to a network \n(such as C-V2X), even a fully equipped AV is unable to detect objects that are not within its line of sight (NLOS). "}
{"doc837": "## Vehicle Onboard V2X Safety And Communication Systems\n\nThe threat posed by a conventional vehicle to a VRU varies based on the vehicle's design and type. For example, sports utility vehicles (SUVs) \nwith their elevated frontal structure are more prone to striking pedestrians, increasing the likelihood of serious injury or fatality. This heightened risk stems from either direct head impacts or the vehicle running over the pedestrian. In conventional vehicles, several safety assessment approaches are reported including trajectory prediction models (Wu, 2019; Zhuang, et al., 2022), V2I-based warning systems \n(Wang, 2016; Liu et al., 2018) and smart infrastructure integration (Ma, 2019). \n\nThere is a growing emphasis on integrating V2X-related safety equipment into modern conventional vehicles. Such vehicles feature onboard sensors in the form of Advanced Driver Assistance Systems (ADAS), serving various functions such as providing information, issuing warnings, or enhancing safety. For example, an in-car Vehicle-toPedestrian (V2P) collision avoidance system enables continuous information exchange between pedestrians and vehicles. "}
{"doc838": "A standard V2X system traditionally has the following components \n(Wang, 2019): \n- Vehicle communication device (OBU) \n- Pedestrian communication device (smart phone, body-mounted sensor) \n- Infrastructure/Roadside Sensing Unit (RSU) (pole/structure mounted sensors) \n- Information processing unit (IPU) (edge device or server) \nThe OBU module facilitates wireless communication between the vehicle and the IPU or the VRUs. There are several modes of communication in a V2X system including Wi-Fi, WiMAX, BTE and cellular networks. Bustos *et al*. presented a computer vision-based pedestrian safety scheme to process street-level images to develop a hazard landscape for VRUs that is updateable at every 15 m (Bustos, et al., 2021). \n\nLiu *et al*. presented a radar-based perception method that utilized a 75 GHz radar to detect and track both vehicles and pedestrians and predict collision situations (Liu et al., 2018). A dead reckoning mechanism based on a neural network algorithm to calculate pedestrian's trajectory and predict any impending collision situations has also been reported \n(Murphey, 2018). In a rapidly developing urban pedestrian scene, realtime discovery of VRUs is of critical importance. One effective approach is the Collective Scanning method, which reduces the time taken by a vehicle to receive responses from pedestrians through various channels. \n\nAdditionally, it employs an 'Extension Receiving' method to avoid missing Vulnerable Road User (VRU) detections. The method improved the overall detection time by 42.52 ms for the latter technique thereby reducing the overall detection time to 72.13 ms (Fujikami, et al., 2015). He et al. reported the latency impact of utilizing WLAN and BTE communication across different V2X communication channels to assess and rectify location inaccuracies in GPS-based pedestrian localization \n(He et al., 2017). The study's findings indicated that Dedicated Short Range Communication (DSRC), characterized by its low latency, proved to be more effective in scenarios where speed limits exceeded 90 km/h. "}
{"doc839": "Furthermore, for speeds up to 108 km/h, GPS accuracy should not deviate by more than 3 m. In recent AV-based collision avoidance scenarios, DSRC-based communication notably demonstrated efficiency, especially when obstructed line of sight with pedestrians prevented their detection through cameras, radar, or LiDAR. Gelbal *et al*. detected and localized pedestrians in the immediate vicinity of the AV via two DSRC \nmodems (Gelbal et al., 2020). The paper detects and localizes pedestrians when traditional line-of-sight sensors like cameras, radar, and LIDAR fail. The work also introduces a modified version of the elastic band method for real-time collision avoidance and presents model-inthe-loop simulations. \n\nIn a generic road traffic scenario, pedestrians and cyclists are the slowest responders to any developing hazards in their vicinity. Hence, a vehicle's awareness of a VRUs accurate position, speed, and orientation in real-time are essential to be integrated with the driver warning systems of conventional vehicles as well as in the motion control logic of AVs. Modern-day smartphones commonly report positioning via the inbuilt GPS combined with several proprietary location calculation methods. However, these methods still do not provide the level of accuracy needed for an AV to pinpoint the position of a VRU. Continuous location monitoring is a power-hungry process due to its continuous background-based pinging. There are various energy-efficient mechanisms reported including a P2P GO method based on the Wi-Fi direct localization. The method reported a 22.4 % improvement in the safe delivery of messages and 36.8 % more energy efficiency compared to the WAVE standard (Lee and Kim, 2016). Substantial work in this area has focused on RSU-IMU-assisted localization (Ma, 2019), LiDAR-to-IMU \npositioning (Wu, et al., 2020a), GNSS fusion with Inertial Measurement Units (IMUs) and Wheel Speed Sensors via RSUs (Hoang, 2017), \nintegration of inertial sensors with a particle filter to improve vehicular positioning within an Ultra Dense Network (Liu and Liang, 2021). \n\n## Beyond The Line Of Sight: The Role Of Av Sensors"}
{"doc840": "Pedestrians' onboard sensor diversity is relatively limited, with smartphones being the most prevalent and often the only devices. Yet, the widespread usage of smartphones, their ubiquitous coverage, and diverse embedded technologies make them the ideal source to localize and track. The literature frequently reports the use of GPS positioning applications on smartphones, serving as collision indicator systems that display warnings and vibration alerts (Hussein, 2016; Liu, et al., 2016; Barmpounakis, 2020). To improve GPS signal-related accuracies, several techniques integrate IMU-based corrections to compensate for positioning errors in dense urban areas and tunnels (Hellmers, 2013; Yao, 2017; Wang, et al., 2020a). On the vehicle side, inertial navigation systems with accurate onboard localization identify and broadcast their own location via a communication network. One limitation of such systems is that a large majority utilize smartphone GPS which are power-hungry devices. Li *et al*. have presented a novel powerconsumption mechanism that shifts to a coarse-level GPS-based localization mechanism that relies more on the device pedometer (stepcounter) and cellular signal strength changes to achieve an average location precision of 92.8 % while conserving 20.8 % energy (Li, et al., \n2018). \n\nIn recent years, there has been a notable expansion in the deployment and integration of AV platforms. These advancements involve an extensive array of sensors and broader coverage. Thus, V2X safety systems integrated into these platforms have the potential to enhance the safety of VRUs in the surrounding area. For instance, LiDAR or radar sensors onboard an AV offer a considerably wider range and coverage compared to human drivers, enabling more detailed area monitoring. \n\nMoreover, the introduction of 5G-based technologies has facilitated realtime communication capabilities between neighboring vehicles. When combined with modern AV sensors, these protocols can substantially improve the identification and tracking of NLOS VRUs. Section III presents a review of V2X communication protocols and sensors. The section further delves into the impact of sensor placement and the related work. "}
{"doc841": "![4_image_0.png](4_image_0.png)\n\nfacilitate interoperable, efficient, and reliable communication in AVrelated systems. DSRC is one such technology that originated as an IEEE 802.11p standard to provide Wireless Access for Vehicular Environments (WAVE) for V2X applications. The protocol provided Basic Safety Message (BSM) exchange to share a vehicle's status information that included position, speed, and direction to other users (Yin, et al., 2014). The medium operated on the 75 MHz bands of the 5.9 GHz spectrum with the upper layers and security specified by the IEEE 1609 family. The standard was first approved for use in 2010 and approved in certain 2015 Japanese models before being adopted in some US Cadillac and Volkswagen Golf 8 models in 2017 and 2019, respectively (Boovarahan, 2021). The DSRC had several challenges including channel congestion in high traffic environments, absence of a handshake/ACK in frames broadcast, limited communication due to no internet, inability to receive broadcasted messages and channel leakage (self-interference) \n(Wu, et al., 2013). The DSRC/WAVE standard utilizes wireless LAN (WLAN) medium to establish DSRC channels to enable vehicle communication on short to medium ranges of up to 300 m. The WAVE standard revolutionized the automotive communication industry as it eliminated the need for an intermediary (server). This not only eliminated latency issues due to direct communication but also extended the applicability of such systems in remote areas with poor cellular coverage. Soon after the DSRC, another vehicle communication protocol based on cellular networks originated. This protocol was termed C-V2X \ndue to its ability to operate on cellular networks. The goal of this protocol was to improve road safety for more effective communication between vehicles and the infrastructure. This facilitated efficient traffic flow, reducing environmental impact, and providing additional data exchange and passenger information services. \n\nA direct C-V2X allows the transmission of data packets to the receivers while encompassing the following categories (Weber et al., \n2019): \n- V2V (Vehicle to Vehicle): V2V medium covers safety message exchange between vehicles for collision avoidance, speed control, emergency braking and lane changing. "}
{"doc842": "Fig. 2 describes a use case covering various V2X components along with sensors to identify and connect various road users. \n\n## The Infrastructure Sensors\n\nThe infrastructure-based sensor paradigm offers superior coverage due to its flexibility in sensor placement, height, and positioning. This adaptability ensures efficient monitoring of blind spots and detection of VRUs even in NLOS situations. Depending on specific circumstances, the sensors employed can include a variety of technologies such as cameras, radars, and beacon detector systems. Additionally, distance-based sensors such as radars and LiDARs provide precise distance and depth information across different scales. An RSU edge device processes the data collected from these sensors. The on-premises computing of sensor information minimizes the communication overhead of sending all the information to a cloud-based server. Such a localized compute model is termed the Multi-access Edge Computing (MEC) model. The principle of MEC is to localize data processing to local high-performance nodes instead of the cloud. Recent contributions in this domain have reported the utilization of the V2X Cooperative Awareness Messages (CAM) \nserver and VRU-based smartphone GNSS to facilitate real-time status sharing of VRUs with the vehicles (Ru\u00df et al., 2016; Napolitano, 2019; Zoghlami et al., 2022). The vehicles share the localization information of the VRUs in real time via these CAM servers. "}
{"doc843": "## Vehicle-Based Sensors\n\nVehicle-based perception sensors have possibly seen the highest focus of research due to direct application in the ADAS and AV industries. ADAS has gained significant traction in the past 10 years. The provisioning of ADAS is now becoming a norm even in entry-level automotive models. Some of the well-known ADAS technologies include the Automated Emergency Braking Systems (AEBS), adaptive cruise controls, electronic stability control, parking assist, smart navigation, lane assistance, collision avoidance, and artificial intelligence \n(AI) based assists. In more advanced use cases, AI-based ADAS systems actively report functionalities like automated parking, pedestrian detection, blind spot monitoring, and driver or drowsiness detection (Okuda et al., 2014). ADAS continues to evolve as an increasing number of sensors are integrated into modern vehicles including GPS/GNSS, \nshort-to-long distance radars, cameras, LiDARs, IMUs and SONARs (ultrasonic sensors) (Smith, 2021). However, vehicle-mounted multisensor platforms lack the necessary coverage to monitor the relatively small proportions of VRUs adequately due to their limited field of view. A conventional ADAS-equipped vehicle employs a wide array of sensors to create a 360-degree area of awareness. Table 1 presents several ADAS \ntechniques available in modern-day cars alongside the commonly used sensors. \n\n## The Sensor Communication Paradigm"}
{"doc844": "Fig. 3 shows an indirect communication mechanism that allows the exchange of information via an on-premises message exchange server. \n\nUnlike DSRC, indirect C-V2X allows the cellular network to gather information from several vehicles including non-DSRC/non-cellular vehicles (Ansari, 2018). With the advent of 5G communication, and its better reliability and lower latency, millions of vehicles on cellular networks now incorporate improved situational awareness such as traffic-based speed advisories, GPS map updates, as well as over-the-air (OTA) updates of automotive software. This also facilitated traffic management on larger scales. The original release of this protocol (Release 14/R14) complied with the LTE standard that eventually extended to 5G and 5GNR in Release 15 and 16 respectively. The R16 protocol introduced PC5 and LTE-Uu interfaces to obtain a diversity gain (Lianghai, 2018). The PC5 interface had a shorter range of less than a kilometer and operated in the ITS 5.9 GHz band while providing information on the vehicle's location and speed. The Uu interface provided a longer (>1km) range and provided information from further ahead such as accidents, congestions, etc. The later version (R15) presented \n\n| A comparative analysis of research and development contributions across  ADAS/C-V2X use cases.  Approach (Sensors) Description Citations  Cross-traffic assist (GPS/  Sensor fusion to predict  radars)  collision course with other  road users at traffic  intersections  (Qi Liu, Liang, et al.,  2021)  Intersection movement  assist (IMA) (GPS/  radars)  (Miucic, et al., 2018); (  Sander et al., 2019); Qi  Liu, Liang, et al., 2021)  Emergency Electronic  Brake Light (EEBL)  warning (Ultrasonics/  radars)  Vehicle trajectory  estimation for collision  estimation  Sudden frontal car braking  (Miucic, et al., 2018)  identification  Automated Emergency  Braking (AEB)  (Cameras/radars)  Safety system to identify  frontal collisions via  trajectories, speed, and  orientation estimation  (Sander et al., 2019)  Traffic & route updates  Local area or enroute traffic  (GPS, 5G, radars)  updates consolidation to  issue live reports  (Wu, 2020c)  Blind spot warning  Blind spot driver warning  (Cameras, radars)  systems against VRUs  during lane change, turning  or reversing.  (Brandl, 2016); (Jeong  et al., 2016); (Naranjo,  et al., 2017); (Miucic,  et al., 2018); (Maruta,  et al., 2021); Qi Liu,  Liang, et al., 2021)  Left/right turn assist  Any turn-based assists to  (Cameras, radars)  minimize collisions from  vehicles coming from the  opposite direction  (Miucic, et al., 2018); (  Sander et al., 2019)  Cooperative lane change  (CLC) assists & warning  (IMUs, cameras,  LiDARs, GNSS, 5G)  A specialized lane-change  maneuver based on  surrounding traffic density  and information to  minimize the impact on the  overall flow of the traffic  (Brandl, 2016)  VRUs (IMUs, cameras,  VRU's positional and  LiDARs, GNSS, 5G)  orientation integration  with AVs systems to  facilitate safer automotive  maneuvering  (Hussein, 2016); (Li,  et al., 2018); (Malik,  2020); (Parada, 2021)  Adaptive cruise control  (ACC) (Cameras, radars,  ultrasonic)  Speed adjustable driving to  minimize congestion based  cellular traffic data  (Liu and Kamel, 2016);  (Yadav and Szpytko,  2017)   |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|"}
{"doc845": "developments that catered more towards the AV industry and provided network-agnostic, low latency direct communication that could work up to speeds of 500km/hr. Molina-Masegosa and J. Gozalvez presents a comprehensive review of the LTE-V standard based on the PC5 interface \n(Molina-Masegosa and Gozalvez, 2017). With an improved link budget, this standard performs better than the 802.11p or DSRC alternatives. \n\nMost notably, the article presents a detailed analysis of LTE-V mode 4, which does not require any cellular infrastructure support. The mode also supports redundant packet transmission, various subchannelization schemes, as well as the infrastructure assistance. \n\nRecent developments in the Mode 3 domain have introduced enhancements ensuring a more stable resource management, reducing signaling overhead and packet collisions(Aslani et al., 2020); (Sempere-Garc\u00eda et al., 2021). As mentioned earlier, Mode 4 needs no support from the cellular infrastructure. This makes the mode more robust, especially in areas with lesser cellular availability. The focus of research in this domain has primarily been on areas such as congestion control (Mansouri et al., 2019), comparison of communication performance, packet transmission, and Modulation and Coding Schemes (Gonzalez-Mart\u00edn, et al., 2019). Organizations like SAE, IEEE, and ETSI actively support the protocol through security standards (Bazzi, 2019). Although gaining popularity, both the DSRC and C-V2X standards come with their own set of advantages and disadvantages. One aspect of C-V2X facilitated latency-tolerant use cases that included telematics, infotainment, and information safety cases. The 3GPP has recently published its new V2X "}
{"doc846": "![6_image_0.png](6_image_0.png)\n\nstandard known as the 5G New Radio (NR) air interface. \n\nIn the work reported in the literature regarding various C-V2X use cases, Sander *et al*. (Sander et al., 2019) re-simulated a 372 left-turn across path/opposite direction (LTAP/OD) accidents. The simulation showed a 59 % crash avoidance if only the turning vehicle was equipped with the Intersection Automated Emergency Braking (AEB), which increased to 77 % in the case of both vehicles equipped with the AEB \nfunctionality. Wu *et al*. utilized an RSU to calculate the speed and location of a vehicle pair. They used this information to assess the collision probability of the vehicles and issued intersection collision warnings to the drivers (Wu, et al., 2020b). VRU collision avoidance system based on indirect C-V2X are commonly reported with the VRU identification being carried out via various sensor combinations such as radars and infrastructure-based CCTV cameras. These sensors typically connect to RSUs that are equipped with an image/signal processing edge device via LAN/WLAN or cellular links. The RSU is responsible for the integration of camera and radar-based cyclist identification and distance/depth information from the radar or LiDAR sensors mounted on the signal gantry (Wu, et al., 2020b). Likewise, the RSU receives location and trajectory information from the bus or any vehicle with their planned intersection movement, which in the case shown in Fig. 3 is a right turn. Moreover, depending on the availability, the cyclist may also broadcast their position and speed via a body mounted V2X sensor or a mobile application. Information fusion from the vehicle, infrastructure and VRU sensor creates an area of awareness. Based on the movement pattern of each of these dynamic parties, the edge device calculates the collision probability of the bus with any VRUs and broadcasts a warning to the bus driver. "}
{"doc847": "## The Effect Of Sensor Placement\n\nExtending the scope of cooperative V2X perception, the strategic placement of sensors within infrastructure is a critical topic. LiDARs are specifically well-known for their ability to extract rich depth and 3D \nobject information. Hu *et al*. presented a LiDAR sensor placement method aimed at the optimization of the spatial configuration of LiDAR \nsensors on vehicular platforms. Rather than adhering to the conventional approach of LiDAR installation, data collection, model training, and model performance evaluation, they opted for a unique method. Utilizing 3D bounding boxes, they generated a probabilistic occupancy grid to optimize the placement (Hu, et al., 2021). Dead zones are a common challenge as a LiDAR placed at a specific part of a vehicle's body may create a dead zone on the other side of the vehicle due to the vehicle itself. Kim et al. focused more on the dead zones and lower resolution challenges based on sensor placements. Their approach developed a genetic algorithm driven approach where the LiDAR Occupancy Grid (LOG) is encoded as a chromosome. Each LOG receives a fitness score based on the resulting dead zone and resolution of its placement. This score eliminates the worst performing LOGs and sensor configurations during the evolutionary run (Kim and Park, 2019). Cai et al. developed a LiDAR simulation library in CARLA (Cai, et al., 2022). They used surround, solid state, and prism LiDARs and simulated their digital equivalent in the CARLA simulator and evaluated the placement efficiency simply by the object detection accuracy. For each infrastructure placement, the accuracy was measured via the same V2X/multiagent perception model. Similar work by Du *et al*. extended to a range of real-life situations including traffic flow, and speed parameters as well as keeping high-vehicles proportion in the analysis. The team positioned the sensors in both single and dual directional configurations, covering eight scenarios with spacing of 50, 100, 150, and 200 m (Du, et al., \n2022). The method used object detection measurements as the evaluation metric and the results showed a significantly low missing probability at 50 m which increased with the increase in the percentage of trucks from 10 % to 75 % with 0.05 to 0.3. \n\n## Av Components In C-V2X"}
{"doc848": "The design of conventional vehicles based on ADAS systems essentially supports a driver in addition to providing preventative measures \n\n![7_image_0.png](7_image_0.png)\n\nsuch as emergency braking and adaptive cruise control (Table 1). In the case of an AV platform, the context changes since an AV's decision support and motion control principles need a tighter integration of sensors. Extending an AV's sensing capability to include collision possibilities from VRUs brings additional challenges due to the nature of each of these VRU types. In this context, C-V2X represents an information-sharing paradigm model that provides the situational awareness logic for an AV to allow it to incorporate VRU safety. This section presents a critical review of an entire AV pipeline within the V2X \ncontext and explains recent research contributions at every relevant stage of the pipeline. An AV platform is equipped with a wide array of sensors that act as the data sources that generate its perception capability. Fig. 4 illustrates the various stages of an AV pipeline. "}
{"doc849": "## Mapping And Route Planning\n\nAV platforms make use of high-definition (HD) maps for navigation and route planning. HD maps may strictly not be needed for autonomous navigation, but they simplify several routing and planning stages. For instance, based on an AV's current position, if a map discovers a traffic cross-section, the V2X module activates a cross-traffic-assist module that will provide crucial spatial\u2013temporal information related to VRUs that are in the vicinity. Another crucial use of HD maps may be in localization where the multi sensor input can be cross validated with the HD map information to get a better position of the platform with reference to the VRUs. In situations where the GPS signal is lost and precise vehicle positioning is crucial, a mapping and route-planning system's ability to rely solely on onboard sensors like cameras proves particularly valuable. \n\nSensor-assisted localization is a commonly explored area for localization. Researchers have recently reported the implementation of Visual Simultaneous Localization and Mapping (SLAM) for autonomous driving and other ADAS-related applications, combining camera-based landmark identification and HD maps (Milz, et al., 2018; Tripathi and Yogamani, 2020; Qin, 2021). A large proportion of these techniques utilize deep learning-based algorithms for the identification and comparison of visual landmarks such as buildings, poles, traffic signs, etc., to localize the vehicle. "}
{"doc850": "These maps create a pre-computed understanding of the world that allows AVs to localize accurately. A standard HD map comprises two core components: \n- 3D tiles rendered from depth data obtained from cameras, LiDARs and radars. \n\n- Semantic information to give meaningful labels to various elements in the world. \n\nThe latter component elements encompass intersection elements like driving boundaries and virtual lines, as well as traffic signal information elements such as traffic lights and road signs. Additionally, these elements may encompass driving-related information such as crosswalks, stop lines, buildings, and other static elements. Integrating V2X elements seamlessly is vital to precisely position VRUs and accurately predict their trajectories. "}
{"doc851": "The SLAM module combines the HD map and route information from the mapping module to localize the vehicle and create a digitized environment. The routing information obtained from the mapping module along with the digitized environment performs two core objectives. Firstly, it broadcasts AV's location via the V2I interface to the RSU on the V2X Module. Secondly, the V2X module broadcasts each of the vehicle's location, speed, and orientation-related information to other road users. Moreover, the RSU obtains location information of other VRUs and vehicles to each V2X-bearing vehicle. The SLAM module also shares the localization information with the perception module that is responsible for the generation of a unified understanding of the AV 360-degree surround. \n\nChou *et al*. have presented the use of ConvNets that use rasterized images to predict pedestrian and cyclist trajectories (Chou, 2020). \n\nCarlos Gomez \u00b4 \u2013Hu\u00b4elamo *et al*. have developed a multi-object tracking pipeline based on the semantic information from HD Maps integrated with a Birds Eye View (BEV) Kalman and Hungarian filtering and tracking algorithm. The approach predicts the future trajectories of VRUs based on a Constant Turn Rate and Velocity model (Gomez- \u00b4\nHu\u00b4elamo, et al., 2021). Despite the effectiveness of hybrid sensor-HD \nmap systems for localization, the rudimentary positioning of AV platforms is conventionally done via satellite-based technology commonly termed under the Global Navigation Satellite Systems (GNSS) umbrella. Despite the global effectiveness of the GNSS receivers, several factors affect their standalone integration in an environment where timing, accuracy and availability are of crucial importance to developing a realtime area of awareness for an AV's surroundings. "}
{"doc852": "An AV sensor suite employs an array of sensors to generate the perception of the environment surrounding the vehicle while localizing the vehicle accurately against its rapidly changing scene. For the AV platform to operate safely, real-time processing and understanding of its 360-degree environment are crucial. This section explores the various sensor types used in an AV platform within the V2X/VRU context. Fig. 5 presents a typical sensor integration setup comprising of cameras, LiDARs and radars. With the goal of object detection in mind, prioritizing background subtraction becomes essential as it enables better clustering of 3D point groups from camera depth and LiDAR/Radar point clouds. \n\nMoreover, it allows an accurate, pixel-level understanding of each pixel of the scene image. Conventionally, LiDARs are well known for their capability to perform superior background subtraction due to their accurate distance scans (Wang, 2020c; Wen and Jo, 2021). Utilizing longto-short range radars further enhances the point clustering from the LiDAR feed, improving frontal collision avoidance by removing scanning outliers from both radars and LiDARs (Wang, 2020c). This integration particularly facilitates the identification of smaller-sized objects that radars on their find challenging (Kwon, et al., 2016). Once the foreground is efficiently extracted, the AV is localized based on a combination of GNSS/RTK-based positioning and HD Map referencing commonly known as visual odometry which cross matches critical static objects such as traffic signals, stop lines, etc. via the HD Map reference. \n\n![8_image_0.png](8_image_0.png)"}
{"doc853": "The perception system at this stage identifies other dynamic objects such \n\n![8_image_1.png](8_image_1.png) as vehicles, pedestrians, etc. via a combination of local vehicle-based sensors as well as position and orientation feedback from other road users. The consolidation of this information creates a wider behavioral understanding of each of the dynamic objects present in the surrounding area of the AV. This review assesses this stage by examining on-body sensors on various road users, including pedestrians and cyclists, to critically evaluate the current state of the art in VRU safety. \n\nFig. 6 shows a comparison of strengths and weaknesses of various sensor types in terms of various commonly reported and infrequent edge cases. The commonly reported challenges in an AV's perception system include distance estimation, object speed measurement, lateral resolution, and object classification. The infrequent, edge cases may involve any or more of the cases (e.g., object classification) but in the presence of poor weather, or low visibility conditions. The next sections present a review of various sensor capabilities in terms of VRU identification, coverage/range, distance estimation and speed measurement. A comparison of these pros and cons is further evaluated in Table 2. "}
{"doc854": "| S. Adnan Yusuf et al.                                         | Transportation Research Interdisciplinary Perspectives 23 (2024) 100980                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n|---------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------|\n| Table 2  Strengths and weaknesses of various communication technologies and sensorbased (radar-based) technologies for VRU safety.  Communication  Strengths Weaknesses  Type                                                               | Table 2 (continued )  Communication                                                                                                                                                                                                                                                                                                                  | Strengths                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Weaknesses |\n| Type                                                          | architecture.  Ability to utilize  network resources in the  same mobile network  (Thom\u00a8 a, 2021)  Self-reflected signals  from remote radio units  used to sense the surrounding environment  (Zhang, et al., 2017);  (Rahman, 2019)  A third receiver  exploiting the communication signal for passive  sensing.  Time difference of  arrival and triangulation  used for localization.  Better target detection  capability of distributed  MIMO radars (Haimovich  et al., 2008)                                                                                                                                                                                                                                                                                                                                                      | user access and diversity  in resource allocation.  (Zhang, et al., 2017)  Line-of-sight between  the sensor and the object  needed.  Non-metallic or lowreflective objects may not  be detected.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n| 6G networks  (Wild et al., 2021);  (Wymeersch,  et al., 2021) | - Low latency  High reliability  communication  Real-time cooperative  safety applications  High-density  deployments  Scalability supported.  Network can reach 1  cm detection accuracy  (100 + GHz frequency)  Camera-free object  positioning  Object distance/  position via LoS  Doppler shift for  velocity calculation  AI/signal processing | - Infrastructure equipment  deployment  Maintenance  requirement  Cannot identify the  object type.  Lack of coverage in  certain remote areas  Increased attenuation  at high frequencies  Significant bandwidth  required.  Spectrum resources  needed.  Data privacy and  security considerations                                                                                                                                                                                                                                                                                                                                                  |            |\n| 5G Near Radio (                                               | - Scalable/efficient radio                                                                                                                                                                                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n| Chen, 2021)                                                   | interface network and  parameters  Higher bandwidth of  up to 500 MHz  Forward compatibility  to the next decade                                                                                                                                                                                                                                     | - Communication with the  network needed for  localization and target  detection.  Designed for  communication.  RSI is difficult to extract  from 5G devices.  A joint wave form  design for sensing and  communication is still  missing.  Outdoor sensing: More  complicated due to more  scatter and dynamic  objects involved.  Existing 5G methods  made for shorter ranges.  Existing 5G sensing  made for single objects.  Lack of sensing  applications  Beamforming: Energy  consuming, high running  costs  Specialized equipment/  expertise required.  Affected by  interference/signal  attenuation.  Data privacy and  security issues |            |\n| JCAS - single                                                 | - Nearby objects/VRUs                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n| transmitted signal                                            | detection in real-time  (Liu et al., 2018)(Toker  and Alsweiss, 2020); (Cui  and Dahnoun, 2021);  (Sheeny, et al., 2021);  (Palffy, et al., 2022)  All weather/lighting  conditions operation  (Sheeny, et al., 2021)  Distance and speed  measurements accuracy  (Gelbal et al., 2020)  Highest spectral efficiency (Zhang, et al.,  2021)  No mutual interference  Low cost due to shared  transmitter and receiver  Information sharing  via a joint design and  optimization                                                                                                                                                                                                                                                                                                                                                      | LiDARs in VRU identification  LiDARs are one of the predominant sensors used in the AV industry  that generate a depth perception of the surrounding area by emitting  lasers. The sensors obtain range information of various objects by  receiving laser returns from reflecting object surfaces (Li and IbanezGuzman, 2020). Despite being one of the crucial sensors available in  an AV design, LiDARs pose certain limitations including inaccuracies on  reflective surfaces, data sparsity at longer ranges, degradation at high  sun angles or shadows and low operational altitudes (Warren, 2019).  Moreover, denser data maps provide better depth information at the  expense of the computational complexity involved in object classification tasks. In the VRU context, LiDARs' ability to identify smaller objects  due to their shorter wavelength makes them an important sensor. Yet,  they suffer from an operating altitude limitation of 500 - 2000 m and  their limited usage in nighttime or cloud weather (Widmann, et al.,  2000). The sensor is also commonly used to generate HD Maps of areas  to assist with AV navigation and motion planning. A large majority of  such systems combine various sensors to complement the weaknesses of  one with the strengths of the other.  For VRU identification, LiDAR usage has been widely reported in the  literature such as in kernel density estimation for pedestrian cluster  identification in point clouds that are then translated into location coordinates (Liu et al., 2019). Likewise, Wu et al. propose a multi-LiDAR  pedestrian detector as a two-stage pedestrian classifier where each  LiDAR presents an SVM-based single class object proposal that is further  filtered via an AdaBoost classifier (Wu, et al., 2021). A multi-sensor  fusion approach is reported for VRU identification in foggy conditions  based on the fusion of information based on a Yolov4 object detector and  a LiDAR point cloud fusion (Wu, et al., 2021). Similarly, V2P-based  proximity information from pedestrians is relayed and combined with  LiDAR-based detections onboard an AV. This hybrid approach eliminates missed VRU detections due to occlusions with the communication  system carried by pedestrians broadcasting their location, speed, and  direction to the AV's V2P module (Flores, et al., 2019).  LiDARs use rapid, sweeping scans to generate distance-based 3D  coordinates known as point clouds. Unlike radars, despite providing  crucial distance information even for smaller VRU point clusters, the  data for each LiDAR sweep is sparse in nature, irregular and with no  order. Hence, the 3D structural information encoded in these scans does  not contain as clear information as a conventional camera does. Each  point in a LiDAR scan, however, contains features such as reflectivity,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n| - Limited sensing range due  to restricted transmission  power (Zhang, et al.,  2021)  Full duplex operation  requirement  Transmission hardware  more complex  Interference and clutter  are difficult to suppress -  unwanted echoes  challenging. Clutter  suppression techniques  from radar to mobile  sensing not yet fully  developed.  Sensing parameter  extraction - extraction of  sensing parameters  challenging due to time,  frequency and space  variance, random multi                                                               |                                                                                                                                                                                                                                                                                                                                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |            |\n\ncolor, normal, etc., which are scale and transformation invariant and hence may prove beneficial for VRU identification. One major drawback of LiDARs is their sensitivity to various weather conditions. In rainy conditions, the water droplets in rain and fog scatter the light emerging from LiDARs thereby reducing the range as well as inducing inaccuracies. Likewise, solid particles in snow and smoke generate false returns leading to unreal obstructions in the sensor's line of sight (Roriz, et al., \n2022). Several methods for weather-related LiDAR noise removal are reported in the literature. Some well-known methods in this domain include voxel grid (VG) filters that use outlier removal mechanisms. The VG filters have been reported by several point-cloud improvement methods where point candidates are divided into equally spaced grids that generate one-to-many point mapping between the 3D points and their voxels (Ye, et al., 2020; Quenzel and Behnke, 2021; Wen and Jo, 2021). This method has two sub-methods - hard (Zhou and Tuzel, 2018) \nand dynamic voxelization (Zhou, et al., 2019; Cui, et al., 2022). The latter method provides more stable detection in point cloud generation by maintaining raw points and voxels. Despite the reported accuracy of voxel grids, they are known to be computationally expensive, especially for complex objects. This makes it further difficult to apply the technique to pedestrian clusters in real-time. Other well-known mechanisms include the statistical outlier removal mechanisms and low-intensity outlier removal techniques (Balta, 2018; Roriz, et al., 2022). Another trend in the V2X genre is that of infrastructure or RSU-based LiDAR feeds. Unlike vehicular LiDARs, RSU-based LiDAR units are generally mounted higher-up and hence are better capable of handling blind spots. Wu *et al.* have presented an adverse weather conditions handling application based on fixed LiDARs in a roadside use case in windy and snowy weather (Wu, et al., 2020b). The research has presented a ground-filtering method to discard background data in windy conditions based on a ground surface-enhanced point clustering method. Lee *et al.* have presented LiDAR to LiDAR transition from sunny to adverse weather conditions (Lee, 2022). Rivero *et al*. used LiDAR as a weather sensor where a 9-month duration of data is collected to identify and model four weather types: clear, rain, fog, and snow. The focus of this research was specifically on the detection of the road asphalt regions (Vargas Rivero, et al., 2020). Roriz *et al.* proposed an FPGA-assisted weather-related LiDAR signal de-noising method using a Dynamic Light Intensity Outlier Removal algorithm (Roriz, et al., 2022). \n\nOn the object classification aspect, the lack of clear spatiality traits in LiDAR scans makes it difficult for deep learning models to learn the data against matching class representations. Moreover, the rotation variant nature of LiDAR scans based on which angle of an object was obtained during any specific scan, makes training a deep learning model task even more challenging. Fusion of radar and imaging data with LiDAR scan has frequently been reported to address the deep-learning-related modelling inaccuracies due to data sparsity. A similar approach generates a pixellevel depth feature map (Gao, et al., 2018). The feature map fed into a Convolutional Neural Network (CNN), which learned feature-specific information from this pixel-level data to identify objects in an AV \nenvironment in real-time. Despite several attempts to utilize CNN for 3D \nobject classification, the genre has poor handling of sparse datasets due to several reasons. Most notably, CNN's direct application is difficult since unstructured 3D point clouds are irregular (Song, 2020). Moreover, most volumetric 3D CNN methods are complex and hence lead to very large storage and computational costs. Again, this makes it difficult to handle many VRU clusters such as at pedestrian crossings. To resolve these issues, Song *et al*. presented a CNN-based method that identified 3D objects by transforming the 3D points into Hough Space. The method included a semi-automated point cloud labelling method leading to object 3D Hough space generation and the eventual 3D object classification based on CNN. Alternatively, Kim has used YOLO-based object detection and projected LiDAR feedback on the detections to get a pixellevel classification with 3D object clusters (Kim et al., 2019). Yoshioka et al. presented a Real Ada Boost classification method to identify four object classes in AV LiDAR feed that included cars, pedestrians, cyclists, and background (Yoshioka, et al., 2018). Capellier *et al*. focused more on the VRU identification object and focused on a Binary Logistic Classifier to differentiate point clusters representing VRUs from any other objects (Capellier, et al., 2019). "}
{"doc855": "Currently, a large proportion of research into object detection combines various sensors. This technique, however, poses a significant risk where sensor failures may lead to the collapse of the entire perception pipeline. Ideally, each of the sensors should have its own redundancies in place and a global integration layer must not depend on individual sensor feedback (Cui, et al., 2022). Moreover, the possibility of infrastructure mounted LiDARs presents a promising venue for blind spot minimization. Yet, cost, AV standards, long-distance measurements in high-speed journeys, and adverse weather conditions remain some significant challenges (Li and Ibanez-Guzman, 2020). Almost all these challenges can be addressed effectively by the utilization of radar technology in AV. \n\n## Radars In Vru Collision Avoidance 11\n\nRadar technology in AV operates with a millimeter wave paradigm that provides higher resolution for obstacle detection and centimeterlevel accuracy for location and speed determination. The earlier use of radars in the automotive industry was limited to the detection of other road vehicles. The radar sensors used in such scenarios were 2-D capable sensors that only measured the speed and distance of objects. The technology used in imaging radars moved from low channel to high channel count thereby inducing an elevation as well as advanced signal processing and MIMO configurations (Li and Stoica, 2008). Radars are one of the most used sensors for collision avoidance in a V2X architecture. VRUs positions are propagated via a communication link to a roadside terminal and in turn to VRUs as warning signals. A vast majority of work on the communication side of this domain utilizes BLE, \nWi-Fi and cellular (4G/5G) signals to communicate with VRU smartphones. Potential arrival areas (PAA) reporting of pedestrian locations in conjunction with an always-on GPS has reported a battery loss of 78 % after a 32-hour test (Li, et al., 2018). Generally, local computation of collision avoidance on user phones is more efficient. On the other hand, performing such high-compute-intensive tasks on smartphones is reported to lead to more battery consumption (Thompson, 2018). "}
{"doc856": "Unlike LiDARs, Radar sensors function effectively in cloudy conditions and during nighttime operations, offering longer ranges. However, due to their longer wavelength, radars can only detect larger objects. \n\nThis sensor type finds frequent applications in collision avoidance systems. Millimeter-wave radars, commonly operating in a frequency range of 30 - 300 GHz (1 - 10 mm wavelength), are widely used for VRU \nidentification (Liu, 2020). For automotive applications, radars with reported frequencies are generally in the range of 76 - 81 GHz. Millimeterwave (mm-Wave) radars are frequently utilized in systems for concealed devices detection and posture estimation (Sengupta, 2020), and as a Doppler radar to detect and identify human movement (Chuma and Iano, 2020; Lang, 2020) and high precision human tracking (Cui and Dahnoun, 2021). As per the IHS data, cameras and millimetre-wave/ \nmicrowave radars form 70 % of automotive collision avoidance sensors. These radars are renowned for their capability to penetrate fog, smoke, and dust, allowing effective operation in challenging environmental conditions (Liu, 2020). \n\nResearchers have extensively discussed pedestrian detection using radars in recent literature with one approach integrating portable GNSS with IMU sensors to establish reference points for automotive radar. Additionally, efforts have been made to integrate LiDAR point clouds with Doppler Effect Regions of Interest (ROIs) from radar scans, addressing the prevalent issue of occlusion (Kwon, et al., 2016; Kwon, 2017) and similar attempts in leveraging depth information from stereo cameras (Palffy et al., 2019). For non-line-of-sight (NLOS) detection, a secondary microwave secondary radar-based detection technique has been proposed (Kawanishi, et al., 2019). Other radar-based pedestrian detection approaches include Frequency Modulated Continuous Wave (FMCW) used to identify the coherent phase difference of pedestrians with a Doppler FFT (Hyun et al., 2016) elimination of mutual interference (Avdogdu et al., 2018), combining vision-based features with mmWave radars for improved detection (Bi, et al., 2017; Guo, 2018), and incorporation of deep learning techniques to identify pedestrian profiles directly from radar scans (Azizi, 2020); (Palffy, 2020; Wu, et al., \n2020b). Despite several attempts on NLOS and partial occlusion challenges, integration of VRUs particularly those hidden completely at NLOS need a robust communication mechanism to improve the collision possibility awareness of AVs. "}
{"doc857": "Radars are ranging sensors like LiDARs that conventionally operate on a 77 GHz frequency with a wavelength of 3.9 mm compared to automotive LiDARs exhibiting smaller wavelengths of 905 - 1550 nm. \n\nDue to an even larger wavelength, radar point clouds are sparser than LiDAR point clouds. This characteristic makes it even more difficult to identify two closer or smaller objects. This is generally due to the smaller aperture sizes where most of the signal does not reflect due to specular reflection. Moreover, the lower angular resolution results in object merging which makes it more difficult to cluster two close-by objects \n(Immoreev and Fedotov, 2002). Despite their weaknesses, radar sensors find widespread automotive applications ranging from cruise controls of ADAS to collision avoidance in emergency braking systems. Traditional radars, also known as 2D radars, typically create an array of readings with each point representing a single object. Imaging radars, alternatively known as 3D radars, offer distinct capabilities. \n\nConventional automotive radars are somewhat like single-channel LiDARs due to their 2D point cloud return. Despite the somewhat rudimentary and legacy nature of these imaging radars, there has been a substantial amount of research into object identification using imaging radars. Toker and Alsweiss utilized a mmWave radar to distinguish pedestrians from vehicles. This was achieved by detecting distinct limb motions, resulting in varied velocity values, as opposed to the uniform velocity profile generated by rigid vehicular bodies (Toker and Alsweiss, 2020). "}
{"doc858": "On the contrary, the recent 4D genre of radars measures 3D position as well as the velocity of objects. These radars have about a single degree of horizontal and vertical scan resolution. Earlier attempts on radar datasets used these 2D scanning radars lacked Doppler activity that resulted in image-like datasets. Some well-known datasets in this category include Radar RobotCar (Barnes, et al., 2020), RADIATE (Kim, et al., 2020), and MulRan (Kim, et al., 2020). The Frequency-Modulated Continuous-Wave (FMCW) radar datasets in nuScenes and RadarScenes lack elevation information that makes them unsuitable for accurate 3D \nperception (Caesar, 2020; Schumann, 2021). On the 4D radar, Meyer & \nKuschk(Meyer and Kuschk, 2019) Rebut *et al*. (Rebut, 2022) and Palffy et al., (Palffy, et al., 2022), have reported next-generation radar datasets that include the elevation information to assist with the 3D object detection modelling in the deep learning domain. A large proportion of radar dataset generation activity now focusses on 3D object detection via deep learning algorithms though many report integration with the camera (Meyer and Kuschk, 2019; (Nabati and Qi, 2021), [154], and LiDARs (Feng, 2019; Wen and Jo, 2021). \n\nLong-range radars are rapidly finding applications in the autonomous and ADAS domains in use cases such as adaptive cruise control, collision avoidance, emergency braking systems and integrated sensor applications such as improving autonomous vehicles' occupancy grids \n(Yadav and Szpytko, 2017; Hung, 2019). These radars typically operate on 76 - 77 GHz of the frequency with an angular azimuth and elevation accuracy of up to \u00b10.10 and a range of up to 300 m. Due to their ability to provide four-dimensional measurements including range, Doppler, azimuth and elevation, these radars provide signatures that allow accurate classification of various object types such as cyclists, and pedestrians in complex, fast-speed driving scenarios (Yadav and Szpytko, 2017; P\u00b4erez, 2018). \n\nShort-range and surround radars are close-range sensors that provide blind spot detection (Kuo et al., 2017; Liu, 2017), collision warning (Saleem, 2017; Zakuan, 2017; Arumugam, 2022), parking assist cases (Hung, 2019), and autonomous emergency braking use cases (Flores, et al., 2019). These short-range radars generally provide a wider field-ofview (FOV) of \u00b1900 detection and \u00b1750 measurement and an operating frequency of between 76 and 81 GHz with a range of up to 180 m for motorcycle detection cases. The surround radar usage includes freespace estimation in AV perception systems, blockage detection, and auto-alignment and interference mitigation. Their elevation detection capability allows usage in curb detection scenarios specifically in lateral collision cases (Flores, et al., 2019). Excluding the short and long-range types, VRU detection and tracking falls in the medium-range category including cross-traffic identification of cyclists, pedestrian detection at crossing intersections and any other on-road VRUs (Arumugam, 2022). "}
{"doc859": "In the medium-range radar category of 4G radars, four signatures range, Doppler, azimuth, and elevation angles, allow better target identification and tracking. Waveform bandwidths, coherent processing interval (CPI) and the aperture of the antenna array determine the Doppler and angular resolutions. For a coherent radar, CPI is termed as the total sampling time. A higher resolution 4D radar imaging requires a longer CPI, greater bandwidth, and aperture size. The Doppler velocity and radar cross sections (RCS) classify road users better. Unlike LiDARs, these radars have lower cost and power consumption along with allweather operation capabilities that make them ideal for autonomous applications (Li, 2019; Li et al., 2019; Zhou, et al., 2022). To get a more robust and reliable sensor feed for object detection and tracking, the perception stage involves the combination of cameras, radars, and LiDARs with the camera sensors calibrated intrinsically and with LiDAR \nextrinsically as described by Zhang (Zhang, 2000) and Wang *et al*. (Wang et al., 2017), respectively. \n\nIn a typical AV safety use-case, the circular and medium to short range radars with a range of 40\u201380 m are commonly reported and address VRU-related use cases including blind spots (Kuo et al., 2017; Liu, 2017; Zakuan, 2017), cross-traffic assist (Brandl, 2016); (Sander et al., 2019), pedestrian detection (Avdogdu et al., 2018; Kawanishi, et al., 2019; Azizi, 2020;Toker and Alsweiss, 2020) etc. (Fig. 7). Longrange radars often combine with cameras and LiDARs to develop more reliable frontal and back collision avoidance and adaptive cruise control systems (Kwon, et al., 2016; Liu and Kamel, 2016; Yadav and Szpytko, 2017; Guo, 2018). \n\nJoint/Integrated communication and sensing (J/I-CAS) \nJCAS is a technology paradigm that integrates communication and sensing functionalities in a single entity. This allows the device to perform both communication and sensing together, hence improving reliability, robustness, and security of the system. "}
{"doc860": "For systems below 6 GHz, different communication standards including Wi-Fi, Bluetooth, and cellular 4G/5G technologies with frequencies in the range of 2.4 - 5 GHz including Wi-Fi signals are used. In the sensing context, Wi-Fi signals detect motion and position via the motion-based signals strength variation. In the cellular domain, mobile network operators detect traffic density in specific areas via signal strength. 5G supports ultra-robust, low-latency communication leading to its use in real-time sensing and control applications. \n\nRobots and autonomous vehicles possess accurate geo-localization capabilities along with precise situation recognition abilities. Wi-Fi and Bluetooth signals commonly perform obstacle detection as well as localization and mapping tasks in the AV domain. As discussed earlier, the DSRC technology operates at 5.9 GHz and allows V2V and V2I \ncommunication for a wide range of safety applications including collision avoidance, traffic intersection management, and emergency vehicle warning. \n\nEach of the mainstream AV sensors have their own strengths and weaknesses as elaborated previously in Fig. 6. For instance, LiDARs have operation limitations in poor weather conditions leading to a need for "}
{"doc861": "![12_image_0.png](12_image_0.png)\n\nradar technology integration. However, the current radars spectrum is not equipped to deal with the large number of AVs expected on roads soon. In addition, mobile spectrum so far cannot cope with the data transfer rates needed for multi-sensor AV platforms introduced an alternative to address this challenge, operating both sensing and communication-based sensing in one spectrum to enable the utilization of that spectrum for both communication and sensing functions. Commonly termed Joint Communication and Sensing (JCAS), the technique exploits the existing communication systems signals for sensing. The technique finds it applications particularly in the AV \ndomain where the vehicle uses the sensors onboard to exchange messages. A capability offered by 6G in this regard is the integration of mobile communication and sensing where the AVs must record their surroundings via the fusion of sensors such as radars, LiDARs, cameras and ultrasonic devices. The cellular spectrum cannot withstand huge bandwidth demands where the positional data from these sensors reach the range of 100 GB/s soon. However, during mobile sensing, significant mobile resources are not needed hence giving rise to the concept of JCAS. A few examples of this mode today are seen in LTE and 5G bands though the device must be connected to the network, send, and receive signals to allow localization. This is more useful in areas with little or no GNSS connectivity, especially in indoor areas. Saur *et al*. demonstrated active localization where wireless 5G interface detected VRUs with up to a meter accuracy along with their trajectories and potential collisions predicted. Another extension of JCAS has been in the Ultra-Wideband \n(UWB) impulse radio system (IEEE802.15.4z). Telephony, automotive, and electronic manufacturers standardized this system under the Car Connectivity Consortium, and major phone manufacturers have begun utilizing the UWB impulse radio system for localization. This allows enabled devices to localize other objects or mobile devices tagged with beacons. Likewise, the UWB spectrum makes it possible to localize sensor nodes in challenging NLOS use cases such as aircraft cabins (Ninnemann, et al., 2022), exercise activity tracking [169] and indoor individual tracking (Alloulah and Huang, 2019; Shi, et al., 2022). From the traffic perspective of JCAS, Bartoletti *et al*. have explored the use of 5G-V2X side link signals concerning performance bounds on range and speed estimation under different traffic conditions. The research investigated the use of 5.9 GHz vehicular communication system by exploring the radar sensing ability of side link V2X communication signals (Bartoletti et al., 2022). \n\n## Cameras In Vru Identification And Depth Perception"}
{"doc862": "Cameras are possibly the earliest perception sensors used in the automotive industry. The initial focus of imaging devices was on ADAS functionalities such as 360-degree and reverse parking assist, driver awareness, lane departure warning, adaptive cruise control, pedestrian detection, and traffic sign recognition (Dabral, 2014). Like radars, cameras portray a variable set of characteristics when considering a wider scene understanding in the automotive domain. People commonly use these devices for their object classification and depth perception capabilities as standalone sensors or in combination with other sensors \n(Ming, 2021). However, due to the light-dependent nature of standard imaging devices, common RGB cameras are known to struggle under low visibility, poor weather, and velocity measurement domains. \n\nResearchers have reported the use of multispectral imaging devices for pedestrian detection, integrating non-color information such as depth and thermal signatures to improve detection [175]. On the thermal domain, several attempts have been made using Haar wavelets, AdaBoost, SVM (Qi, 2016), faster R-CNN/CNN (Wagner, et al., 2016; Kim et al., 2018), Random Forests (Lahmyed et al., 2019), and HOGbased feature classification (Rujikietgumjorn and Watcharapinchai, 2017). Most of these techniques originate from a highly computeintensive image-processing domain where a remotely networked GPUbased processing server results in a performance bottleneck, especially with the increasing proliferation of such image-based V2X nodes. This has recently resulted in the introduction of a more localized compute model termed Multi-access Edge Computing (MEC). The principle of MEC is to localize data processing to local high-performance nodes instead of the cloud. Researchers have proposed the Age-of-Information \n(AoI) metric for real-time VRU status processing via a cellular network \n(Emara et al., 2020). Another approach utilizes V2X Cooperative Awareness Messages (CAM) server and VRU-based smartphone GNSS to facilitate real-time status sharing of VRUs with the vehicles (Ru\u00df et al., \n2016; Napolitano, 2019); (Zoghlami et al., 2022). \n\nEven though radars and LiDARs are primary distance estimation sensors, obtaining dense depth maps is a computationally expensive task (Ming, 2021). Cameras are one of the most crucial sensors in the AV domain since they offer unmatched object tracking and identification capabilities. Moreover, researchers widely report the capabilities of cameras for rapidly identifying objects in a wide range of scenarios. CNN \nis one of the most frequently applied deep learning mechanisms with their capabilities in automated feature identification in complex images/scenes and weight-sharing capabilities. Moreover, contrary to standard Multilayer Perceptron (MLP), CNN is shift-invariant with smaller weight sizes and a hierarchical scene understanding architecture. This makes CNN a well-known method in use cases needing rapid object segmentation needs including the AV domain. The technique however is spatially invariant which makes it difficult to learn efficiently from angular variations in 3D objects like those obtained from LiDAR \nfeeds. Yet, the technique has widely been combined with LiDAR point clouds to generate RGB-d based understanding of scenes. There are two main camera types with their own distinct characteristics when it comes to distance measurement, namely monocular and stereovision cameras \n(Toulminet, 2006). Distance estimation via monocular cameras utilizes correspondence assignment between two image points in two images where the triangulation method estimates the distance of each match. "}
{"doc863": "Hence, the accuracy depends upon the match's accuracy and correctness. The monocular method, on the other hand, is a process of estimating the distance of each pixel of an RGB image relative to the camera. Aladem & Rawashdeh developed an encoder-decoder architecture based on CNN to use the single task network to achieve semantic segmentation and depth prediction from a single image (Aladem and Rawashdeh, 2020). Naisen *et al*. implemented the Shift-RCNN (Faster RCNN) method with 3D object dimension and localized orientation prediction along the camera projection matrix to predict the car, pedestrian, and vehicle classes (Naiden, et al., 2019). Other CNN variants for monocular images-based depth estimation include FastMDE \n(Dao et al., 2022), and Bayesian cue integration (Mumuni and Mumuni, 2022). Repala and Dubey presented a dual-CNN unsupervised architecture for unsupervised depth estimation in monocular images. The DNM6 and DNM12, 6- and 12-loss models utilized two CNN for each of the left and right stereo-pair images to predict the respective disparities. \n\nThe results from the DNM12 model showed better performance than the DNM6 (Repala and Dubey, 2019). Li *et al*. presented a stereo R-CNN to detect and associate objects in right and left images in a simultaneous manner (Li, Chen and Shen, 2019). The method claimed a 30 % \nimprovement on both 3D detection and localization tasks. \n\n## V2V/V2I Based Collaborative Perception. 14"}
{"doc864": "The research community has extensively reported coordinated route planning via V2X. Establishing a datalink where vehicles with different LOS coverage share their scanning features enhances visibility, particularly for VRUs and conventional vehicles. One approach is to pool various permutation invariant operations where Chen *et al*. presented a Multi-view Object Detection Network (MV3D) integrating the birds-eyeview (BEV) and frontal LiDAR views with the RGB camera images (X. \n\n(Chen, 2017). On the other hand, a view aggregation technique that used multiple, varied-angle object views to generate 3D models by Su et al. was extended by Wang *et al*. and introduced an innovative concept of sharing neural features via V2X. This extension of the methodology to a different platform enables the creation of a 70-mile information-sharing radius, allowing each vehicle to share and receive information with nearby vehicles (Wang, et al., 2020b). The technique uses a spatially aware graph neural network (GNN) to combine the data received from all the nearby vehicles at various time and viewpoints instances. \n\nInformation from surrounding AVs has been categorized into three levels: early fusion, later fusion, and intermediate fusion. Early fusion methods communicate raw sensor data to other vehicles and the onboard compute capabilities of these vehicles then make predictions based on local processing (Q. (Chen, et al., 2019; Chen, et al., 2019). Due to the extent of information broadcasted, it is impractical to operate and share this information in real time (Wang, et al., 2020b). Late fusion methods, on the other hand, transmit detection outputs both in temporal and spatial capacity. Rausch et al. proposed a Constant Turn Rate and Acceleration and unscented Kalman Filter predicted the position of the communication partner both in a spatial and temporal domain (Rauch, et al., 2012). Rawashdeh et al. presents a YOLO and Multi-stage DenseNet based bounding box combining and alignment system that identify and localize the vehicles. Furthermore, the study includes vehicle classification, distinguishing between sedan, hatchback, etc., and ultimately calculates the center position of each vehicle (Rawashdeh and Wang, 2018). The performance of the underlying model substantially depends upon each vehicle's performance in the network. Other intermediate approaches have also been reported that share intermediate level features and information with networked vehicles. Chen *et al*. "}
{"doc865": "proposed a voxel-based future fusion method where they saved features in a hash table for non-empty voxels in the 3D LiDAR occupancy map. The approach used Spatial Feature Maps (SFF) that were sparser compared to Voxel Feature Fusion (VFF) and hence more easily compressible with a lesser bandwidth requirement (Chen, et al., 2019; Chen, et al., 2019). Extending on the same concept, OPV2V by Xu *et al*. put forth a method that utilized minimal bandwidth with high accuracy. The technique compared four LiDAR detectors with all three fusion strategies and compared them with a no-fusion scenario. All four methods generated best results for the intermediate fusion case with VoxelNet improving the AP@IoU accuracy from 0.688 with no fusion to 0.906 for intermediate fusion (R (Xu, et al., 2022; Xu, et al., 2022). \n\nBuilding upon the intra-vehicular sensor fusion work, we integrated infrastructure elements into the overall picture. Infrastructure-related sensors, being ever-present facilities, were compared to AVs in any setting. This can be specifically useful at key locations such as intersections, and crosswalks. Xu *et al*. proposed a unified fusion framework termed V2X Vision Transformer. with the infrastructure and vehicle sensors combining intermediate features while encoding and compression the data. On the vehicles side, the V2X-Transformer can then consolidate this information for object detection (Xu, et al., 2022; Xu, et al., 2022). On the dataset aspect, V2V4Real and DAIR-V2X have been reported as two, real-world cooperative perception datasets (Yu, 2022); Runsheng (Xu, et al., 2023). The DAIR-V2X also defines a VIC3D \nobject detection to collaboratively locate and identify based on sensor inputs from both vehicular and infrastructure sensors further demonstrating and improvement of 15 % in AP compared to the single vehicle use case. V2V4Real contributed three benchmarks including 3D detection, tracking and Sim2Real domain adaptation. \n\n## Conventional Gnss And Augmentation Services"}
{"doc866": "Traditional GNSS receivers like those used in standard user smartphones measure the time difference of arrival between a satellite and a mobile device. The signals travel through the ionosphere and atmosphere, causing them to experience a slowdown. Due to errors during this phase, traditional GNSS-only devices normally have accuracies restricted to 2\u20134 m (Jakowski et al., 2005). Conventional GNSS-based receivers may not be reliable enough for use cases that require pinpoint accuracy and high reliability. Several augmentations to the traditional GNSS have been introduced during the past few years including the satellite-based augmentation systems (SBAS), differential GNSS DGNSS) and Real Time Kinematic (RTK) and Precise Point Positioning (PPP) (Demkowicz, 2022). The conventional GNSS systems calculate positioning by estimating the range between the satellite and an observer. Hence, the apparent range is the observed time of signal transmission between the satellite and the receiver as a multiple of the speed of light. Several types of errors affect the time, including satellite position in orbit, clock errors, satellite biases, receiver hardware characteristics, and ionospheric and tropospheric effects. (Karaim, 2018). These effects result in inaccuracies of around 3 - 8 m if only relying on satellite signals. GNSS augmentation services play a crucial role in addressing a large proportion of these inaccuracies by providing within-centimeter location accuracy. This section discusses various types of these services in detail. \n\n## - **Gnss Location Service: Rtk Differential System.**\n\nReal-Time Kinematics (RTK) is a high-performance differential GNSS \ntechnique that provides very accurate positioning in the presence of a base station. RTK utilizes carrier-phase and pseudo-range measurements normally recorded at fixed reference locations known as receivers, with the reference network being fixed and the receivers being nonstationary. The fixed base station sends location error corrections to a moving receiver that can be within a 40 km range. The majority of GNSS receivers get their corrections via an internet-based delivery service via the \"Networked Transport of RTCM via Internet Protocol\" (NTRIP) \nprotocol, satellite, or cellular subscriptions. "}
{"doc867": "The technique employs carrier measurements and a known-location base station to eliminate the primary positioning errors of the rover (GMV, 2011). On its own, Network RTK is known for inaccuracies for vehicular positioning applications including the deterioration in the communication system, lack of coverage and GNSS signal outages (Stephenson, et al., 2012). Walters *et al*. recently studied signal outages within the context of Connected and Autonomous Vehicles (CAV). on the coverage aspect. The work reported only 18 % 4G coverage on UK roads in 2017 whereas in an urban setting the fix loss quality was only 51 % under dense building cover (Walters, 2019). The study found that loss fix quality is not yet sufficient for vehicle tracking even in lightly covered environments when using GNSS RTK-based technologies. The normal accuracy of RTK-based systems remains around 10 cm. \n\n## - **Precise Point Positioning**\n\nWhile the RTK provides corrections for specific locations, Precise Point Positioning (PPP) broadcasts to a larger area with comparatively lower accuracy. This method eliminates or models GNSS-related errors via a single receiver mechanism with corrections transferred via satellites. The solution depends on a network of reference stations that generate GNSS satellite clock and orbit corrections (Bisnath and Gao, 2009). The method combines precise satellite positions and clocks with a dual-frequency GNSS receiver to achieve a centimeter-level accuracy that can be even more accurate in certain post-processing and static modes. A recent study by Du *et al*. evaluated the vulnerabilities of the method; revealing that the most common errors include satellite clock jumps and drifts, bad navigation data uploads, signal power fluctuations, deformed signals, and radio frequency filtration-related errors. "}
{"doc868": "(Du, 2021). In the context of AV, the most common limitation of this method is its inability to account for atmospheric calculations in its corrections. While it is globally accessible, even in remote areas, the method may have a longer initialization time, often exceeding 20\u201330 min, which can make it unsuitable for AV applications (Rizos, et al., \n2012). \n\n## - **Gnss Location Based Ssr Services.**\n\nTo mitigate the weaknesses of both RTK and PPP-based systems, one proposed technique is to combine the RTK accuracy and quick initialization times with the larger broadcast technique of PPP. The method requires a base station every 150 km that collects GNSS data to calculate the correction models of both satellites and the atmosphere. A denser reference network is necessary for PPP due to the localized nature of atmospheric corrections. Subscribers receive the corrections through cellular, satellite, or telecommunication services. Generally, a combination of these services performs well to cover a range of use cases from dense, urban positioning to remote rural areas. The correction model utilizes a message format called Space State Representation (SRR). Recently, SSR/PPP RTK systems have been reported in the context of smartphone positioning, providing Centimeter Level Augmentation Service (CLAS) (Asari et al., 2017; Darugna, et al., 2019; Asari et al., 2020). This approach is expected to bring centimeter-level accuracy to the positioning of VRUs in AV use cases. Table 3 describes the characteristics of various GNSS augmentation services in terms of initialization time, position accuracy, coverage, bandwidth requirement and infrastructure density. Fig. 8 presents a comparison of various communication mediums used to broadcast position error corrections to various user types ranging from high-density urban settings to remote rural areas. Table 4 provides a consolidated comparison of strengths and weaknesses of various sensor types along with potential sensor fusion possibilities. "}
{"doc869": "## Inertial Navigation And Cellular Positioning\n\nDespite significant improvements in satellite-driven positioning systems, the domain still presents challenges in the AV domain within enclosed spaces such as tunnels, forest cover or high-density urban areas. This makes any GNSS-based services have poor or no coverage in such areas. Several non-GPS methods are reported in the literature to provide positioning information in areas with poor GNSS reception including local Wi-Fi networks, Inertial Navigation Systems (INS), \nCellular Positioning, Bluetooth to sensors and HD maps. Several approaches have been reported in the literature on indoor or GPS-denied positioning use cases including WLAN-based RTK-GPS (Dinh-Van, 2017; Musha and Fujii, 2017), Visible Light Communication (VLC) (Kuo, et al., 2014; Yasir et al., 2014; Xu, 2015), RFID (Bekkali et al., 2007; Ting, 2011; Bai, et al., 2012), Bluetooth (Bekkelien et al., 2012; Jianyong, 2014; Li et al., 2015), Ultra-Wide Band (UWB) (Gigl, 2007; Garc\u00eda, 2015), Ultrasonic sensing (Yazici et al., 2011; Yucel, 2012), \nZigBee (Zhao, 2008; Liu et al., 2021), IMUs (Hellmers, 2013; Yao, 2017) and computer vision. \n\nVLC uses LED-based lighting sources to provide accurate indoor positioning by modulating data transport via LED sources. The technology is well known for its low power architecture, larger bandwidth support, and secure mode of transport. Despite being very accurate, the technology has its shortcomings including interference issues with other ambient light sources. The technology is reported to have integration challenges with Wi-Fi systems. VLC systems are also known for issues such as atmospheric absorption, shadowing, and beam dispersion. Most importantly, the source and receiver must be within the line of sight which is one of the most prominent shortcomings in the V2X context. "}
{"doc870": "IMUs stand out as one of the most extensively studied non-GNSS \nsensors, owing to their multifaceted localization and navigation capabilities. These abilities stem from the precise measurements of linear accelerations provided by accelerometers and the rotational movements captured by gyroscopes integrated within IMUs. Liu *et al*. proposed an anti-collision system based on a combination of IMU, RTK, and HD Mapbased location calculations for V2P (Qi Liu, Liang, *et al.*, 2021). A large majority of sensor fusion technologies for non-GPS location calculations include positioning calculation based purely on IMUs (Wang, 2016), LiDARs (Eckelmann, 2017); (Wang, et al., 2020a), cameras and HD maps (Toledo-Moreo, 2018); (Xiao, 2019). \n\n| Comparison of various GNSS augmentation services.  GNSS Augmentation RTK RTK-PPP   | PPP   |          |        |\n|------------------------------------------------------------------------------------|-------|----------|--------|\n| Initialization Time (seconds)                                                      | 1     | 60       | 1800   |\n| Post initialization accuracy (cm)                                                  | ~1    | 2\u20138      | 3\u201310   |\n| Coverage                                                                           | Local | Regional | Global |\n| Bandwidth requirement                                                              | High  | Moderate | Low    |\n| Infrastructure Density (km)                                                        | 10    | 100      | 1000   |\n\n![15_image_0.png](15_image_0.png)"}
{"doc871": "LTE-V2X was one of the earliest systems that used radio signal-based mechanisms to improve location accuracy (Kong, 2019); Qi Liu, Song, et al., 2021). Moving forward from LTE-V2X, the advent of 5G NR-V2X is now considered a pivotal enabling technology in connected and autonomous mobility sectors. This has increased the location accuracy of the carrier vehicle from > 1 m in LTE-V2X to 0.1 m while providing subcarrier spacing of up to 240 kHz compared to the limited 15 KHz LTE-V2X with increased reliability of 99.9 % (Bagheri, et al., 2021). NrV2X exploits new positioning methods such as Multicell Round Trip Time (Muti-RTT), Uplink Angle of Arrival (Ul-AoA), and Downlink Angle of Departure (Dl-AoD) to improve the location accuracy (Ghosh, et al., 2019). Qi *et al*. proposed a User-Equipment (UE) based positioning architecture which contained a Terminal Block based on location information from several sources including satellite, sensor, and cellular network information. The Network Block 5G, RTK and RSU assisted data transmission for the positioning terminal. The third Platform Block provided Real-Time Kinematics (RTK), map database and HD mapsbased location compute capability. Finally, the fourth Application Block provided services based on this high-location-accuracy data for various C-V2X-based assisted driving, lane navigation, planning and autonomous navigation tasks. \n\n## Av Behavioral Planning For Vru Identification And Tracking\n\nIn Fig. 9 we have proposed an end-to-end AV pipeline with the integration of the infrastructure and onboard hardware units that combine the localization and motion trajectories of both vehicular and VRU based sensors. The model predicts the future path and motion behavior of the AV based on both the visible road users and NLOS based sensors. The VRUs contribute to a single, unified occupancy grid to generate a consolidated understanding of each of the road users. The occupancy grid draws an object's structural and positional information from both the V2X-connected vehicles and the VRUs. The location and orientation from the vehicular viewpoint generate an area that suffers from information blind spots, particularly for smaller-sized VRUs such as pedestrians. In a standard urban environment, a large proportion of VRUs is likely to be occluded behind fences, poles, or any other road infrastructure creating blind spots. At traffic intersections, RSU-based sensors can minimize a large proportion of such blind spots, but the use of infrastructure-based sensors cannot be made prevalent due to the difficulty and costs involved. To address the shortcoming of both vehicle and infrastructure-based sensors, VRU-based sensors aim to fill the positional awareness gap of VRUs. As of the current state of the art, provisioning of advanced depth and image-based techniques onboard VRUs does not seem possible due to the disproportionate sizes of these sensors. The smartphone technology however has incorporated many sensors that provide sufficient accuracy in terms of positioning, speed, and orientation of individuals. The most common type of phone-integrated sensors/technologies are GNSS/RTK and IMU such as accelerometers, gyros, and magnetometers. GNSS may still struggle to provide accurate positioning specifically in areas where the sky view is limited; however, IMU-based inertial navigation may still provide methods to compensate for the lack of GNSS-based positioning. "}
{"doc872": "- Identifying VRU distance and boundaries (Vehicle/Infrastructuremounted) \nSemantic segmentation is a deep learning domain that is extensively investigated in computer vision for drivable space and object segmentation. However, the technique on its own suffers substantially from the lack of depth understanding of conventional cameras in cases where, for instance, the pavement matches in color and visual appearance of the road. This shortcoming is often addressed by introducing LiDAR coordinates and combining pixel-level depth by superimposing extrinsically calibrated LiDAR scans with segmented object boundaries (Wang et al., 2017; Wang, 2020c; Wen and Jo, 2021). This also facilitates the identification of smaller objects such as pedestrians and cyclists that are difficult to be identified with standard 4G radar signatures (Kim et al., 2019). The integration of 4G mmWave automotive radars plays a crucial role in collision avoidance at shorter ranges where cross-traffic and onpavement pedestrians' trajectories can be calculated to estimate collision probabilities. Radars are also frequently reported in cases where even smaller-sized VRUs are identified by combining scan returns with vision information (Lekic and Babic, 2019; Meyer and Kuschk, 2019; Azizi, 2020; Sengupta, 2020; Bai, 2021; Dong, 2021). \n\nDifferentiating pedestrians within tight clusters at places such as signaled crossings is one challenge where understanding each, separate road user regardless of occlusion is crucial for tracking. On the vision side, this is addressed by instance segmentation which allows each pedestrian or cyclist to be accurately identified. However, most deep learning instance segmentation methods suffer from the high computational workload and hence are deemed unsuitable for AV/V2X applications processing of several, partially occluded VRUs. Recent reporting in the domain of real-time instance segmentation has been recently reported. Dbolya *et al*. have reported on a two-stage object segmentation method that utilizes a dictionary of non-prototype masks over an entire image and then predicts a set of linear combination coefficients for each instance (pedestrian or cyclists in this case) (Bolya, 2019; Bolya, 2020). Similar single-stage segmentation methods have also been reported for video and image segmentation in domains including car parts segmentation (Cao, 2020; Yusuf et al., 2022). \n\n## - Tracking Multiple Vrus And Re-Identifying"}
{"doc873": "Multiple Object Tracking (MOT) is a computer vision technique that analyzes image sequences to establish object motion over connected sequences. After VRU segmentation or detection, tracking is the next stage in the understanding of VRU behavior. Deep-SORT is the most reported method in the tracking domain which was initially reported for vehicle tracking but was then further extended to track other dynamic objects (Hou et al., 2019). The method which is primarily based on a Kalman Filtering and Hungarian algorithm, however, suffers from a significantly high number of false detections and lower accuracy in clustered/occluded objects. Recently, other more efficient tracking mechanisms are reported including Single Shot Multi-Object Tracking \n(SMOT) and TracTrac (Heyman, 2019; Li, et al., 2020). \n\n## Table 4\n\n| Role of various sensor types with reported strengths and weaknesses in various combinations.  Pros Cons Potential solution (s) Distance   | Speed                                                                                                      | Visibility                                                                     | Classification & tracking                                                          |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n|-------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|\n| Radar                                                                                                                                     | Low visibility                                                                                             | False detections in                                                            | The fusing of radar and LiDAR point                                                | (Kuo et al., 2017); (Liu,  2017); (Zakuan, 2017); (  Maruta, et al., 2021)                                                                       | (Hoang, 2017); (  Yadav and Szpytko,  2017); (P\u00b4erez, 2018) | (Lee, et al., 2017); (Gao,                                                                                     | (Hyun et al., 2016); (Avdogdu et al., 2018);                                             |\n| 2021); (Sheeny, et al., 2021)                                                                                                             | (Kawanishi, et al., 2019); (Azizi, 2020); (  Toker and Alsweiss, 2020)                                     |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| operation                                                                                                                                 | clustered groups                                                                                           | clouds for more robust VRU cluster  identification                             |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Resilient to                                                                                                                              | VRU classification                                                                                         |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| weather                                                                                                                                   | inaccuracy due to                                                                                          |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| conditions                                                                                                                                | smaller sizes                                                                                              |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Camera                                                                                                                                    | Accurate object                                                                                            | Lack of accurate depth                                                         |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| identification                                                                                                                            | perception                                                                                                 | Computer vision-based segmentation,                                            | (Adi and Widodo, 2017); (                                                          |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| detection and tracking of VRUs.                                                                                                           | Salman et al., 2017); (  Dandil and \u00c7evik, k.k.,  2019); (Zaarane, 2020)                                   | (Wicaksono and                                                                 | (Han and Song, 2016); (  Alluhaidan and Abdel-Qader,  2018); (Yi et al., 2019)     | (Han and Song, 2016); (Wagner, et al.,  2016); (Alluhaidan and Abdel-Qader,  2018); (Chebli and Khalifa, 2018); (Tang,  2018); (Yi et al., 2019) |                                                             |                                                                                                                |                                                                                          |\n| Setiyono, 2017); (El  Bouziady, 2018); (  Tang, 2018)                                                                                     |                                                                                                            |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Poor low visibility  operation                                                                                                            |                                                                                                            |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| LiDAR                                                                                                                                     | Accurate  distance  measurement                                                                            | Difficult object                                                               | Integration with cameras to improve  long-to-medium range VRU                      | (Kwon, 2017)                                                                                                                                     | (Dayangac, 2016); (  Postica et al., 2016); (  Zhang, 2020) | (J. (Wu, 2020c); (Vargas  Rivero, et al., 2020); (  Sheeny, et al., 2021); (Lee,  2022); (Roriz, et al., 2022) | (Toulminet, 2006); (Yoshioka, et al., 2018);  (Feng, 2019); (Ye, et al., 2020); (Quenzel |\n| 17                                                                                                                                        | classification                                                                                             | recognition.                                                                   | and Behnke, 2021); (Wen and Jo, 2021); (  Wu, et al., 2021); (Roriz, et al., 2022) |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Compute-expensive  data                                                                                                                   |                                                                                                            |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Better object                                                                                                                             | Integration with radars to improve  false radar detection and improved                                     |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| classification                                                                                                                            | Sparse dataset                                                                                             | collision avoidance                                                            |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Radar                                                                                                                                           | Accurate                                                                                                   | Computational                                                                  | Development of a unified occupancy                                                 |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| overhead                                                                                                                                  | grid containing person-level  identification and tracking  information shared over the V2X  network        | (Ren, 2019); L. (Wang,                                                         |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| et al., 2021)                                                                                                                             | 2020); (Najman and  Zem\u02c7c\u00edk, 2020)                                                                         |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| (Dong, 2021); (Long,                                                                                                                      | (Lekic and Babic, 2019); Yi,  Zhang and Peng, 2019; Z. (  Liu, 2021); (Liu and Song,  2021) ; (Liu, 2021)) | (Bi, et al., 2017); (Palffy et al., 2019); (Gao,  2021); (Nabati and Qi, 2021) |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| Camera                                                                                                                                           | identification                                                                                             |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |\n| LiDAR  Fusion                                                                                                                             | Weather  resilience  Long-range  object detection                                                          |                                                                                |                                                                                    |                                                                                                                                                  |                                                             |                                                                                                                |                                                                                          |"}
{"doc874": "![17_image_0.png](17_image_0.png)\n\nTracking VRUs via vehicle-based sensors can only provide VRU\nmotion information for individuals that are not occluded. NLOS VRUs present the highest level of challenge to an AV as many such may be hidden behind parked cars or other visual obstructions. The sudden appearance of such a VRU may leave less time for the AV perception system to prevent a collision. Inertial navigation technologies on VRU smartphones provide additional location improvement in the absence of reliable GPS reception ( Hellmers, 2013 ), ( Yao, 2017 ). Real-time relay of this information to the vehicles in the vicinity provides the most critical information to prevent collisions. In addition to the position, speed estimation also holds importance in the accurate estimation of the collision parameter of the VRU. Speed estimation of pedestrians is reported under the temporal prediction domain reported by the application of recurrent neural networks (RNN) methodologies such as the Hidden Markov Models (HMM) ( Tong, 2019 ) and Long Short-Term Memory (LSTM) networks ( Azizi, 2020 ). The technique is also wellreported in predicting personnel trajectories in covered areas such as buildings and caves and is known to provide up to centimeter-level accuracy. However, using inbuilt smartphone IMU, the accuracy of dead reckoning for V2P collision avoidance is an area that is yet to be properly investigated. Moreover, due to the vibration-based nature of deadreckoning systems, they are reported to work well for pedestrians. Inertial navigation for cyclists on it's not been commonly reported, and most systems integrate GPS with inertial navigation to improve GPS-\nonly positioning ( Shen, 2020 ).\n\nThe ultimate integration of vehicle and infrastructure-based sensor information consolidates on an occupancy grid which is essentially a cell-based grid array containing the location of each dynamic object. On a temporal scale, it is this 2D/3D representation of AV space that is used to train a machine learning model to facilitate and predict the future path of each of the dynamic objects in the Path Planning stage. The challenge at present is to facilitate the technologies that could make the VRU data available in real time to the AVs in the immediate vicinity. With the availability of a VRU's location and orientation in a vicinity can then be incorporated with the trajectory prediction logic onboard the RU or the vehicles. A robust behavior prediction algorithm on such an architecture will add an additional protective layer for the VRUs."}
{"doc875": "## Conclusion\n\nThe design of AV platforms is rapidly evolving to incorporate advanced sensors and onboard computer hardware with advanced maps and wayfinding capabilities that maximize safety for VRUs. The communication paradigm's efficiency is critical to ensure real-time information sharing among various road users. Future AV development may include sensor costs and power consumption requirements as crucial factors while increasing the range and reducing the form factor. Additionally, advancements in deep learning principles are improving precision and robustness against noisy data, making it possible to identify and track a larger number of dynamic, smaller-sized objects.\n\nOne direction in this field is the development of advanced sensors that can provide a more comprehensive set of capabilities to act as a safety layer for VRUs."}
{"doc876": "Another direction is the integration of advanced communication paradigms that can efficiently share the status of various road users in real-time. This will create an information-sharing network that can maximize the safety of all road users, including VRUs. The development of more advanced and efficient V2X communication protocols and sensors, such as C-V2X, will be essential for enhancing the safety of VRUs. The integration of LiDARs, radars, and cameras for VRU identification and depth perception will also play a vital role in this regard. In this context, the advent of centimeter-level reception using PPP-RTK, \nand better coverage of cellular networks are also likely to contribute to the GPS/GNSS-based coverage even in denser/shadowed areas. \n\nFrom the AV sensor point of view, there is an increasingly sophisticated set of algorithms for the behavioral assessment of VRUs. One potential extension to the prediction of VRU trajectories can be investigated towards the integration of temporal deep-learning methodologies such as HMM, LSTM, 3D-CNN or GRUs. 3D CNN is well reported in the literature for their effectiveness in the prediction of vehicular and pedestrian trajectories with applications ranging from video scene understanding to dead-reckoning systems in the IMU \ndomain to track personnel in zero-GPS environments. LSTM due to its ability to temporally contextualize the learning process to remember historic movement patterns may be a potential candidate methodology for situations such as remembering the reappearance of a cyclist being occluded behind a bus to be reappearing on the road again. \n\nAs part of this review, we have also proposed an end-to-end AV \nmotion controller architecture that is driven by a temporal deep-neural network that incorporates both visible and NLOS road users. Our ongoing aim is to develop this as a real-world use case and validate it on public roads. To provide concluding remarks on this work, we believe a robust solution for VRU safety can be achieved through a combination of AV technologies, and robust data exchange mechanisms between VRUs via advanced communication technologies, and the use of more reliable positional algorithms. "}
{"doc877": "Ansari, K. (2018) 'Cloud Computing on Cooperative Cars (C4S): An Architecture to Support Navigation-as-a-Service', in 2018 IEEE 11th International Conference on Cloud Computing (CLOUD), pp. 794\u2013801. Available at: https://doi.org/10.1109/ \nCLOUD.2018.00108. \n\nArumugam, S., et al., 2022. A comprehensive review on automotive antennas for short range radar communications. Wirel. Pers. Commun. 1\u201328. \n\nAsari, K., Saito, M. and Amitani, H. (2017) 'SSR assist for smartphones with PPP-RTK \nprocessing', in Proceedings of the 30th International Technical Meeting of the Satellite Division of The Institute of Navigation (ION GNSS+ 2017), pp. 130\u2013138. \nAsari, K., Kubo, Y., Sugimoto, S., 2020. Design of GNSS PPP-RTK assistance system and its algorithms for 5G mobile networks. Transactions of the Institute of Systems, Control and Information Engineers 33 (1), 31\u201337. "}
{"doc878": "Chen, Y., et al., 2021. Radio sensing using 5G signals: concepts, state of the art, and challenges. IEEE Internet Things J. 9 (2), 1037\u20131052. \n\nChen, Q. et al. (2019) 'Cooper: Cooperative perception for connected autonomous vehicles based on 3d point clouds', in 39th International Conference on Distributed Computing Systems (ICDCS). Available at: https://ieeexplore.ieee.org/abstract/ document/8885377/ (Accessed: 27 September 2023). \n\nChen, Q. et al. (2019) 'F-cooper: Feature based cooperative perception for autonomous vehicle edge computing system using 3D point clouds', dl.acm.orgQ Chen, X Ma, S \nTang, J Guo, Q Yang, S FuProceedings of the 4th ACM/IEEE Symposium on Edge Computing, 2019\u2022dl.acm.org, pp. 88\u2013100. Available at: https://doi.org/10.1145/ \n3318216.3363300. "}
{"doc879": "Lekic, V., Babic, Z., 2019. Automotive radar and camera fusion using generative adversarial networks. Comput. Vis. Image Underst. 184, 1\u20138. \n\nLekidis, A., Bouali, F., 2021. C-V2X network slicing framework for 5G-enabled vehicle platooning applications. in 2021 IEEE 93rd Vehicular Technology Conference \n(VTC2021-Spring) IEEE 1\u20137. \n\nLi, G., et al., 2019. Novel 4D 79 GHz Radar Concept for Object Detection and Active Safety Applications. In: GeMiC 2019\u20132019 German Microwave Conference. Institute of Electrical and Electronics Engineers Inc., pp. 87\u201390 Li, P., Chen, X. and Shen, S. (2019) 'Stereo r-cnn based 3d object detection for autonomous driving', in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7644\u20137652. "}
{"doc880": "Machardy, Z., et al., 2018. V2X access technologies: Regulation, research, and remaining challenges. IEEE Commun. Surv. Tutorials 20 (3), 1858\u20131877. https://doi.org/ \n10.1109/COMST.2018.2808444. \n\nMafakheri, B., et al., 2021. Optimizations for hardware-in-the-loop-based v2x validation platforms. in 2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring) \nIEEE 1\u20137. \n\nMalik, R.Q., et al., 2020. An overview on V2P communication system: Architecture and application. In: In 2020 3rd International Conference on Engineering Technology and Its Applications, IICETA 2020. Institute of Electrical and Electronics Engineers Inc., pp. 174\u2013178. https://doi.org/10.1109/IICETA50496.2020.9318863 Mansouri, A., Martinez, V. and H\u00a8arri, J. (2019) 'A First Investigation of Congestion Control for LTE-V2X Mode 4', in 2019 15th Annual Conference on Wireless Ondemand Network Systems and Services (WONS), pp. 56\u201363. Available at: https:// \ndoi.org/10.23919/WONS.2019.8795500. "}
{"doc881": "In: In 2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - \nProceedings. Institute of Electrical and Electronics Engineers Inc., pp. 1\u20137. https:// \ndoi.org/10.1109/SSCI.2017.8285398 Musha, H. and Fujii, M. (2017) 'A study on indoor positioning based on RTK-GPS', in 2017 IEEE 6th Global Conference on Consumer Electronics (GCCE). IEEE, pp. 1\u20132. \n\nNabati, R. and Qi, H. (2021) 'Centerfusion: Center-based radar and camera fusion for 3d object detection', in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 1527\u20131536. \n\nNaiden, A. et al. (2019) 'Shift r-cnn: Deep monocular 3d object detection with closedform geometric constraints', in 2019 IEEE International Conference on Image Processing (ICIP). IEEE, pp. 61\u201365. "}
